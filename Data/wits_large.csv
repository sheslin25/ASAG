,Unnamed: 0,Unnamed: 0.1,ID,Response,Grade,Question
0,0,0,5ac95126c93bab762f619ae6d9e0457a3ae69e32d351c6f444adf2fed30efe3915f7f9845b1ec549d2f270b573f92967241b205877e7a669570b3a332b14617a,"There is a possibility that the height of the BST has become too large from all the inserts that its experienced over the years. Even though searching or making changes to a binary search tree is on average a lot faster than doing the same on other data structures, when the height of a tree becomes too large it can become longer to traverse and will give us something closer to linear time complexity. Although the tree becoming larger is inevitable, we may make traversing it easier by converting it into an AVL Tree. This change will cause the tree to become less one-sided by changing the position of nodes, however, the order will remain intact and we will gain the lower height and higher speeds we are looking for.",3.0,0
1,1,1,502fef2d6fe9da5464e8c9384e9e17ec9e027605731f937c9c268939dfba42b423927e1ae32d93e126c685489559ff30ae83edb07a6c11513af9f28236779e80,the memory allocated is full.,0.0,0
2,2,2,90a8f27cfb71d61b9c73a7a8ab33730e3ebc85bfa97c54d9b613ce87b305b9e1aa432bcfbae1c2c5d2035b82671180a8d7f60a46fa0262145d5fd6b791318ce7,"One possible problem is that the system is not deleting students that graduate/leave, and hence the tree keeps growing and growing with each new student, cause a noticeable slowdown in search times due to the increase in size of the tree, as the newer students will continuously be added lower and lower in the tree, requiring greater traversal of the tree through nodes of irrelevant/old nodes. A simple fix would be to update the system to automatically delete any students that leave or graduate, keeping the tree at a somewhat consistent size throughout 10 years. ",0.0,0
3,3,3,158bc4a6a09d1d1f60a3174579dd63b17d40ca380bf126e52a49b005e6d33ba7bdbb0d4d003014825659fe0bdbb49f2fd5e45256e7b5b723af7ad889e792a934,"the system in 10 years will be slow because the number the students that have been in wits has increased a lot over that 10 years. what is causing the system to be slow is that it wont be doing amount of linear work
in order to improve the system an organised data tree ",0.0,0
4,4,4,3068685c76e4b2c329c64b4a981abf59ea0591abc5a7b11e62ce43c420b142b81f90f5e9d316d436b64235d5ad493fb04d7af76ae8a7eac84bd371103293e146,"The BST is becoming degenerate, making the lookup time complexity closer to O(n) instead of O(log n). This could be corrected by using an AVL tree instead. This will balance the tree as it grows to keep the tree's height as small as possible, therefore increasing the lookup speeds.",4.0,0
5,5,5,c1f6abfd4fc5318b969d8b42d7f10e1364425c616a8b69c8f8594b69d2c7a7743a83790314faf11cc3b382f3287fb00f531687f09a9146a00ce2dbe39062eeff,The issue is that the system still holds the records for students who have graduated meaning that there are student numbers in the BST that are not getting searched. These students not getting search are at the top of the BST and the ones getting searched are at the bottom. To fix this issue the university should delete student numbers from the BST that have graduated.,0.0,0
6,6,6,afeeaae30229bbf9032ee9948e95a3a98860a874d1b1d0d67ee088b120bc22e9fb34f7eeb7b1df4260a0f1a548b9e0b11d627eaa2a17433f88a21e97dee9550e,yes,0.0,0
7,7,7,4bccbfcaa9439271fb4e221590e1fd6768f9a6170a62193e2aa38f727ca7e838985ca00984f7b4a782149961c288a265aac8163c38e74ff4f6279a0f9baaec5e,"A binary search tree simply means that the value(right)>value(parent)>value(left).  This means that while the access time is at best O(log(n)), as the tree gets more and more unbalanced the access time tends to the worst case scenario O(n) ie. linear time.  This is what is happening with the student database, as every single year of students is going to have a larger number than the ones from the year before it, so the tree is becoming more and more right heavy as the years pass. As more and more students get added, the time is increasing from something logarithmic to something linear, which is far less efficient.

A solution would be to switch data types entirely for the student database, as BSTs by design are going to do this, since the numbers are not random - they are increasing every year.

An AVL tree would be ideal, as the worst case scenario would no longer be possible. If the tree is becoming too right heavy, it will rotate till the issue is fixed. This means that access time will be O(log(n)) and no longer tend to O(n) as was happening before.",5.0,0
8,8,8,0210a9d3772d4f5814d5d585f47b6503d720f89ae8ca72b5fb7136f3da85dccbdba73ac11df998e73774b6321c99446733c7c479dc009a4e0dc92678413ef102,"It may be that the input size increased made the logarithm became slower . To fix it we need to implement the constant algorithm ,since it does not depend on the input size .",0.0,0
9,9,9,6a7a49da689922560451287b4e285dafdb4a0bfd283c9d3d5a6941f50de9e8434c4baab959d6ac95be4270bc3e3b12632437fec1cc1ffa0e88747c0a4bcc97e6,"The system may have slowed down as the increase in students leads to an increase in student records, many of the numbers may be allocated at the lower points or the leaves of the BST's which would mean that the data will be accessed in linear time instead of logarithmic time, and this causes the system to get slower as more students join Wits. Using AVL trees could help solve this problem as it can help transform BST's into a more balance and a more easily accessible BST. As its easier to access data with a logarithmic height instead of a linear one. AVL trees help ensure that the BST has a logarithmic height.",4.0,0
10,10,10,a69deeb1d09b2c2f2efacf2adabcd40f91cbdaa6d8a94b958b4f80eb19e04ba4658d33a6b07d41e2293e3dc7c648d0c9d4ec03fdc6df749e7a11d1c6ae138068,this is a degenrate tree (which happens over 10 years) and makes the bst tree slow. A correction would be to use an avl tree because it makes the tree undegenerate and fast in terms of searching time.,3.0,0
11,11,11,a130bfe9418c91d178f590031c0c9939b5fca90db77973d7f6178ded40014a7172640da790c28b96fd7fb6c80913844b332b017840744966e0e7f4da01d28945,"The problem is probably that as the years pass, the students getting added to the tree are largely people born in later years than students already in the system. Since ID numbers start with one's year of birth, this means that the vast majority of the students are being added in one subtree - to the right of the students born in the very early 2000s and to the left of the students born in the twentieth century. As the years go by, this issue compounds as additions are being weighted further and further within this subtree and predominantly on its right. The far right side of this subtree of the binary search tree starts to make up most of the tree, making it extremely badly structured for searches. The tree approaches linear height as time passes, making the search time approach O(n).

To correct this issue we should apply the AVL condition that the heights of any node's left and right subtrees can differ by at most one. Thus the height will always be logarithmic, making the search time O(log(n)). The necessity of doing rotations constantly when adding students to the system will increase the time needed to add them, however, not by that much and given how much it will improve the search time, it is worth it.",5.0,0
12,12,12,fa243626fbe26ef57e9cb51b64e34cda34860d25833be057b8aacb2413654723774f7590965ed807a0415dd0e925f4717e86fc15d11f310737f703eab68fbabd,"The worst case height of a BST is h=n-1,where n is the number of nodes but ID numbers in this case and over 10 years, the number of students is increasing meaning an increase in the number of nodes, also increasing the height of the tree. An increase in height leads to a decreased speed in the system. we can correct this by decreasing the height of the tree by making it a perfect tree. Decreasing the height will result in a best case height of BST; h = log(n+1)-1, and hence speed increases again.",0.0,0
13,13,13,613c2ba250835f60dd8d6152221f9e06173d3c4bcc77f7b6c456f0bb9860c2fa0917972ea9f5067f4fe1f88b30007ef0f5e48ef265e8c878004f67d405750a94,"the issue would be that as the amount of students increase so to will the amount of insertions, therefore causing the tree to be one sided and unordered. By utilising a balanced tree structure or an AVL tree structure it will help to avoid this issue as the tree is balanced and searching for the nodes will always be 0(logN)",3.0,0
14,14,14,8052ea5813981ce1b1dc18dcce8d4c10c33b769890ea3f35ecc1dc5a6465b4897efddc1a12c6d7a26b5d0da8ca3c779589f99331e5d2c411636cea22d157833a,"as the number of students increases with time, this means that there will be more students, so as the Binary search tree code will be slow.we can solve this b balancing the tree or by using AVL tree instead of BST even if it takes more space it consumes ",1.0,0
15,15,15,e9f55a461571038daf39646f8c350339a639982fda3a68a7de2c663bf3b55fcfe5c2c1470245e6cd83dc29b1d2c16e474b9b4bcd8ac2d4eb9b9e2eef6125ba6e,The system became slow as the tree is unbalanced and is known as a degenerate tree most new users have ID numbers from the 2000 on wards and these all get inserted to the left of the tree ,3.0,0
16,16,16,ee3d89b0d1151de34e3cf3043fc2b6592a400e8ce8a1d14d3b5e77f1fc57f3bb24de4a9c4426effca79ea565b502539dcf46a1f1d27d52e0d1e79029ce2f8aab,"Since a binary search tree is being used, once there are too many ID numbers added to the tree, the tree maybe become unbalanced. This is because of the fact that most new ID numbers are going to be from the 2000's onwards, beginning with 00, 01, 02 ect)  and will all get inserted on the left on the tree. As a result it would take much longer to search the tree and to insert/delete nodes. It would take longer to do this since the tree would take longer to traverse through. 

This could be corrected by rebalancing the tree and making the tree an avl tree. To do this we could rotate the subtrees recursively while maintaining the AVL properties until the tree is balanced. Once we convert the tree to an AVL tree it will remain balanced since all AVL trees must be balanced trees.",5.0,0
17,17,18,8d5ceb816f2781032ee62700b4d8e0c49eadb89db294dfede287a0eaeacf6b8016c744cd4dfe71d03f0f6caf776956147ca479b489362862217860010178b882,The number of students might have increased. The computer that Wits is using might be slower or have became slower when the time goes on.,0.0,0
18,18,19,c0046d9efb5ac101c14867d2717db3e08d6ef4577447593b970d77add7785e77e104d1c4da7ccd26febfc9dec54c612f8ab1164fc3489c3f123475dd1c711486,"the binary search tree may have been an optimal storage strategy initially, but as time passed and the volume of student records to keep track of increased and in turn the tree may have become heavily degenerate and since the worst case the search time of a bst is O(h) therefore searching for records subsequently get slower as the number of operations required to attain a particular record on a heavily degenerate or unbalanced tree increase drastically due to the obscured height

and to correct this issue and keep the system running fast and to keep accessing of records quick we can implement a balanced tree data structure to store the records, thus keeping the height of the tree log(n) and the search complexity will always be O(logn)",3.0,0
19,19,20,2a73fae534f6399be599dee1f1de2adaec9431f39943abeccc1ca0cc827521f43446d764a73ff779a0d169bd025aa1ff69232dd0892e2b573939bb6ed6281bd6,"The system is getting slow because the BST does not have a balance condition so as the years get larger, the IDs get larger as well, the tree becomes almost degenerate and imbalanced. We can correct this by using an AVL tree which has a balance condition and ensures that our tree always has a logarithmic height instead of a linear height.",4.0,0
20,20,21,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"Over time, the system tree has become somewhat a degenerate tree. This makes all operations such as insert update and search on the BST very slow. The system can be improved by using AVL Trees which is basically a Binary Search Tree with extra constraints that keep the tree balanced and ensures that the height of the tree is log(n) at all times. This allows for the BST to be in its optimal state.",3.0,0
21,21,23,412b107ec0ff412753968aa6ffdad40da21fbfd59417aac428d07f6c064389cc24911eb533cf92e901bf7845b76400d7d3831fd1347350b39d220d9c58729d2b,"The larger the number the number of students the more memory will be used, if the number of students becomes larger it will make the system slow and takes time to search for a student's record. i would suggest to use the vector as their insertions and deletion are usually faster and they are easy to sort but would be slow at searching for the ID compared to the BST. but i think the vector will win because the cache perfomance is so good but trees will win if you have large amount of data.the balanced trees will work fine and will help in the perfomance since cache perfomance is so good",0.0,0
22,22,24,92a2ed8f4716bed3b0e0c50f4d71ca4d4c6f96e622febc9b471f947d10b8500c23531ab4582c0648a7ceef71efcbb7100102c2a6bd33328ed40abb07652829ad,"The problem is that there are more records of students than 10 years so searching for a student will take longer as we would traverse to more student records.

 A solution to this problem is to make the BST a complete binary tree which would decrease the amount of time taken to search for a student record. The complexity will be O(logn).",0.0,0
23,23,25,092586b17aeb228a8396915c438a564c216c3df48ac6ded66b121dcea5684d3dbe0caab83fcadb656d3a0a26a4c4e1546317909dd36270918915c4447ba4370c,"1-the number of items have increased 

to correct this we can use contiguous implementation ",0.0,0
24,24,26,8498970fc897a847cb08416ff377f1fef48bec60ecb47ecc86ba0d40abc666899852250e00e887a707bf5de87564f205ddbe85abfd397367947073bde3e3789d,"It is possible that the Binary Search Tree isn't balanced and as the tree grows as you insert a new student, the height of the tree increases unnecessarily, making it slow as it has to traverse through some extra long paths. 

A way to fix this, would be ensuring all Binary Search Trees are AVL Trees to ensure that the BST is balanced and that it has a reasonable height, by undergoing various rotations to balance the tree in general, when inserting and as well as when deleting nodes (the student records)",3.0,0
25,25,27,4541bddfe14df82661aaba793d25bb038432ba934014876821269e81b4029af8b6064a54828f0509d14ee3f303c32ee014b7221977ad133bace3b01a694e694c,Our data structure doestnt have enough memory to capture all the data its been givem,0.0,0
26,26,29,a51b1137941b4a2c9fd6d66da41292b1d5da2b0315b3c4cbaa7f507deed0fbfe1d51f7372760847ad411ee0d78ff9de354c3d1a9bb27433af4b5f7b732027fa9,"Lopsided BST with a height = O(n).

If student numbers are issued in a numerically ascending order the BST grows only in one direction (right), causing an unbalanced BST. 

An AVL tree might be used instead of a regular BST.",4.0,0
27,27,30,042f0747487a4bd00158870bdd61aa0642e3092908b59c86040adb32b033044415ba779e2f72dddd4b2fd903b8027b6d8a9bbb87005066d4c2dd8814e02e0e21,"Overtime, as more and more student enroll in Wits, more and more insertions occur to the BST which leads to it being unbalanced. The new student numbers are inserted in the most extreme linear way, perhaps in the left most side of the tree or the right most side of the tree,  thus degenerating the binary search tree. 

The best way to correct this is by using a AVL tree tree which with every insertion and deletion, the tree will always retain its property of being balanced. ",3.0,0
28,28,31,55ff8d4f9ee8af9848a55dc4a2a3322adb850c959c61827806d583f4f72e4caf8076da8ae41627b21a0edd1eccee2cd496b303fbcb256d41e8ba6c3b55c02e66,"This tree isn't self-balancing, and the data is being inserted in an increasing order. This gives out the worst-case performance for an unbalanced tree method is O(n), so adding n elements is O(n^2).",0.0,0
29,29,32,66c130d147af93128f149a1c3cbc0822def0372144aa77769fad8d406e0bf1fdaea5c4080bf967de52230b79e34763f78e3d8c34ddd69955b5c9b8521c52443c,"As more ID numbers are entered most of the new ID numbers would be in the 2000. Although your information is ordered you could have one branch becoming extremely long. This would result in the tree becoming unbalanced or degenerated as you don't make sure that when you are inserting numbers that the height of the tree stays at the best case scenario. This means that you would end up not getting the best case time complexity within the program as you add more ID numbers to the tree.  An AVL tree or Balanced Binary Search Tree would have solved this problem as it makes sure your height is always best case, i.e O(logn).",5.0,0
30,30,33,174e38c18f0521eafee3b73a0ffb8449a8c5784d547a0843ddac9c9176015fedd2516d8b3d18b017cc9000d2b315ebe1757a54b724f337f3a99202881366a527,"Over the years, the tree will grow mostly on one side, most probably the left as in the current year 2020, the university has students born mostly in the late 90's and early 2000's. This means it has students whose ID numbers start with 9 and 0. Over the next decade more and more students who's ID numbers start with 0 will be added until 2012 the latest, when students with ID numbers starting with 1 will be added. This means that the BST will grow much heavy on the left side and might resemble worst case binary tree. 

This may be corrected by ordering the students not by ID number as a whole but their 

in the year 2030, most of the newly enrolled will be born in the year 2011 and so going forward, most learners' ID numbers will start with the digit 1. ",4.0,0
31,31,34,5221e1f3d933576f202c0725eb1b1536ee1b49681a3fc7d8f1a5f7ce021be47e8c2ad1016a78e47c8f005a4abc05514dc591b463cb92d3c640fd02125cf688e6,"ANSWER:

	* Initially, a BST is generally an efficient way to represent data of student records (string values), however continuously over the ten years (where student numbers increment in number and unless there's a staff member being added - the subsequent student will always have a numerically greater student number) - the tree has become a DEGENERATE (unbalanced) TREE.

	* Become of this unbalanced property, data is now not stored in an inefficient way (it probably will be the case that it's so unbalanced - that it offers no advantage to a Vector or Linked List and so it would be time complexity O(n) ), thus making operations and FUNCTIONS (ESPECIALLY SEARCHING) ON THE BST RELATIVELY VERY SLOW.

	* A way to correct this: Since an AVL (Avelson-Velsky and Landis) Tree has the property of SELF-BALANCING, insertion and deletion of elements will RESHAPE/RESTRUCTURE (at least a sub-portion of) the tree in such a way that the deviation of height between different ""routes"" (traversals to different leaves) are close (i.e. not greater than 1).

	* In summary, using an AVL Tree will correct the problem of the very slow system that uses only a BST since the structure of the BST does not efficiently store data compared to an AVL Tree because it will be so unbalanced that one side will have a height far greater than the other.",4.0,0
32,32,35,bee12730d57033f530e6d3af850b801527bbf28710ff5b08a5e590d280e30c6a0345b61d0e3b24cafaad1628aee3191406710ce83cd7009c586afaf78d031389,"_Assuming the first two digits in a student number are graduation year:_

As the amount of students frows over the years with numerically larger student numbers - the BST will gradually become more of a degenerate tree. This explains why the system starts to get slow as the big O equations (Search, Insertion, Height, Deleletion, etc) start as O(log(n)) for a complete tree and changes to O(n) for a degenerate tree over time.

To improve the system, you could change the variable/student aspect that's compared to something more relevant. However, the better long term solution would be a different data structure -for speed, I'd use an AVL tree because of their balance condition and similarities to a BST. This would result in a similar amount of space used with constant time complexity of O(log2n)",4.0,0
33,33,37,2f496bb2a99de18fa436df0deced0620c47daee5ce37cf49cf6b3200c20eb84e5a9b7a47850d29ff143886bc9932f54f86b6a1101a1d0f70874e22b40b657cec,"It can be caused due to the fact that the binary search tree ends up performing a linear search operation (0(n)). This happens when the tree is skewed; meaning that they may be a consecutive trend in the student's ID number thus creating a stretched-out tree.

to solve this we could convert the binary search tree into an AVL tree ",3.0,0
34,34,38,e5092ab1c7e17d25e5db9dfc9252b8c31679cb1e2b17a0be836efd97ce606988409f994ae92e4e1f795d2d139fe2c46eff4d5f244e605f9f08c46d7129da95d2,"Binary search trees do not have a system in place to regulate the size of the trees branches or balance the tree. As you add records to the BST the tree will become more unbalanced with longer branches becoming more prevalent. This means that the tie complexity of the system goes from O(log(n)) for a balanced tree to O(n) causing the system to slow down when retrieving data. This can be fixed by using an AVL tree instead of a BST. An AVL is a self balancing binary tree, it ensures that the tree is always balanced which keeps the time complexity of the system in its best case time complexity of O(log(n)). This way as you add more student records over the years you avoid developing long paths that the system has to traverse.",4.0,0
35,35,39,a44191cff1258114ca99a354cbcf13b3d3a3dcbbff75ad642f883f0afb3c431e62d034975452796897dce8086c431437065cbc80fc5ae095e71da50b0ce40ae0,Over time the tree becomes unbalanced which makes it slow when searching of adding a node . In order to correct this an AVL tree should be used which will ensure that the tree is always balanced ,3.0,0
36,36,40,b65e52333a31f01a7d7a5dae0ff6fc8ed82b8b5283406f591e8d448f865292ea8162938b0259891df516358cc77c51dca3895b350dbb36cf96d6c23e9b3fa27a,"The system could be slowing down as after ten years the tree has too many nodes since Student records don't get deleted every year when new students are added to the tree. It would also slow down in terms of adding new students since it is an ordered tree so the amount of time to make sure that the new student is in the correct place is O(logn). This system is the best for what is needed as other storage means such as arrays, linked lists and vectors all have a search time of O(n) which is longer that the tree's serach time which is O(logn). In a situation where adding to the database was more important than searching it a linked list should be used as its insert time is O(1) but sadly its search time is slower than that of a binary tree so a binary search tree is the best way to store this data.",0.0,0
37,37,41,7099f15d1fb337686bf427fedb824d4eefc2c359e7374f808226d1191d0f74342e42146c05dfa9cdc17fbdc8dce0a4cb75b417e6eb24978dd57c4773dec73b21,"After 10 years, the amount of student records must have increased a lot and therefore the binary search tree contains a lot of data/nodes causing the amount of time to search for a student record to increase as well causing the system to slow down. This could be corrected by deleting student records that do not attend wits or have graduated and do not return after a certain period of time. This would decrease the number of student records that are not in use and cause the system to be faster.

Time Complexities of a BST:

Best case of a BST:     O(log(n))

Worst case of a BST:     O(n)",0.0,0
38,38,42,d7e19f96a6aba1e381d06c4d14cd8af55d98ac1778548325b5d3026d929df87b2abc3d523dd5623a58ab296187735de8598844f1ea29e935b29ced21ed87e297,"The Tree is ordered by the ID numbers of the students, which consists of their birth years first. This is an issue as it it will result in the tree becoming unbalanced as many students will be placed on one side of the Tree. To fix this, it may be more beneficial to use a different comparison, e.g. Student Numbers.",1.0,0
39,39,44,4c6f807c2ce1ab585dfa9622ceaade81e43b8fe88ba8af5d95eb11efdad75a8b1190eb5c2d48dff34f29ac730bf0895fdaf308c3995dbd7f2103246c342b70a1,The height of the bst could be really big due to the data been inputted into the search tree(e.g most of the data been inputted causes it to be place on the right  ). This could cause the system to be slow.,0.0,0
40,40,45,828a54706b7956f06065af9a928b49958122a77b54a5e0593021ac1ee5bfac90e0bf9488291ceaad9b7538bfadd4796253d8359db184b0bd7f7e1ed456e8f30c,"The system is slowing down due to an increase in the size of the data as students records increase.

This can be corrected by choosing another data structure that is suited to handle large sizes of data efficiently and faster.",0.0,0
41,41,46,5f1f239814321ab1f431320367ad013e94b2f66dc9f45345746644a7c6190c150b15690868f1b18e7468353f42b32ce7d5d9e6673f3e33a12996a386f5985adf,"The problem is that over the years, thousands and thousands of students area added and because the data structure is a BST, there is no way of controlling the height and shape of the tree. And thus, the trees height has gotten massive over the 10 year period. I would change the data structure from a standard BST to an AVL tree, which is a BST with an added condition to control the height of the tree and guarantee the height of the tree remains O(logn) regardless of the amount of students added. ",1.0,0
42,42,47,dc116295695675ce8f8f9dcde7d1d181a1fc34469a4bd2a570b8ca26a7951f6381d662fe47ef41e490d057b64113abc45be11b89047c039c48685692d843ce1d,"The Binary Search Tree is quick with a small amount of data but with large data, systems get slow because the Binary search tree they use, does not balance like an AVL tree which is balanced correctly. With AVL tree, the height difference between the node in the two-level which are contiguous is between 1, 0 or -1. the system tree could look like a degenerate binary tree, in which every node has 1 child and the rest has null and this caused to have the tree's height to be in the worst-case- n-1. As height is greater or in the worst case, it becomes difficult to record, add, compare, and order the student's data.

Therefore, we must try to keep the height to be log (n) which is an AVL tree's height and this will make the system fast with a large amount of data. To correct the system to the AVL tree, we need to convert the system to an AVL tree, not just a binary tree only by implanted algorithm and conditions.",3.0,0
43,43,48,e15ad332a60fd21f9642a607905bc6a0a968e3d65f0ab448161698266492242c990fc890cd09bab4dffa30a30230d6c043c42b0ef218d6e81e40a2206a0638d0,"As the years proceed the number of students in the university increase and this increases the amount of memory used by the BST as the branches expand the time complexity from the root to the new students at the new leaves increases. This can be corrected by using a circular array queue, which uses pointer arithmetic and has the benefits of spatial caching therefore the time complexity to access every student is constant and is maintained as the years progress and new students are added. I",0.0,0
44,44,49,e02b2e6799a632f8edf7a4522f9a996ef61735be79c062229a0e89a8ede6774052ec8736d48de69d3335b6ebe5ac154baf9a59c6f5866c7ad081372900ff0ff8,"The structure of the binary search tree is the reason for the system slowing down. Because the student Id number represent the year the student started their university. With time, all the new id numbers would be added to right side and so this would result in the tree getting a poor shape. And therefore, if there was a good shape previously we would get work done in 0(lgn) time, now that would take 0(n) time. As a result, the system starts slowing down over the years because n keeps on getting larger.",3.0,0
45,45,50,cf96d5be5169d5386c2ce2a3ae914384cd3ff74c0ae41c6fc53cb4ef592a7f9882d33970f1f807fe79c0e961bedb5189d6cfa997817a7684663f34c5e5fffad2,"Since a Binary Search Tree has no balancing property, as students are added - the height 0f the tree will grow in a linear manner (if every node has exactly one child which could occur if each subsequent student added has an ID number that is less than the previous, this creates a degenerate tree with height proportional to its number of nodes resulting in linear search times) or a logarithmic height if in the best case, the tree is a complete binary tree resulting in logarithmic search times. 

However, as more and more students get added, the height if the tree will start to grow faster thus leading to slower search times since the height of the tree is so large. With no property to maintain some sort of balance in the tree, a very inconsistent tree could form with bad search times resulting in the slow operation experienced. 

If Wits wishes to continue using a Binary Search Tree, they could implement the balance condition and create an AVL tree which would ensure that the height of the tree is bounded below a logarithmic time and height. This would also ensure the tree is always balanced and would avoid the problem of every node being a child of the previous(degenerate tree) as stated above and will also ensure the height of the tree does not get unnecessarily large . Reducing the height of the tree and balancing the tree will ensure the tree is no longer slow when searching as not as many nodes will have to be traversed further down, since nodes will be balanced and the height will not be as great as before, thus less comparisons and less time taken.  ",3.0,0
46,46,51,c52fe90555e82813bbf7f31602e97c4095475fbbf85ff26471f0158158110480233228486a71767a61c524c47fe301d427e9bdbb31f3216eb95878f59314ec4c,The problem could be that over the 10 years it became harder and harder for the BST to sort the lists and keep them sorted which then becomes a big problem when elements are constantly being added to the list which is happening due to new students.,0.0,0
47,47,52,8cfb9c3f85d9b6edb1f914f05f74928e81fe7cb4cefb95f1de4efb3fd1ac54a2356179dfe5b33b1cac09455e2960c015d866e1097ed5d7d20fbbdcb0d2aeee6d,"This could be due to the ordering of the nodes in the tree as in the best case the height of the tree is log2(n+1)-1 which results in a time complexity of O(lgn) and the worst case height would be n-1 resulting in a time complexity of O(n), thus slowing down the speed of the system as over time a linear complexity is much slower than that of a logarithmic complexity.

This could be fixed by setting conditions to the ordering of the tree to ensure that the height of the tree is log2(n+1) thus having a logarithmic time complexity and with these new conditions reorder the tree. Basically make it an AVL tree, which is in turn a self-balancing binary search tree.",1.0,0
48,48,53,276b4e11850dbed5adc6f0fd4249cf0b5f1cdc0a0dfd3d76321298301426fddeaa12e60021bdff5fc27802e2537ea3a2e891dc9c51166641bf68a7d7906d00b7,"As time goes we would have to add new students that enroll into the university meaning that the search will take more time as there will be an increase in the number of items stored .

since student records change all the time , a root node now might be a leaf in the coming years so this would also contribute to the system being slow.

system overload could also be a factor",0.0,0
49,49,54,a300869c4f32047b23ac68a02d99d6a69e15fcc6cb6903bc4e640c72bf256b08b631e89f75d7f7263574f4383932390c2f4b98297d3a8bfdd9da2320bf30b053,"As the years go by, this binary tree is going to get bigger and bigger, as binary trees usually have a height of log(n) this means that the search time is in order of O(nlog(n)). Therefore when there is less data to search for, the time to search is relatively fast. However when n starts to get bigger and the tree gets bigger, the time to search gets much longer. This would be in the case that the tree is an AVL tree which it does not appear to be. As it is just a binary search tree, the tree can get very unbalanced and lead to an O(n) time complexity, this would be the worst case scenario for this tree. 

As the system gets slower during the years, you could make an AVL tree of years, i.e. 2020,2021,2022 and so on and have a values with the first student number recorded for that year as one of its children, then you can have a search algorithm which searches for a student number which is in between two years as it will be less than one year but greater than the year before.

This would allow for more trees ie more space complexity but allows for the faster traversal of trees as the data stays relatively small compared to 10 years worth of student numbers.

A different solution is that you could make this binary search tree into an AVL tree, which will allow for a constant O(nlog(n)) time complexity which will make sure that the time is faster than an unbalanced tree. However I would personally go for option 1 as it will allow for faster search times and than an entire tree made up of student numbers.",5.0,0
50,50,55,188f5f32ff22cc30082222ed760e5fe1e0a340d9ae7ecfafe10b384746f7f9c7803d064927e2b5ebaba803119e7d5eafdd11883d383dd0d5a80b8dfe524c593e,"okay so in the beginning we will experience no problem with the time it takes to look up a student because the students in that time (year 2020) will be of the same age group/years that are really close to each other so their ID numbers will not have that much differences so it will form a tree that is almost balanced.

Now from my understanding it will start off as almost balanced so as the years increase students of different age groups will enter the university the the will become one sided (right heavy) .For example it will maybe start with the 1999 group then move to 2000 which go on the left of 99 as 00<99 then when the 2001 group enters then they will be on the right of 00 because 01>00 then as years increase they will keep going on the right so the tree becomes right heavy.Then tree will not be balanced at all.

So the height of the tree also changes from O(logn) to O(n) so which means the searching through the tree will now become slower as O(logn) is faster than O(n).

So this can be corrected by transforming the tree into an AVL tree which transforms the height from O(n) to O(logn) by making sure that the tree is balanced through AVL conditions.So now searching through the tree won't be slow any longer.",5.0,0
51,51,56,17ea794106565b342d0071ecda1b602670f938db088b102cae298b8fa539f99c81604db8696804a94225d5fcb56b3538a2b45e5527c8d0a393e5e2aa5ae7c0be,"The cause of the system slowing down might be due to the structure of the tree becoming degenerate as the number of records grow which would then cause the algorithm to do a O(h) amount of work. A solution might be to implement an AVL tree to ensure that the structure of the tree is always balanced, which would guarantee that the algorithm would do O(log n) amount of work",3.0,0
52,52,57,d0487881fde4213facde4c9cd0143d5802f701e002f130b7eaa6dd04f68f58612ae33c39c89beceae1495437bbe2376be3003369a31f0f2bc6f9e0c5a369707a,"With the addition of new IDs it is possible that in the BST the IDs could begin to be positioned in such a way that it begin to resemble a vector.

(i.e each ID node only linking to one child, particularly possible if the IDs are just increments of each other)

Thus increasing complexity from O(log(n)) to O(n).

To solve this problem we can try to reorganize the BST to AVL standards, this will result in a more balanced tree and complexity will revert to O(log(n)).",1.0,0
53,53,58,07ab043d70e14725f955703ce65a95b6912342e429a6c9a7dec43aacd53b63f2b0d3ebef4da8ffdff01a86c6c296ffe0e21e4d798223854fe6e651460e1d7280,"The BST being a complete tree is not maintained when adding students and so the tree has become a degenerate tree where there are parent nodes with only one child. 

This can be corrected by making the BST an AVL tree using rotations so that the height is not the worst case height for a BST.",3.0,0
54,54,59,73f8ac3de0d9e29b34984491080a2a437e9d07081ef998fb53c2e73bde6a76efa33589c04809db77b67bfaaea71b13e4b7480f42fd75bb56aca6e9a4110b16f7,"As the years go by, the students enrolling in the university will be younger. Eventually, the new students will primarily be those born in  the 2000's. This means that their ID numbers will start with a 00. Their number will therefore be smaller and placed on the left of the BST. Therefore almost all new entries will be placed on the left and almost none on the right. The tree will therefore become unbalanced to the left side. This can be solved by implementing an AVL tree instead. An AVL tree is still a BST, but with the special property that the heights of the children of a node may not differ by more than one. If the property is broken, the tree will be rotated to comply to the property once again and the tree will be balanced. This has the advantage that the height of the tree will always be of the function O(logn) and therefore the search will always be optimized vs the worst case height of a normal BST.",5.0,0
55,55,60,b1a3a9f62a3efb88815155da55fbf2f2fafa14dd37234e9f11b5f00a231a31fde1494bd63f6ac5858aefb97ae2c7130be129cb66d65efd0dfa784ad99b296be3,"Adding more and more student ID numbers will increase the height of the tree and over ten years the height of the tree will become massive. Seeing that this is a BST, there is no condition implemented to balance the tree and keep the height at a reasonable number. Therefore every time a search is done it is done with the worst case height( h=n-1). 

To keep the tree balanced and the height reasonable, an AVL Tree can be used. There will now be a balance condition implemented and the height of the tree will be reasonable and the search function will be guaranteed to be logarithmic(O(Log(n)) in time. Therefore increasing the efficiency of the search for the data.",1.0,0
56,56,61,3b413468f9946530e16c6d2ced91ab45356664eb3ef35b2823043a9391b6766aeb5cd1cde7c7799a9976f4713f096989c7f13a6ea1b6e1be3f9af94b87e0d40a,"As students are added the tree begins to become unbalanced. Students would likely be added to one side of the tree only. This would lead to the runtime of searching and inserting to become closer to O(n) than O(logn), causing the system to slow down dramatically. If an AVL Tree was used instead this problem would be avoided as the tree would be kept balanced by the AVL condition.",3.0,0
57,57,62,e23792b17279f93b3cce4dddca09079f761a6a0f2795c6c3c7434b417d9b72d4e94d0c740b318fb5b6d57338883455b8fe250e5759d4aa78bd8b7bd3bfed6a55,"After 10 years many students would have been added to this system and if this BST has no balance conditions then the new students being entered will probably be younger than the students already in the system, making the BST look very linear to one side. Thus when searching for records the amount of work done could be close to O(n). Instead of an ordinary BST, we could change this system to an AVL tree, this ensures a height of O(log n) at all times making the worst case search time complexity O(log n) which is much faster than O(n). And the average age will be near the top of the tree making the average work even less.",3.0,0
58,58,63,5efe3fbf856ecf3a15a69292118ba94b4935a0dba8b272f0af264465d64a2e654697453d0e3e6e72201dc798f4cd3f27b28fbe0c2032a2a7784e39ed4c150909,"The tree needs to be balanced and the system is going to be doing more work to ensure this (given the accelerated growth) hence the process it takes to balance the tree will take longer. The list has to constantly be in sorted format (based on ID number) but this will still require a lot of work especially when inserting a student into the tree as you have to traverse all elements and move nodes accordingly which has worst time complexity of O(n). If the structure type does not accommodate for it being unsorted then the amount of work done/steps taken will increase and hence take more time. 

The solution to this problem would be to have a search key similar to that of a quick sort to narrow searches and options available thereafter perform another search on the smaller group of values to find the one the user is looking for.",1.0,0
59,59,64,72dd44c1821dd2a2380b55f5907e16bfe4370a758e591d726ccded6a8be12ed056b16e3fc6be17ba264f1643ae18b41b7fe1a5fa76a3d9621150f89706d252d5,"-time taken to compare or access the student record and ordered base on their ID number depends on the number of items compared.

-the time complexity is O(n) since we do each comparison at a time

-over the next ten years more students had to be compared and more space was required hence the system slowed down.

-since the system does a single comparison at a time, we can improve it by making it do multiple comparisons at a time which can be done by removing the data after it has been compared.",0.0,0
60,60,65,5f1f48eaee5ac422a3c6fa6a37eae574e54bf5c31dcf24e0e6dda503da6ac10d5be4b86335df2a703c5cb0a92be355a3535eec42ddde1a798228e8594808928b,"Let us assume that the majority of the students at Wits were born pre-2000. Due to the fact that ID numbers start based off the year one was born, we can see that the majority of the students would have 'large' values due to their ID starting with either a 8 or 9 ( in most cases). Due to this, the majority of the students will be on the right side of the BST tree. However, after 2000, all students will have an ID number starting with 0 (assuming that they were born pre-2010). Thus they will have 'small' values due to their ID. Due to this all the students born from 2000 onward will be on the left hand side of the tree.

As the years progress, there will be more students that will be born post 2000, and less students that are born pre-2000, due to them leaving. This means each year, we are continuously adding students to the left hand side of the tree, whilst simultaneously removing students from the right hand side of the tree. As this continues, the tree becomes more and more degraded and unbalanced as the tree approaches looking like a linked list (in a tree format, all students will only be on the left hand side), thus it will take more time and work to traverse through the height of the tree, and as the search function of a BST is dependent on the height of the tree, the system will slow down.

To fix this we should use an AVL tree instead as it will always guarantee that the amount of work it will take to traverse the height of the tree will be O(logn), and thus the system will always be faster at finding a value compared to a BST.",5.0,0
61,61,66,8278e2d003c29d98e8cfc7117cefa90b7503054f5b50b162eaded6981387fa2f1b8b8f0ae2fa0d58942ac81f9cf7fda1cd474d106727d602bcd9f2d647883b50,"it is constantly receiving new student records as time goes on so it needs to sort the n elements first so this increases the time complexity from O(log(n)) To O(nlog(n)) .
to correct this we need to find a sorting algorithm like(HashTables) that will first sort the elemnets first then use the BST .",0.0,0
62,62,67,fd6a36ea3be7fe00a0626c8ff80a591e0ee46b9eb9f16c4ccfb925e8237975ae584522b908d7f487d3fa4016ee5035673c870e0b6b78ebf935c75fa0905d0961,"The number of nodes on both sides of the BST might increasing which increases the size of the BST, this means the time we take to traverse through the BST will be increased as we have to go even deeper into the BST for both insertions and deletion.

we can use a different method the Quick sort method where we use a good pivot by using the median of 3 method this will eliminate the worst case and the best case but this will ensure we don't have a slow system since that is  the worst case",0.0,0
63,63,68,48452c6af5685c82851988d96add3ed11ed530ba837e28f21c3e92d7b83a44fbe9879abbcb6e1ae0256b1dc9b2ef98a34c294dacae561958335cfe0e83b08e8d,"The cause for the system to slow down is that, the binary search tree is not perfectly balanced (inappropriate memory layout) as more students are registering over the years. This result in more comparisons taking place. 
Therefore, there will be more cache faults performed.

This could be corrected by laying the memory appropriately (perfectly balancing the tree) to reduce the number of cache faults. ",1.0,0
64,64,69,de345146608f48652cf9ec333ad07816bb0cf99089477ca7af207bce7f9f2c81b03f0e317efccc60f220182480d765ee6b6291c08b7723e7e91dd8402a584cdd,"The problem is that the tree becomes unbalanced as the first 2 digits of an ID number represents the year that person was born, as the years go by and the people registering at Wits are born later and later meaning they will always be placed on the right side of the binary search tree as the integer value of the ID will almost always be greater than those who registered before because they were born later, a way to fix this would be to restructure the tree to be based on the ID starting from the 3rd digit. The 3rd and 4th digits of the ID number represents the month someone was born in, so if the root is someone with a birthday roughly in the middle of June, no matter how many people are added to there will always be roughly a 50/50 split on people placed in the left sub tree and people placed in the right sub tree, this maintains the O(nlogn) search times rather than the O(n) search time creates by the list structure caused by including in the first 2 digits of the ID",3.0,0
65,65,70,f03b1f416ca031a8c9d6db448d0d8439f9016edf947b1c8b45411ef2872c68250d908495b49ab16d7b6e23f038f5ac72fb1ec72bfe11a51db67cec76a8643ecb,The problem may be caused by the increase in the height of the tree (the number of nodes is becoming very big). That could be corrected by ,0.0,0
66,66,71,922be3881d23d4f79d2fe24bf6321a23d63d950205b6ff6979047d1cc7c61465b9b18bdf8228c338eb886bb3010ea5578ec21cbc2819ca5ad2860838b719658d,"The system slows down as over time when more student ID 'nodes' are added to the binary search tree simply because the tree becomes more and more unbalanced with increasing insertions. The height structure does not allow for efficient searching of the BST and thus the time complexity continually deteriorates, taking more time to complete a search for a student.

This problem can be solved by improving time complexity for searching the BST by improving the height of the tree into a logarithmic one by using a Balanced Tree, viz. The AVL tree structure. This ensures searching of a Student ID is done in a time complexity of O(logn) with n the number of student records. 

Thus allowing for a more efficient structure for student records at high scales, and thus quicker searching compared to the BST.",3.0,0
67,67,72,0ffad2820b9adf1fbb6d7105f83a5954e33ce5d91444ff2b6251d15d1a8c5a988e64634ca1a4f0e01e237f0fdb8290b82c533e1fa1a822b32c02e6052c618e98,"The tree has become unbalanced or degenerate. The majority of the new users ID numbers will get inserted on the left side of the tree, this is because their ID numbers are most likely from 2000 upwards. 

This can be corrected by using AVL trees and balancing out the tree by doing the necessary node rotations which will not make it that slow anymore. ",4.0,0
68,68,73,4795114f3afe1274590e0a1f19de90527c5847fc255bd0189e17daffae55e382487cd961fd300bbb3c50ca9f987687623e87a7237bb50d7f5d0bd58f320efd98,"The tree has become unbalanced or rather degenerate.

New users of the system/new students are most likely born after the year 2000 and therefore have ID numbers from 2000 onwards which all start in 00 or 01, because of this these ID numbers all get inserted on the left of the tree.

The height of the degenerate tree will also no longer be a logarithmic function.

To correct this problem, a balanced binary tree shouldve been used instead, for example : an AVL tree or binary tree could be used!

If the tree is balanced then speed will no longer be a problem.",5.0,0
69,69,74,b35e384f7c5ceb06d79c3b93cc63fcaa47042ffefb6b106d30f49be852e804e9feab1392cb217f65d7e7d63ec9914fbf325012c10f23427d79d4c0865092862e,Over time the binary search tree may degenerate meaning it is more like a list (and therefore not as fast as a binary search tree). I would correct this by adding balance conditions like those in an AVL tree to prevent the tree from degenerating. This would mean that the search times become O(logn) as opposed to O(n) times when the tree is degenerate.,3.0,0
70,70,75,d320af019b5c5fbf5996000b6f0c018e158d92ab05c3709236e5a03a6b328c59c1ab963403ff89c119e51b19d4eaa6320e2573a8bf4efb41ca5bbf92364ab8b6,"The system has gotten slow as we added more and more student records throughout the 10 years, this is most likely because we did not have any condition to ensure that the height of our tree would remain logarithmic. The height of our tree probably came close to reaching its worst case of n-1, and therefore every time we would traverse the tree the complexity would be linear O(n).

This could be corrected by using an AVL tree instead, where we have conditions to ensure that the height of our tree remains logarithmic. This will make use of things like rotations to ensure we have a well structured, balanced tree of logarithmic height. This ensures that every time that we traverse the tree the complexity is logarithmic O(logn)",3.0,0
71,71,76,bef6837a7fdfe1da5fe1293f44c76b96d3b8dcc796faa186ced378d3238a30c359695c10ba31e008e6450186def6f4c6da86e1819e6310ac4629db0e4ae2f7c4,"There has been a memory leak, which means memory that was allocated was not deleted after the user was done with it. To correct this issue, all I would need to do is deallocate the memory.",0.0,0
72,72,77,ee66ed151b20f2c15b5115f8b2c4fd312cc74408ed945a84bb7f699ad1a7972c932ae28ae3a673ec55d38f3c6b49ab5107d141ab55e4e963155df1dc24bf5495,"The binary search tree works fine at the beginning because the time complexity is O(log n) and for best case is O(1). Initially the is a sort of balance between the ID numbers that are greater than the root and those that are less than the root. After 10 years the system will be slow because most student will be on the right side of the root due to their ID numbers, this will happen because the ID NUMBERS INCREASES  OVER THE YEARS for _example a person born in 2001 their ID number starts with 01 and a person born in 2011 their ID number starts with 11_, so 11 IS GREATER THAN 01. When Wits now capture the new ID numbers most of them will be greater than the root. The right side of the root time complexity will change from O(LOG N) TO EXPONENTIAL O(N^2).",1.0,0
73,73,78,c01425271443b193ce09add717a13c5f03e56291a15f580c8ffbb713e75d1afdc1826b33b91330419ca4db414a4703bd7b9474559be3d7689b82c2ecbf73906a,"As time passes, thousands of new students will be added to the tree. Therefore, the tree would be unbalanced as one of the sides of the tree would be heavier than the other and the tree would become degenerate. The system will slow down because we will be performing tasks on the tree at O(n), linear time, instead of O(log(n)), logarithmic time. To correct the situation we would have to make the tree into an AVL tree to balance the tree. This will improve the time complexity to O(log(n)) time and allow the system to perform at a faster rate. ",4.0,0
74,74,79,a39aa34c391034439ba958ca98869143599e2cc20097d4066633e71706d0b615be58b0586a9143631148978c46ccf7746504f4abfa225c0f60b106eb68d6aeb5,"A possible reason for the system slowing down could be the increase in data sample size. Initially with a small sample it is quick to narrow down results based on ID numbers since the chances of the first digits of the ID numbers being the same are slim and decreases further. (For example in a data size of 1000 students, 10% students may have the first 5 numbers the same, but only 0.0001% may have the first 7 the same)

With a larger sample size the chances increases further and takes longer to narrow down (For example, a data size of 100000 students, 20% may have the first numbers the same and 0.001% may have the first 7 the same)

Some possible solutions may be:

-add an extra field (currently studying, graduated, on hold, etc) which helps narrow down preliminary search results based on said conditions

-assign a shortened identifier number through encoding or other means (such as the current 5 digit student numbers we have)

-Make sure the BST is AVL (which prevents degenerate trees that take long to traverse)",1.0,0
75,75,80,98d78e9c828344508b695719d0252934ec81638b460881dd9abe0087d3148c90c09f4ac72696b8c6cb5d749b644a041f0fa7f6d6c483866227774b40bcf364d5,"If they are not  sorted before being inserted in the tree searching may slow down

In order to fix that they have to sort them before being inserted in the tree.",0.0,0
76,76,82,e06c3717f5eff40cf06c551e6ebf1004bb478bf8fc38ebcba99f54530677cde6de5ea93590e51ef3d1e09f18ed2aa22502c287548e3398f50b4cf8f8e940073d,"Due to a Binary Search Tree's structure where a value greater than a certain node it is being compared to goes on the right of it, as student numbers increase as they would over the years, the values will continue to be placed on the right of the tree. As more students are entered into the system, the tree will become right heavy as the only available place will be on the right side. This means that we will always be searching in the Worst Case scenario which means the amount of work done will be O(h) where h is height of tree which means it would be O(n), a linear amount of work. As the height increases the longer it takes which would be the reason that the search is slowing down. The way we could fix this would be to somehow make the tree perfect so that we could make the Worst Case scenario of work be logarithmic, O(logn), which is a major improvement. We could do this by changing the structure of the tree by doing rotations on certain nodes to reduce how heavy it is on each side. This would increase the system speed. ",3.0,0
77,77,83,59ba65c517c334e25d3ae45ca0766a06b5a36061abfca1dd80f0f9e00eca00b8fc96224e4fcd721b2a66146a086c07a1cca9cf5028a8fc5d88a04890a96fe5a7,"The binary search tree has become unbalanced and degenerate over the years. As ID numbers of recent students start with the same or similar values from 2020 onwards, they all get inserted on the same side of the tree causing this imbalance. 

This could be corrected by implementing a Balanced Binary Search Tree such as an AVL Tree.",4.0,0
78,78,84,7aa4a41956fb10b2ea3a02d2d85c1eec912704226ca5710248e26fa3e0fa199d5048abcac9423a11d00a49ffe75bdd51e2b3cd752d5f6899af51dc4b580afed1,"The Binary Search Tree is a great data structure for this problem as if the tree is NICELY STRUCTURED, in the WORST CASE FOR SEARCHING FOR A NODE (student record), we would have to TRAVERSE THE HEIGHT of the tree which would be LOGARITHMIC. In Big-O notation, this would be O(LGN). 

However, if the TREE IS NOT NICELY STRUCTURED and starts becoming more degenerate, the HEIGHT OF THE TREE BECOMES MORE LINEAR and we have to traverse to more nodes which is less efficient than logarithmic. In Big-O notation, this would be O(N). 

As time has gone on, this is exactly what has happened. More students have been added to the system, and NODES ARE BECOMING MORE LEFT OR RIGHT HEAVY. This is forming a more Degenerate and unbalanced Binary Tree which has a linear height and search time, rather than Binary Tree which has a logarithmic height and search time. 

To SOLVE THIS PROBLEM WE COULD TRANSFORM OUR REGULAR BINARY SEARCH TREE INTO AN AVL TREE BY IMPLEMENTING A BALANCED/AVL CONDITION where the absolute value of the difference of a node's left child's height and right child's height, must be less than or equal to 1. 
i.e | HEIGHT(LEFT CHILD) - HEIGHT(RIGHT CHILD) | <= 1. 

This CONDITION ENSURES THAT OUR TREE WILL ALWAYS HAVE A LOGARITHMIC HEIGHT, AND THUS IN THE WORST CASE WE WOULD DO O(LGN) AMOUNT OF WORK TO FIND A STUDENTS RECORD BY TRAVERSING THE HEIGHT OF THE TREE. 

IF THE CONDITION DOES NOT HOLD FOR A CERTAIN NODE, then we would have to PERFORM SUITABLE ROTATIONS in order to keep this condition. 
In addition, when INSERTING a new student into the tree, we would have to do a MAXIMUM OF 2 ROTATIONS in order to keep the condition.
But when DELETING a student from the system, WE MAY HAVE TO DO ROTATIONS TO EVERY NODE ON THE PATH FROM THAT NODE TO THE ROOT IN ORDER TO KEEP THIS CONDITION. 

By implementing this condition, the system will be a lot more efficient when searching for a students record's. ",4.0,0
79,79,85,1b24ef0d303f3078167a7dbca152a2c1d687ceab3654a2ae76bf73e5ee1cc0069be94db2fff74908c1492e9ab7afab08d7fd457a365a4c193c2adc5bcd9b850a,The reason the tree may end up being slow maybe because the ids we are storing will end up creating a degenerate tree. Binary Search Trees work with the concept of linked list so we can end up running out of memory on the heap and the ram will be filled and not have enough memory to execute the program much more faster. the more Ids that are collected the greater the tree and more ram is filled and slower the program. ,1.0,0
80,80,86,185dc4c21423a9741e871c6f410e59bdca77c391c194cec101c75b3cca04c937f124a0057340342b97dc026d09e5d98b6cb6fda9dab2b9032e1e211b08f87356,"* Binary Search Trees don't guarantee a structure that allows the height to be log(n).
	* Over time, it is possible that the tree started to become degenerate, which would mean that searching for a student started to take a linear amount of time. Over 10 years, this linear time would really affect the performance of the system.

	* A way this could be corrected

	* An AVL tree. The AVL properties will force the height of the tree to always be log(n), this way, searching for a student will always take O(logn) time. ",3.0,0
81,81,87,8fd97c5322558e2423003672fe174f30c080d208985516c4cd8749e1d3f072ac5736c633a74790122fa877f92436ac7777fc9cf9c36610a77bd1566b6903427e,"The number of student is increasing and thus even the ID are increasing in value, it will cause the right subtree to grow long while the left subtree remain small, so the tree become unbalanced and thus it will result in system getting slow.

We can fix this situation by using an AVL tree so that the tree remain balanced throughout.",4.0,0
82,82,88,bd50a1f76e0acde64b2131110f2268f08aef333a162fed075d374337a58f0180c5f1efb88a7f6560e676d09d9ae71856da1ed18b029ff6c96af885a57d9fef75,The problem is that the tree is growing or becoming too longer on the right hand side and that is why it takes too much time to locate new student (the new id numbers are added on the left). we can use an AVL tree to fix this problem.,3.0,0
83,83,89,9607664f15775a14ee634c51fe9c149f525e26b98d5914c3165e84652908eb3f36dc6b5eb9602fdd2aa10815feb68c6202a768e4280fe2bc5565e0190f5672e7,"From a data structure perspective and in regards to searching through data structures to find elements the system would seem to run very quickly in the first few years when the amount of elements are manageable by most data structures, but as the number of students of the university increases the time takes to search through the data structure for a students details may become very long. This would happen when creating a tree with the underlying data structure that would require you to search O(n) amount of times. Using a underlaying data structure such as a vector may speed up the search process.",0.0,0
84,84,90,50ac02db01dc47f0f24bb2a0e8bc1bebe3aac1ecfe652f1c87b260f45da4def0a267392e043e67a0b0f3a39374188322db34615d5257a196fc0978d4d004e1ed,"The data of the students who are out of the University   are not being deleted from the system
Adding to the above problem, new students from high school adds to the data structures of the University, therefore with this ignorance of removing those that are excluded, graduated or dropped out, the varsity data structures will just keep on adding. more and more information of students will be on the system, making to hold more information, thus making it very slow

Solution might be to remove each and every learner who have graduated or dropped out, or even excluded from the system, and add new students, first years on the system ",1.0,0
85,85,91,20effcbf64917de69f0f441958ac819d52ad486a65f959444a5ddd14ca83a40e581709b6bb9eae431ca2dd02ce933a201bc9b7e43298585d0858d76601344ce0,So from a data structure point of view because we are not using an AVL tree structure it is possible that we will form a degenerate tree at some point in time and a degenerate tree will greatly increase the complexity of the tree from logarithmic to linear because the height increases. So when the height of the tree becomes linear then it will take longer to access the nodes which are further away resulting in a slower system.  ,4.0,0
86,86,92,89daf5e5dd9d5cd464a1dba203796d2fcea5b46dd29cb10e72e0dd7e72373ac4fd8e96b5e3d9813a2ed44c552171318e265b869630b10e2e2b1c3ee4cc7320d3,"As the number of students increases, the time complexity takes longer because the height has increased.

This could be solved by using an AVL tree.",3.0,0
87,87,93,0a1eb6f30606d1f92d934eb03ca9d55d90d2ab3f505cdcb3ba02589cc6678998e8754ce7335373d6c01684ffed4a20fad8a976d2479c3f801a51d1c2b0d4ed50,"the reason for the slowness is , as the number of students increase , you will need to traverse to the bottom of the tree to add another student and as that occurs , it takes a longer period of time each time as the tree gets larger and larger. I am assuming that when the tree was constructed, a student no. that was fairly in the middle/ towards the end was chosen so that the tree would have numbers on either side of the root. if not so then a possible solution to this would be to do a rotation so that the tree can be balanced and thus decrease the height of the tree, making it easier to traverse through the tree.

how can this be corrected? 

Every year , obviously, the number of students will increase, and these new students will have student numbers greater than the previous years students. when they are added to the tree they will always be to right of the right of the previous person. thus after every insertion do a rotation on the tree to ensure that you can always have a balanced tree which will greatly reduce time when searching through a tree. ",4.0,0
88,88,94,a837228a932a0a88d86d56984d3a65abcc9744de389dd1a09c0dbc6344b07254c5f44d2d0e035800fe07d8fd7ef535a3af313b16fa0ec5085dc57d2a491f0957,"Traversing to the bottom of the tree to add a new student. 

As more students are enrolled into wits the tree becomes relatively long causing it to take more time to traverse to the bottom of the tree to add a new student.

A solution to this problem would be to place two pointers one in the middle of the data set and on at the end of the data set. Thus making it easier and quicker to look or add more students by just using the pointers that were put into place by either traversing up or down from that specific pointer.",0.0,0
89,89,95,1489eb158e53466602df55c1ff7f77273c9913450f0796e43815428214c7433748ab1168262af0196b8d73779fe2b0792d76aba9ed45066d1d5d48c57b55c0b6,If the BST is a degenerate tree then its time complexity would be O(n) which might appear fast due to the tree being short in the beginning but over time the speed at which data can be received becomes progressively slower. The best thing to do in this case would be to make the BST at least a complete tree. This would make the time complexity O(log n). Another approach would be to use an AVL tree. Their self balancing nature would help keep the height O(log n).,4.0,0
90,90,96,eacc5211df7d685afcc35802886c12863f0c8244351fcd398189af9fa9bf26e12a751640dd66f6200f43478fc4f6782d51b4f6c4a782ca1b75e12c96dded3eec,"As the Binary Search Tree grows, the time that it takes to insert and lookup values become longer. This is because as the tree gets bigger, the binary search tree becomes unbalanced. To elaborate, because the items are inserted according to ID'numbers, the tree can become one-sided and unbalanced. This causes operations such as searching, inserting and deleting to be very slow. To substantiate, the worst case for the time that it takes to search for an item in a Binary Search Tree, where N represents the height of the tree is O(n). This means if the BST is very large, it can take a significant amount of time to search for items. This causes the system to slow down. 

As a result, this problem can be rectified by using an AVL Tree. Whenever you create an AVL tree, you are required to implement an algorithm that performs the necessary 'rotations' in order to make the tree 'balanced'. Because an AVL Tree is balanced, the time that it takes to perform operations such as searching, inserting and deleting is significantly faster than a Binary Search Tree. To substantiate, the worst time-complexity of searching in an AVL Tree is O(logN).  Therefore, the worst-case time complexity of an AVL Tree is far better than the worst-case time complexity of a Binary Search Tree. As a result, by using an AVL Tree to store the records, the system will speed up. ",5.0,0
91,91,97,d96af73b5be668f5dd689aeab89641b2c7231424c7456f3ea33f65b38aaefabde723924090d862562454b1c8a6f22cbeb22245f54dc09b6ff5593a40d39e2839,"A binary search tree is efficient, but because we are continuously adding to the structure it may be storing in an inefficient manner. We can correct this by using a balancing condition and this will convert our BST to an AVL tree. This ensures efficiency

Because we are storing data from the last 10 years. We have a large volume data. This will increase time taken to search through all the records. This can be corrected by storing older records in an archive, and keeping the relevant records in our data structure.",4.0,0
92,92,98,74d9bc92412f8c3ff2851eb60d7164b5df173c9c4dc214351b20de54e473afd02c6de0a58df8f38e8034cea31df2b0fd7682d3f538a4da451a42ed390cc33c67,"Because the ID numbers increase year to year (birth year of applicants gets greater and ID numbers begin with the birth year) Not only does the number of nodes you have to search through increase each year- It may occur that the tree starts to look more like a linked list, more unbalanced and skewed, than a complete binary tree and so operations like search will then tend to be performed in linear O(n) time in the worst case, rather than in logarithmic time O(logn) and this will cause the system to slow down. This could be corrected by applying the AVL property and maintaining the balance condition of the binary search tree (the difference in height of the left and right subtrees is at most 1), ensuring that the height of the binary search tree will always be logarithmic and search will take at most/average O(logn) time.",5.0,0
93,93,99,364ce0d9b555b7fbcffabb10a359d7f7e38b464e534b9a29447029ab1ebdabfad20a4341f04f3a61405ee0dc6245a44f1b6329878e01aafc141ca4d5cdb571fc,"an increase in the amount of students in the Binary search tree and a potential degenerative tree.
turning the Binary Search Tree into an AVL tree so that search is done at O(logn)",3.0,0
94,94,102,24404807247a19fa0eb28edfebfb33701c7bf0ce5da4f252098d5b07602e418852b18cd29763fdb981a6cf7530167e7c60c21dd57b0dd95a95c25a71b9515eda,"By using a BST to store the records of students, this would mean that the amount of work done by the functions to access and manage the student's records increases significantly. We could increase the efficiency of the system by implementing an AVL tree.  ",1.0,0
95,95,103,3e664d9b290450a26a44195a29971d5e7c7434afb68523c4038cc69f5c1285f4c94e2b62945fc7bf5800f3a5190a2876a925f82823b3806d9c640fa0e0d73571,"* As the number of students increased new ID numbers had to be assigned to the students meaning we had to add more numbers to our binary search tree, The students ID numbers probably had to be assigned in an ascending fashion where last student gets highest number this would insert numbers in the right side of our tree following the binary search tree rules, After a period like 10 years our Binary search tree would be a degenerate tree on the right hand side, we would end up doing more work when searching for a value as the degenerate tree has a linear O(n) equivalent causing us to use more time  as the amount of work done is determined by the height of the tree
	* A way to fix this would be to ensure that the height if the tree remains a logarithmic function O(log(n)) , we can do this by using an AVL tree which ensures that no mater the insertion our height remains logarithmic, this would decrease the amount of work we do from linear to log,",5.0,0
96,96,104,dc016101375a4c30fa08c850e4ef82abdd66ca922170c25b2eda3c6f7009abcdda2dafb1c86a512fdd1b897c4c9da94be8f7047b535d50f3a259b1e698b13e05,"A balanced binary search tree is close to being full but not necessarily completely full. At each node, it has around the same number of nodes on its left subtree as it has on its right subtree. Therefore, the find, insert and delete functions on a balanced tree tend towards being logarithmic O(lg n). The more unbalanced the tree becomes, the longer the search time grows, until, at worst, the operations will tend towards being linear time O(n), as the tree becomes skewed. 

Every year, students' id numbers increase as id numbers start with year and therefore as time goes on, the year increases therefore students id numbers increase. The tree will be skewed to the right and unbalanced as the id numbers start increasing and therefore will only be added to the right of the root of the BST (there may be some exceptions for empale if people took gap years or deferred). The BST will start looking like a linked list which will make all the operations of a BST take longer time to complete and therefore will cause the system to slow down. Every year we will be adding more nodes then each time we want to search for a node we will have to traverse though more nodes to find the node we want. This is why the system is slowing down. 

This could be corrected by implementing the AVL property in order to ensure that the height of the tree will be logarithmic O(lg n). ",5.0,0
97,97,105,39f1ebb534a7edaa837d48cbd4115f72e8c5e63b7a4efafc271bf59036c6638038d9febb4eab796e3f3e68165bcbad6c2e1a9ad37eb71f421ecdb12f31f4f4c5,"As more elements (student records) are inserted into the tree, the shape of the tree may start to take on a more unbalanced shape(More nodes lie on one side of the root than the other). This is because with each consecutive year, the first two digits of the ID number  increases, and consequently more elements fall to the right of the root of the binary tree (as each year passes, elements are no longer inserted to the left of the binary tree). This great imbalance in the tree gives the tree a height that is very large in comparison to a tree that is balanced. Consequently, since various operations performed on the tree (such as inserting a record), is linear in the height of the tree, access to student records become slower.

To prevent such from happening, a condition must be added such that the absolute value of the difference in height between any two sibling nodes must be less than or equal to one. This will result in the construction of an AVL tree, which is logarithmic in height. With this condition, the height will increase to a smaller degree (in comparison to the tree described above) with each passing year. Consequently, operations will not slow down as much. ",5.0,0
98,98,106,833bd82b84984eac1561a2aa471c7fa8ce8fc83eb43410d162adbb99836f9c60ca90f110500d0a4cfae027c10757354954059b39ea510643c3c10d5e8f6e1bb9,"The system is slowing down because there are too many students to keep tracking, the tree is now very long, there are many roots to pass to.",0.0,0
99,99,107,7c87322598f2ceacf4938051fa8e249fba61f740f1c131025859319c9334a0e7c5eed0d631406a69aaecd55c3154797379e9e557934a0c639e13848fc2a797db,"The system maybe slowing down due to the increase in ID numbers of students (As new students come into the institution to study) causing the BST to be bigger in height and this would recursively make it difficult or slower to traverse through the degenerate tree as it would take O(n) time to search for a specific students' ID number. We could implement an algorithm that can make our tree to be an AVL tree, in that way we can be able to regulate the tree to have a height that is off O(logn) time complexity allowing searching through the tree to be much faster than before.",4.0,0
100,100,108,eee70f1328b3cdb194af70a4822cc7feab4c1f2f6aa8f1c3d195e1593437b3077b36a3a63265ad79d2faed3c1dc2010c5f323409bdd6e1b2e860317721256dce,"Students who are no longer a part of the university are still kept on record and as such the time it takes to traverse between each student increases. To fix this issue, students who have graduated or left the university, for whatever reason, need to be removed from the BST.",0.0,0
101,101,109,249e9eaf48a6ca1524336796643b1021d4ea59f9ea64287d7770c8c08e88ca9d76b31f4d65b880c825f283c49f03d66834bc8a5aef3bcb8880daa0f21458adeb,"Over the years the tree gets bigger as nodes are added for each student record. 
The time complexity for BST is as follows:

	* Insertion O(log n)
	* Removal O(log n)
	* Search O(log n) 

Removal requires the nodes to be reordered to maintain the properties of BST. Hence, as the tree gets bigger, the efficiency decreases making the system slow down.",1.0,0
102,102,110,29fcf57bccb37a2f0d949733d7028b65c0e2df19a9ddbd0c547e57467d84c825defbaf635dea276a63c3d3e85a6fb4f7a84d6da08661ca46728f222c62700315,"The factors that may be causing the system to slow down are the system running in linear time O(n), when inserting a node it could be inserting linearly O(n) which means it would traverse through the height of the tree, however the main factor could be due to time. This means that after 10 years (if the system has  not been updated and improved) when searching through the tree you would be traversing h times through the tree (the amount of work done is proportional to the height of the tree). The absolute worst case would be to traverse through the tree  looking for a value that is not in the tree which is linear O(n) and would be not efficient, especially after 10 years.

This factors could be corrected by running the system in constant time O(1), inserting a node logarithmic time O(logn) but the absolute best case would be when there is a hole in the tree when inserting, by optimizing the system to have balanced trees which will make the search time faster than before.",1.0,0
103,103,111,1c067bf4dc46efea1d97764ec9e8512203198a06760dfe663905444adb3c11970401fd40f402aab42c0c01db7d7d76641060c3df878232bbed315bb7d13f0aab,"The reason for the system to be slow over the 10 year period is because the data in manages has increased this increases time complexity of the system it operates in a worst case scenario. 

A solution to this problem is to use sorting to arrange the data in the system so it would be easier for the system to work. ",0.0,0
104,104,112,2d66cc49a7ffe05cc8bbfc302bcf20656e7f907877a7522f7da110ca45abf9d13e838fa2518e2db3e38e88bb214034f63934465720849e92200572791f51d840,"This could be due to degradation of hardware such as RAM and Hard drive or it could also be due to fragmentation.

To solve this you could upgrade or renew your hardware or defragment your hard drive.",0.0,0
105,105,113,3dd0e6b0aa4ca279a9a8f781013cc1ffadd92a615d343d8f7162570e3cd2647c9fb452de2221fcafa1322a70dac1ad1ef68bd5efe79682df415f360b352ef94b,"Better Performing Algorithms would be deloveped, the system would have large amounts of data to consume thus run slow. 

To fix the problem, one would regularly improve the system. ",0.0,0
106,106,114,8240603fa734ed603f090dc4c8bce2f226cd0f876026dfa595bd8492bf9acd3d4bb834f9651a57ba591889e5cf0e84e937e21bd54121dfe09399f647a5d4f575,As more students are added to the records there is more data that needs to be processed and it takes longer to find a particular student,0.0,0
107,107,115,cdf5a55df376657eda6b008ced4f7043cdba2f1d1b7da216b9e5df9fd11e894729a95890612c52ba24c8f6e0b1099b039f557d8043ee19615f361b8a60481af7,"The tree has become degenerate. ID numbers start with the last 2 digits of the year the person was born in, so new users that were born from the year 2000 and going on will have ID numbers beginning with 00, 01 for the year 2001, 02 for the year 2002, etc. So they will all be inserted on the left of the tree. To correct this problem, you could use a different data structure, such as a balanced binary search tree. ",5.0,0
108,108,116,9d599f5b4528664877cde67e20618306dd9ba2d042eff74f086d6094f809424f26b3522b41500c22020384b725682a3a9de08fa52bd56f223acd18ce507d7fd6,"The system is slowing down as time progresses due to it being unbalanced. This is a result of input only being inserted on one side of the root. Due to the two previous statements the worst-case searching is slow due linked list being linear O(n)

To correct this issue you can use an AVL tree, which is a self balancing and self sorting tree. This would prevent the system slowing down.",4.0,0
109,109,117,d10eb2653552348dd29e31d9127ca9b9ab3966f67dcfba3fbaef7bc1fba74c3549309defc8e00e457f7427150a3162c0ca17e3f3d6529fa8df4aa4e4195dbeec,"* The tree has become unbalanced/degenerate
	* New users likely have ID numbers from 2000 upwards and all get inserted on the left of the tree
	* It could be corrected by using a balanced binary search tree (AVL)",5.0,0
110,110,118,2dec7d91f389ea815b08c16bf0ce77e60642ceca404945e8ad369e8ed82ed28e57d6cf12351d45add693d36c78a2ba5f4910e162bacba9689368c6699766d9b3,"As the years pass and more students join the university and therefore there are more nodes in the tree, the height becomes larger and the searching becomes slower. It is far more likely that one is going to search for a more recent student and therefore the traversal will be longer due to the node being at a larger height. This problem could be corrected by making the tree an AVL tree so that the height is always and element of O(logn) and therefore, the searching process should be sped up.",1.0,0
111,111,119,e669fcade771c8ac126f6aaaaaa9562b24a7e63cb2b8a26b67162e1919636fc9c8117e6d9c38b6dbe2b9896b1404543b4d1d48335aa3385388e129cb234e4996,"As the years go by, the the number of nodes increase making the binary search tree longer. The longer the BST, the time increases to search through the tree therefore the system will be slower as years go by.",0.0,0
112,112,120,072df8e3c1de059673d8b782c554cf64da21277fb2ba12d1d8f4ab73cd1269538ca3968b89e11ecaa84835030161cc68c0efae276a64b66f06c4f0c8a0d2ada3,"This is based on the fact that binary search trees have all values smaller than the current node to left and all values larger than it to the right. Since we are using ID numbers searching through the binary search tree for input after a few years will be very difficult based on the representation of numbers.

The binary search tree worst case time complexity is O(logn) and as the size of n increases the time to search substantially increases.",1.0,0
113,113,121,21f09107df149216c5f40e2d6eaefa443c1ac6ce9ddec594661383f2e53455e2769bfb1bb81bee158e80bc0b01db2da739108bc4386c15bb286ac35afa1a5409,"As time goes on, more student records are being added to the binary search tree, thus the tree is continually increasing in height, which means that it will take longer and longer to find a particular student record. In the best case the student record is at the root so only a constant amount of work is done but searching for other student records is more likely which will take either a logarithmic amount of time or a linear amount of time depending on how the tree was arranged (degenerate tree=linear time, perfect tree=logarithmic time). To account for this problem regarding tree arrangement, convert the binary search tree to an AVL tree to ensure that the height of the tree stays at a reasonable value. By keeping the tree at a reasonable height this makes searching quicker.",1.0,0
114,114,122,8b711f86a0e0fd2c39d5f02ba2888612f603b1e29ac872778bb22eb91072c41a1a4c3f396ac1783e4ea49d806b40a998dee128cf46fea841c4d6fa80f6f2360e,Binary search tree could have gotten significantly bigger over the years thus making tree traversals slower. Solution would be to break up tree into smaller trees that would all be traversed at the same time.,0.0,0
115,115,123,8a8eb86cf56dd2444d2bc5441387c73e3fcbac4867da844d41e7ee67a78c9e8b163da9822047fef10101762a7abd4eba2ff040d29869420924f78a2c686ad858,"Over the years the BST will degenerate due to the ordering principle sending all the new numbers the the left of the binary tree. So if you were born in 2000 then your ID will start with 00 which will go to the left side of the tree because previous students would have had IDs starting with 90 (born in 90s) etc. This means that moving forward there will not be any record going to the right hand side of the tree until the year 2090 - this is if your records start from the 80s. This is a long time to wait for the tree to somewhat correct itself.

I think the reason the system is slow is because we have a long list which now takes O(n), a linear amount of work to insert. To correct this I suggest the use of an AVL tree which is a self balancing tree which has logarithmic height as it balances itself as such. Complexity is O(lgn). ",5.0,0
116,116,125,11033a17d67159be6a6bbc8378c0392c95d06eb759a822fa4a4ab3fcd33a9e9c6b4e8e1a2ffedc295aecb757927d81558a966188674240b280a874a24f0debc2,"The system has become slow because the Binary search tree has become unbalanced therefore it will search for student records inefficiently and slowly.In order to fix this, we would have to make the system use an AVL tree ",3.0,0
117,117,126,b47128b210e7cc636fb0b5325c08248ffac624374ed1eaac62c3594d5f67da91cc887cbf07a6c3571b2149ad963910548cff788f165204f9df156115e859a64b,"In 10 years, there would be a significant increase in the amount of data being added to the BST. This increase in data would lead to the tree becoming increasingly degenerate. (_As students enter the university, the first 2 digits of the IDs would increase yearly, because majority new students are born later than previous students. Because their ID numbers are getting larger, we would be continuously adding to the right of the BST causing a degenerate tree.)_

_
_

When the tree is degenerate, the height tends to (n-1) (where n is the number of students). This is highly inefficient and would cause any operations/searches to be increasingly slower as data becomes increasingly large.

To fix this, the BST needs to be rearranged into an AVL tree. When this happens, the tree is ensured to have the most reasonable height. In this case, the tree will have a maximum height of 2logn, which is significantly better and more efficient than a tree of (n-1) when data becomes increasingly large.",5.0,0
118,118,127,52240fd5da488c8fea93f35bf4efe57000386d8c8d0c85c5b680c74f1a8feca90e13d4df01d1470660907e2655f277134bf53af33144e84c3793614abbdf6e99,searching for a node in a tree is proportional to the height of the tree so when you insert new student records the height will get significantly large making searching slow. This can be rectified by using an AVL tree which will balance the tree and make the height as small as possible allowing for faster searches.,1.0,0
119,119,128,38046b991658125dabc236638e4678ce8b6ce1a14066e89cee307b4ad43150545ef075aca8b10f61c4cd3909f6915397eea519e89ce5ad74fb62a1715837f925,"Firstly a BST performance is mostly affected by the height of the tree. Since the higher the tree the greater the depth becomes and in return a greater chance for a branch of the BST to look like a degenerate tree. In other words, the search time will be that of a linked list. If the binary search tree fits the maximum nodes with the minimum hight then it will be O(logn) and if it degenerates it should be O(n).

POSSIBLE ISSUES

Since they are compared and ordered _based _on their ID numbers this can mean that as time goes the"" first generation"" of students(nodes) gets shifted down meaning as new students come by the old students will be pushed down on the tree. Depending on exactly how their ID numbers as compared and ordered. The old student can also be pushed down on one side of the tree and the new student on the other side. This could mean over ten years those students or any can be pushed down the tree to a very great degree. Even if the best case is considered and it always arranged in a perfect, due to sheer number of student this can make the size of the tree very large.

POSSIBLE SOLUTIONS",3.0,0
120,120,129,38046b991658125dabc236638e4678ce8b6ce1a14066e89cee307b4ad43150545ef075aca8b10f61c4cd3909f6915397eea519e89ce5ad74fb62a1715837f925,"Firstly a BST performance is mostly affected by the height of the tree. Since the higher the tree the greater the depth becomes and in return a greater chance for a branch of the BST to look like a degenerate tree. In other words, the search time will be that of a linked list. If the binary search tree fits the maximum nodes with the minimum hight then it will be O(logn) and if it degenerates it should be O(n).

POSSIBLE ISSUES

Since they are compared and ordered _based _on their ID numbers this can mean that as time goes the"" first generation"" of students(nodes) gets shifted down meaning as new students come by the old students will be pushed down on the tree. Depending on exactly how their ID numbers as compared and ordered. The old student can also be pushed down on one side of the tree and the new student on the other side. This could mean over ten years those students or any can be pushed down the tree to a very great degree. Even if the best case is considered and it always arranged in a perfect, due to sheer number of student this can make the size of the tree very large.

POSSIBLE SOLUTIONS",5.0,0
121,121,130,38046b991658125dabc236638e4678ce8b6ce1a14066e89cee307b4ad43150545ef075aca8b10f61c4cd3909f6915397eea519e89ce5ad74fb62a1715837f925,"Firstly a BST performance is mostly affected by the height of the tree. Since the higher the tree the greater the depth becomes and in return a greater chance for a branch of the BST to look like a degenerate tree. In other words, the search time will be that of a linked list. If the binary search tree fits the maximum nodes with the minimum hight then it will be O(logn) and if it degenerates it should be O(n).

POSSIBLE ISSUES

Since they are compared and ordered _based _on their ID numbers this can mean that as time goes the"" first generation"" of students(nodes) gets shifted down meaning as new students come by the old students will be pushed down on the tree. Depending on exactly how their ID numbers as compared and ordered. The old student can also be pushed down on one side of the tree and the new student on the other side. This could mean over ten years those students or any can be pushed down the tree to a very great degree. Even if the best case is considered and it always arranged in a perfect, due to the sheer number of students this can make the size of the tree very large.

Over time due to the number of students, it is possible for a student to not be arranged in a complete nor full binary search tree. A change that values may be degenerate.

POSSIBLE SOLUTIONS

A possible solution can be to split the tree with respect to age on the ID. This should half the search time. When in search time the system will first check the age then will be placed onto the correct searching tree.

A good method is to opt for an AVL tree. This will ensure that the tree is guaranteed not to have the worst case ",3.0,0
122,122,131,38046b991658125dabc236638e4678ce8b6ce1a14066e89cee307b4ad43150545ef075aca8b10f61c4cd3909f6915397eea519e89ce5ad74fb62a1715837f925,"Firstly a BST performance is mostly affected by the height of the tree. Since the higher the tree the greater the depth becomes and in return a greater chance for a branch of the BST to look like a degenerate tree. In other words, the search time will be that of a linked list. If the binary search tree fits the maximum nodes with the minimum hight then it will be O(logn) and if it degenerates it should be O(n).

POSSIBLE ISSUES

Since they are compared and ordered _based _on their ID numbers this can mean that as time goes the"" first generation"" of students(nodes) gets shifted down meaning as new students come by the old students will be pushed down on the tree. Depending on exactly how their ID numbers as compared and ordered. The old student can also be pushed down on one side of the tree and the new student on the other side. This could mean over ten years those students or any can be pushed down the tree to a very great degree. Even if the best case is considered and it always arranged in a perfect, due to the sheer number of students this can make the size of the tree very large.

Over time due to the number of students, it is possible for a student to not be arranged in a complete nor full binary search tree. A change that values may be degenerate.

POSSIBLE SOLUTIONS

A possible solution can be to split the tree with respect to age on the ID. This should half the search time. When in search time the system will first check the age then will be placed onto the correct searching tree.

A good method is to opt for an AVL tree. This will ensure that the tree is guaranteed not to have the worst case ",5.0,0
123,123,132,16f82e0a87e8ddd62872296dc55051239fbed9bd7e989d4564eab3d0b0bd3dd97f30debd1ef7c57a72ffc4e972a5a710915f103218e9d2778be68d8b10a7d403,"The BST will becomes unbalanced at some point when there is a great number of records ,and cause the system to work slow when searching for the record and making comparisons.

New users will have ID Numbers which are less than the current ID Numbers in the tree, due to the fact that it is the 21st century. This means new ID Numbers will begin with  00,01,02 and so on. Due to the binary search ordering property there will be an increase on the left hand side of the tree as the ID Numbers are less and leaving the right hand side alone and this will cause the imbalance and overload.

Using an AVL tree which is self balanced, it will correct this issue as the tree will be balanced even when new records enter the tree. It will always sort the records out and be efficient to use.

And this means any insertion, deletion and searching of records will take place at a speed of (in big -O notation) O(logN).",5.0,0
124,124,133,0299c9665122a8d00cc0df25e8e955973b075c02ae0224028d3e17e0f6c78e173fd5823d4f6996d851096c01dce443a63e66dd04d704cdc88987434a35c7ee6d,"The size of the data structure is what is causing it to slow down. There are too many students thus too many nodes and branches and it will cause a delay when searching for said students.

This can be corrected by implementing a new system. A new system would be one of LinkedLists. It will be far more efficient and cause less of a delay and thus be a better alternative.",0.0,0
125,125,134,ec395a3ecaad23df4073c1f706e156a2dc0df6ec9ab518f824a5ee32c21f2fee951d1dfe316e50e996ee47ec57ebf1b3a335db07c23fa71520fbcc864e608a4d,"-A binary search tree is sufficient in terms of speed however as time goes on more students were added and thus the system became slow. This is because the ID numbers were placed in a sorted order/ increasing order so the system was getting the worst time case performance being O(n) because the tree is unbalanced / the height is more then it is when balanced thus more time is spent traversing when searching, inputting for example . 

- For this to be corrected the tree will have to be balanced to decrease the height, essentially making the tree an AVL tree. This will decrease the time used to search for the student/ input student for example. ",5.0,0
126,126,136,3837dadab543b77e6f128ba9a8d8da78c2418db534c738ed6ec8b39b65e15b00b1edfc55f3352bc7c7a8d43caed752b501a4dacf57e482fae1681e617f041081,Data storage might not be  well maintained. The system might not be upgraded.,0.0,0
127,127,137,2edf0656134d19474a53dbbe5225dc2a3f4aaa1130b603fed547f4fc2584f94df9c6d11c108fecf09067c54daf57f86fbd618dbf612a4c65bf741c812ed66b6a,"I think that the system is becoming slower because a large number of students is added every year, thus expanding the BST (the ehight of the BST is increading) by a lot, every year. Searching for a student record will increasingly take longer as there are now more nodes in the BST to traverse through. It would be more efficient to use an AVL tree, for the system at Wits, as an AVL tree can rebalance itself; it ensures that the the height of the tree remains resaonable. An AVL tree's behaviour makes it faster in worst cases; the tree keeps rebalancing itself so that in the worst case it will take O(log n) amount of time, which is much  better than a BST, which takes O(n) amount of time in the worst case.",3.0,0
128,128,138,dc28526a371ecd3cfbb01f874b966e2e2019f65befa98a250b0089b346a7e303549dac2ead3ffeef0d3b7ecff19ac3d890b35956aa010524ff365cf1275bd971,"There reason could be that the number of students has increased sufficiently which is slowing down the process because more traversals have to be made. To help correct this problem, the Binary Search Tree could be converted into a balanced binary tree, such as an AVL tree. This will help improve the search operations as it reduces the amount of work needed to traverse through the tree in search for the specific ID number.",3.0,0
129,129,139,d5eef99882213e9e893ef6d31b163cddd65b11b328a038af368c63b9dea5c55582d674f73b7f44a7ffb0e808a2c14f224354666b5c8da68a3cf145583cdbcada,the memory or data type used has no space,0.0,0
130,130,140,27b7c01b5507de27227f1b4c06fa92833846a84fa96c3732f3663fb00fd83e6f0c7c3e711cd797752bf30bb3a828ffa9c255dc629b8adb95ea32e0eed6535409,"Since at first the BST was on its best performance that means that its running time was in the best case. Now over the duration of 10 years The system could slow down due to more and more data being inserted. This will inevitably lead to the data in the BST to be unbalanced therefore the performance of the search, insert and delete in the BST will reduce reaching the worst case thus a slower system.

This can be corrected by implementing an AVL Tree in the BST so that the original BST would become less skewed and be balanced which will lead to the system being fast because it will be full and the performance will be on the best case.",3.0,0
131,131,141,43337822a8495f6346099bee6f1b1379846d1e116a80358eff95ac9a35a5e9db993d15f49931c7a4d1543bc7328dae0e418202f217ef071778281db16cfc2fe9,The data structure may have to traverse through the longest path from the root to the leaf and this takes O(n) time and this may have resulted in the tree becoming unbalanced on the one side of the data structure. The data structure could have become degenerate make it also take long. This takes a long time due to the BTS tree having to traverse through a lot of recoded in linear time. To correct this one need to make the Binary Search Tree into a AVL tree so that the access time to get a node will be O(nlogn) time. Thus resulting in a shorter average time than the longer O(n) time. The BST tree can be made in to a AVL tree by doing the required left/right rotations based on whether it is right/left heavy. This is done respectively.,3.0,0
132,132,142,df4be51196b13a9d9df6ef77eee120b801ef4ba7a8945fcd04077415ae29d58c8d1e0814291c20adeb94f43f2f99c6c2290c6dde5a70ac85841035ecc662212f,"The problem is that, over the 10 year period, the BST grew to be significantly large. This made looking up students significantly slower as the whole tree might need to be traversed to find a student in the worst case resulting in a linear time complexity- O(n). 

A possible solution would be to use a depth first search method when searching the tree.",0.0,0
133,133,143,112623e30928da280b124065b33eb8360f6fe49f45f9b97cc7a540f6e550a5152dd7bbbd6ba167e88c839362c8fd2148a3e881c83493d58d2e9fd2216c604c8a,"As new and younger students come into the university over the next 10 years, the first values of the students' ID numbers will become bigger than the BST root node. Resultantly, new student records will be added to the right and deleted on the left as ID numbers become bigger. This will result in a degenerate tree which resembles a linked list with searches having a complexity of O(n) instead of O(log n). Thus, searching the tree will be harder causing the system to slow down. This could be corrected by introducing a balanced tree which provides logarithmic height, such as an AVL tree (BST and balanced condition at every node). However, the BST property of an AVL tree still poses the risk of the system decaying to a linked list. As such, a binary heap can be used to correct the system as it has better constancy (no BST ordering) than the AVL tree because it uses a vector which provides contiguous memory and cache.",5.0,0
134,134,144,f76d34739c22495666539e328b829579ffb8d2806837813ff647c9a67384130ec26d74d58bb855836384f12b1b3b03f93c1062fce50fa1b459dbac86affbee20,"Because the nodes correspond to a student record and are ordered based on ID numbers each new node has a larger value than the previous node all get inserted to the left of the tree which means the tree has become degenerate and unbalanced. The time complexity for searching the tree is then proportional to the height of the tree.

We could fix this by creating an AVL tree which is a self balancing binary search tree.",5.0,0
135,135,145,2ab3b11f5f1782f4246740fe903154429a2490492d0572263d7ff046cace7736e29d65d602215296304ea46aa69325f3d67b03459c0b518493888576c52ace89,"The cause might be that in 10 years, the university now has many students, thus it takes time to access the data required.",0.0,0
136,136,146,f4baa24ad720b1250dc8a9d5d7170a55ee764630dc2c7f87292182bdad71ecf2851e6fec34c6913b3b5952d370fbd9d0459efe69a1541c4221908a8f498f268c,"Initially, the tree would be relatively small (i.e. not too many levels and a small height value) and as more students are added the BST grows. However, since the BST uses ID numbers these numbers will generally increase over the years since the first two numbers of an ID number are that of your year of birth and as predominantly students born in the 2000/2010s will be enrolling over the 10 years, the ID numbers will be increasing (i.e. most in 2020 will start with 01, in 2021 will start with 02, etc).

This means that as more students are added, insertions to the binary search tree will mostly be added to the right each time with fewer and fewer to the left of the root. The tree will be lopsided to the right and so the structure of the tree deteriorates and so accessing these students through a search function will require more time consuming traversals. Dealing with a well-structured tree (say a perfect tree) would result in a worst case search of O(logn) complexity whereas for a poorly structured tree as described above the worse case becomes of O(n) complexity. 

To try correct this, a balancing condition could be implemented, such as with an AVL tree i.e suppose the balancing condition is such that for a parent node p: |height(p.left)-height(p.right)|<=1.

This ensures a better level of structure to the tree; one that will be less lopsided to the right as the condition will not allow this. The tree is balanced. Insertions will ensure this balancing condition is reached by using rotations and maintaining the property. This should allow for faster traversals as fewer comparisons have to be made and searching the desired node is then a less laborious task. ",5.0,0
137,137,147,0937f3be42654657ad069520ce77541d5a98ac5749be01a645bd806b70eacd3e8fd42ac59b2732fb7275b059278710559211b932636ce097f43773ecefbba842,"The number of students is increasing so it becomes difficult to find a certain student, so it can be fix by deleting former Wits students, students who are no longer students should be removed from the binary search tree",0.0,0
138,138,148,ee9a54c657ad0d8bba4bde06638e509cdb2a338e06761f819025e545929c0973eae422171c63064d2ec75c6fa5edd42d44dd67fd5b59e36f33fd89e07c72a43f,"* The problem is that when times goes by some people drop out ,they are deleted from the system and their ID number gets deleted also from the Binary Search tree which cause the memory leak, that is why the system starts to get slow. 

	* We can fix this by checking drop out students, when a student drops out their ID number must be deleted according to how we delete things in the Binary Search tree.",0.0,0
139,139,149,93c90404569325fe60b728e076fbba3cf65e437046307f80389f0bc8991e0972c6f04c428807930e8f3ec23f714c2c1a1c5a69ba6ec135ea91d23224a8d3d68d,"The first thing that is causing the problem is that when the Binary Search Tree is created it will never be a perfect tree. The BST will almost everywhere be a degenerate tree, and this will make it take longer for a person to traverse through the tree. It will never be efficient to use such a tree.

To fix this you can consider using a different data structure. You can use a vector that is in ascending order of the student ID number, and each of the ID number in the vector can have its own tree. Not specifically a binary tree but a tree that will include all the details of the student (Address, Name of degree registered in, year of study, faculty, etc.). ",1.0,0
140,140,150,e2110671a4eab220560a21f9e1e9feb257ad75ab23f504a892c8df780bcf445f866d86be0cb87936d65c86a82a0daabcca41a6174ec4192f8f61c7d3034cdab4,"Each node will have a max of 2 children in a BST.

After 10 years, the depth of this tree would be very large and unbalanced, since most of the nodes would be aligned to one side for each year, which would not guarantee O(LOGN) search times.

A correction would be to balance it, forming an AVL tree because a time complexity of O(LOGN) would always be guaranteed for searches.",5.0,0
141,141,151,91ebe020e489f0682b9824bba92593f1328536973fcefa2088842b20b827aef8bdfb02c354fbd4b326e7989de48aea571427c17aa049b6dadee99c74f1c15bdb,"* Each year wits accepts new students so the BST is getting too long to, so accessing a student is close to o(n).

	* This can be corrected is the tree gets structured in a different way, make sure the AVL property in maintained so that adding and removing a student can take o(log n) ",1.0,0
142,142,152,86a089b08f86e9c1d63b469ed69474a00b3c8a302414b59395dac01ecff0bf909a9721c007531f0f7d3273bab8151790358055f69bbfd852502b400b0f09160c,"Tree is degenerate.

ID numbers of all users are probably from 2000 upwards and all get inserted on the left of the the tree. ( ID starts with 000..)",3.0,0
143,143,153,fecc59057a0e209589be1452a92558843a93237db9707d9614670e76673fb2cec05cbca3488156012b8fb3cd1467b373d250bc116d0aec57eaa9cbe2d676c3fe,"Binary search trees are setup in a way where the lower numbers go to the left of the parent and the larger numbers go to the right of the parent. 

Since ID numbers are setup in a way where the year of birth is the first 2 digits of the ID followed by month and day, Therefore in the first year the system is implemented all students year of birth may be very close to each other(for the purposes of simplifying the question/answer we will assume all students in a given year are born in the same year). Since we in 2020 and system was implement in 2010 we assume first year students were initially born in 1992 and their ID numbers will start with 92. Their month of birth should be evenly distributed over January to December. So adding all these students to the structure would give a fairly balanced tree. A the years progress over the next 7 years the tree becomes more right heavy as the student ID numbers start growing with the years 93, 94, ... , 99. from year 00 and 01 being the last  years of the problem the insertions should go down the left side of the tree starting to balance out again but over time become left heavy as the century progresses. 

The skewing of the tree would definitely bring about performance issues as the complexity to search the tree would start growing as the height of the tree gets worse i.e. greater than O(logn).

If we decide to still use a tree structure to represent the data we can add in a balance condition to our tree to effectively convert it into an AVL tree. over time the tree will remain balanced and the height of the tree will be forced to be O(logn). this will keep search time down to the max height of the tree. ",5.0,0
144,144,154,31f89aaef7c39dc86c93cfdeddea5fc5554c3cbe3838d2616d1fbc1745414f7096809e9261e2fb009c92beaaac49eaef9633b3b3c92cef0606b8cfb14522414d,"The system might be slowing down because the Binary Search Tree is unbalanced, meaning that the tree has more nodes to the ones side, to the extent that it is reducing the efficiency that a Binary Search Tree should offer. This is because the system is comparing students' ID numbers to determine which side of the tree the new student should be added. Each year, when first years are added to the BST, they will most likely be added to the right of the tree because their ID number is most likely larger than the previous year, due to being younger (i.e. most first years this year were born in 01*, most of next years first years were born in 02* etc.). This could be corrected by implementing a balancing algorithm such as an AVL tree. This will allow the system to perform its functionality at a level that a BST is supposed to offer.",5.0,0
145,145,155,ba6cb46aa6ff6581fcd2828d6944742916cd44c20dbee87513cab04b763159ab5e8fcc20c0eaa029b5cead3d4e1911b67590f3a4b4a64f4e9fa942648249fc12,Since the tree has become unbalanced. New users probably have ID numbers from 2000(ID starts with 00) onwards and get inserted on the left of the tree,3.0,0
146,146,157,5e36a0e7b93c9d082984c03228c748a0348993dbc7307752e7acfbf7e44b3df39b6aedb0dd5c68b0421254e8914343a9e052d4d15e260e3ecd7ef28810b12ec9,"The binary search tree may have started to appear more so like a list/chain. Assuming that student numbers are allocated in ascending order (year 2020 all the new student numbers range between 2200000- 2400000, year 2021: 2400000-2600000 to the year 2030 where the IDs begin 32xxxxx). If student numbers were allocated in such a way, the tree would start to be incredibly right heavy with little to no values to the left of the root. To search for a value you would very quickly start traversing the height of the tree which is going to be closer to (n-1) in height (n being the numbers of nodes).  Hence time complexity will be O(n). 

The solution would be to introduce an AVL balancing property. This will ensure that the BST will not resemble a degenerate tree and that the tree will remain balanced with a reasonable height. More specifically, height remains logarithmic and hence searches will also be logarithmic in complexity- O(logn). When searching through thousands of IDs, O(logn) will make a substantial difference in comparison to the original O(n).",5.0,0
147,147,158,3b7ba058c213da5b009b852338bd7811b0b333deac0854db354a0930a97dfd9a75a355c850c84b231661aa372d01d30ba66a900988cb0816a825f579f99d06fc,the increase in number of students would result in the system being slow and thus less productivity so i would suggest the use of a ternary search as it is more faster,0.0,0
148,148,159,da41b5784cff76181334839886a3282f17377acfc2b99b7b1cfd5eb402d7c42f7a8c3da46e88bb566478f9b4c4b7f67a4191bcc68a114acbd97bf83a3de9df3d,The memory is piling up so the best way to fix this is to delete memory that is in the system for over 10 years.,0.0,0
149,149,160,48b61851d938b41ee8c845154660df999994e48772e63eb0fc08241d1da91dd060085f370b13a4f968cd076d5b498fb619542e3786a80328ae705382da43a829,"After 10 years, the number of student records has increased and this has led to us having a very big and complex Binary Search Tree. Performing traversals has become very time consuming with time. I would suggest that the system should take a maximum number of student records and once it has reached that maximum it should create a new category of students that will have its own binary search tree. The categories of students could be divided into years. So every 5 years, the system creates a new BST for the new group of students. ",0.0,0
150,150,161,dd4d3f7f0edeb1ac41639c249d21094a6b301b7b08a2b59f88a3c56108d3780e80f6d45ac6aad546dd8e534b771a87a6c21d9fd70855e1599b2fe31c102d2f10,"the tree has probably become unbalanced, all new people most likely have ID number that start from 2000 and going up, and these will all get be left dormant of the left of the tree",3.0,0
151,151,162,b3e3cb2c21ce148370b5e2f91fd1c15e350a5dbb48b70710937a60df00151bac26d80bc3a7bdad4c31eb69ebb35264a7c7773c7f45cef6e057b05eb18d125d01,"N are the number of students in the system. As time progresses, more students are added into the system, which makes the binary search tree very unbalanced. The ability of finding, inserting and deleting names decreases and it reaches its worst time case complexity of O(N). It ends up requiring more compute time because of the excess rebalancing and caching is therefore poor.

To correct this, a binary search tree should only be used when the student names are full at every level, an AVL tree can be implemented for re-balancing or a new data structure such as an array could be implemented where values can just be shifted.",3.0,0
152,152,163,fab0c08585f01f39bdd5713989938b2aef8147d8e35de70c5d59fbafc82fccc76aba13478c24fc3147fdbd68a82631cc191656dd2fac4d8bab7b8a9d57889e38,the system is out dated ten years later and  a lot of students have become part of the university rendering the system slow,0.0,0
153,153,164,8c4ece10bea4707d74ad8e485b192cf388c1aaad3dd5b625cadaaa6a947d3861bc0547f235d6ff3af091e10ce08cd771b73e98b692a991cef32a92e7b557b387,"Since ID number are randomly selected without use of any specific criteria, the Binary Search Tree might be coming unbalanced. Initially, the ID numbers were allowing the Binary Search tree to have a good shape, that is complete or full but as the number of children increased over the years, this good shape was becoming distorted that is degenerated thus leading to the system  becoming quite slow with worst case search complexity of O(n)

This can be corrected by using a balanced Binary Search Tree like the AVL tree. Under this implementation, the student's record can still be ordered using their IDs but the structure will be different. This allows the worst case search complexity of O(log n) which is quite fast.",3.0,0
154,154,165,ef56d487f412ffdca7b3412858b2ccd1fa21fc365016661f00994f5e06683c6e545b948b70c4775a9a839e6049995e36f03b1f06a7374933a80a9013b6052c37,"the problem that will arise will be that as the number of students increase , the amount of insertions will increase too which will cause the tree to be heavily one sided and unordered .this would cause delay. With the help of using a balanced tree structure or an avl tree structure , the issue will be solved and the tree will be well balanced as searching for the nodes will be 0(logN)",3.0,0
155,155,166,cbae5eeb6217dfd80bce3b9f9dcc6a487de93ab5d86c0254cee58b6e3923317f7e11f9c1e67f0e0269268aa476f5f7d41a06d2c8bc23012e2299f02af5f41761,"Over 10 years thousands of students will be inserted into the tree which would slow down any functions.

But a big problem is that the students are compared/ordered based on their ID number. This means that in most cases, future students ID numbers will be ""bigger"" because their year of birth increases (which increases the first values of the SA ID Number).

Because of this almost all new entries will be placed on the same right side of the tree. So the height of the tree would become very large.

When searching in a Binary Search Tree the amount of work done is proportional to the height of the tree. (Thus depends on the number of nodes in the tree and in worst case can take O(n) work).

So the structure of this tree would result in a lot of time and work needed when searching for a student after a few years.

This could be corrected if students are ordered according to something other than their ID number, or perhaps just even a different ordering of their ID number (like swapping from YYMMDD to DDMMYY). This should result in a more balanced tree.",4.0,0
156,156,167,3143af8e534af5f9178a128c44433d6c35da771cbbc382af1235851f68f2e6c0baf6b6c7dc7aef9c829246db2be183570b22a8f6e1e10870c8fab148df9fe20f,"As more nodes are added the binary tree may start to become unbalanced and tend to be heavier on either the left/right subtrees, additionally, when nodes are deleted from the tree it can cause the tree to become unbalanced.
when the tree becomes unbalanced it could mean that a large number of nodes are ordered in a single line on the tree, resulting in a linear structure which will cause search times to become more linear ,O(n), as opposed to the original logarithmic complexity of the tree.

This can be corrected by maintaining it as an AVL tree and performing the appropriate rotations so that the distribution of the nodes is more or less equal across the tree, thus rebalancing the tree and maintaining it's logarithmic complexity.",3.0,0
157,157,168,0814448191d29da9008582aa1dc261271817cf4f70631f519f01177439d50267cb21e8d39c1f121e1aee03914798dbfab1836210758982742e26c801f01d7bc4,"the tree has become unbalanced.

ID numbers of new users are likely to start from 2000 onwards meaning

they are insertedon the left of the tree.

solution: use a balanced binary search tree",5.0,0
158,158,169,ff19555f4968eaf6b17bb10af6db84bf6855788e0e3b7ee821c1ffda56b494a21c444a2b2d428df7663376a15417c71a0487c22f17f2e142320070a4287c2554,"Because of the ever growing ID numbers, Maybe n has grown so much that it takes more time to do the search and there are now possible memory leaks.",0.0,0
159,159,170,d7ea0f2a38310b663df581928807c739d1135118819d5b7623733f4d054b7f50d32672538781df6012ffae2751400911c7d428efb70c05b3c3719b6aef5da475,"From a data structure perspective , the find/search operation in a Binary Search Tree has a time complexity of O(h). This means that the bigger our binary search tree gets the longer it takes to find a particular node ( and in this case an ID number). So after 10 years of continuous use we have a very large binary search tree which increases the runtime.  I would advise the university to use an AVL instead of a basic binary search tree because for the search operation in an AVL tree the complexity is O(log2n). This complexity holds for best and worst case situations.  I find this better then an BST in the long run as the AVL will always perform better than the BST in those worst case scenarios . Those said ""worst case"" situations could be when the data we are inputting is skew",3.0,0
160,160,171,f8ab0f6e15e6bf9e99acd11cfb6b5455d3c0019e87064465e59d88ccaf25c640a5ce1b900a6011a9e3fa052e11195ca6da9faf3eac510a5a07330facf6daee23,"As years pass by, the BST becomes very big and long and becomes inefficient because in the worst case scenario , we have to traverse along the longest path from the root to a leaf before inserting(O(n)), It might be that new students have IDs that start with similar digits and therefore all of them get inserted on one side of the tree, creating an imbalance . To overcome this,  I would use an AVL tree, so that no matter how many traversals and how big the number of students is, the time complexity will be log(n), even in the worst case scenario. ",4.0,0
161,161,172,7d8cef0de14cc2a74c530bc45e24878a9bc41b99484642b220015c976fedb5143bed1f3d3d656335fb8356093aebda35cf38a76a3da63375271eacce35baf518,"As the years goes the number of vertices increases the tree increases, the system uses BST to insert students. To fix this the system should either use min/max binary heap(depending on the order of the students ID's). From it will be easy to get the records of students that are still in Wits.",0.0,0
162,162,173,267e2a74684712f40153e983cf911454f693aaba7aeefb5a018f4e1b42bb05582faee8c5c865be8869988dea6e1c2f220a507c49209244aad2cd13359f2247d7,The system is slowing down due to the fact the as more students get enrolled the large the size of it becomes so it must be a perfect binary tree or it will take logarithmic time.,0.0,0
163,163,176,697569647a6a588c9c373a5024008db721a653b65b6012b1420a317275c41e987a73e70671dd59ab61b2f3c74ff4747358e271031a490a1dc6b41faa87e269c1,"SEARCHING (Look Up) for a student in a BST means we need to traverse all elements in order, which has a worst case of O(n). The time complexity is O(h) where h is the height. The ",0.0,0
164,164,177,105766c5f6c790d6dc620b520090a2b98c0a0346078f36035aaeb57fa8cf54742716f9a0480d2973b6fef7f78bbaa5ba4bda7aa17dd42f5bc2f195af88fa494c,"As more and more students are registered the insert method does not create a balanced binary search tree. This means it does not create a tree whereby the left subtree and the right subtree has the same number of nodes. This causes the tree to be unbalanced, and so to find the point of insertion we would have to recurse very deeply.

To correct this would be to implement the tree with an algorithm that keeps the tree balanced, regardless of the order in which elements are inserted. The insertion method could be changed from recursive to iterative.",1.0,0
165,165,178,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"=>Most processors have branch predictors.In the case of a binary search, the branch is hard to predict so the system might have been slow due to the system getting it wrong half the time.

=>It can be improved by choosing three random pivots(students) among the number of students only to choose one pivot amon gthose three,and record them recursively.",0.0,0
166,166,179,a871558daae8ec7755dd112b899b7fd46e06cb2a4cebf4c0a75ca226dba4bf419ef0333177fa6862ca71f931535c6fb1250ed993a029aa9b63a8c18ad277bce2,TREE HAS BECOME UNBALANCED OR DEGENERATE .NEW USERS LIKELY ALL HAVE ID NUMBERS FROM 2000 ONWARDS  AND ALL GET INSERTED ON THE LEFT OF THE TREE .WE CAN CORRECT THIS BY USING THE BALANCED  BINARY SEARCH TREE (AVL).,5.0,0
167,167,180,d91427bf4ad99661f4ac49ddce8054ec473a7fcef1ab133d8d24c3ab9e806480afe6773c225af63871bd9b36c6d59fe3d802d967ab7b71f90b46e5238ce08052,"As Wits register more student ,the number of student increases.As we add the data to our binary tree search it increase and the reason why our system is becoming slow is that our insert method is recursive,that goes deep,and this will end up not create a balanced binary tree.From root ,the left subtree is not equal to right subtree,or where the right child of every node is null,this result in extremely unbalanced.

reimplement your tree that keeps the tree balanced

  ",0.0,0
168,168,181,16cb13e3f20264dff11bab6b4074b1ead9b8e1cf1d7a12dd1238f56fff77a643c79324083d48280a979ad65c97d7690c011f0b94300438693e7e3022511b7be3,"BST can easily become degenerate eg: the ID numbers of new students may start similar due to students being born in the same year, and the longer the decade goes on for the more students you have with ID numbers starting with 0. They would  be all smaller than the root of the tree( students born before 2000, with ID numbers starting in the 90s) causing the tree to become left heavy and end up acting very similar to that of a linked list which would be very slow with this huge database of students. the lookup time for a student could get very close to O(n)
A way to avoid the tree becoming degenerate could be to implement an AVL instead as  that will always remain a complete tree by rotating the tree each time an insertion and deletion happens to maintain the AVL condition and will not see significant slow downs later on when searching for a student as you will be able to find a student in O(log(n))",5.0,0
169,169,182,7fa0256939f3801d7cb837f49e23433b9e2c72a7153a75d58ee05f6ce597913275599303f990f67fdc180f91407271656e81578b90488fda76d6e550e9bb3533,"In 2020 students are most likely born in the late 1990s or early 2000s. So the BST works great as the students born in the 1990s are inserted mostly to the right side of the BST and students born in the early 2000s are inserted mostly to the left side of the BST (ordered based on ID numerical value, also ID number starts with year of birth).

However over the next 10 years the system will keep inserting new students to the left side of the BST since students are most likely born after the year 2000 so the ID number numerical value is smaller than the students born in the 1990s.

This causes the tree to be unbalanced and left heavy, which acts like a complicated forward linked list. This decreases the efficiency of the BST as time complexity becomes more linear when searching.

To correct this it is best to us a AVL tree since inserting to an AVL tree, it will always balance the tree to the AVL properties. Hence keeping the time complexity logarithmic.",5.0,0
170,170,183,5602a599f37ceb4d3d0abbebb674a8cfae2a81d9f53137cfbc7a1bded150cbaa8a83e4431db27b0e21c60021690e3731e8677add172b47aa9e637944b71f019d,"As the number of students increases it will take O(logn) time to modify the list, to retrieve elements of the list will take a longer time too.

By permitting tree rotation we can try to minimize search time",0.0,0
171,171,184,8898c8dc647252a67895b09c0b6e1e1b46e9abbd7623ddf40416335c9bffe71bf94348a71bd79a7ce33d630fd22f8d8b30ee288c330b6c240bf1f662dbee2a5b,"What could be causing the system to slow down?

-After each year when new applications are accepted, the general birth year increases and so the new ID numbers will (at most times) added to the right of its parent. When this occurs over years, the subtrees become degenerate and the asymptotic complexity approaches O(n), becoming inefficient.

-The jump of the first two digits of the ID number from 99 to 00 could also cause problems. the ID numbers starting with 00,01,02... will be always less than those with 99,98,97..., this also causes the subtrees to become degenerate. 

How can it be corrected?

- Rather than using a Binary Search Tree, we can use an AVL Tree. An AVL Tree balances itself (when |h.left-h.right| >1) before subtrees start to become degenerate. And so it maintains the O(log n) complexity (when inserting and searching).",5.0,0
172,172,186,b3916d46d881833f987b1688b8c10f933afdc9a4fa5bd760932846eb945fb5e69406c926d4b58830137510a4b06c87b7babebfdb5983ea8a0ed2ed2ae65cf4e6,"The BST becomes unstable or unbalanced.

The new students within the 10 years or even after are more likely to all get inserted on the left side of the binary tree since there are high chances that all their ID's start with 00

This could have been corrected by using AVL-trees and Balanced BST",5.0,0
173,173,187,c718924f7c8d9a7a64a6ff4f30cf0bd792fd01badc8e93c67bb9f465f99e38ae7a35ce6981a32a52aefd75b95f9c2030a30069dc473e0db1d92882cea2629f0f,"The tree seems to be degenerate. New students IDs are added to the left of the tree, causing the imbalance. This can be resolved by using an AVL tree.",5.0,0
174,174,188,9f85bd574a0fb5fa07c95cbd2dc5aa7f4cb77f83ea58b24cf50b8a111ddaa2e08d644409b7ea28dad73defdb2393c136cc039b51ec3ed144b40271a76c7c7470,This happens because  the memory starts to overflow over time and hence we can fix this problem by regularly maintaining the system.,0.0,0
175,175,189,939ec9a57a50490db2733608917f50113db66f29232d7ede4b3f765d85522c6883d672d7c5bad821ddeab74dbf066c3294635d07979c4557288fa30e0ff3d929,"For searching all elements ,we have to transverse all elements, with a complexity O(n). The time complexity is the worst case especially after 10 years. It would be inefficient in terms of time when we have to search for a student. The deletion also has a worst case  time complexity of O(n).",0.0,0
176,176,190,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,The nodes are not visited a certain number of times.  The nodes needs to be visited a certain number of times for the system to be faster,0.0,0
177,177,191,3d5672708313ecdecf3f1bac84303e47d2cb39b8840c7477b8533d1e068614b468fd7d22ee29e9082419dadb2d36cb98607131a6fdfff05e1696dee4c36a9722,The slowness of the system might be caused by the large number of students records that were being kept over the 10 years. When looking at student it will take time because there are large number of students in the system and also adding a students records. Would have to search through the tree and in some cases the student record can be located at the leaf of the tree. When searching for that student it will take long to find that student record.  The problem can be corrected by using a vector.,0.0,0
178,178,192,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,The progression of the years results in the height of the tree increasing. This increases the number of nodes that need to be processed and invariably increases the processing time. This will lead to the retrieval of data being slower.,0.0,0
179,179,193,3ea55861b5c8eafb81b8565f1d54cc453a6c146015319e65651c96131a93fe003ed97c4b0e5ead0032066879ea3f910a9115040fa5bb190fe1c4bece13c4f763,"In 10 years, more students would be registered, this making the BST wider, and take up more memory, this would cause it to slow down. It can be corrected by making a BST for each year and then saving it. After saving it, It should be cleared.",0.0,0
180,180,194,2e609516b3c283ff23ddaea06d0df01ad6175f48861d0223a4409ebe1c7df8e383fe146f147415f2605c7a0103b96921b1ffd763ab4924efe18fd229dedbae68,"From a data structures perspective, searching for students in an unbalanced/non-AVL binary tree in the best case will have a lookup time of students of O(log n) but in a worst case O(n).

The reason for the search being fast initially then slow over 10 years is due to the fact that in 2020 there is a spread of students with ID's starting with years from prior to 2000 (_80-90)_ and students with IDs proceeding from 2000 (_00), _this means that initially the binary search tree is sort of balanced between the two generations making up each sides of left and right branches of the binary tree. Which leans the search complexity of the system closer to O(log n) than O(n) in 2020.

However over the next 10 years, the majority of new students added to the system will be born in the years 2000 and onwards, and new students added to the system each year will generally have ID numbers which 'increase' due to the procession in years on ID numbers (eg. in 2021 students with ID numbers 03xxxxxxxxxxxxxx would join but in 2025 students with numbers 06xxxxxxxxx would join). As a result of new students joining with incrementing ID numbers, the binary search tree branches which stores all students by ID number will become skewed more heavily on their right side, eventually forming a branches which resemble the structure of long linked lists rather than parent-child trees. This and the fact that the tree is unbalanced(degenerate) are the leading factors in which the tree search complexity becomes linear O(n) from what it was initially logarithmic O(log n).

To correct the inevitable unbalancing of the binary search tree it is important to convert the tree from a normal BST into an AVL balanced BST, which will ensure that the binary search tree does not become a degenerate binary search tree and maintain a O(log n) search time complexity when searching for new students.",5.0,0
181,181,195,0745491c3d066e21ade2f2d4d85d4695dac91b9131eb26e8aed287a29c7e24ee4d3c6beb342324906b0ab6475785f0d2fea5c9799af48cbec9547c62e95d041e,"Since Binary search trees work on the condition of LeftNode< RightNode and ID numbers are fairly arbitrary, when added over a period of time this may cause the BST to become unbalanced since one branch may become overly favored and replicate the structure of a linked list.ie. The tree becomes degenerate. Hence the tree complexity will become closer to O(n).

To correct this we will need to have a balanced Tree so we can implement and AVL Tree which uses a balancing condition which ensures that the tree remains balanced and the time complexity always remains at O(logN).

 ",3.0,0
182,182,196,64e451748c8e64219c1dcf31828cb7ded38a1447346285c9e9b6559aebe71fd6c492c0cffcdb5c0c6a652b339b2aa51ca0d8310a628f12a661261dc55ced044f,The cause of slowing down of a system is because the amount of student BST increases which make the system to be slow.It can also be corrected by changing the system from BST to a system that will be able to hold a high amount of students.,0.0,0
183,183,197,379090fe3e1a52426e2efa659f8053df23496a4ea586e166878cbb0762b73fc0c775123cfc178af91eb03c2a90701a95a01965d904e259f9143a2034f3310380,"I would say the problem would be after some time of inserting them, they got skewed to the right (i.e. The tree became right heavy) so traversing through it and inserting took longer (i.e It takes O(n) time to insert and search through the BST) .

My advice would be that they use and implement AVL trees since they have a self-balancing property and also the improved time complexity of O(logn) for insertion and searching.",3.0,0
184,184,198,0b4066304490dceaa89df857c52096e501a361b0158a4122fe0743ccedb637acfd51e379e86df6a8a4f667a87b6d33f81aa5b4a035dd7d71db1ee1c7171afd95,"the problem might be that the binary search tree is unbalanced or maybe skewed too much on one side since we have been adding a lot of student records so you might find that to find an item you have to go through the whole height of the tree which is inefficient, to correct this we should use an AVL tree since it promises us that to traverse through the tree we would use logarithmic time(O(log(n))), which is ideal",3.0,0
185,185,199,eaf6c4c43d71c21a9611ab529dceabe1fb33ac3bf543bdbce13d249f7b6251a8ae478c786f76da007fed6f3e8c11ab62610c853fb7d3dd853fe2afc80fe40704,"one cause might me that the number of students has just been growing for ten years meaning the bst just kept growing too, and since bst works on lists that are sorted which is not feasible, especially since elements(students) are constantly being added to the list the high number of students lead to the system slowing down with time. 

To solve this from my understanding is yearly maintaining, you will have to delete students who have graduated / deregistered / died basically all who are no longer studying at the school",0.0,0
186,186,200,bec70f18652f9b1ec67ee94e23471083fc0530aad868499d925d500e71ccfd4f82652eb49a909778379c4583e97ce1464a3ae78de3b07114cb3a9e4c1179d625,"After 10 years, the amount of data stored in the tree would have increased a lot. This could cause the system to start slowing down. ",0.0,0
187,187,201,2752a012a3acfc041a30d5a655085eade0eb440b54f67d20ed248f27ebf41fd19d90129f4fd7d4c48bc1b7b721b3638118e357f1785837b03bc7def7da08253e,"The tree has become unbalanced as the new users will have ID numbers from 2000 (i.e the ID numbers start with 0...) onwards which will all get inserted on the left of the tree. 

A single rotation will fix the problem, therefore it should be an AVL tree.",4.0,0
188,188,202,9dfb1f3f8489eba0c312316ab375b0eb3fde4cc7c592108ea20fe9063368bfeafc3cfc95ddf50eff3397d93bb8f4939d82490505e330285e8ec3eab94f0e646a,The system might be cooling down because of an increase in the amount of students in the binary search tree and a potential degenerative tree. This can be corrected by turning the binary search tree into an AVL tree so that the search is done at O(logn).,1.0,0
189,189,203,d7c77f30d552bc7123c47a393150633fcb38e3fd4494c0719ab3e795427a25ebd94ddf4a99e62386015c277c2ae9c2c2987302ac9d67747a56f662f55ee7b2c6,"The tree has become unbalanced.
The new users likely all have ID numbers from 2000 onwards and all get inserted on the left of the tree.

A single rotation will fix the problem. ",4.0,0
190,190,204,82694cf634b012a9b99356edee5aefc22b24ba7895f93507fd59a70aa1b507058de91ae69d4a669273414cbd851ebdc45bb8d210bcd7e76b8c63d620d83813d3,"The binary search tree may have become a degenerate tree in which the height of the tree becomes unreasonably large making all operations on the binary search tree inefficient.

A solution to this problem is using an AVL tree instead because it keeps the height bound by O(lgn) by using balancing constraints and thus it will make all the operations that need to be performed on the BST much more efficient.",1.0,0
191,191,205,135bdbdca9dab16566a02b87eb86b2b03e986360c36387bc6b252f2a7b0098a14637a43a9d1d68d223771b954b34555f039489b7af8726eba774f24a3c3a0d42,"ID numbers increment over time, causing a binary search tree to be right heavy as new ID numbers are only inserted on one side. This creates a degenerate Binary Search Tree with a maximum Binary Tree height. Looking up a student could take a linear amount of time in the worst case if the student has the max ID number, O(n).

This could be corrected using an AVL Binary Search Tree. This will allow the tree to be balanced as new ID numbers will not cause the Binary Search Tree to become right heavy. It will also make looking up students easier as not every node needs to be visited. The height of the Binary Tree will be logarithmic in this case, therefore a better time complexity. O(log(n)).",5.0,0
192,192,206,a8e9f7af885a794cf115ef4ae2efb719a045fef1a67ed1ceb91d47fac21a3c207363f092625ba28d25fab14149b9e5cb63f7997360c20c56ec6163be05ed3db3,Bst employs recursive approach which requires more stack space. Also programming bst algorithm is erroneous ,0.0,0
193,193,207,51b14b2f7889e1ac981e708359c401aa462001095a9f5423485f3bbb9e8ce44431d8f3cccca086e476a0ff46c4b6be46a5ea213e998e4c15dbacc349673103fb, 2020 is ,0.0,0
194,194,208,525cefc66631b9eb601410acc1c632cc3a6d9976bb8f3ac653d46807a4053f29a6c3c85a0e8a38a43486b45bae46acd949e27f910bf00828afed11257c7034f3,"Over the period of 10 years the number of students greatly increases, making the tree larger and larger. The best way to fix this would be to create an algorithm which would encode (huffman) the entries thus reducing the lenght of the entries instead of identifying all 13 charectors of the ID number.  ",0.0,0
195,195,209,1a588e676388eab699476b49a00fa1013110acdcf89dcc5a2ff2c6e7b4d1cc5fff03a1daa5e3f8069ad9a846f88030beb884f390c11da3f442ee0a6ebc1a9307,"A binary tree is most efficient when it is balanced and over time the tree might have become unbalanced by the growing number of nodes in the tree, so we would need to ensure the tree stays as balanced as possible. So we need some self-balancing mechanism in our binary search tree algorithm. We could implement an AVL tree which is a balanced binary search tree. So every time a node is inserted or deleted the tree would go ahead and balance using rotation. ",4.0,0
196,196,210,f682ecdc1752e81b56fe41b112e9132a1831f14cd9ba0ec72eae2c8c098b94a2736f903a3211d58aeb928498913e4972f6d3f995b03aff3dca7903b620bfdd1e,As years grow the size of students that gets enrolled grow too. And this will lead to the system taking longer time to run. So in order to resolve this we will have to make sure our BST has a perfect binary tree structure so that the search time becomes logarithmic(Thus the system will have better perfomance). ,0.0,0
197,197,211,a83848dae9e11c32fb0fef1054c9f0420423c74efa66838a210a7774eb07b64f5a5df97bc2a33594ee565ea37cacb65f8fcddd5281fc0b93d6e6e1b0ba5da1ac,As the years go by the number if students increase in the BST and the degenerate tree making the BST change into an AVl tree so the search is done at O(logn). ,3.0,0
198,198,212,d9db0d62eb972d7cdf4f37e10bdbf3c1fe24b4325a048050d64042994d0e2a7ef0c9b1f76e9ab479bae9fb331e67c69ba4663f294fef8e66b6d36cb8560984ec,"This is because time to access an item depends on the index and the number of items. 

So at first there were few students and the system had to do less comparisons of a student records with their ordered base on their ID but as the number of students increased there were more comparisons needed to be done which takes much longer because one comparison is done at a time and thus it takes much more time and slows down the system. This is the worst case scenario, where each node has one child.

Also because of the space and memory, at first there was less memory required as there were fewer students  but after 10 years there were more students and more memory used which slowed down the system.

The time complexity is O(n) because a single comparison is done at a time.

We can improve this by optimizing our data through sorting, for example using the Merge Sort algorithm to sort the students according to their degrees maybe, then after sorting, we do the comparisons and this will decrease the time at which we do comparisons and increase our time complexity and speed of the system. ",0.0,0
199,199,213,2a38888a8b80ad136312b78d25e48a8f2ffafd5c8eeba2c39a3cf4d0b1565a722030f9463fa977a5038fd88a16d989882eed3aeb8631f846fa1888531a07766e,"The height of the binary tree increased over time as the number of students increased, hence when you transverse the tree it will take a longer time thus the system will be slow. This tree will have a degenerate tree properties; a height of n-1; ",1.0,0
200,200,214,86eb6a509a4b81bb5d0775617d6b551b5529a8196aa8cfd54e1d4c97046fcb8692ee1866ca18888be1695e57bab3f84e888b219e99049227e002908717268d42,The reason why the BST is slower is because it has a larger amount of data and the BST is imbalaned.       ,1.0,0
201,201,215,b4e094c982f7331975cb926eaf035ebce731db0364374bd4c72773048d23a8f901eb66b98a1aa6744d785a2a739991dc6061132d03cc224ca0f87155c45d2fc3,"I think what causes this is that as time goes the number of students increases in the BST and a potential degenerative tree might cause this problem.  To correct this, one must use an AVL tree instead of BST.",3.0,0
202,202,216,410f5f2a0ab82ccde7abe6a8e7d7cb9864a018d183c6ed86c6cce29f6e2d9844145b0454fb1b2fbcceeee4cd055b83957007dfb5bfe20ad1ba170076440ad2aa,"Chunks and chunks of memory are stored on the servers and because some unwanted/unused memory is not deleted, it  will start to clog up the the servers causing it to be slow.",0.0,0
203,203,217,14bf4a341dc9827953823163cd007e766c263b8c396bea85416367e8c4908e0df252e9e3ac38e08223a3bcc05a108adef9f1881af30b78d3c7220ceb7c6be157,"A binary search tree is a hierarchical data structure and so initially, the tree is able to store all the ID numbers effectively and maintain a tree that has both left and right nodes making it easy to traverse through for the required value - this is the best case of storing the ID numbers of the students .This gives us the best case ,where the tree has a logarithmic height. Over the ten years however, the ID numbers start branching out from one node, per year of student enrolment , this leads to a degenerate binary search tree which ultimately results in degenerate subtrees of the tree we had in the base year. This gives us the worst case where our tree then has a height of n-1 in the subtrees , hence slowing down the system over time. ",1.0,0
204,204,218,517d279e4f4fa180cead9abbf9164c66f1f5087d4cdf819d16181b872c485b731441c3c47f5e4caa6ebf9c8752b2409dfa2a4b66821ec7f949cd467f9af4a449,"The increase in the amount of students in the Binary search tree causes the system to slow down.
This can be corrected by turning the Binary search tree into an AVL tree so that search is done at O(log n)",1.0,0
205,205,219,b62178f325a37f31c95fa1765add6431ffda3b6e9e137a6c1634820014c3bfc3f4c574a7130344e47d262896d038b700c7e7372470c7667fbf621506106a2a97,"This system would slow down due to the BST becoming unbalanced/degenerate.A possible reason for this could be; as time goes on ID numbers tend to increase, thusly all new users will then be added to the left of the tree, or as a result of users being removed over the course of the 10 years could cause a skew of the data to either the left or right of the tree resulting in an unbalanced/degenerate tree.

A possible solution to this problem would be to use a balanced binary search tree, such as an AVL.

  ",5.0,0
206,206,220,999b8af04a99b1971783a730d1a109e30fdff2f88a1f40dc36731dceaa01148aef1c1f5d96b5999593020819ebc46f676235aa6d5dc12859b91750c9e8b5c9c4,"As I keep inserting new and deleting previous data the tree started to be left or right skewed,this mean the height of the tree became O(n) instead of O(lg(n)) which is  the height we are looking for as it makes operation efficient.a tree of height which belong to O(n) has time complexity of O(n)  .deletion is also the same as insertion ,time complexity is O(n).

An AVL tree will fix the problem because it has a property where the difference between height of left and right child must be 1 or negative 1.whenever the property is broken I can do rotations to fix the height of the tree which gives me a guarantee that the height will belong to O(log(n)) and the time complexity of search and delete will be O(log(n)).",1.0,0
207,207,221,6e1111ad11474e6379168f87057eae3076970c620dec3cffde8e98db6de9322b94aefef0b0414a791717f61331121e1ad9f15c607c1ff40afee80bcc8c3257b0,"There are two possible issues:

1. The ID numbers might have constantly increasing, such that a degenerative tree is formed and extends only to the right of nodes.

2. A similar situation may happen but this time with the ID numbers values decreasing, and the nodes extend to the left nodes only",3.0,0
208,208,222,c1286f1c232c6d387eeffb3a9ae6d790ac3ad1f1fac37750b18cf612c71fd36fe953b51c47fd9c32675834dfcfeeb4241d300006f8e7524c2034298fbdb534a5,"The slowing down of the system may be caused by an increase in the amount of students,thus increasing the size of the binary search tree.

This can be corrected by turning the binary search tree into an avl tree so that the search is performed more efficiently at O(logn).",1.0,0
209,209,223,a8b16fc0f5a2c752f3497016181c5ad9db439554c5d81073a232375aae20a22a97cca43a22eeec6af33455ba644c036ec4f0c737bb5b05eab312d892fb42141f,"If all student numbers increase by 1 and the smallest student number is placed as the root of the tree, this would cause the tree to look like a degenerate tree opposed to a complete or perfect tree structure. This means that it will be no different to using a vector or linked list. It will cause the system to slow down as it will be doing O(n) work when searching opposed to O(lgn) work. 

This problem can be fixed by picking a median student number to act as the root of the tree to balance it. 

Another thing that could be slowing the system down is having old students numbers still in our tree. When looking for new students, we'd have to go through all the old information first which is unnecessary. Putting students who have graduated into a separate tree and deleting them off the main tree might help to make it quicker. ",1.0,0
210,210,224,13c060e9a128226d326b883081af9bf1d8d87f9594a5842046c134e481d515a3c3262c6c71b891f6321e7a0714b1981629c933e2f5180f487fe5e4ff9fbfb937,"when we increase the input of a function we are also increasing the running time. as the input approaches infinity there will be asymptotic complexity. there is a possible that the number of students had increased which slowed the system.

we can improve this by updating the system in means of changing the BST to AVL trees, this is because from Big(O) chart we can see that O(log(n)) perform excellent which is in AVL trees.",1.0,0
211,211,225,d677c40ee83c073e739609546ee27f2f0369bdfea2f9eb4c0be282329c3c282f85e22f67cd4095d13179a1dffcedf7b97c35e169242b176c21ab16ca909706cb,"At first we see no problem with the time time takes to look up a student since the students in year 2020's ages don't differ much hence the identical numbers won't also differ, this will form a balance tree. As students enter university it will start becoming heavier on the right then tge tree loses balance. The height of the tree also changes from O(logn) to O(n)  making searching through the tree slower because  O(logn) is faster than O(n).This can be solved by transferring  the tree into AVL and changing the height from O(n) to O(logn) . Balancing the tree with AVL conditions then searching wont be slow",4.0,0
212,212,226,a6cbd9ef4254fe8af85a007d826775c435fb06a9685b41af9c8fbcc1aa9032cf01b8f0c9af4ef707e7765a02209b930d4e00c4f235567b637a6d4f874da706d3,"The system slows down due to an increase in the number of students in the Binary search tree and a development of  potential degenerative tree.

This could be resolved by turning the Binary search tree into an AVL tree so that the search could be done at O(log n)",3.0,0
213,213,227,9dc85d5fc9d9d7b3ced470df92bc3f618b906428cc44daba96ce09d4da7c5e6251f817ad8b6d168d5489d3951e1d39f87f0ab87e50f2ae36060fe5a0c0501b6d,"The structure is only that of a Binary Search Tree, which means that there is no balancing condition in place that ensures that the shape is efficient. Therefore, over the course of 10 years, many, many students may have been added, the result of which is several degenerate subtrees. This would lead to the height of the tree being absolutely ridiculous—nearly equal to the number of nodes in the tree or the number of students, in other words. Essentially, the system would just be going through a sorted list until it finds the student it needs. The best case would be that the student is at the root (so O(1) work) but the worst case would be close to checking every single node (O(n) work).

The solution is to implement a balancing condition that ensures that it is not only a Binary Search Tree, but also an AVL tree. This will prevent the existence of degenerate subtrees, which in turn will lead to a smaller height and therefore, fewer comparisons that need to be performed to find the student. The condition will enforce that sibling internal nodes have a height difference of no more than 1 and the result will be that the tree will always be at least complete and sometimes, even perfect. Therefore, the work that would need to be done to find a student—equivalent to doing a comparison at each level of the tree until the student is found—would be significantly reduced. The best case would still be that they are at the root, which would still be O(1) work to find, but the new worst case will be equivalent to doing O(log n) work. 

Insertions and deletions (new students enrolling and students leaving/graduating, respectively) will be a little more complicated, since the condition will have to be checked every time and rotations may have to be performed, but this will still be better than trying to insert to or delete the end of a really long degenerate subtree. (Deletion will take longer than insertion).",3.0,0
214,214,229,2aebde6b5faaed73a67c0847887873c4b7d8d2f0c1ec3c5d1ae00fb183c3e53559681b2ee97a4692d74712db8b222e3239fa5e199b01863e771a9daa54a4abee,"To search for students ID number in the tree, the simple path is taken from the root to the leaf ,  as searching through the tree is done in o(n) amount of time and over the period of 10 years the number of student was gradually increasing which then required more to be done when searching through the tree as the path became longer and longer.

A binary heap can be a better option to optimize the work because the ID numbers will be sorted in a special order which will enable a quick search through the data.",1.0,0
215,215,230,55fe3fe2f479a6880b0c712c4e8a68696125fae47531859339e76b32fd81a881527cd93fc43bbd4116f56991339ff706e490311026cb817361fafa6e47ec0b11,"The tree has become unbalanced(degenerate) ie it is many times over heavy on the one side.

new users are likely to have ID numbers from 2000 and onwards where before it was all the 1900s people so their ID numbers started with numbers later in century such as 98,65,73 but now all start with 01,04,02 which would all go far left.

to fix this you could use a balanced binary search tree.(eg AVL tree)",5.0,0
216,216,231,07076ad9a7e3813bce19a739ebedaab894d1a330269763e0925227d8822b601591c19afe0ea5ecf81637c9b73f442db6cacafab2329d262fef0fb68d97bef78a,the number of students in the BST will increase over the years and a possible degenerate tree may create a BST into an AVL tree so that the searching of students is happening at O(logn). ,3.0,0
217,217,233,385c7b29eec3366a404f1d7e1159d0447aefec67a3c8b61a32481883579eeb6ab7ee9fa654afbb7d3b9a4b7a30f0a2b32be3cbd9d9a3dfbfe943be567e01c394,"The use of memory.As the system gets used, the memory of course is also being used. So the system can get a bit slow because of lack of memory. Deleting information as time goes on will reduce memory leaks. ",0.0,0
218,218,234,128e2656328deed2d77d2ef28a4c653d82a40a62fd734c4ccb3dafb70805db8a812cccc608184c6cbda73e2bdda34e6f81ec5dacc95d16cb9a78cba4ff089ac5,"As the data fills over time, the speed at which",0.0,0
219,219,235,a4b357e6c513407a3f73e018d48744124b021c84118df87b2c5b8e04d323a2617925ac5e8914f6f5e2cef827697f24c494dff1b737d41053b4639d5bc52397fe,"As time goes by, the number of students admitted at wits increases every year.

therefore 10 years ago there were fewer students than in 2020, as a result keeping track of students was easier because of the smaller number, comparing ID number and student record took less time because of the small number, but in 2020 there are more students and that means more comparisons and more time taken to compare the student records and ID number making it less efficient and take longer",0.0,0
220,220,236,f64eaf53775ca019aa46e95d674f953f5fe42b8661af69f4cf932eb77a69c0b6057310158946905b9d5788a5b3a8acd5e3f0f489603023b3ef81fc676dabaddd,"As you  push  back  IDs to the bst tree.you you will pushing back the ID that is less than the previous one causing the BST to be left heavy which is inefficient .to slove the this we would use the AVL trees. 

AVL trees will be helpful in balancing the left heavy nodes making the memory more sufficient avoiding memory links. ",4.0,0
221,221,237,0fa5d829ab37316f131667488ff6244b79b525ac275e022289de875a4f7426de94ef384d30176ee34a2851d47d343e62431c37057ae6054ad83ff76862ff86ab,"As you add ID's, you will be adding an ID that is less than the previous one causing the BST to be left heavy which is inefficient. To solve this we would use an AVL tree which balances the records.

As you remove a records, the pointers will be pointing to an empty memory cell if not accordingly disposed causing a memory leak thus slowing down the system. To solve this, we have to use the delete keyword to make sure that the pointers are deleted.",3.0,0
222,222,238,144eeee721d9e8e354eb4082314275e62c11041d44be43b8ce859ef7b3771d75b20bf8c5e57d1be61ad45dfaf6913441e9f0c454cb3f6c496eef977f71a42b51,"The system may slow down because as you add more and more ID Numbers the number ( value ) are increasing , although they are ordered at first that is why the system was working fine as more and more numbers are added from the structural view of the BST we keep adding on the right hand side of each node and therefore as time goes the BST becomes like a degenerate tree . and traversal will need O(n) . We can use the AVL condition to make our tree balanced so the traversal takes the best case of O(logn) ",3.0,0
223,223,239,744cc5a93fd7edad364406b30ceaa6836705a7419bd01ed97b04c61f1235130699ff789e400cc607e1772b19b35bf800957b6bd74b1e52cf1974d01500560533,"The reason is because each year new students are added, and, since the BST is based on the students' ID, the order of the nodes in the Binary Search tree becomes very inefficient. Each year when new students join the university, their 'BST node' is compared to the other nodes and if their ID number is greater than the current node's ID, it will go to the right, if it is less the current node it will go left, IDs are never the same so that case is excluded. Although this property is maintained, it does not result in an ordered tree. This causes searches on the data base to take a long time. The BST is most likely degenerate after 10 years and hence searches take longer. This could be corrected by implementing an AVL condition and converting the tree into a AVL tree. This would result in the tree no longer being degenerate. This would result in shorter paths for searches. For clarity, an AVL condition is as follows: the absolute difference between two siblings may not be greater than 1. ",5.0,0
224,224,240,36dc611e5a5c4c004053dab4fefc6b9a5b0bc6b95bad46c0ada67bd1d7f42775da4dc0cb387f6915f676d0a13a5decf47d86380ae9bc1d77138d6578f380b0f1,"Primarily the BST adds or removes records, so if there would be an ineffciency, it would be in either one of the operations.

For removing records, an inefficiency would be improperly disposing of node pointers when a certain record is deleted. This can cause memory leaks which will fill up the memory of the system hence slowing down adding and removing of records.

For adding, a possible inefficiency would be if there is a continual adding of records that contain ID numbers that are less than the previous numbers. This will cause the BST to be lengthen on the left-hand side which will slow down searching the tree. A suitable solution is to implement an AVL tree instead of a BST.",1.0,0
225,225,242,f786d4a53e476362ee6b6cac013b5aa057803211cb74556b039162da9be82c23d9395512d9e4320c69ff2f74e18df3e862b758b12f302cbbc8a9df857835a235,"problem with BST is that height is not controlled and height mainly depends on the key, searching for an element also in a BST has the worst case complexity of O(n) and the more the height increase the time complexity will also be O(h) so as the number of students grows it  will take even more time to search for a student.",0.0,0
226,226,244,81154b05e4f928b53509f7c1c5be300df7727a57475fef4dc890a0ed2da338d799d10f5f4687d4b684727a16cbab8d171f22f9e0fd6eace7b2dad79dbb4aad65,It can be that the system is thrashing Meaning it is running larger files which then may cause the system to degrade. We can correct it by increasing the computers RAM and decreasing the number of programs that are running on the computer,0.0,0
227,227,245,ccf7d410dc101f452d9a948b712ad377b341ca6596c1859156f3933afb607efc0a86da4f59e37c6e1a277f9ce0eea0ef54b5043786b160cee7cc698898c1aa62,As time passes and more entries are added to the tree the tree is most likely becoming unbalanced. The tree is at its most efficient when balanced due to the nature of the traversals used to insert data and search for data. A suitable solution would be to implement an AVL tree. This is because AVL trees make use of functions that balance the tree when data is inserted or deleted. This will make finding data of a student substantially faster (with a a worst case of O(log(n)). As well as making the system faster it future proofs the system way better than the BST. This is because it does not slow down as significantly as a BST when the size of the tree is increased.  ,3.0,0
228,228,246,9d9fbdb8f0b5a55cc81f40af01c24b37d17fe31db439c419f81b64ca34d8f4ebfcf1ed9c7ba472f3885693ca593e5565dfb6d3c7a7ecc8755427baec264e52b2,"The issue is that new student ID's are made in a sequential order, so every new student ID added to the BST is larger than the last one added, and hence it larger than all the ID's being stored in the BST. 

So when inserted, the new ID continuously goes right in the tree until it reaches the end of the outer right branch. This results in a degenerate tree (or at least something very close to a degenerate tree), and the more ID's which get added, the more unbalanced the BST gets. 

Balanced trees organise their data in such a way that the height is always a logarithmic function of the number of nodes n, so when we search for an ID and have to traverse the height, we end up doing O(lg(n)) work (lg = log base 2) instead of the O(n) work we were doing with the degenerate tree (and this makes a major difference in performance as the tree gets very large). This is what is slowing the system down.

To correct this, I suggest turning the BST into an AVL tree. AVL trees add a condition which ensures the tree remains balanced. To do this a number of rotations would need to be performed to transform the initial BST into an AVL tree (or you could create a new AVL tree and copy all the nodes over), and after that every insertion and deletion may require rotations to keep it as an AVL tree. However, with this method, searching should remain relatively quick as the tree grows, and it will certainly be a lot faster than previous. ",5.0,0
229,229,247,a69e74ae8b4a039273c9779403a7bf9afeff6c0402c7c4b81445db3dcb6b7c6d2a0c70d795b1a5404bd22d002454afb4812336b41db02ff960eaf7c2625641fa,"When searching for a student we have to start at the root node , compare what we are looking for(in this case an Id number). If its less than the root node we recursively search the left subtree or if its larger then we recursively search the right subtree.

With more students entering Wits the tree gets bigger. In the worst case what we are searching for may follow the longest path of the tree fro the root to the leaf. Meaning that the work we are doing is equal to the height of the tree. 

This means we are either doing O(log n) or O(n) depending on the structure of the tree. 

Using an AVL tree( balanced BST) which is self balancing will help speed up searches.",1.0,0
230,230,248,d3ddf356f072bf43331098b8a43e33c8b3192b402decaa6c3b442e9385a8eff79ab7318fc38d8ae8da018a53bd14daa455a684126f1cf0ce97908dac2dc0af07,"So if each year we keep on adding student numbers that are either lesser or greater from the ones on the previous years our tree may become degenerate . Meaning its height will also be increasing as the we keep on adding (linear).So searching may take linear time which is not good as student numbers get added.

This can be fixed by 1)making the student number random .this may bring a better tree structure but not as effective as

2) using more specialised / selfbalancing  bst like AVL trees ,binary Heaps then we are sure of getting a complexity that is an element of a logarithimic function.

  ",3.0,0
231,231,249,6e573d9284194cc7291f560a714a872dd47b4e061283e85a73d0f329ec03550a03a1a3f166b0239189f5a0ff40814ee55278425a8a226193ee0b842b340ab615,"The slowing down of the system occurs as the Binary Search tree becomes more big,this leads to an unbalanced tree.The tree must always be balanced and sorted.",1.0,0
232,232,250,59d6b044c8e3defdb04ae33f65223b9a348ff28a2986757f1ff92456374522a233c59e08e3595ef590565b6c7312655ac0d183d5fa106548d9bdc3808d7fd503,"Students in the same year usually have their first 6 numbers in their ID being similar to each other. This means that there are not many differences  and this will form a tree that is semi balanced. As time goes by different students of different age groups enter the system  and this will make the tree INCREASINLY right heavy (i.e unbalanced). The height of the tree will thus change from O(logn) to O(n). Since O(logn) is better complexity than O(n), the system is now slowwer than before- as its complexity is O(n).

To fix this issue we must introduce an AVL tree that uses AVL conditions to transform the height from O(n) to O(logn).",3.0,0
233,233,251,e297ac13d644c28497e53e0845b865aca91f53637da30cace639c33479dad1c99be8abd444014be886b73f635741e9cc8d11a7d33228fb4866fbadfc7725d88c,"As the number of students increases the height of the tree increases and the system will take more time to traverse to the bottom of the tree causing the system to slow down.

The solution is to have multiple Binary Search Trees whereby each BST will have students that are born in the same year.",0.0,0
234,234,252,fad8ed201b5420145528f1f55dddd6df344bd6b8c41089ce34f690b1ada879c754292238d4020efb35d824794aea9c5b38d2a0434e36e803dd8ffcc5a8541493,"* CAUSE OF PROBLEM - Over the last 10 years hundreds of students ay have joined the university and therefore their ID numbers would have been added on to the binary tree. ID numbers change with the years, which implies that many of the new students would have similar ID numbers that would be inserted on to the left side of the tree. Over the duration of the 10 years an increasing amount of students' ID numbers would be inserted on to the left side of the tree, causing it to become unbalanced and degenerate. Instead of the time complexity being logarithmic (O(LOG)) it becomes linear(O(N)).
	* SOLUTION-  There are methods to ensure that the binary tree maintains a good structure. This can be done by ensuring the tree remains in a good structure after every insertion or deletion. We can use an AVL tree to keep the tree balanced.",3.0,0
235,235,253,d42cf42830844a9ee1d0ff0af8c2f689af280ff8f6db853246aca542789b88210a975754cb807f66256c17bb8f0db7f822b9fd7b118d4ccaab17c4ee83f0a430,"The system has turned into a degenerate tree overtime and therefore making the operations of the BST very slow.
This can be resolved using AVL trees as well as other operations to keep it normal.",3.0,0
236,236,255,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,"As time went on the data structure became unbalanced from left to right because if we can check the ID numbers of students it recent years, it may be the fact that their ID's start with ""00, 01, 02, 03..."" so from that time the only side getting inserted is left which then causes the data structure to be unbalanced.",3.0,0
237,237,256,95ec574d0b5e5bd453bdf228b8fd6b36983c901c9b25f9afd384cc03675a32e20d389dce83833059b544924f4ab4040a1eb7a22d75cffd2643cd89107295fe1a,"As the records in the tree are being sorted by ID numbers, each year the numbers will on average be larger than the previous year, and due to this the BST will become lopsided overall as most of the values will be place on the right hand side due to the BST sorting larger numbers to the right. This tree will no longer be ""triangular"" in shape as each year there are more values to the right, simplified it would resemble a line to the right. This problem can be solved if the tree is instead constructed as a AVL tree as this would balance the tree (ie: ""triangular"" shape) and make searching much quicker than the original at large n values.",3.0,0
238,238,257,a24d4454b3c0f0611764d00de2a1119612fa4ae5c81fcdcf3800d4c6304de97c1896fb4640ae9520917c1bfdc4dabf12f730cd0013b9af7ab3a73969db3c7eea,"The data structure is logarithmic generally however given that it is a binary search tree and assuming that each student number is consecutive relative to enrolment, the height of the tree keeps worsening as each consecutive value is added to the BST. Given that this is the case, perhaps deleting older student numbers would be a better idea than leaving them in as it may be causing the system to lag. Additionally for the data structure, forcing the tree to be a complete tree would greatly improve it's performance. The system should automatically remove students that are no longer enrolled.",1.0,0
239,239,258,c76ad062cb3f9ba2556bec1587c1d89b089f2df63d9bed184a50eead5884d030c988356231ec2465bf2dfe9d6ac011b44586a721987fbdacc7384e0d7bc1bf14,"As the number of students increases, the binary search tree also increases and creates an imbalance. The system gets slow because of this imbalance.

One way to correct this is by implementing an AVL tree.",3.0,0
240,240,259,d25db0824a9dd89b8306dc484932409aa0ac87f6e9cd46591627f8005d6820292ad0928aa72897c2e9719ede0b047240f3ae45e7cf394e50ddacecd0d21dbbfd,"As the student entries increase, the tree becomes imbalanced which makes the system slow down.

We need to balance the tree in order to correct the problem.

To re-balance the tree, we need to re-implement the tree by building a linked list out of a balanced binary tree. We find the middle item and then use it to build a balanced search tree. We should traverse through the tree from left to root then right recursively in-order to make a sorted list.  The left subtree contains values that are less than the  root and the right subtree contains values that are greater than the root",1.0,0
241,241,261,dcb36512b447a313662d0f410494b8558ba9ebb01567bc86a95298f6904541d3214ff36bc5d7b6282877fc7d17b5d1d22bd45efc068f60d6574cc4f66e60986b,Over time the reason why the system might be getting slower might be because it does not support the extensively large amount of data entered. ,0.0,0
242,242,262,a145f431c410e1843f72d391833766088999724bb061c5de5f99600df8121e13bf82a081ec160d9db7d03b37234415de509f5f9b183164404c67b123311c46ff,"The number of students might have multiplied over time and therefore more memory is required to store the student records. The cache memory might be full-> storing unnecessary data which can be referred to as ""junk files"", clearing the cache will allow for more available memory which will allow the system to operate as efficiently as it did 10 years ago when it was created  ",0.0,0
243,243,263,2ac52bf7176b74f783c4dc472a3ad61819784c24e47b750c3635810bda8131880643be2f953dc39facdc68dcec02aa6cc62d7628e7e8b294770838010259c464,"The problem would be that students who have left have not been deleted off the system, therefore that memory has not been freed and accumulates memory that is not being used or does not need to be accessed anymore.

This could be corrected by deleting students that do not attend Wits anymore off the system. More memory could also be allocated by doubling the size of the memory that already exists, this would allow for more students to be entered on the system for years to come.",0.0,0
244,244,264,8c276f2a894ec8359a82f6a7f8b543cee4dafa5e339dd5fcbdd9b626de04d860f6a771f050054850d4263b60fc7c9e2f46a60c4568664a5f9854894846a3920d,"The increase in the amount of students will slow down the BST and it will degrade as more and more students are enrolled. 

We could convert the BST to an AVL tree so the search becomes O(logn) which is will be significantly faster.",1.0,0
245,245,265,67d402955c162ab6452295b6b5d26eba2d31759d3c95b63363fb0f3d4d6e0b04ac632a790b3b479c13437abea8e6208b9e8122018f1333c3a720caa36adbe27b,"As the years go on during the 10 years, the starting digits of the ID numbers start to get bigger than in earlier years. This will cause the binary tree structure to form into a degenerate binary tree, causing the search times to be in linear time complexity and not in logarithmic time complexity. This can be corrected by using AVL trees and introducing the AVL balance property making search times to be logarithmic.",5.0,0
246,246,266,2bed72130045c9fb6315517a1cd0576fdbc71ee8714b8107f6ddc3d51fbc170cd1fbdf2110982b17b6e61a87f656eb89a47f0eef9a898bfa08b1c56801ac6236,"---Depending order of the ID's as years pass by if we are busy adding or removing students records from the tree,we might find that we have ""Degenerate tree"",which will mean that we are likely to be doing the most amount of work when we are adding and fetching student records in the future.

---The number of nodes or the height of tree would have increased,so when adding or fetching students records we would be doing the most amount of work.",0.0,0
247,247,267,5f92eb6a07aed01e019162660614241903fd30335dc49cd736d18a97a0b8e4d8d8eaa7a31ce7cb8ad65e895e5a8906b98d2e7635d42d019af72333c76c35da1a,"The data as time proceeds becomes unordered and takes up a lot of memory, slowing down the system. This can be corrected by by removing all the data that is unused.",0.0,0
248,248,268,c3db465470d91ba6cd0242ed3a549831510dda1562b623b02e3665b5f6f9bac2d6ad4723d79407874899cc2fdd039731483c651b9cdef6d97acefd5884ce52f6,"As time passes the ID numbers will only increase and we'll only be adding on the same end of the tree(the right end, not necessarily down down the same edge) and hence the height will keep on increasing and the time it takes to access the item with the largest ID number value will have O(n) time complexity. we can remedy this by using an AVL tree instead which has a functionality of keeping the tree balanced and hence we'll keep using the BST but a more efficient version which will have O(logn) time complexity.",5.0,0
249,249,270,fa1eda9b8fa6b29f42c58daabae31bf791920b445112a81a69b6dedf246e690834edf4a9bccdbfb3388e2f377e3232fb5275faf86faadfacc5b8aa731f092ec3,The binary search tree might stard to get full if there is an increase in the number of students over the 10 years. That will create a cluster of the data. Nodes in the BTS may be improperly placed. It will take longer to. look up a student's profile or data. ,0.0,0
250,250,272,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,"Depending on the structure of the tree, time complexity is either linear: O(n) or logarithmic O(lgn) therefore as the number of students stored in the system increases it will take a longer time to perform a search.

The binary tree may have children that only have one child causing the time complexity to be linear: O(n). In order to change this, the binary tree would need to be restructured so that it is complete and the time complexity would be logarithmic: O(log n). O(log n) is faster than O(n) therefore the system would speed up.",0.0,0
251,251,273,22ce118158e8ed0c1187b952e36a1938ab0c22e942e01d9258ed224302f7ecf3665fc06c4060e629850d16f04e008f7cd12363e7f782d4370a1dd3b7af113bbe,"It is possible that the tree structure has become degenerate or unbalanced. If the tree becomes degenerate than traversing the tree to look up a specific student may take longer because you might have to travel more edges due to the height of a degenerate tree, which is the worst-case height of a Binary Search Tree. If the year is 2020, many students will have been born in 2000 or later and so their ID numbers would correspond to years in the 2000s (or 2000 itself), such as 00 and 01. This will result in being inserted on the same side of the tree since the tree is built based on their ID numbers. ",4.0,0
252,252,274,345be80864afc907be82fb1649b77c0adec50aae15f4ef84437e11fadfe016330e25837968742fea1eb2ce613ab96c93820c486d64c303075c7edd75cdec8068,"It is possible that as time has passed the binary search tree had taken on a skewed shape due to the constant insertion and deletion of students(as well as the possible increase in student size) in the binary search tree as student drop out or leave after finishing their degrees, this shape could result in the tree being searched all the way to the bottom without finding the key(student record) this would increase time complexity and time complexity can also be increased by an increased number of student which contributes to the binary search tree having a bigger height .",0.0,0
253,253,275,e40d8bf3b05bd8e034438beb235a1631a28b193d6edc5587f765a26d4981e60fae4fcb9a995036a1c2815f2073b85fc4667e3d6bbfc0e5a63b847c8fa219ba80,"An issue with plain binary trees is that the search times in them can vary from O(log(n)) to O(n), depending on how balanced the binary tree is. If the tree is perfect, complete or height balanced, then inserting (adding a record), removing (deleting a record) or searching (finding a record) will all have a time complexity of O(log n). If the tree is degenerate or very unbalanced, insertion, deletion and searching will all end up having closer to O(n) time complexity. 

What might be causing the system to slow down is that the binary tree is becoming more unbalanced over time. Also, as more records are added over the years (i.e. as n grows), the difference between the best case O(log(n)) time complexity and O(n) worst case time complexity will become more and more noticeable as the difference between the functions increase. Also, seeing as the data structure is not contiguous, there will be more cache misses when attempting to search for a value, making the system even slower. 

In order to correct this problem, the AVL condition could be enforced in the tree and the tree could be converted to an AVL tree. This would help ensure the best case time complexity for insertion, deletion and searching. Another alternative would be to consider a completely different data structure. ",3.0,0
254,254,276,4cd28cc2ad591ac499048f07ffdf4d516b0d616e007ea0ed86d6d8211078fbf6b0e376e19e715d3f5e8e0639e85069e7aadf7f7c053054c13b6c8367b692aade,"The height of the tree might have become longer, perhaps due to having more students. We are now talking about the worst-case scenario of efficiency in which the amount of work done corresponds to the height of the tree( longest path from the root to a tree).

In this case, if the height of the tree is h, we transverse h times. So we will do either O(logn) or O(n) depending on the tree structure. Because more work is now done the system gets slow and looking up a student is harder. Searching through a tree takes even more work and time. ",0.0,0
255,255,278,e8a6e8174a6dd6e314677435e7049c0e3009b13d8a5df4000710970679e38e84d121d59138dfaf7218a7bd9e9ad0ee03d92b55f5f1e73be1e9206de0707e798c,"At first the system works great and is really fast as the runtime complexity is in _O(__LOG N), LOGARITHMIC TIME_, where N is the number of values in the data structure. 

However, as more data is entered over the years the system begins to slow down as the Binary Search Tree is altered and since its complexity is limited by the height (or depth) of the tree, its runtime changes. The Binary Search Tree is now of O(height), and it may be that the height and number of nodes are equal, so searching/inserting data now is _O(N), LINEAR TIME._

Each step in the search/insert/delete goes down one level, so in the absolute worst case, we will have to go all the way from the root to the deepest leaf in order to find X, or to find out that X is not in the tree, or insert a new least/largest student number. Or in other words _T__HE TREE HAS BECOME DEGENERATE._

To fix this problem, we may add a condition to the Binary Search Tree to make sure the height of the tree remains reasonable, and so that height remains O(log n) and less work is done. _INTRODUCING A BALANCED CONDITION_ is the way to correct the problem. Or in other words switching to an _AVL TREE_ instead.",3.0,0
256,256,279,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"The system is slowing down , because as we add to the data structure, we create a new chunk in memory and link to it. After a given period the data, even though ordered, will require more memory to be efficient, as the height of the binary search tree increases.

This could be corrected by creating a min binary tree, that way the new students will be on top and looked for initially, as the common rule will be the new data will be the most used. 

Furthermore the height will be controlled if we use an AVL tree, that way the amount of searches we use will also minimum, i.e. log(n)",1.0,0
257,257,280,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"The system is slowing down , because as we add to the data structure, we create a new chunk in memory and link to it. After a given period the data, even though ordered, will require more memory to be efficient, as the height of the binary search tree increases.

This could be corrected by creating a min binary tree, that way the new students will be on top and looked for initially, as the common rule will be the new data will be the most used. 

Furthermore the height will be controlled if we use an AVL tree, that way the amount of searches we use will also minimum, i.e. log(n)",2.0,0
258,258,281,68fe12a6f9e2217ee251160c4237430d186ca3b8284710c350ca5f0256d2abc683b1a854a2f30cab6e69feb98c61fbf1aee4d6e9df2ab12a86588aec00a8c95a,"There is no difference at first because the time time takes to look up a student in year 2020's ages don't differ much hence the identical numbers won't also differ, this form a balance tree. As students enter university it will start becoming heavier on the right then the tree loses balance. The height of the tree also changes from O(nlog) to O(n)  making searching through the tree slower because  O(nlog) is faster than O(n).This can be solved by transferring  the tree into AVL and changing the height from O(n) to O(nlog) . Balancing the tree with AVL conditions then searching wont be slow.",5.0,0
259,259,282,1e30eb511c307c57041552d3f3ff58f0e01dff16b4bbeafb7e1426a20560b5727bf879a4c238af04f66b8c454f01b583c75d2d8fab510951c437d49081081f31,The system slows down because the tree has become degenerate and to correct this a balanced binary search tree must be used.,3.0,0
260,260,283,061f56d837e6405fc3da18b48c234575e946e21c4f8a87e4ff0140618b0afc839b770f98def91d7072d96fe9e6cbacdd2d64a21bf2c7aaeab14c8c197a8e0535,"The problem is the comparison of ID numbers since the digits are a lot, so to solve the problem we must use a number which has lesser digits like the student record, so we must create a Binary Search Tree where the node corresponds with the ID numbers of the students compared with their records.",0.0,0
261,261,284,2c57052c92283203acd8d1c12f3f24bff9fcc6fc06d4ccaf21f6b88069300e298296f4f82426d3a1b2f0d2ff83e57ea1826f7e8e04b0393de99a4b442ad3afab,There are nodes that are not removed for students who have finished their degree. We have to remove the nodes of the students that have finished.,0.0,0
262,262,285,f0db6745b82c8442a04741f69d90ab699cfa4f3ce386836ba0d3ae6a18d50c9ca2d13114c6327692eaa69266b7b9c9c7378c99ca64e0ec19c0994415cc5bcc80,"When the system was created, it had a fixed number of students. Over the years it was not updated to keep on taking the median ID number so that the left and right side of the BST is balanced. Now ten years later, the BST is now one sided as the ID numbers that are coming in are always greater than those that came before. So now the BST is now like a linked list and the search is almost like a linear search. The flaw can be corrected by balancing the tree from time to time periodically, or introduce the AVL property to the BST so that it is automatically balanced each time a new sudent is added.",5.0,0
263,263,286,eb636b71b69b444b76b68045ede7c5b96290b63dc94e90986ac7258b980a7f8df480d1b6926e41ac5186df7da647131dcbb111a84e28e5a68a37dc453c1f06bf,"The system slows down because of the increase in new student numbers which increase in value as compared to the prevouce years and students from prevous years years leave. So this leads to more data being stored at the right side of the tree thus creating a list instead of a tree so run time becomes O(n) intead of the intended O(log(n)).

The solution would be to use an AVL tree.",4.0,0
264,264,287,8ef07cfaa662dbfc2a6f67c4eb6899f0aec0231f063886ccf26dc730e0a79b7cf9f7721c25d0389628fb118a214101e554b383179ae6195a341f858f22a17c0b,The reason why it is  giving us a problem is that there has been an increase in the number of students that go to the university and when you are dealing with binary search trees you will need a separate tree for each item you want to be able to search  and each item on the tree is an item so we end up with a very large tree which may take us time when we are trying to find an item. We must use an AVL tree as it will make things faster .,1.0,0
265,265,288,805e6508996d13ddf1a18b1d2e18c5a73d82b749916487ddfd386d326e8ba2b06a4521a365c23ea00b66ba06fb5efe331adbdc0f46e49478cb1d6923fb8a6c24,"USING VECTORS DIRECTLY LEADS TO INEFFICIENT IMPLEMENTATION AND IN THIS CASE IT SEEMS LIKE THE HAVE USE THEM DIRECTLY FOR THEM TO SOLVE THIS PROBLEM THEY NEED TO USE THE CONTIGUOUS MEMORY THEN THEY SHOULD IMPLEMENT THE CIRCULAR ARRAY AND THAT CAN LEAD TO EFFICIENT IMPLEMENTATION AS THE FUNCTION OF THE PUSH BACK AND POP BACK OF THE VECTOR THEY USING O(N) AND WHEN WE START TO IMPLEMENT THE CIRCULAR ARRAY THE FRONT, SIZE, POP BACK AND PUSH BACK FUNCTION THEY USING O(1) TIME COMPLEXITY WHICH IS THE BEST TIME MAKES IT TO RUN FAST.",0.0,0
266,266,289,d14b989bcb894978cca36e7e5f61001f5674d5a63e03700520c57accee4d5d7687b97d71bfffe56071d64d16c01c84e867fd79ad35b152d9c5667b7efa04e45e,"* The Binary search tree might be becoming less balanced as the university gets new students. The height of the tree becomes unreasonable and searching through the tree becomes slower.
	* Another issue could be that students that graduate or drop out dont get deleted from the heap properly, causing memory leaks.",1.0,0
267,267,290,df1465243969e50a7c244171c33cdd8b84e73574759fd453aca87a46591b145e500e27e8f5be3935920bd9b19cabcd2edf5bdb2b726205f4ec6c454c76481975,"The system might slow down because of an increase in the number of students in the BST and a greater amount of input of items placed on one side of the root which makes the BST to be unbalanced and inefficient.

This can be solved by balancing the BST or converting it into a AVL tree which will make the system more efficient with a search of O(log(n)) time.",3.0,0
268,268,291,7ad6b014f9c54f4af21e21f5ded12f480a954caacae0b1ae202d37d441149e00126be0ab20466a777e1dde3487a3cf0d1df830a29d9d1df5f045525d8082c235,"The system becomes slow due to the large number of students that have been added to the tree without being removed when the year ends, with 10 years of adding a number of students, it bounds to have a very large number of students that the system has to go through to find certain students, making it slower. It can be that the height of the tree is very long that it causes the system to take a long time to reach a value that it wants. A solution to this problem would be to remove previous students, by analyzing the system which may take time but it is helpful with the process of searching during the year rather than having to struggle at finding a student. The system can also have different Binary Search Tree systems' for each new grade which makes it easier in the long term to access student's details.",0.0,0
269,269,293,3c8ef47908d3cd928b1c534badd201440c60b2b604fa8a52405f68cbbd0aba5679ca35b2fdc867109c6d52e6515d07e1098629991bf6cae4e1b61afff4c41b9f,So with a BTS after 10 years when searching for the student who where inputed in the system first will take long to be found because they will at the beginning of the tree and this will slow down the system as the years go by more and more memories will be added and memories will have to be deleted.,0.0,0
270,270,294,2a0df219aac143a2ab259ed39069368d09faa1d674232d6d8a5a0299284966b0b712226c702276000af1418c0c7120be9e30f8742712afc25a87bebd377d57d9,"The system may be slowing down because of the memory being used , furthermore if they are comparing the data for every student from every year, this may pose a problem for my binary search tree because it will most likely using a depth first search which is faster than a Breath First search but as the sample size increases and more work is required to be done, in the long run the worst case is Linear, so as sample size increases, so does the work. The time complexity is also linear so the time it takes, is longer as sample increases which will slow the system down.",0.0,0
271,271,295,49811d763ba759a50f2e0c233e15588b02d4f863f2daf7bb9891b1e7fc339a6758ecc3a62c1286ec47602b5e14c6edff45dda6e0d22355027319e6c73f32c285,"the reason may be that the list began to become degenerate as different student numbers were made causing very long  traversals through to get to newer students as the newer numbers being greater could of just continuously increased the height of the tree.

This could be corrected buy changing the tree to be in avl tree to reduce search times to become logarithmic as the height of the tree will stop becoming degenerate cause of the conditions of an avl tree.this could also help in search times as the order of the tree can guide the search.

they could also use a min or max binary heap to store the data making the trees complete instead to stop te degeneration of them and reduce search times to logarithmic cause the conditions for a binary heap dont allow degenerate binary search trees.",1.0,0
272,272,297,5204f1bef2136d15a15e2bc81fec661c33bfcaa03530558479f291b586c10eaadde8b3f1da2bdb0c585b8e4de129c95a1cc00f8b5982206443ac7a6b2014c46d,"There is high number of entries as the year goes by, and also note that every entry is unique so it will take up it own space leading to the overflow",0.0,0
273,273,300,bb7a5218ab3dfcc0ac546d608943de6dcbb3727d09e6f5dbb5e885ea5b24939174aaaa40e8672ce63fa53f6af97ad899b29ea3229ae18c85c504ca3dcaa7d71a,"The tree is slowing down because the tree has become unbalanced/degenerate. Maybe more students might be getting records less that the root and therefore they all get inserted on the left of the tree, so

the height increases making the time complexity the worst case which will slow down the system [O(n)] .

This can be corrected by using: Balanced Binary search tree, AVL (makes the height shorter), Red-Black, B-Tree.",4.0,0
274,274,301,e59ea024db9d632851c3ca6a66839f5b0b1c07351136bfecb43aa5f9ad7a1d759a03bc9f89a03c280e88a3efb50858d069c0f4da4316f05a94c171e84b8ef55f,The BST is time consuming and thus making the system slow,0.0,0
275,275,302,7b3fc596e109278830391a5f8c8488dfccf10a0f5d5014d4d43c1b543ed6a0c08d21b8c586959c6fae23648c8bea8b649d014b5be61ca28cc781144226c95d55,bts is time consuming and this causes the system to be slow,0.0,0
276,276,303,75a3383738a198a57b5bf911227bc1acefa5387a63447f6ac8def117cc9ca26c926b9a06fe676ff769e333554195eaa647257e22733d67710ae7508ceb7f3115,"The element contained by each node is greater than or equal to the elemnts of that children nodes making the Tree not to be a binary heap, which results in the system to be slow. It can be corrected by taking the last element in the deepes level and swap the out of place the place with the its highest priority child, this will increase the speed of the system.",0.0,0
277,277,304,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,over time the binary searches recursive approach would require too much stack space and it was written by a student in 2020 thus the student was under intense stress and a binary search algorithm is error prone  and difficult so probably a mistake would be made. also the process of caching is poor,0.0,0
278,278,305,a592984647d3091ee5e099fc2735b33f4b784c89b64e4457845f78efb428589dd115991447ef2d8a431a9e8442665bad85cd9e35f45bdb7652b9adfcaecefdce,"the system slows down because the BST now has the worst case time complexity ,the algorithm now has to move through almost all the elements before it can get to the required value

it can be corrected by making the BST a min binary heap",0.0,0
279,279,307,cec5c5d76a671273e0f9371ae893a0f4c2ff89a302afba60a55ed47df25e76493286a5dc1d008dcab637f3c3c155e4e5b2158e820a7aa91a63b886b5ee485778,"The cause of the degrading efficiency of the system could be the fact that the binary tree is inserting new entries such that the tree is becoming degenerative. As a result it's time complexity is close to or is linear (n-1) and thus it is becoming very slow as the amount of data is increasing. This could be fixed by forcing the tree into the form of an AVL tree where it it is balanced and thus guaranteed to perform at O(log(n)) efficiency, making the system considerably faster.",3.0,0
280,280,309,8049e1d0a5ce881b749a9c9461a73e821d1792fbc2adc39e1be0be7717d99f93abbe732f68ade8cbd01333fb3e4a5adeb13b3875a705e5218706e5b68e7e0885,"The system might be slowing up because 10 years of adding data leads to BST with a lot of elements, and in order to retrieve something we always have to start at the root. So the more elements we have the more time it will take to retrieve something, O(n).

One way this could be solved is to try and implement a code that will convert the traversal through the Tree to be an O(1), constant time, which will be faster and retrieve faster.",0.0,0
281,281,310,6faaf9b1d085a393b028ace82b2996765123fa315b9f4a8ed8db3a15b212a1737ea08b0cd8412ff053120963926bb68c4544ec749acc155d82f591062af2caa1,"This may be caused by an increase in the number of students after 10 years, thus causing the database to increase and the system to be slow. Time complexity of inserting, deleting and searching BST is 0(n) in worst case.

This could be corrected if they implement a height balanced BST such as AVL trees which offers 0(log(n)) insertion, deletion and searching.",1.0,0
282,282,311,c4a46955ab90460a7f7ea08b20b02537758cd0f1f3801bb0b96314fe0ff9d069021459ba5c9b4434a1085ce9d389652fee31ac82384418540ac50a261c57a498,If the system added to and sutractive from without rebalancing it with time the varience in tree height can lead to increased search times due to this in efficient layout as traversing these trees can increase the number of operations. If the BST were to be made into and AVL tree and balanced annually with student intake and departure this would correct this slow down issue.,1.0,0
283,283,312,d5acfd7b46a030b29f7c66a4b1581ff2012d0ccf49d5bca978171e9bdeb669a4e3f41049f7e32dc031f0947e94ce07cc6178891342c05dfe3c3aefc0b7389e15,Tree has become unbalanced/degenerate. News users likely all have ID numbers from 2000 onwards and all get inserted on the left of the tree(ID : 00...) ,3.0,0
284,284,314,41bb0c2e0e2dcb02b9f9f1ee3111cbc68804641053382c305478fa2326a399203b7fe49cd1764c6ca36f08ca084788dc24318a43b94e5654ce4c305e53f20868,"The system could be slowed down due to memory leaks , or floating pointers that are taking up additional memory",0.0,0
285,285,315,68f3486fba3e90fbb30d257d9f425b479699474b4734aedaec9e7b7e62738dec31c232429f41b1b79d289e2acf53beed558d49f905e55176ee54e1327b9aa184,"As time goes by, all new students  are most likely to have IDs starting less than 2020 upwards.  The height will not be in control. This can make our tree  to unbalance since all new student's IDs will all go to the left sub-tree of a year 2020. To improve this we will have to perform a rotation",1.0,0
286,286,316,5530a3289902a9b8046211b23e363c2d17c53d3dae60408ce782dad21065a511eb819cc437440b28be1c0ee28957c16d3c143820d415553d97979e1db0f64c5b,The number of students might be increasing and the number of nodes in the binary search tree  which means that searching will eventually take a long time(worst case) and more memory is gonna be used,0.0,0
287,287,317,31b91a2cbe9d38c5c018d832e6594c5b3ffdd38b6555291e43c52124c88f4048eafce37a5d4c9670e25f88cb39302cf31b3d02ee2f55200c7e6b2364a2a7b4e0,The space is causing it to slow down. Make the binary search tree correspond complete ,0.0,0
288,288,318,c1e502cb9307976ed3c86bb3e1a2a0d1fad4d05b1ff3b6ca09a4a8992703680a55c9ae6e51c9417d756549fe340afbac12cdfcd3dbe4f6a560b6a171ce7f1eeb,"since the first 2 digits of the ID number represents our birth years, over the years as the university adds newer and younger students, the first 2 digits of the ID numbers will increase and over these years, a lot of students will keep getting added on the right side of the tree and the imbalance would make searching for students take a lot longer as the tree has been tending towards a more degenerate structure in comparison to before (many more students on one side than the other). Seriously larger heights would more likely have to be traversed through as Wits searches for students and perhaps perform other operations after 10 years rather than back in 2020.

This could be corrected by changing the algorithm to include the AVL condition to try and ensure a more balanced structure within the BST.",5.0,0
289,289,319,9403a6055052838effd7ee11ccb772d87904528f067a64dac873492ac316e3dec04949023db9aa2c93819f94c53c4c5c1b5e1941d51e786c3ee0dff6e062b7fc,"1) Due to increase in number of students over time the tree might degenerate and the height of tree increase very fast.

2) Tree must be balanced",1.0,0
290,290,321,a8a6f16c3b5d8f4755f7eb78bf3b30b3fcd48aa230fef5ea89b91ac8d3f907d172975e412462fedb56018255e449735f198b3b28f7d5f0e5940abd8a597ba08d,"Initially, the system was fast because there were few students recorded, starting from 1 and growing upwards. This too up less memory. But as more students are recorded, the more the memory is used. ",0.0,0
291,291,322,ac00d5695452023736c168247b6e6e7ac1c86c1918ba65ce039a3ac355db0c0c6d3945a25b1f4c24df8db20417ffdf726ff5a44586e3fb4757147f393e36515b,New users might have a portion of the ID number which is the same for all users and hence this may cause the new data to be inserted on one side. And the tree became unbalanced. We can correct this by using the balanced binary search tree.,3.0,0
292,292,324,50bf7158c02ac959a654397828640953fde6ae96998246b7ac558dc294c40e8b3a562d7e6e70935713ff59ab0e3d08bfd8b5372f4903ef58b527560ee2b16c51,With more students there are more nodes to go through and the program might not be replacing the nodes belonging to the students who have already graduated. The program must be made to remove or replace those nodes which are no longer necessary.,0.0,0
3837,3837,5519,b35e384f7c5ceb06d79c3b93cc63fcaa47042ffefb6b106d30f49be852e804e9feab1392cb217f65d7e7d63ec9914fbf325012c10f23427d79d4c0865092862e,"Using a vector to implement a stack:

Push: Code a push_front function that reallocates the vector to a new spot in memory with the new element at the front. O(n) Linear complexity.

Pop: Code a pop_front function that reallocated the vector to a new spot in memory with the first element removed. O(n) Linear complexity.

Peek: Use a built-in front function. O(1) constant complexity.

Size: Use built-in size function. O(1) constant complexity.",7.0,12
3838,3838,5520,c52fe90555e82813bbf7f31602e97c4095475fbbf85ff26471f0158158110480233228486a71767a61c524c47fe301d427e9bdbb31f3216eb95878f59314ec4c,"Since you would be implementing a stack and a vector,  you would only work of the top of the stack which is the front of the stack. Therefor everytime you pop of the stack it would be popped off the front of the vector and no where else in the vector. The complexity for push_back would be O(1) best case and O(n) worst case.
For pop_back it would be O(1) best case and O(n) worst case.Peak or top would be O(1) constant. Size would also be a constant O(1).",7.0,12
3839,3839,5521,dc116295695675ce8f8f9dcde7d1d181a1fc34469a4bd2a570b8ca26a7951f6381d662fe47ef41e490d057b64113abc45be11b89047c039c48685692d843ce1d,"then it can have pop front and push front  and both complexity will O(n) and even pop back and push back,it will O(n), but i need to use redo and undo stcak. Size will be O(n)",4.0,12
3840,3840,5522,cf96d5be5169d5386c2ce2a3ae914384cd3ff74c0ae41c6fc53cb4ef592a7f9882d33970f1f807fe79c0e961bedb5189d6cfa997817a7684663f34c5e5fffad2,"Since we can only add and remove items to the top of the stack, using the front of the vector should work fine as we have access to the front() functions and size() functions.

For a Stack to be implemented, we need to have a push function to add things to the top of the stack (front of the vector), we need to have a function that removes things(pops) from the top of the stack(front of the vector) and we need to have a size function to determine the size/ number of elements currently in the stack/vector. We also need a peek function that will return a refrence to the thing on the top of the stack/front of the vector (this can be done utilising the vectors front() function which returns the thing at the front of the vector. 

1) The pushback function will have to add a thing to the front of the vector. This will need to copy the vector over to a new vector(with a size is 1 larger than before) in order to add an element to the beginning of the vector. Since the whole vector will have to be copied over and (in the worst case will have to be reallocated) this will take a linear amount of time O(n) as each element will have to be copied. 

2) The pop function will have to remove an item from the front of the vector. Since vectors don't provide a popfront function (as they are contiguous) The vector will have to be copied to a new vector with a new size of (size - 1). This will take a linear amount of time again, as each element will have to be copied to a new array. O(n) 

3) The top/peek function will take a linear amount of time as we can just return the first item in the vector using either pointer arithmetic or the front() function. This will always take constant time O(1) 

4) The size function will take a linear amount of time since it will have to loop through and count each item in the stack/vector. This will always take a linear amount of time since it depends on the number of items in the stack so O(n) time. ",10.0,12
3841,3841,5523,1c067bf4dc46efea1d97764ec9e8512203198a06760dfe663905444adb3c11970401fd40f402aab42c0c01db7d7d76641060c3df878232bbed315bb7d13f0aab,"I can create a class Stack, using the vector as the underlying storage. The class should contain a push_front function so that new elements should be added in the front of the vector since we want to use the front of the vector as the top of the stack. I would create a pop_front function so I can remove from the top of the stack. 

I could have a function that returns a reference of the first element in the vector so I can get the reference to the item in the stack. 

The complexity of push_front is O(1).

The complexity of pop_front is O(1).

The complexity of T& Peek () is O(1)

Then I could use the return size function to get the number of items in the stack, the complexity is O(1)",7.0,12
3842,3842,5524,3b413468f9946530e16c6d2ced91ab45356664eb3ef35b2823043a9391b6766aeb5cd1cde7c7799a9976f4713f096989c7f13a6ea1b6e1be3f9af94b87e0d40a,"You could implement this stack by adding and removing items to the front of the vector, however, this would require copying items to keep memory contiguous (we always have to move each item up one position when pushing, and down one position when popping) and so the complexity would be linear ie O(n). We would also need to implement these push_front() and pop_front() functions ourselves. The size and peek functions are handled by the vector's in-built methods. The size and peek functions would have constant time O(1) as normal.",11.0,12
3843,3843,5525,b65e52333a31f01a7d7a5dae0ff6fc8ed82b8b5283406f591e8d448f865292ea8162938b0259891df516358cc77c51dca3895b350dbb36cf96d6c23e9b3fa27a,You would create a stack and all data stored in the stack will be that of a vector. To add an item to the stack will take O(1) time as the item can only be added at the top of the stack and thus become the stacks first item. The same goes for removing an item as only the top item of the list can be removed thus also taking O(1) time. You also only read the data from the top of the stack and once done with that item it is deleted so you can only move down the stack once you have finished with the top item of the stack.,0.0,12
3844,3844,5526,d7e19f96a6aba1e381d06c4d14cd8af55d98ac1778548325b5d3026d929df87b2abc3d523dd5623a58ab296187735de8598844f1ea29e935b29ced21ed87e297,"The stack will make use of the vector's front function in order to see the top of the stack, as well as the empty function to determine if the stack has nothing on it. These will take O(1) time. The Push and Pop functions will take O(n) time as they will have to make use of temporary variables and will need to loop through each element in the vector, pushing each one to the next position in the vector before adding the most recent item.",7.0,12
3845,3845,5527,a130bfe9418c91d178f590031c0c9939b5fca90db77973d7f6178ded40014a7172640da790c28b96fd7fb6c80913844b332b017840744966e0e7f4da01d28945,"Pushing to the top of the stack would now be a push_front function, meaning that we'd move every item one block ahead and then assign a new value to the first element. In the best-case scenario, there would be enough space to move every item forwards. However, if the allocated space is full we would have to reallocate memory, assign a new value for the front item and then copy every item across (one block ahead of where it was previously). Both of these cases are O(n), though. We would have to make n copies either way. In the best-case, we would also have to do one assignment, and in the worst-case we would also have to allocate memory. These operations would, however, not change that the time complexity is linear.

Popping from the stack would be a pop_front function, in which we move every item one block of memory back. We would simply have to reassign every item to be the item ahead of it and then delete the last item. This would be O(n), regardless of best- or worst-case scenarios. We would have to do n reassignments regardless of anything. If the data-buffer is still more than one quarter full, we would simply do n reassignments. If the data-buffer is now less a quarter full or less, then we would also make n copies into a new, smaller data-buffer. Either way, the time complexity is linear.

Accessing the top value would simply be the front function which uses a single pointer dereference, making this O(1) no matter what.

Getting the size of the stack would be exactly the same as if we were using the back of the vector as the top. We would simply return n_items, which is kept track of through other functions. This means that no additional operations are needed and we simply perform one very simple operation. Thus the size function is O(1).",11.0,12
3846,3846,5528,82694cf634b012a9b99356edee5aefc22b24ba7895f93507fd59a70aa1b507058de91ae69d4a669273414cbd851ebdc45bb8d210bcd7e76b8c63d620d83813d3,"Firstly, I would declare the vector then implement the relevant functions:
1.Push_front - O(1)

2.Pop_front- O(1)

3.Peek- O(1)

4. size - O(n)",2.0,12
3847,3847,5529,0745491c3d066e21ade2f2d4d85d4695dac91b9131eb26e8aed287a29c7e24ee4d3c6beb342324906b0ab6475785f0d2fea5c9799af48cbec9547c62e95d041e,"I would do this by creating a vector with initialized allocated space of 1. this means that there will always be an extra block of memory at the end of the vector. 

I would then push_front values to the vector and keep moving existing values further down. The best case complexity of this is O(1) and the worst case is O(n).

The pop_front function would work in the same logic with the same time complexities.",5.0,12
3848,3848,5530,39f1ebb534a7edaa837d48cbd4115f72e8c5e63b7a4efafc271bf59036c6638038d9febb4eab796e3f3e68165bcbad6c2e1a9ad37eb71f421ecdb12f31f4f4c5,"pop_back(): Copy all elements (apart from first element), over to the left. This overwrites the first element with the second element now being in the first position at index 0 which correlates to the top of the stack. If less than 1/4 of the allocated space is used, reallocate memory to vector and copy elements (besides first)over to the i-1th position in the new buffer. Time complexity is O(n)
push_back():Move all elements over to the right and insert new element into the first position. If the vector is full, reallocate memory (of twice the size of the original memory buffer) to the vector, insert new item into the first position of the new buffer and copy all other elements in original buffer over to position i+1 of new buffer. The new buffer should be twice as large as the first buffer. Time complexity is O(n)

size(): call the size function of the vector class. Complexity is O(1)

peek(): call front() function of vector class. Complexity is O(1)

the vector would be a private member whilst the functions are public",11.0,12
3849,3849,5531,d42cf42830844a9ee1d0ff0af8c2f689af280ff8f6db853246aca542789b88210a975754cb807f66256c17bb8f0db7f822b9fd7b118d4ccaab17c4ee83f0a430,"push - requires O(1) since less work is needed to push items to the front 

pop -  requires O(1) 

top -  require O(1) 

size  -  require O(1)",3.0,12
3850,3850,5532,5e36a0e7b93c9d082984c03228c748a0348993dbc7307752e7acfbf7e44b3df39b6aedb0dd5c68b0421254e8914343a9e052d4d15e260e3ecd7ef28810b12ec9,"An additional stack would be created. All values from the previous stack will be transferred from the original stack to the newly created one. As a result, the newest element added will now be at the bottom. This process would be continued until the original stack in empty with front being at the top of the stack. This would be O(n) complexity. The original empty stack would then be deleted",2.0,12
3851,3851,5533,297de9e92f0b5f666b5f42405cac621415fb2c64763fdc11b8d57538dae3ffa9e272dd3efdad0a974813033e43539624b9741e3632c9573318e9a12bea633c7a,"This would be implemented by having the top variable point to the front of the vector at all times. Pushing variables would be O(n) as each variable is pushed to the front(top) of the vector. Thus, when a value is pushed each existing value must be moved one back in the vector. When popping the first value must be removed and then the remaining values must be moved one forwards in the vector making the complexity O(n). The top of the stack will never move.",7.0,12
3852,3852,5534,e40d8bf3b05bd8e034438beb235a1631a28b193d6edc5587f765a26d4981e60fae4fcb9a995036a1c2815f2073b85fc4667e3d6bbfc0e5a63b847c8fa219ba80,"For push, you would need to use the push_back function to increase the size of the list and then move the item to the front of the list and then move each item up by one space in the vector. This would have a time complexity of O(n), and the space complexity would be O(n). 

For pop, you would need to copy the value of the n+1th index into the nth index, starting from 0 until the max index. You would then need to use the pop back function. This would have a time complexity of O(n), and a space complexity of O(n). 

For size, the variable recording the size is stored inside the object for the stack, so this function would return the value of that variable, which means it has a time complexity of O(1). 

For peek, you would need to return a reference to the Thing in index 0, meaning it will have a time complexity of O(1).",11.0,12
3853,3853,5535,2a73fae534f6399be599dee1f1de2adaec9431f39943abeccc1ca0cc827521f43446d764a73ff779a0d169bd025aa1ff69232dd0892e2b573939bb6ed6281bd6,"1. Push() - Use push_back(

2. Pop() -

3. peak() - 

4. size() -",0.0,12
3854,3854,5536,174e38c18f0521eafee3b73a0ffb8449a8c5784d547a0843ddac9c9176015fedd2516d8b3d18b017cc9000d2b315ebe1757a54b724f337f3a99202881366a527,To add an item into the stack I would use push front and to remove I would use pop front these two function would take the same time always to run. To peek  I would return a reference to the first item. ,1.0,12
3855,3855,5537,d5eef99882213e9e893ef6d31b163cddd65b11b328a038af368c63b9dea5c55582d674f73b7f44a7ffb0e808a2c14f224354666b5c8da68a3cf145583cdbcada,"using the c++ vector function, we can not push and pop at the front but the size and peek function will do. To overcome the problem we will create a new vector function that has a pop front and push back function.The pop and push front will do the work in constant times",0.0,12
3856,3856,5538,16cb13e3f20264dff11bab6b4074b1ead9b8e1cf1d7a12dd1238f56fff77a643c79324083d48280a979ad65c97d7690c011f0b94300438693e7e3022511b7be3,"PUSH- this is inefficiant and will always take O(N) time as always have to go and copy each element irregardless if vector full or not, if not full the elements are just copied to the next block of memory, otherwise they are copied to a new memory in their current possition+1 and then insert the new item  at the front of the vector

POP -would need to just move each element in the vector back one position and decrease no allocated, if vector is less than a quarter full would have to reallocate memory , either way O(N)

SIZE-call vector size function which returns a stored value O(1)

PEEK- Can simply just get the refference of the first element with the operator function or the begin function, O(1)",7.0,12
3857,3857,5539,d96af73b5be668f5dd689aeab89641b2c7231424c7456f3ea33f65b38aaefabde723924090d862562454b1c8a6f22cbeb22245f54dc09b6ff5593a40d39e2839,"Since the front of the vector is the top of the stack. the latest stack is always at the front.

add new stack- push_front - move all items one block along and insert new stack in the front of the vector- linear time complexity

remove stack - pop_front - move all items to the block previously and remove the first stack- linear time complexity

peek- front - return the first stack in the vector - constant time

size- size - return the counter variable that holds the size of vector- constant time",5.0,12
3858,3858,5540,24404807247a19fa0eb28edfebfb33701c7bf0ce5da4f252098d5b07602e418852b18cd29763fdb981a6cf7530167e7c60c21dd57b0dd95a95c25a71b9515eda,"As the object in the front of the vector will be used at the top of the stack then:

-the push function would need to firstly copy over each object in the vector one space further and then only can the newly specified object be inserted into the front position of the vector as the top of the stack. This would have a time complexity of O(n). 

-the pop function would be required to remove the first object in the vector and then copy every other object one space backward. This would have a time complexity of O(n).

-the top/peek function would simply return the object stored in the first position of the vector which would have a time complexity of O(1).

-the size function would need to return the size of the stack/vector and the vector type keeps a size counter and is updated as objects are added or removed from the vector hence it would have a time complexity of O(1).",11.0,12
3859,3859,5541,8240603fa734ed603f090dc4c8bce2f226cd0f876026dfa595bd8492bf9acd3d4bb834f9651a57ba591889e5cf0e84e937e21bd54121dfe09399f647a5d4f575,"Use push_front to push to the stack, Q(1)
Use pop_front to pop from the stack, Q(1)
Use the front function to peek, Q(1)
Use the size function to get the size, Q(n)",3.0,12
3860,3860,5542,24ddd7a0d5b35a9bdbeb9a6cd62ada87a4901fab347efd86489f1b2e17964822556ee10a0103983d49fdf2477d3d64f6702d59741c364edd11f42906c3bdb067,"I would implement a pop front and a push front function for the vector.

The pop front function will always create a new buffer will n-1 allocated, then copy all the items respectively excluding the first one.

The push front function will always create a new buffer with n+1 allocated, push the thing that I want to push first then copy all the other items respectively.  ",3.0,12
3861,3861,5543,dc28526a371ecd3cfbb01f874b966e2e2019f65befa98a250b0089b346a7e303549dac2ead3ffeef0d3b7ecff19ac3d890b35956aa010524ff365cf1275bd971,"This would make the functions or operations of the stack easy as a ll functions would have a constant time complexity O(1.

push()- this would work using the push_back function, adding all items to the front and reallocating space if needed.

pop()- would pop in the front of the list and reallocated space if needed.

size()- this would return the size of all the items in the stack whilst popping elements from the front and incrementing the counter(which was initially zero).

peek()- simply will return a reference to the first item using the front() function.",4.0,12
3862,3862,5544,48742644955ff1df5e9438b158fe5c8f20c2d07d0778b03adb953d373c991b6155a23d1f85c41ff0cc6c9d4311c4ad31f296412bee149a2c0eeac5233763ea82,"Declare an empty vector inside a for loop,for copying the remaining items after popping from the front of the stack

Worst case - (n^2)
Best case - (n)",2.0,12
3863,3863,5545,d320af019b5c5fbf5996000b6f0c018e158d92ab05c3709236e5a03a6b328c59c1ab963403ff89c119e51b19d4eaa6320e2573a8bf4efb41ca5bbf92364ab8b6,"To implement a push function, we will be adding to the front of the vector which means every time a new element is added every element in the vector has to be moved to the right hence there are n operations which need to be completed for this to happen therefore the complexity is O(n)-linear.
To implement a pop function we will be removing the first item in the vector which means that every time we remove an element from the vector every element has to move one position to the left, this requires n operations and therefore the complexity will be O(n)-linear.

To implement the Top/peek function the builtin vector function vector.front() can be used and this can be done in constant time hence the complexity is O(1)-constant.

The size function can also be done in constant time using the builtin vector functions and hence the complexity is O(1)-constant.",11.0,12
3864,3864,5546,f786d4a53e476362ee6b6cac013b5aa057803211cb74556b039162da9be82c23d9395512d9e4320c69ff2f74e18df3e862b758b12f302cbbc8a9df857835a235,"i would include all the header files,create a vector of vector<int>data,define an integer variable top and initialize it to -1 and implement my operations which are push,pop and size .to push an item to the vector i will say data.push_back(value) and to pop i will say data.pop_back() and to check the size i will say data.size().",0.0,12
3865,3865,5547,a39aa34c391034439ba958ca98869143599e2cc20097d4066633e71706d0b615be58b0586a9143631148978c46ccf7746504f4abfa225c0f60b106eb68d6aeb5,"PUSH

I would be required to place any new items to the bottom of the stack however we can only access the top of the stack. Therefore I must copy the items in the vectors to a new vector (in reverse order) so I can add to the end then copy it back with the new item at the bottom of the stack. This is O(2N) LINEAR TIME in best and worst case scenario

POP

Similar with Push I would need to copy the items over to a new vector then pop_back and recopy to the original vector. This is O(N) LINEAR TIME in best and worst case scenario.

PEEK

I can access the top item which at the top of the stack in O(1) CONSTANT TIME

SIZE

I can use the built in storage of vectors to access the size of the vector in O(1) CONSTANT TIME",9.0,12
3866,3866,5548,185dc4c21423a9741e871c6f410e59bdca77c391c194cec101c75b3cca04c937f124a0057340342b97dc026d09e5d98b6cb6fda9dab2b9032e1e211b08f87356,"This was in the lecture...

Push

This will push to the front of the vector, which is not a vector function because its a very bad implementation of a a vector. This will always take O(n)

Pop

This will remove the item in the front of the vector, again, terrible implementation hence there is no vector function for this. This will always take O(n)

Peek

This will look at the front of the vector, so vector.front(). This will always take O(1)

Size

This will still call n_items as usual, so this will take O(1)",7.0,12
3867,3867,5549,e2110671a4eab220560a21f9e1e9feb257ad75ab23f504a892c8df780bcf445f866d86be0cb87936d65c86a82a0daabcca41a6174ec4192f8f61c7d3034cdab4,"stack.push() -> In order to add a new item to the stack, the vector container's items would need to be moved to their next position (i +1). If there is space this would take O(N) time. There is no space, a reallocation would need to happen, which would STILL BE O(N) time.

In the end, it is ALWAYS O(N) time.

stack.pop() -> Each item, following the first item, would need to be moved one place forward (i-1), causing the first item to be overwritten ('popped'). If the number of items is less than a quarter of the allocated storage, then a reallocation is needed, taking O(N) time. If not, moving the items would still take O(N) time.

In the end, it is also ALWAYS O(N) time.

stack.peek() -> Accessing the first item of a vector will ALWAYS BE O(1) time.

stack.size() -> Vectors always keep track of their size. This function will ALWAYS BE O(1) time.",11.0,12
3868,3868,5550,49811d763ba759a50f2e0c233e15588b02d4f863f2daf7bb9891b1e7fc339a6758ecc3a62c1286ec47602b5e14c6edff45dda6e0d22355027319e6c73f32c285,to do this you would make the first item in the vector equal the top of the stack meaning the size() function would always have constant time because the number of allocated items would be previously stored.This also means that adding new items to the stack would require moving all the values in the stack to the location provided after its current location. So because each item will be moved every time a new object is added to the stack the push_back function would have run time O(n) and so would the pop_back. the pop back would be so because after removing the item in the front it would have to move very other item back one location.the peek function however will have constant time as it can be directly reference with vector operator due to the memory being contiguous.,11.0,12
3869,3869,5551,6e1111ad11474e6379168f87057eae3076970c620dec3cffde8e98db6de9322b94aefef0b0414a791717f61331121e1ad9f15c607c1ff40afee80bcc8c3257b0,"If this is the case then it means that the back of my list is the front of my list, meaning when pushing items at the back of my list, instead of using push_back() I'll use push_front instead same goes for when I am removing an item from the back of the list I'll use pop_front. This will take contant time.",2.0,12
3870,3870,5552,5f1f48eaee5ac422a3c6fa6a37eae574e54bf5c31dcf24e0e6dda503da6ac10d5be4b86335df2a703c5cb0a92be355a3535eec42ddde1a798228e8594808928b,"In order to implement a stack we would need to have the functions: push(), pop(), top() and size().

The push function would have to be a user defined function as push_front() is not in the STL for the vector. For this function we would have to first check if n_allocated =n_size, if it is not, we copy all elements over by one, and then insert the element in the front of the vector by changing the value of the first element to the wanted value, which before the insertion of this element, would be a copy of the second element. Due to this, it would have a time complexity of O(n) (linear time). Should n_allocated=n_size, we would have to reallocate the current vector. However, before we copy all the elements from the original vector into the new vector, we will use the push_back() function on the new vector for the element we wanted to push to the front of the vector. After this we would copy all the elements into the consecutive spaces in the new vector. In this case, it would also take linear time (O(n)) due to the copying. Thus pushing will take linear time, and after either of t

The pop function would have to be a user defined function as it pop_front() is not in the STL for the vector. We would have two separate options for this function. If n_allocated/4<n_size, we would delete the first element by calling its destructor. We would then copy all elements one position back in order to fill the gap created by the deleting the first element. Due to this copying, this process would take linear time. If n_allocated/4>n_size then we would need to reduce the size of the vector and reallocate it. This would require copying all elements into a vector of half the size of the original vector. When doing this copying though, we do not copy the first element of the original vector as we wanted to pop/delete it. Due to this copying, it would tale linear time (O(n)). This popping will always take linear time.

For the top() function, we would simply just use the front() vector function, as it returns a reference to the first element in the vector, which will be at the top of the stack. Thus it will always take constant time (O(1)).

For the size() function, we would simply use the size() vector function. This would entail us essentially returning the value n_items, thus this would take constant time (O(1)).",11.0,12
3871,3871,5553,fa243626fbe26ef57e9cb51b64e34cda34860d25833be057b8aacb2413654723774f7590965ed807a0415dd0e925f4717e86fc15d11f310737f703eab68fbabd,"since there is no pop_front and push_front in vectors, i would reverse the order of the elements of my vector, then use push_back which would require O(1) in best case and O(n) in the worst case. pop_back( ), would require O(1) in best and O(n) in the worst case.  the top and size function take O(1).",7.0,12
3872,3872,5554,0fa5d829ab37316f131667488ff6244b79b525ac275e022289de875a4f7426de94ef384d30176ee34a2851d47d343e62431c37057ae6054ad83ff76862ff86ab,"1.with push function we just have to add an item on the front of the vector. We will do this in a constant O(1) amount of time.

2.with pop function we have to remove each and every item on the back until we reach the item on the front then remove  it. We will do this in a linear O(n) amount of time.

3.with peek function we have to remove every item on the top until we reach the item on the bottom(front) then return its reference. We will do this in a linear O(n) amount of time.

4.with size function we are going to go through each and every item on the vector while counting the number of those function using a loop then return the number of items. We will do this in a linear O(n) amount of time.",3.0,12
3873,3873,5555,b3e3cb2c21ce148370b5e2f91fd1c15e350a5dbb48b70710937a60df00151bac26d80bc3a7bdad4c31eb69ebb35264a7c7773c7f45cef6e057b05eb18d125d01,Complexity- O(n). Adding items to the top of the stack without removing items from the stack,0.0,12
3874,3874,5556,ee3d89b0d1151de34e3cf3043fc2b6592a400e8ce8a1d14d3b5e77f1fc57f3bb24de4a9c4426effca79ea565b502539dcf46a1f1d27d52e0d1e79029ce2f8aab,"to use the front of the vector as the top of the stack, we need to add and remove items from the front of the vector instead of the back like we usually would. As a result, we would use push_front instead of push_back for our push function, pop_front instead of pop_back for our pop function, data.front instead off data.back for our peek function and our size function would remain the same. Push would be constant in the best case and linear in the worst case. Pop would always be linear. Peek and size would always be constant.",7.0,12
3875,3875,5557,e9f55a461571038daf39646f8c350339a639982fda3a68a7de2c663bf3b55fcfe5c2c1470245e6cd83dc29b1d2c16e474b9b4bcd8ac2d4eb9b9e2eef6125ba6e,"Using a stack based vector with the front as the top item of the stack means that every item you add to the stack will become the first item in the vector therefore the functions that make up the stack will be 

data.push_front()(best case O(1) and worst case O(n))

data.pop_front()(best case O(1) and worst case O(n))

data.front()-would always give the first item in the vector and would be constant O(1)

data.size- would return the size of the vector and would always be constant O(1)",7.0,12
3876,3876,5558,73f8ac3de0d9e29b34984491080a2a437e9d07081ef998fb53c2e73bde6a76efa33589c04809db77b67bfaaea71b13e4b7480f42fd75bb56aca6e9a4110b16f7,"You could implement this using the push_front and pop_front functions. These functions aren't coded into the standard vector functions, but can be manually implemented if you code your own vector class. These functions aren't ideal as they would require that you move everything up one space when you either push or pop and therefore they have the complexity of O(n) where n is the amount of items in your vector, since you'll have to move n items each time you call either of these functions. To access your last item, you just call the front() function. This runs in constant time, O(1), as you only need to access the first item using the built in [] operator.",9.0,12
3877,3877,5559,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"*The simplest application of a stack is to reverse a word.You push a given word to stack-letter by letter-and then pop letters from the stack.Which takes O(n) of time.

*Another application is an ""undo"" mechanism in text editors; this operation is accomplished by keeping all text changes in a stack.Which takes O(1) of time.",3.0,12
3878,3878,5560,b47128b210e7cc636fb0b5325c08248ffac624374ed1eaac62c3594d5f67da91cc887cbf07a6c3571b2149ad963910548cff788f165204f9df156115e859a64b,"Let the vector be named data.

There are 4 main functions that need to be created for the implementation, namely: push, pop, peek and size.

push(Thing t) - we can use the push_front(t) function to add to the top of the stack. best case- O(1), worst case- O(n). This is because when the vector is full, it will reallocate with double its size and copy all items.

pop() - we can use the pop_front() function to remove from the top of stack. best case- O(1), worst case- O(n). This is because when the vector is less than 1/4 full, it will reallocate half the space and copy all items.

peek() - we can use data.front() to access the top of the stack. This will always be O(1) 

size()  - we can use data.size() to get the amount of items in stack. Always O(1)",7.0,12
3879,3879,5561,17ea794106565b342d0071ecda1b602670f938db088b102cae298b8fa539f99c81604db8696804a94225d5fcb56b3538a2b45e5527c8d0a393e5e2aa5ae7c0be,"We would need a need push_front, pop_front, peek and size functions

For the push_front function, the time complexity would be O(n) as we would have to move across n items before doing the insert at the front of the vector

For the pop_front function, the time complexity would be O(n) as we would also have to move n items in order to keep track of indexing locations

For the peek function the time complexity would be O(1) as we would simply access the index of the 1st item in the vector

For the size function, the time complexity would be O(1) since we're keeping track of a size counter in the vector",7.0,12
3880,3880,5562,092586b17aeb228a8396915c438a564c216c3df48ac6ded66b121dcea5684d3dbe0caab83fcadb656d3a0a26a4c4e1546317909dd36270918915c4447ba4370c,"I would use push_front instead of push_back and pop_front instead of pop_back.

COMPLEXITY:

for push-O(1)

pop-O(1)

size-O(1)

top-O(1)",2.0,12
3881,3881,5563,cbae5eeb6217dfd80bce3b9f9dcc6a487de93ab5d86c0254cee58b6e3923317f7e11f9c1e67f0e0269268aa476f5f7d41a06d2c8bc23012e2299f02af5f41761,"Create a vector to use as stack.

To push to the stack, you would insert the value to the front of the vector. This would take O(n) because the vector values would each have to be reallocated.

To pop a value from the stack, you would erase the value at the front of the vector. This would take O(n) because the vector values would each have to be reallocated.

To peek at the top of the stack, you would return the value at the front of the vector. This would take O(1) because you would always just look at the first value of the vector.

Top get the size of the stack, you would return the size of the vector. This would take O(1) because a vector stores its current size, and we would just be returning this.",7.0,12
3882,3882,5564,d0487881fde4213facde4c9cd0143d5802f701e002f130b7eaa6dd04f68f58612ae33c39c89beceae1495437bbe2376be3003369a31f0f2bc6f9e0c5a369707a,"Push:

	* use the push front method  to add items to the front.
	* The complexity will be O(n) because each item needs to be shifted towards the back or the vector would need to be copied to a larger vector if it is full.

Pop :

	* use the pop front method to remove the first item.
	* The complexity will always be O(n) each item would need to be shifted toward the front of the vector or the vector would be copied to a smaller vector when it is full.

Peak :

	* use the front method to get the first item.
	* The complexity will always be O(1) since it is the first item in the vector.

Size :

	* use the inbuilt size method to get the size.
	* the complexity will always be O(1) since the size is stored and adjusted according to changes in the vector in the vector class.",11.0,12
3883,3883,5565,ff8092e7aa4e021dd13cb98107d467aae4489986d4e06673b1b4c81ebb2bbfe82687888ce375f42c4423ae545a48ef629cc67802c799162dd6a5d1de2f545d85,"declare two vectors vec1 and vec2, insert elements to vec1 using push_back(), copy each element from vec1 to vec2 starting from the back so that the last in vec1 is the first in vec2, this can done by the loop. vec2 is the one that we need.",0.0,12
3884,3884,5566,5efe3fbf856ecf3a15a69292118ba94b4935a0dba8b272f0af264465d64a2e654697453d0e3e6e72201dc798f4cd3f27b28fbe0c2032a2a7784e39ed4c150909,"Create stack class

Push:
You will push on elements at the top of the stack + 1 (if there is no elements in the vector currently). Increase/increment top. Continue pushing into the stack by insertion then increment. (Note: New placement is the top of the stack)
Pop:

For popping, remember the top of the stack is where increment was last made. Change to whatever element you are required to change it to. Increment through and allocate next value in the vector. (Remember that's where the top will be indicated as)

When n_items = n_allocated we have run out of space and have to reallocate all of that space by doubling size of array. 

Peak:

reference to what is on top

Size:

keep track of size of vector

create private function to store values.",2.0,12
3885,3885,5567,52240fd5da488c8fea93f35bf4efe57000386d8c8d0c85c5b680c74f1a8feca90e13d4df01d1470660907e2655f277134bf53af33144e84c3793614abbdf6e99,"You would implement this the same way as you would if the back of the vector was used as the top of the stack except when adding and removing things from the top of the stack, you would use push_front and pop_front. the size and top functions would remain unchanged and still have a constant amount of time while the push_front and pop_front functions would now always take a linear amount of time.",7.0,12
3886,3886,5568,66c130d147af93128f149a1c3cbc0822def0372144aa77769fad8d406e0bf1fdaea5c4080bf967de52230b79e34763f78e3d8c34ddd69955b5c9b8521c52443c,"The 4 functions that will be used from the vector class are the pop_front(), push_front(), size() and front(). This will be implemented the same way as if the top of the stack was the back of the vector, due to the fact that vectors are made up of contiguous memory. This means that the pop_front() function would generally take 0(1) amount of time, but worst case (when the vector becomes a quarter of its full size, it will reallocated the whole list with half of its memory size allocated) it will take 0(n). The push_front() function would have the same time frame as the pop_front() function which is generally 0(1) but worse case (when the vector runs out of space, it will reallocate all the items in itself into a new memory space that is double the size of the previous space) it will take 0(n). The size() function will always be 0(1) as the vector class keeps track of its size. Finally, the front() function will also always be 0(1) because of the property of contiguous memory.",7.0,12
3887,3887,5569,2ac52bf7176b74f783c4dc472a3ad61819784c24e47b750c3635810bda8131880643be2f953dc39facdc68dcec02aa6cc62d7628e7e8b294770838010259c464,"In a vector, pushing to the front of the vector will increase the top of the stack. For example if you would add something to the end of the line(front) it would be equivalent to adding it to the top of the stack.

If you are pushing to the back, the work of the function call has a best and worst case. The best case is when there is already space and it does a constant amount of work (O(1)). And worst case is a linear amount of work (O(n)). ",2.0,12
3888,3888,5570,cdf5a55df376657eda6b008ced4f7043cdba2f1d1b7da216b9e5df9fd11e894729a95890612c52ba24c8f6e0b1099b039f557d8043ee19615f361b8a60481af7,"The front of the vector corresponds to the top of the stack so to add to the stack, we add to the front of the vector and the best case complexity would be O(1) if there is already space and the worst case would be O(n). To remove something from the stack we remove it from the front as the front of the vector corresponds to the top of the stack, the best case would be O(1) and the worst case would be O(n).  To return a reference to the top of the stack, the complexity would be O(1) as the front of the vector corresponds to the top of the vector. To return the number of items in the stack will always be constant time, O(1). ",6.0,12
3889,3889,5571,eacc5211df7d685afcc35802886c12863f0c8244351fcd398189af9fa9bf26e12a751640dd66f6200f43478fc4f6782d51b4f6c4a782ca1b75e12c96dded3eec,"In terms of the push, pop, size and peek functions of the stack: 
Push: 

A vector push front method does not exist and to implement one would require a time complexity of O(n)

Pop: 

A vector pop front method does not exist and implementing one would require a time complexity of O(n)

Peek function: 

using the vector front() method which has a time complexity of O(1)

Size function: 

using the built-in vector size function which has a time complexity of O(1)",7.0,12
3890,3890,5572,4bccbfcaa9439271fb4e221590e1fd6768f9a6170a62193e2aa38f727ca7e838985ca00984f7b4a782149961c288a265aac8163c38e74ff4f6279a0f9baaec5e,"push, taking in Thing t as a parameter: O(n) time. Best case - Move every object one further place than it was previously in the vector (1st element becomes 2nd, 2nd element becomes the 3rd, so on). Worst case - If the vector is full, make a new one with double the space allocated, along with moving every object one further place. Both the best case and the worst case take O(n) time.

pop : O(n) time. Best case - Remove the object at the start of the vector, and move every object one place further back than it previously was. Worst case - If less than a quarter of the space is being used, make a new vector with half the space, along with moving every object one place further back.

front : O(1) time. Return the object at the front of the vector, which takes constant time.

size: O(n) time. Traverse through the vector, and return the number of objects.",11.0,12
3891,3891,5573,8c4ece10bea4707d74ad8e485b192cf388c1aaad3dd5b625cadaaa6a947d3861bc0547f235d6ff3af091e10ce08cd771b73e98b692a991cef32a92e7b557b387,"PUSH

For the push function, I would continue using the push() function just like in normal situations but each time an element is added, it is  allocated to the address [0] so that it shifts to become the first element in the stack. I will use recursion to make sure that last item to be  added gets the address[0] and the memory the addresses of the rest of the elements get incremented by 1. Complexity though will be linear O(n)

SIZE   

Since vectors automatically calculate the number of element, I would use size() to get the number of elements. The complexity of this function is independent, so its constant O(1)

PEEK 

Since the arrangements is almost the same as the one in the normal vector, I would use the function top() to get the last element to be added. The complexity of this constant O(1).

POP

The last element to be added is at the front of the vector. I would use recursion to make sure that the element at position [0] is deleted and the rest of the elements' positions are decremented by one. Since the first element is the focal point, the complexity is constant time O(1) but linear O(n) in the worst case",11.0,12
3892,3892,5574,8898c8dc647252a67895b09c0b6e1e1b46e9abbd7623ddf40416335c9bffe71bf94348a71bd79a7ce33d630fd22f8d8b30ee288c330b6c240bf1f662dbee2a5b,"Considering the 5 Stack functions:

	* Push
	* pop
	* top
	* size
	* empty

The Vector functions that will be used in each Stack function:

	* Push front
	* pop front
	* front
	* size
	* size(check if its size is equal to 0)

And their complexities are:

	* O(n) - linear
	* O(n) - linear
	* O(1) - constant
	* O(1) - constant
	* O(1) - constant",7.0,12
3893,3893,5575,7099f15d1fb337686bf427fedb824d4eefc2c359e7374f808226d1191d0f74342e42146c05dfa9cdc17fbdc8dce0a4cb75b417e6eb24978dd57c4773dec73b21,"I would implement my stack with the container = std::vector<Things> , where as you add or remove items it removes it from the FRONT of the vector requiring to reallocate the vector in the heap when adding or removing an item and causing it to take a linear amount of time..

For push_back(T value) function: Requires O(n) amount of time as each item in the vector must be shifted or reallocated.

For pop_back() function: Requires O(n) amount of time as each item in the vector must be shifted or reallocated.

For pop()/peep() function: Requires O(1) (constant) amount of time as a vector is contiguous data.

For size() function: Requires O(1) (constant) amount of time as a vector keeps track of its size.",7.0,12
3894,3894,5576,ac00d5695452023736c168247b6e6e7ac1c86c1918ba65ce039a3ac355db0c0c6d3945a25b1f4c24df8db20417ffdf726ff5a44586e3fb4757147f393e36515b,"To insert new items to the top of the stack I'll have to create a new vector every time I push to the top of the stack. This means I'll have to make a copy every time I insert a new item. The only time I don't have to make a copy is when the item is the first in the stack. So in the best case scenario, i.e when the item is the first in the stack it only takes a constant amount of work. In the worst case, i.e when I have to make a copy, it'll take a linear amount of work because I'll have to create another vector, insert the item in the first position and copy the others. For the pop_front() function there's also a best and worst case scenario. The best case scenario occurs when there's only one item in the stack and so we just pop the item off the stack, this will take a constant amount of work. For the worst case scenario, we have to create another vector and copy all the remaining elements after removing the single item at the top of the stack, so this will take a linear amount of work. For the size function there's only one case and it's constant. To get the reference to the top element we'll use the function front and it takes constant amount of work.",4.0,12
3895,3895,5577,16f82e0a87e8ddd62872296dc55051239fbed9bd7e989d4564eab3d0b0bd3dd97f30debd1ef7c57a72ffc4e972a5a710915f103218e9d2778be68d8b10a7d403,"We would push front ,pop front in order to add or remove the item and this would be O(1) as it is from the front of the vector.

When wanting the size and peek of the stack we would use the normal function data.size( )/data.peek( ) and this would be in constant time O(1).",3.0,12
3896,3896,5578,07ab043d70e14725f955703ce65a95b6912342e429a6c9a7dec43aacd53b63f2b0d3ebef4da8ffdff01a86c6c296ffe0e21e4d798223854fe6e651460e1d7280,"In the standard vector library there is no pushfront() and popfront() methods so this will have to be implemented. 

The peak function that returns a reference to the top of the stack would be calling the front() function from the vector. This should be linear as the vector uses a contiguous block of memory and so the size peak function will be O(1). 

The size function can use the preexisting size function from the vector. This should be O(1) as the vector should be keeping  track of how many items are in the vector. 

The push function would require going through the vector and moving each element to the next position in a reverse loop. This will occur n times regardless of whether there is enough memory allocated for the vector. Hence pushing will be O(n).

The pop function would also require using the destructor for the first element and then updating the vector by shifting each element to the previous position. This would mean looping n times through the vector hence popping will be O(n).",11.0,12
3897,3897,5579,14bf4a341dc9827953823163cd007e766c263b8c396bea85416367e8c4908e0df252e9e3ac38e08223a3bcc05a108adef9f1881af30b78d3c7220ceb7c6be157,"To push, we allocate that block of memory to the element we wish to add, while keeping track of our top. Once it has been added on the stack, we increment our top-so that it refers to the consecutive added element. Best case for push is O(1), worst case is O(n)-this is when we need to reallocate . 

To pop, we simply remove the item at the top of our stack. This takes 0(1) time if there is no need for reallocation and O(n) time if there is. 

To peek ,we simply return a reference to the item at the tip-this takes constant time, O(1)

For size, the vector stores the number of items and hence this takes O(1) always.",7.0,12
3898,3898,5580,128e2656328deed2d77d2ef28a4c653d82a40a62fd734c4ccb3dafb70805db8a812cccc608184c6cbda73e2bdda34e6f81ec5dacc95d16cb9a78cba4ff089ac5,"The first element in the vector will always be the top of the stack. This means that when we add items, we make use of the push_front function, which places a new item before all of the existing elements in the vector. This also means that when we remove an item, we make use of the pop_front function, which removes the very first item in the vector. This would mean that the operation time is always a constant, O(1), until the vector is full, in which case we would need to create a new vector with double the space, which would take O(n) time.",3.0,12
3899,3899,5581,1e30eb511c307c57041552d3f3ff58f0e01dff16b4bbeafb7e1426a20560b5727bf879a4c238af04f66b8c454f01b583c75d2d8fab510951c437d49081081f31,"To get the front of the vector to correspond to the top of the stack- instead of pushing back every new element, I would create a function that would enable me to push front every new element in the vector and instead of popping back I would create a function that would enable me to pop front. In that way when I call the top function it will return the 1st element entered in the vector(front of the vector).",0.0,12
3900,3900,5582,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"push- add the element to the vector O(n)

pop- remove the first element in the vector O(n)

peek- return the first element's value O(1)

size- return the size of the vector O(1)",7.0,12
3901,3901,5583,2dec7d91f389ea815b08c16bf0ce77e60642ceca404945e8ad369e8ed82ed28e57d6cf12351d45add693d36c78a2ba5f4910e162bacba9689368c6699766d9b3,"Every time you push_back on the vector, you will have to pop all of the elements on the stack and push them again starting from the back of the vector.

Push: O(n)

Top: O(1)

Pop: O(n)

size_t: O(n)",6.0,12
3902,3902,5584,91ebe020e489f0682b9824bba92593f1328536973fcefa2088842b20b827aef8bdfb02c354fbd4b326e7989de48aea571427c17aa049b6dadee99c74f1c15bdb,"* push()
Use push_front from std::vector then the lime complexity will always be O(n) because every item on the list will have to move one position up if there's space and if there's no space it would have to reallocate again taking O(n).
	* pop()
Use pop_front from std::vector then the time complexity would be O(1) in the best case and O(n) in the worst case.
	* Peek()
Use front from std::vector and the time complexity will always be O(1).
	* size()
Use the size function from std::vector then the time complexity will always be O(n).",9.0,12
3903,3903,5585,0b4066304490dceaa89df857c52096e501a361b0158a4122fe0743ccedb637acfd51e379e86df6a8a4f667a87b6d33f81aa5b4a035dd7d71db1ee1c7171afd95,"For adding items on to the stack I would use the push_front() function since it would just push everything back and add my item to the front, since I'll be moving all the items to the back runtime and storage complexities will both be linear.

For removing an item off the front of the list i would have to move all the items forward one step using the pop_front() funtion, that would also require a linear runtime and storage complexity

To give me the size of the of the of the stack i would just use the .size() function, and it would just use constant runtime and storage complexities since I'll just be returning a value/constant

To give me the reference to the top of the of the stack i would just dereference the pointer to the vector and just add one to it and return that value, this would also just take a constant runtime and storage complexity ",9.0,12
3904,3904,5586,8cfb9c3f85d9b6edb1f914f05f74928e81fe7cb4cefb95f1de4efb3fd1ac54a2356179dfe5b33b1cac09455e2960c015d866e1097ed5d7d20fbbdcb0d2aeee6d,"You could use a push front function to add an item to the front of the stack, and push every other item one position further. This would be O(1) when there is space in the function for an item to be added and the last allocated memory is not full. It would be O(n) in the worst case when there is no more space in the vector to add an item and you have to allocate new memory and copy and paste all the old items to the new list, pushed one position further and add the new item to the front of the list.",3.0,12
3905,3905,5587,3dd0e6b0aa4ca279a9a8f781013cc1ffadd92a615d343d8f7162570e3cd2647c9fb452de2221fcafa1322a70dac1ad1ef68bd5efe79682df415f360b352ef94b,"First initialize a public class of called stack. Then within the class implement a void push_back function, a void pop_back function, size_of function and Thig top function which will be constant time O(1) in the best case and linear O(n) in the worst case. ",2.0,12
3906,3906,5588,bd50a1f76e0acde64b2131110f2268f08aef333a162fed075d374337a58f0180c5f1efb88a7f6560e676d09d9ae71856da1ed18b029ff6c96af885a57d9fef75,"we will use the push_front function to push to the stack and that will take us constant time if we have space but O(n) if we don't have space and we will also pop from the from of the vector which will take use constant time.

and the peek will take us linear time as we will be accessing the first item on the vector and the size will also take us constant time . ",7.0,12
3907,3907,5589,c1e502cb9307976ed3c86bb3e1a2a0d1fad4d05b1ff3b6ca09a4a8992703680a55c9ae6e51c9417d756549fe340afbac12cdfcd3dbe4f6a560b6a171ce7f1eeb,"push:  I would use a for loop to insert the item in the front an move over the existing items towards the back of the vector. The complexity will be O(n) as the time would depend on the number of items.

pop: I would use a for loop to move over the items towards the front of the vector as each value replaces the spot of the previous value. Time complexity will be O(n) in the best case but O(n^2) in the worst case if too much space is used an reallocation must occur.

peek: I would index the vector at index 0 and return the first item of the vector which is the top of the stack and the complexity will be O(1).

size: I would use the vector's size() function to bring the size of the vector and the complexity will be O(1) because the vector class has a variable member that keeps track of the number of items.  ",11.0,12
3908,3908,5590,8052ea5813981ce1b1dc18dcce8d4c10c33b769890ea3f35ecc1dc5a6465b4897efddc1a12c6d7a26b5d0da8ca3c779589f99331e5d2c411636cea22d157833a,"i could only push at the front, pop at the front, peek at the front and get size counting from the back to the front.time complexity for push is and pop is 0(1) and its also o(1) for peek and its o(n) for size",0.0,12
3909,3909,5591,8fd97c5322558e2423003672fe174f30c080d208985516c4cd8749e1d3f072ac5736c633a74790122fa877f92436ac7777fc9cf9c36610a77bd1566b6903427e,"Whenever we push/pop, we always add/remove an item at the front of the vector and the complexity is O(n). The peak we just return the item and for size the number of items and it's O(1).",9.0,12
3910,3910,5592,eb636b71b69b444b76b68045ede7c5b96290b63dc94e90986ac7258b980a7f8df480d1b6926e41ac5186df7da647131dcbb111a84e28e5a68a37dc453c1f06bf,"To add an item the PUSH_FRONT function would be used and to add the an item POP_FRONT would be used. The complexity of the in a best case would be O(1), that's in a case where the vector has only one item when popping and when the vector is empty when add. in a worse case for both functions, It will be O(n) because when the vector has items when adding or removing everything has to be copied into a new vector every time the function is called.

For PEEK FUNCTION, we just need to return the first item which has a complexity of, in worse and best case still remain O(1).
For ISEMPTY FUNCTION, the complexity will still be O(1) since the is no list of items to go through.
For SIZE function the complexity is O(1) since the we only need the index of the last function plus one",7.0,12
3911,3911,5593,1b24ef0d303f3078167a7dbca152a2c1d687ceab3654a2ae76bf73e5ee1cc0069be94db2fff74908c1492e9ab7afab08d7fd457a365a4c193c2adc5bcd9b850a,"by using the using the front of a vector as the top of the stack we can have certain 2 scenarios for both pop back and push back.with the pop back function in the case were we have 1 item in our vector then we take O(1) constant time to remove it.in the case of us having n items in the list we set the thing at the first element to be 0 and we have to move everything i-1 to the left of their position with i being their position

another complexity we can have is regarding pushing front.in the case when the vector is empty pushing front to it takes constant time O(1).in the case were we have n items we have to move the items plus one from their position.This is the worst case time complexity as will take  O(n) time to push front.",7.0,12
3912,3912,5594,fd6a36ea3be7fe00a0626c8ff80a591e0ee46b9eb9f16c4ccfb925e8237975ae584522b908d7f487d3fa4016ee5035673c870e0b6b78ebf935c75fa0905d0961,"for Push : i would use a push_front function which will insert at the front of the vector this will take O(n) but if it has one element then O(1);
for Pop : i would use a pop_front function which will remove at the front of the vector this will take O(n) but if it has one element then O(1)
for peek : i would use front function to check whats in the front of the vector this will take O(1)
for size : i would use a size which will return the size of the vector this will take O(n) but best case will be O(1)",7.0,12
3913,3913,5595,55fe3fe2f479a6880b0c712c4e8a68696125fae47531859339e76b32fd81a881527cd93fc43bbd4116f56991339ff706e490311026cb817361fafa6e47ec0b11,"* push front

	* shift everything over one position(ie copy postion 5 to position 6, then position 4 to 5 etc... till position 0 is in position 1) 
	* now insert new value at front(position 0)
	* this will always be linear O(n)

	* pop front

	* delete position 0
	* then shift every item to left (ie position 1 to 0; position 2 to 1, etc...)
	* this would be linear O(1)

	* peek

	* return the first item at position 0
	* this will be constant O(1)

	* size

	* return the number of items in the vector
	* this will be constant O(1)",11.0,12
3914,3914,5596,b62178f325a37f31c95fa1765add6431ffda3b6e9e137a6c1634820014c3bfc3f4c574a7130344e47d262896d038b700c7e7372470c7667fbf621506106a2a97,"push_front(): create a new vector, add item wish to add then copy the items from the previous vector to it, O(n)

pop_front(): delete the item at position 0, shift each  item 1 place to the left, best case O(n) 

peek_front(): return item at position 0, O(1)

size():return the number of items in the vector, O(1)

 ",9.0,12
3915,3915,5597,7c87322598f2ceacf4938051fa8e249fba61f740f1c131025859319c9334a0e7c5eed0d631406a69aaecd55c3154797379e9e557934a0c639e13848fc2a797db,"I could create a vector as the underlying container and store elements in that vector,the vector will have a pointer pointing to it therefore to implement the push,pop and peel functions it will take liner time while implementing the size_t size() function will only take constant time as vectors already store their size making it easily accessible.",5.0,12
3916,3916,5598,9d9fbdb8f0b5a55cc81f40af01c24b37d17fe31db439c419f81b64ca34d8f4ebfcf1ed9c7ba472f3885693ca593e5565dfb6d3c7a7ecc8755427baec264e52b2,"Since the front is treated as the top we cannot use the push_back() and pop_back() functions of the vector class. We instead have to create our own push_front() function (not supported in vector class), which would work by copying each item one place forward and then adding the new item to the first spot by using pointer arithmetic, due to the copying of all the items it would O(n) time usually and O(n^2) time in the worst case (when it has to reallocate to make room for the new item). 

Similarly for our pop_front() function we would have to copy each item (after the first) one place back and then pop the last item (as it's a duplicate), this would also usually be O(n) time due to all the copying and O(n^2) time in the worst case (when it has to reallocate).

The top function could be implemented using the vector's front() function which uses pointer arithmetic to return a reference to the first item, this would be O(1) time.

Getting the size would be O(1) time as we just call the vector's size() function, which simply has a variable keep track of the size as items are added and removed.

 ",3.0,12
3917,3917,5599,8a8eb86cf56dd2444d2bc5441387c73e3fcbac4867da844d41e7ee67a78c9e8b163da9822047fef10101762a7abd4eba2ff040d29869420924f78a2c686ad858,"PUSH

linear + linear as would need to reverse, push and reverse again

POP

linear as would have to reverse, pop and reverse again

PEEK

constant time access as this can be obtained using the reference to the front of the vector. 

SIZE

constant time as this is the number of items in the vector. So can get this through size function.",5.0,12
3918,3918,5600,07076ad9a7e3813bce19a739ebedaab894d1a330269763e0925227d8822b601591c19afe0ea5ecf81637c9b73f442db6cacafab2329d262fef0fb68d97bef78a,"we can use push_front to add items to stack and pop_front to remove items off the stack.

we can use ""vector name"".front to find the peek of the stack or reference and use ""vector name"". size to find the number of items i vector.

the time will always be O(1)",3.0,12
3919,3919,5601,48452c6af5685c82851988d96add3ed11ed530ba837e28f21c3e92d7b83a44fbe9879abbcb6e1ae0256b1dc9b2ef98a34c294dacae561958335cfe0e83b08e8d,"I would implement this by using queues.

Time complexity of popping and pushing would be O(1)

Time complexity of size would also be O(1)",1.0,12
3920,3920,5602,999b8af04a99b1971783a730d1a109e30fdff2f88a1f40dc36731dceaa01148aef1c1f5d96b5999593020819ebc46f676235aa6d5dc12859b91750c9e8b5c9c4,As memory is contiguous and we are always working at the front it will make lost of function easier.inside vector class the will be size() function which will increment size when push is called or decrement when pop is called.having size of vector will allow program to use pointer arithmetic but in this case we will work at index 0 so when push is called at best case time complexity  it will be O(1) in this case the is space available at worst case I have to reallocate which means making n+1 copies  thus having time complexity of O(n) .peek function will always be O(1) because we want index 0.pop function has best case when I'm not wasting space time complexity will be O(1) but when space is wasted I have to reallocate making n-1 copies resulting in  O(n) time complexity.inside pop function I will perfom n-1 copies and decrement size resulting in O(n^2) at worst case.,3.0,12
3921,3921,5603,f64eaf53775ca019aa46e95d674f953f5fe42b8661af69f4cf932eb77a69c0b6057310158946905b9d5788a5b3a8acd5e3f0f489603023b3ef81fc676dabaddd,the front of the correspond to the top because we remove/pop or add/push a the top of the stack only. this can either result to O(n) or O(1) depending how the big the stack is,3.0,12
3922,3922,5604,bee12730d57033f530e6d3af850b801527bbf28710ff5b08a5e590d280e30c6a0345b61d0e3b24cafaad1628aee3191406710ce83cd7009c586afaf78d031389,"In a class with a declared vector, implementing this would require push-front,pop_front, peek, and size functions.

PUSH_FRONT - this would add to the start of the vector by first pushing back every item using some type of loop, then adding the reference to the item been added, because of the traversal the complexity would be linear/O(n).

POP_FRONT - this would be a similar process the push_front but instead move each item forward in the list (resulting in a smaller vector) with linear/O(n) complexity.

PEEK - this would just return a reference to the first element in the vector using vector::front with constant/O(1) complexity.

SIZE - this would just use vector::size to calculate the number of elements with constant/O(1) complexity",11.0,12
3923,3923,5605,0814448191d29da9008582aa1dc261271817cf4f70631f519f01177439d50267cb21e8d39c1f121e1aee03914798dbfab1836210758982742e26c801f01d7bc4,"all functions will be public.Vector data will be private.Ensure enough space and all function(void push,pop,Thing&peek ,size) will be O(1),constant time",2.0,12
3924,3924,5606,d3ddf356f072bf43331098b8a43e33c8b3192b402decaa6c3b442e9385a8eff79ab7318fc38d8ae8da018a53bd14daa455a684126f1cf0ce97908dac2dc0af07,"popping

popping would mean pop_front of a vector that would take linear time as items need to be shifted to the left.

pop at the front of the vector

pushing 

pushing would mean pushing at the front of a vector that would mean it would take linear time.

push at the front of the vector

top

finding top will  take constant time cause we can use pointer arithmetic

use pointer arithmetic to take the last thing

size 

it will take constant time",9.0,12
3925,3925,5607,e02b2e6799a632f8edf7a4522f9a996ef61735be79c062229a0e89a8ede6774052ec8736d48de69d3335b6ebe5ac154baf9a59c6f5866c7ad081372900ff0ff8,"if the front of the vector is top of the stack then pushing a vector would always be a constant time function 0(1). So every time a value is added at front it is required to just add on top. Similarly, pushback of the last item would also be constant since the item is right in front. To implement we would make a vector and a class in which we would make all the functions we want to perform as public. After that we would do the necessary coding in which a vector pops or pushfront's an item into the stack.",2.0,12
3926,3926,5608,a837228a932a0a88d86d56984d3a65abcc9744de389dd1a09c0dbc6344b07254c5f44d2d0e035800fe07d8fd7ef535a3af313b16fa0ec5085dc57d2a491f0957,"the implementations of the various function i.e push, back, pop etc will have a O(n) notation",3.0,12
3927,3927,5609,2a38888a8b80ad136312b78d25e48a8f2ffafd5c8eeba2c39a3cf4d0b1565a722030f9463fa977a5038fd88a16d989882eed3aeb8631f846fa1888531a07766e,"Pushing an item will usually be O(1), but will be O(n) in the worst case. Popping an item will usually be O(1), but in the worst case will be O(n). ",3.0,12
3928,3928,5610,e23792b17279f93b3cce4dddca09079f761a6a0f2795c6c3c7434b417d9b72d4e94d0c740b318fb5b6d57338883455b8fe250e5759d4aa78bd8b7bd3bfed6a55,"I would create a vector where I need to keep the top of the stack in front of the vector and I would create the following functions; pop_front(), push_front(), front() and size(). These functions will help to make us to work at the front of the vector.

pop_front() will have a O(n) time complexity as each element would have to be copied 1 space to the front of the vector and if we need to reduce the size of the vector we then just ignore copying the last item keeping O(n) time complexity.

push_front() will have a O(n) time complexity for best case as each element will have to be copied 1 space backwards to free up the first spot of the vector, if the vector size needs to be increased, then we code such that we copy each item 1 space forward therefore we will have an empty space in the front of the vector.

front() will have a O(1) time complexity as fetching any element of a vector is constant because of pointer arithmetic.

size() will also have a O(1) time complexity as the vector keeps track of how many items it has.",11.0,12
3929,3929,5611,48b61851d938b41ee8c845154660df999994e48772e63eb0fc08241d1da91dd060085f370b13a4f968cd076d5b498fb619542e3786a80328ae705382da43a829,"With vectors we are always operating at the back of the vector, and we do not have to traverse through a vector since accessing items is possible.

push_front(): If there is enough space, we move each item one place to the right and we add the new item to the front - linear work O(n). If there is not enough space, we create a larger  vector and copy all n items over and add the new item to the front - linear work O(n). Both the best case and worst case take a linear amount of work O(n).

pop_front(): We just remove the item at the front vector[0] which takes constant time O(1). In the worst case we are wasting space (n_items<n_allocated/4) and so we reallocate smaller space after removing the item - this takes a linear amount of work O(n). 

peek(): Constant time O(1) since we easily reference the item at the top of the list and we always do the same amount of work. 

size(): we already have a size function for vectors and so this will take constant time O(1). ",9.0,12
3930,3930,5612,f03b1f416ca031a8c9d6db448d0d8439f9016edf947b1c8b45411ef2872c68250d908495b49ab16d7b6e23f038f5ac72fb1ec72bfe11a51db67cec76a8643ecb,I'd use a push back function to add data to the top of the stack and implement a pop back function which removes things from the top of the stack(recently added data). In order to find out the amount of data on the stack I'd use the vector size function. To peek the data at the top of the stack I'd return data at the back of the vector.,2.0,12
3931,3931,5613,59ba65c517c334e25d3ae45ca0766a06b5a36061abfca1dd80f0f9e00eca00b8fc96224e4fcd721b2a66146a086c07a1cca9cf5028a8fc5d88a04890a96fe5a7,.,0.0,12
3932,3932,5614,0874df3f65542027273a16915ace9ed9ec51ca5d508f5bc4a25d6e8fb6352a668e9f762cc0692fb52fe5d216cf363f7813d3abecb5d910688f89eb0977699ad2,"I will use push_front,pop_front functions.

push_front= O(1)

pop_front =O(1)",0.0,12
3933,3933,5615,072df8e3c1de059673d8b782c554cf64da21277fb2ba12d1d8f4ab73cd1269538ca3968b89e11ecaa84835030161cc68c0efae276a64b66f06c4f0c8a0d2ada3,"i would use push, pop and front to access the data in a constant amount of tme o(1) and then traverse through the list to get its size using a linear amount of time O(1)",3.0,12
3934,3934,5616,112623e30928da280b124065b33eb8360f6fe49f45f9b97cc7a540f6e550a5152dd7bbbd6ba167e88c839362c8fd2148a3e881c83493d58d2e9fd2216c604c8a,"To add to the stack I would use push front and pop front to remove from the top of the stack. To add to the front, move all items one space to the right. If the vector is full, add the desired item and then copy the other items to new memory. Using the vector all operations, push, pop, peek and size would have a complexity of O(1). However, pop would take O(n) if there is more than enough space whilst push would take O(n) if there is no free space.",7.0,12
3935,3935,5617,2c57052c92283203acd8d1c12f3f24bff9fcc6fc06d4ccaf21f6b88069300e298296f4f82426d3a1b2f0d2ff83e57ea1826f7e8e04b0393de99a4b442ad3afab,"I could reverse the vector first to make the front of the vector be at the top of the stack and the time complexity will be O(n).

Create links curr that will point to head, prev and next that will point to a null pointer. Then traverse through the vector, inside the while loop initialize next to be the next thing that curr points to, the next thing that curr points to should prev, then let prev to be curr and curr to be next and exit the while loop and initialize head to be prev.",0.0,12
3936,3936,5618,a51b1137941b4a2c9fd6d66da41292b1d5da2b0315b3c4cbaa7f507deed0fbfe1d51f7372760847ad411ee0d78ff9de354c3d1a9bb27433af4b5f7b732027fa9,"I would _never _do that!

Every time you add or pop off from the stack the whole vector would have to be copied again. Complexity is O(n) for both those functions. Bad idea.",3.0,12
3937,3937,5619,2bed72130045c9fb6315517a1cd0576fdbc71ee8714b8107f6ddc3d51fbc170cd1fbdf2110982b17b6e61a87f656eb89a47f0eef9a898bfa08b1c56801ac6236,I would just use/call the front function and the time complexity would be O(n),1.0,12
3938,3938,5620,2f496bb2a99de18fa436df0deced0620c47daee5ce37cf49cf6b3200c20eb84e5a9b7a47850d29ff143886bc9932f54f86b6a1101a1d0f70874e22b40b657cec,"With regards to the push back and pop back functions, we will need to keep running to the number of elements we have therefore it will run to 0(n) complexity, regardless of whether or not there is extra space allocated. ",3.0,12
3939,3939,5621,939ec9a57a50490db2733608917f50113db66f29232d7ede4b3f765d85522c6883d672d7c5bad821ddeab74dbf066c3294635d07979c4557288fa30e0ff3d929,I would push front and the complexity would be O(1). I would pop front and complexity would O(1) and I would peek by returning to the front and the compelxity would be O(1) and I would return size which would be O(1).,3.0,12
3940,3940,5622,11033a17d67159be6a6bbc8378c0392c95d06eb759a822fa4a4ab3fcd33a9e9c6b4e8e1a2ffedc295aecb757927d81558a966188674240b280a874a24f0debc2,"To peek at the first item in the vector you would reference the first item in the vector.O(1)

To add a new item in the vector you would push each item to the next position. If there is not enough space you would have to reallocate the data to a bigger vector. And then push the new item into the vector. O(n) for the best case and O(n)^2 for worst case scenarios.

For size you would have to traverse through the vector whilst using and incrementing a counter variable and then return the variable.O(n)

For pop you would move every item in the vector one position backwards and then decrease the size of the vector by 1. And then add the new variable to end of the vector.O(n)",10.0,12
3941,3941,5623,29fcf57bccb37a2f0d949733d7028b65c0e2df19a9ddbd0c547e57467d84c825defbaf635dea276a63c3d3e85a6fb4f7a84d6da08661ca46728f222c62700315,"One would first have to declare the variables in a private stack class, the different functions would be coded such as, push_front function to add the item from the top of the stack ,pop_front function to remover the item from the top of the stack ,size function to return the number of items in the stack ,and peek function to return the reference of the item in the stack. This means that the when using the functions in the stack it would use the 'first in first out' structure. The complexity of the push_front(t) and pop_front() functions would have the best case of being constant(O(1)) and the worst case of it being linear(O(n)), the size() and peek() functions would always remain constant(O(1)).",7.0,12
3942,3942,5624,20effcbf64917de69f0f441958ac819d52ad486a65f959444a5ddd14ca83a40e581709b6bb9eae431ca2dd02ce933a201bc9b7e43298585d0858d76601344ce0,"First we will would declare a vector in the private stack class. 

Then we would enter the different functions starting with push_front which in the best case would be constant and in the worst case would be linear.

pop_front would be used to remove the top value and in best case would be constant and in the worst case it would be linear.

The peek would be used to get the reference of the top value and it will always be achieved in constant time and lastly the size of the vector can also always be achieved in constant time ",7.0,12
3943,3943,5625,3e664d9b290450a26a44195a29971d5e7c7434afb68523c4038cc69f5c1285f4c94e2b62945fc7bf5800f3a5190a2876a925f82823b3806d9c640fa0e0d73571,"since the data pointer of a vector points to the first item address in the heap you could do make it point to the last item by doing your own push front, you could push the items in the vector to the left and loop over the vector so that when an item is added it is in the empty first space and the pointer will still be pointing to",2.0,12
3944,3944,5626,d7ea0f2a38310b663df581928807c739d1135118819d5b7623733f4d054b7f50d32672538781df6012ffae2751400911c7d428efb70c05b3c3719b6aef5da475,"Implementing a stack which uses a vector where the front corresponds to the top in the stack means that the element at the first position of the vector needs to be the most recent. Last in first out , instead we will be pushing at the front of the vector which is usually O(1) , but in the worst case where the vector is empty and we need to create a new one and copy across it will take up lineard time O(n). We would always pop at the front of the vector and this will usually take up O(1) . The size function will remain the same as when we would be popping and pushing at the back of the vector. The peek function will always take O(1) time because we return the element at the first position of the vector.",4.0,12
3945,3945,5627,2edf0656134d19474a53dbbe5225dc2a3f4aaa1130b603fed547f4fc2584f94df9c6d11c108fecf09067c54daf57f86fbd618dbf612a4c65bf741c812ed66b6a,The memory used in vectors is contiguous. If one wanted to pop_front,0.0,12
3946,3946,5628,21f09107df149216c5f40e2d6eaefa443c1ac6ce9ddec594661383f2e53455e2769bfb1bb81bee158e80bc0b01db2da739108bc4386c15bb286ac35afa1a5409,"In implementing a stack, create a class of type stack containing the public member functions: push, pop, top or peek, and size, and the private underlying container, the vector. The void push function would take in a value, and a new block of memory (double the original size) would be allocated and n copies would be made and shifted over to the right by 1 in the new buffer and the value to be pushed would be inserted in the first block of the new buffer. Then, the old buffer would be deleted. This takes O(n). The pop function would simply remove the first item in the vector and shift all the values in it to the left. This would take O(n). The peek function would take O(1) since the first item of the vector can be accessed using indexing. The size function would also take O(1) since size can be found by returning the number of items in the vector.",11.0,12
3947,3947,5629,3068685c76e4b2c329c64b4a981abf59ea0591abc5a7b11e62ce43c420b142b81f90f5e9d316d436b64235d5ad493fb04d7af76ae8a7eac84bd371103293e146,"Create the class, ""Stack"".

This data structure has 4 core methods:

	* accessing the element at the top of the the stack (in this case, using std::vector::front(), which returns reference to the item in front) - time complexity of O(n).
	* removing the item at the top of the stack (in this case, std::vector does not have a pop_front() function; one would have to manually implement it) - time complexity of O(n) because the vector has to copy all elements, except perhaps one, to a new vector.
	* adding the item to the top of the stack (in this case std::vector does not a have a push_front; one would have to manually implement it) - time complexity of O(n) as it requires copying all the elements except perhaps one into a new vector.
	* finding the size of the stack (in this case, using std::vector::size()) - time complexity of O(1)",8.0,12
3948,3948,5630,0a1eb6f30606d1f92d934eb03ca9d55d90d2ab3f505cdcb3ba02589cc6678998e8754ce7335373d6c01684ffed4a20fad8a976d2479c3f801a51d1c2b0d4ed50,"You would have to implement 2 different stacks ( eg. Stack 1 and Stack 2) where for each new vector item , you would first pop every item that is on Stack 1 and push it on Stack 2 . Eventually Stack 1 will be empty and then you add the new item on Stack 1. Now,  to get all the other items back on stack 1 ,  we do the reverse (pop from Stack 2 and push on Stack 1) . In this way the 1st item of the vector will always be at the top of Stack 1.  The time Complexity for every function ( push , pop , peek , size) will be O(n). ",5.0,12
3949,3949,5631,042f0747487a4bd00158870bdd61aa0642e3092908b59c86040adb32b033044415ba779e2f72dddd4b2fd903b8027b6d8a9bbb87005066d4c2dd8814e02e0e21,"To implement a stack using a vector as an underlying storage requires four functions ; pushing an item at the top, popping an item at the, getting the size of the stack and to peek or get reference the top item. To implement push, I'll use the push_front function found in the vector class and this would take constant time if there's space but in the worst case where there's no space this would take linear amount of time. To implement pop,  I'll use pop_front found in the vector class and thus function would take constant time normally but in the worst case where the quarter of allocated space greater than the number of items. To find size of stack, use the size function found in the vector class. This will take constant time. Lastly implement the peek function you will simply return a reference to the top and thus will also take constant time. ",7.0,12
3950,3950,5632,eee70f1328b3cdb194af70a4822cc7feab4c1f2f6aa8f1c3d195e1593437b3077b36a3a63265ad79d2faed3c1dc2010c5f323409bdd6e1b2e860317721256dce,"Complexity will be O(1).

The front of the vector corresponds to the top of the stack due to the First In Last Out (FILO) or the Last In First Out (LIFO) rule that is applied.",0.0,12
3951,3951,5633,f8ab0f6e15e6bf9e99acd11cfb6b5455d3c0019e87064465e59d88ccaf25c640a5ce1b900a6011a9e3fa052e11195ca6da9faf3eac510a5a07330facf6daee23,"- The void push function would use insert() operator, which takes O(1) time because we always insert at the front

-The void pop fuction would use the erase() operator, with O(1) time.

- size() operator to get the size, [O(1)] time complexity

- peek function: front() operator, O(1) time",3.0,12
3952,3952,5634,276b4e11850dbed5adc6f0fd4249cf0b5f1cdc0a0dfd3d76321298301426fddeaa12e60021bdff5fc27802e2537ea3a2e891dc9c51166641bf68a7d7906d00b7,"when adding an element into the stack , i would shift all elements 1 'space' forward then add the element at the front which would take O(n) time

my peek would be my first element which would be found using vector[0]

when popping back i would copy all the elements excluding the first to a new vector and deleting the old vector

i would use the size function to get the size of my stack",4.0,12
3953,3953,5635,364ce0d9b555b7fbcffabb10a359d7f7e38b464e534b9a29447029ab1ebdabfad20a4341f04f3a61405ee0dc6245a44f1b6329878e01aafc141ca4d5cdb571fc,"I would have to create a function that shifts all the other values 1+ places and place the new item at the start of the vector
This would take O(n) amount of time in the best and the worst case",3.0,12
3954,3954,5636,0ffad2820b9adf1fbb6d7105f83a5954e33ce5d91444ff2b6251d15d1a8c5a988e64634ca1a4f0e01e237f0fdb8290b82c533e1fa1a822b32c02e6052c618e98,"PUSH - Add item to the back of the stack (transverse)

            O(n) - Linear Time

POP - Remove item from the back of the stack (transverse)

           O(n) - Linear Time

PEEK - Return the reference to the last item (transverse)

            O(n) - Linear Time

SIZE - Return the number of items in the stack (transverse)

          O(n) - Linear Time",5.0,12
3955,3955,5637,f682ecdc1752e81b56fe41b112e9132a1831f14cd9ba0ec72eae2c8c098b94a2736f903a3211d58aeb928498913e4972f6d3f995b03aff3dca7903b620bfdd1e,"push -O(n)- when there is space in the vector , we move every item to the next index and add at the front

pop-O(1)- we would remove the first item 

peek-O(1)- return the item at the first index

size-O(n)-count the number of items and return the counter",6.0,12
3956,3956,5638,1a588e676388eab699476b49a00fa1013110acdcf89dcc5a2ff2c6e7b4d1cc5fff03a1daa5e3f8069ad9a846f88030beb884f390c11da3f442ee0a6ebc1a9307,"If the front of the vector would correspond to the top of the stack then the size function would still remain constant time since we get the size from the vector itself with functions part of the vector class. The push function requires us to add an item in the front of the vector so would use the push front function from the vector class which will give us constant time complexity in the best scenario. For the peek function would need to return the reference of the top item of the stack which would be the first item in the vector, so we would use the front() function to return the first reference and this will give us a constant time complexity For the pop function, we would need to remove the first item from the vector so instead of using the pop back function from the vector class we would its pop front function. This will give constant time. ",3.0,12
3957,3957,5639,cface2ad53f19c6af9cf068c6ec714a5c87946703ffbbfbb9bed0b96fac38d6afbade6379b2026afdb4cfd3532727e46f1e78cef262470d7e8eac2090f8ff726,Move each item(Stack) in the vector one index back (to the right) - s[index+1]. Give/Assign the new stack (the newly added stack) the index 0. Sought of creating a push_front function...,3.0,12
3958,3958,5640,412b107ec0ff412753968aa6ffdad40da21fbfd59417aac428d07f6c064389cc24911eb533cf92e901bf7845b76400d7d3831fd1347350b39d220d9c58729d2b,The first item in the vector is on top of the stack and the last one is is in the bottom of the stack.Pushing the item at the front of the vector will take constant time and the item will be on top of the stack so is removing it from the vector and stack will take constant time.Find the item at peek will use constant time since is the first item in the list and so is finding the size will use constant time. ,3.0,12
3959,3959,5641,c76ad062cb3f9ba2556bec1587c1d89b089f2df63d9bed184a50eead5884d030c988356231ec2465bf2dfe9d6ac011b44586a721987fbdacc7384e0d7bc1bf14,"The push function would be implemented using push_front and the complexity of this would usually be O(1) but would be O(n) in the worst case scenario.

The pop function would be implemented by using pop_front and the complexity of this would usually be O(1) but would be O(n) in the worst case scenario.

The size function would be implemented by  size() and the complexity would be O(n).

The peek function would be implemented by front() and its complexity would be O(1).",6.0,12
3960,3960,5642,8498970fc897a847cb08416ff377f1fef48bec60ecb47ecc86ba0d40abc666899852250e00e887a707bf5de87564f205ddbe85abfd397367947073bde3e3789d,"In my Stack class:
The first method (the push function): I would make use of the vector insert function and insert the corresponding top stack to the front of the vector. Unfortunately in terms of time complexity, the function will usually linear (O(n)) as I would have to copy each element and move it one position up as I add a stack.

Pop function: I would make use of vector erase and begin functions, and delete the corresponding top stack to the front of the vector. Unfortunately, just like the push function, the pop_function will usually be linear (O(n)).

Top/peek function: I would make use of the vector front() function, which will always be constant (O(1)).

Size function: I would still use the vector size() function, which will always be constant (O(1)).",7.0,12
3961,3961,5643,90a8f27cfb71d61b9c73a7a8ab33730e3ebc85bfa97c54d9b613ce87b305b9e1aa432bcfbae1c2c5d2035b82671180a8d7f60a46fa0262145d5fd6b791318ce7,"This would consist of a vector where you would only be able to add or remove from the front of the vector (the top of the stack). This means that both popping and pushing would be in O(n) all the time as you would have to reallocate the vector with each pop/push and you cannot remove/add from the bottom of the stack. Peaking and size would both be O(1) due to the data structure being a vector and using pointer arithmetic, not traversal, regardless of its implementation.",7.0,12
3962,3962,5644,a24d4454b3c0f0611764d00de2a1119612fa4ae5c81fcdcf3800d4c6304de97c1896fb4640ae9520917c1bfdc4dabf12f730cd0013b9af7ab3a73969db3c7eea,"By using a dynamically allocated data storage, a vector in this case, one wouldn't need to allocate space beforehand. As you read in a stack item, you push_front a stack item into the vector.

push() would have a complexity of O(n)
pop() would have a complexity of O(n)
peek() would have a complexity of O(1)
size() would have a complexity of O(n)",5.0,12
3963,3963,5645,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"pop- all elements would have to be reversed so that the element that was in front can be removed from the back. The time complexity would be linear as all elements would have to be copied to a new vector in reverse.

push-an element will be added at the back of the vector and a new vector will be form which the reverse of the original vector, The time complexity is linear as a new vector with elements in reverse would need to be formed.

peek- the first element of the vector can be returned hence the time complexity is constant as fixed amount of operations are required to return the first element of the vector.",5.0,12
3964,3964,5646,f76d34739c22495666539e328b829579ffb8d2806837813ff647c9a67384130ec26d74d58bb855836384f12b1b3b03f93c1062fce50fa1b459dbac86affbee20,"You'd need to check the size first each time to check if there's enough space for a new item to be added to the vector. If there is, then you'd copy everything inside the vector to a temporary vector. Delete everything in the first vector and add the instruction that you want to be at the top. Then you'd push the previous contents to the back of your vector in their corresponding order.

In the best case, there is already space available. so we just need to create a new memory buffer, copy all the current items, delete them from the current vector, add the new item and push_back. We would do O(1) operations.

In the worst case, there is no extra space, so the vector need to reallocate memory first before performing all the other operations, so we'd do O(n) operations.",2.0,12
3965,3965,5647,8b711f86a0e0fd2c39d5f02ba2888612f603b1e29ac872778bb22eb91072c41a1a4c3f396ac1783e4ea49d806b40a998dee128cf46fea841c4d6fa80f6f2360e,"time complexity would not change

for peek we would just return the first element",2.0,12
3966,3966,5648,3d5672708313ecdecf3f1bac84303e47d2cb39b8840c7477b8533d1e068614b468fd7d22ee29e9082419dadb2d36cb98607131a6fdfff05e1696dee4c36a9722,"I would declare a new vector to add and remove a value at the front,then iterate over the old vector to copy the items to the new one.The complexity would be quadratic since I would have to copy n-items every time  I add or remove an item.",0.0,12
3967,3967,5649,3ea55861b5c8eafb81b8565f1d54cc453a6c146015319e65651c96131a93fe003ed97c4b0e5ead0032066879ea3f910a9115040fa5bb190fe1c4bece13c4f763,"This would mean that in order to pop items from the vector or push items to the vector, I would have to traverse from the front of the vector, to the back. It involves moving from the top of the stack to the very bottom of the stack, where the last (most recent) item in the vector is. The operations will take O(n) time, which is the worst case.",2.0,12
3968,3968,5650,86a089b08f86e9c1d63b469ed69474a00b3c8a302414b59395dac01ecff0bf909a9721c007531f0f7d3273bab8151790358055f69bbfd852502b400b0f09160c,"Push-function: every time we insert an item we would have to keep shifting the rest of the items in the vector up by one and if we reach more than half of allocated storage then we reallocate to new memory.

Pop-function: every time we pop an item we would have to keep shifting the rest of the items down by one and if we reach less then a quarter of the storage then we reallocate to old memory.

Peek-function: constant time will always be taken to get top item.

Size-function: constant time will always be taken to get size of stack.",7.0,12
3969,3969,5651,dd4d3f7f0edeb1ac41639c249d21094a6b301b7b08a2b59f88a3c56108d3780e80f6d45ac6aad546dd8e534b771a87a6c21d9fd70855e1599b2fe31c102d2f10,"size function-> a constant time time is taken to get the size of the stack each time

pop function-> for every item that we pop, we will have to keep shifting the rest of the items down by one and if we get to less than a quarter of the storage then we reallocate to old memory

peek function->a constant time will always be taken to get to the top items everytime

push function->for every item we insert, we would have to shift the rest of the items in the vector up by one then when we get to over half of the allocated storage, we then allocate new memory",11.0,12
3970,3970,5652,86eb6a509a4b81bb5d0775617d6b551b5529a8196aa8cfd54e1d4c97046fcb8692ee1866ca18888be1695e57bab3f84e888b219e99049227e002908717268d42,"* would start of by create a stack vector.It will contain a push front  function that will force elements to enter the vector at the  front of the vector.I the front is representing the top of the stack, this implies that if the element enter from the front of the vector it replaces the element that was currently on top and it becomes on top.Then i will implement a pop front function which will  be popping the top of the stack.The will be a size function that will be  getting the size of the overall vector stack.The will also be a peek function that will be checking the the reference of the top item on the stack.

    The push -- it will be represented by the vector push front function

     The  pop  -- it will be represented by the vector pop front  function

    The peek -- it will return the value ofthe first item in the vector",0.0,12
3971,3971,5653,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"All time complexities relating to pushing and popping will be O(1)

All time complexities for size and peek are O(n)",0.0,12
3972,3972,5654,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"All time complexities relating to pushing and popping will be O(1)

All time complexities for size and peek are O(n)",4.0,12
3973,3973,5655,2dc8bdb77e3c7ca65a7004fc81d01e201b72cc647f001393bf944c06617e5c35dc6d00cb13c94a98ad4a2b0a5135ab7e178732724d9ed1cd93c84c2d08c50e63,We create a class and we initialize a vector which would assign a new block of memory. Inside the class we have a push function which adds an element to the front and we also have a pop function which removes an element from the front.  Inserting from the front and popping from the front will in constant time O(1),0.0,12
3974,3974,5656,e297ac13d644c28497e53e0845b865aca91f53637da30cace639c33479dad1c99be8abd444014be886b73f635741e9cc8d11a7d33228fb4866fbadfc7725d88c,"My first function will be push front and it is O(n) because the vector copies every item on a push front. My second function will be a pop front and it is also O(n) because the vector copies every item to the (n-1) index.

The third function will be a vector front to peek and it is O(1). The last function is a vector size and it is O(1) because the vector stores the number of items.",9.0,12
3975,3975,5657,7aa4a41956fb10b2ea3a02d2d85c1eec912704226ca5710248e26fa3e0fa199d5048abcac9423a11d00a49ffe75bdd51e2b3cd752d5f6899af51dc4b580afed1,"I would first create a stack class that contained a vector and implement the various functions:

For the PUSH function, I would have to create a push_front function, where we move all the elements over by 1 index and then add the new element at index 0. We will also have to reallocate memory accordingly when n_items = n_allocated. This will take O(N) in time. 

For the POP function, I would have to implement a pop_front function, where we copy all the elements starting at index 1, to index - 1. This will get rid of the item at index 0 and we will then pop_back to remove the open space at the end of the vector and to account for the size change. This will take O(N) in time. 

For the PEEK function, I would use the front() function which will return a reference to the first item in the vector. This will take O(1) in time. 

For the SIZE function, I would make use of the size() function of the vector, which will take O(1) in time as it only return the number of items in the vector, which has been accounted for by the vector data structure. ",11.0,12
3976,3976,5658,188f5f32ff22cc30082222ed760e5fe1e0a340d9ae7ecfafe10b384746f7f9c7803d064927e2b5ebaba803119e7d5eafdd11883d383dd0d5a80b8dfe524c593e,so since the front of the vector is the top of the stack we will have to push to the front of the vector in order to add an item to the top of the stack and this will take us linear amount of time O(n) since we have to shift every item in the vector to the right in order to insert the new item at the front of the vector.In order to pop back and remove the item at the top of the stack we will have to pop front which will take us linear amount of time O(n) since after deleting the first item in the vector we have to shift every item to the left since we are using countigous memory.Peek or top to get the value of the item at the top of the stack we are going to use the front function which returns the reference of the item at front of the vector which takes constant time O(1) .With the size we will have to return n items which takes constant time O(1).,11.0,12
3977,3977,5659,8d5ceb816f2781032ee62700b4d8e0c49eadb89db294dfede287a0eaeacf6b8016c744cd4dfe71d03f0f6caf776956147ca479b489362862217860010178b882,All you need is to create a push_front() function for adding elements(its complexity would be O(n) in the worst case)and use front() to access the last element(its complexity is O(1) and create a pop_front() function to remove it(its complexity is O(n) in the worst case).Then you can use std::vector>::empty() and std::vector>::size() to check how many elements are left or if you want the size(their complexity is always O(1) best case).,7.0,12
3978,3978,5660,e06c3717f5eff40cf06c551e6ebf1004bb478bf8fc38ebcba99f54530677cde6de5ea93590e51ef3d1e09f18ed2aa22502c287548e3398f50b4cf8f8e940073d,"To make this work the user could create a temporary stack which would work as a normal stack does. Then a second stack could be made in which the last item entered into the original stack is the first item in the new stack. When an item is push_backed for the stack, a push front would be coded which would send the new vector to the top as intended. The size function would work the same way as the size forwards and backwards is the same. The pop front would still refer to the top. i ran out of time",0.0,12
3979,3979,5661,df4be51196b13a9d9df6ef77eee120b801ef4ba7a8945fcd04077415ae29d58c8d1e0814291c20adeb94f43f2f99c6c2290c6dde5a70ac85841035ecc662212f,"To PUSH, I would need to move every element to the right by one before I can add the new element. To do this, I would have to make n copies (it makes no difference if there is space in the vector or not, I would still have to make n copies whether it is in the current allocated space or a larger one). Thus, the complexity of pushing the front of a vector will always be linear (O(N)).

Similarly, to POP, I would need to move every element in the vector one position to the left. I will always need to make (n-1) copies regardless of allocated space, making the complexity of popping the front of the vector linear (O(N)).

To PEEK, I would simply need to reference the first element in the vector, which is always going to take a constant time because of the use of pointer arithmetic. Making the complexity constant (O(1)).

SIZE simply returns the size of the array, which is an available function of the vector class and is always constant (O(1)).",11.0,12
3980,3980,5662,de345146608f48652cf9ec333ad07816bb0cf99089477ca7af207bce7f9f2c81b03f0e317efccc60f220182480d765ee6b6291c08b7723e7e91dd8402a584cdd,"What I would do is that when the push back function is called, it adds the new thing to the vector, I would then loop through the vector swapping the new object with the objects below it so that every time a new thing is added it always goes to the bottom of the stack, this would be O(n) in complexity.
For pop I would first bring the bottom thing to the top by looping through the stack (starting at the bottom) and swapping it with the thing on top of it until it's at the top and then delete it, this would also be O(n) in complexity.

Peek would have to return the bottom most item in the stack which would be O(1) in time.
With size I would have to loop from the top to the bottom counting each item O(n) complexity",8.0,12
3981,3981,5663,7c7ea0f0ba70a5ea36a02ae9d7f97eb067c3d269f5589f4e06abe536b27c016f062f66e013c160a950a6482d28c9fd24dacd097df0afb924b649425eca6be261,"I would implement the push function as .push_front() and this would take O(1) in the best case and O(n) in the worst case.

I would implement the pop function as .pop_front() and this would take O(1) in the best case and O(n) in the worst case.

I would implement the peek function as .front() and this would take O(1) 

I would implement the size function as .size() and this would take O(1)",7.0,12
3982,3982,5664,ba6cb46aa6ff6581fcd2828d6944742916cd44c20dbee87513cab04b763159ab5e8fcc20c0eaa029b5cead3d4e1911b67590f3a4b4a64f4e9fa942648249fc12,"* I would use push_front to push to the top of the stack and it would always take O(n) 
	* I would use pop_front to pop from the top and that would also take O(n)
	* I would use front() to peek and that would take O(1)
	* i would use size() to get the size of the stack",6.0,12
3983,3983,5665,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,"create a class called stack which uses a vector as the storage then you can implement

the same functions that a vector has such as push_front which would push the thing to the last element of the vector or the top of the stack. this would be in O(1) complexity, pop_back would be in O(1) as you would just pop of the last element of the vector or the top of the stack",3.0,12
3984,3984,5666,d10eb2653552348dd29e31d9127ca9b9ab3966f67dcfba3fbaef7bc1fba74c3549309defc8e00e457f7427150a3162c0ca17e3f3d6529fa8df4aa4e4195dbeec,"We could use the push_front() function to add items to the stack which would take O(n) time

We could use the pop_front() function to remove items from the stack which would also take O(n) time",3.0,12
3985,3985,5667,805e6508996d13ddf1a18b1d2e18c5a73d82b749916487ddfd386d326e8ba2b06a4521a365c23ea00b66ba06fb5efe331adbdc0f46e49478cb1d6923fb8a6c24,"the push function will be pushing at the  front of the stack 
the pop function will also be popping at the front of the stack 

peek function of the stack will be  a the front of the stack also 

and the size function will be the same it will still transverse through the stack and find the total size of the stack ",2.0,12
3986,3986,5668,9d599f5b4528664877cde67e20618306dd9ba2d042eff74f086d6094f809424f26b3522b41500c22020384b725682a3a9de08fa52bd56f223acd18ce507d7fd6,You check size of the vector with a counter (size). Then reference the last item plus one(peek). Reduce the size of vector by one(pop). If space is an issue double the size of vector and then try add to vector (push),0.0,12
3987,3987,5669,89daf5e5dd9d5cd464a1dba203796d2fcea5b46dd29cb10e72e0dd7e72373ac4fd8e96b5e3d9813a2ed44c552171318e265b869630b10e2e2b1c3ee4cc7320d3,"use the ""push_back"" function, with a constant complexity in the best case and a linear one in the worst case.

use the ""pop_back"" function with a constant complexity in the best case and a linear one in the worst case.

use the ""back"" function with a constant time complexity

use the ""size"" function with a constant time complexity.",7.0,12
3988,3988,5670,a300869c4f32047b23ac68a02d99d6a69e15fcc6cb6903bc4e640c72bf256b08b631e89f75d7f7263574f4383932390c2f4b98297d3a8bfdd9da2320bf30b053,If we are to implement a stack with the front of the vector being the top of the stack we would have to use a reverse iterator to go through our vector in order to start at the end of our vector. Once we have our reverse iterator we push each value onto the stack.,0.0,12
3989,3989,5671,74d9bc92412f8c3ff2851eb60d7164b5df173c9c4dc214351b20de54e473afd02c6de0a58df8f38e8034cea31df2b0fd7682d3f538a4da451a42ed390cc33c67,"Implementing a stack with a vector and using the front as the top,means you will pop,push and peek all at the front of the vector. Pushing to the front/ adding an element to the front of the vector requires first checking if there is enough space. if there is you will have to copy each element over one to the right to free up the first block of memory and then insert the new element there. this takes linear time i.e. O(n). if there is not enough space you have to create a new vector with double the memory of the previous one and then continue with the same process. this also takes linear time O(n). in both cases you have to increment n_items by 1.to pop from the vector or remove an element from the vector, you would have to copy all elements over by one to the left and then decrement the n_items by 1. this takes linear time O(n). once you have copied all the elements over by one if the number of items is less than a quarter of the number of allocated  memory then you would have to allocate memory that is half the size of the previous memory of the vector and copy all the elements to the new vector, this is linear time O(n) (but together is quadratic time O(n^2)). to peek you would just return a reference to the front of the vector which is constant time O(1) and size would also be constant  time as the vector class stores a a variable called  n_items which stores the size of the vector so just return n_items.",8.0,12
3990,3990,5672,b1a3a9f62a3efb88815155da55fbf2f2fafa14dd37234e9f11b5f00a231a31fde1494bd63f6ac5858aefb97ae2c7130be129cb66d65efd0dfa784ad99b296be3,"A class of type Stack would need to be created. Inside the class 4 functions would be created, a push function(adds an element to the top of the stack), pop function( removes an element from the top of the stack), top function(returns a reference to the element at the top of the stack) and a size function ( returns the size or number of elements in the stack). Seeing that the front of the vector is now the top of the stack, in the push function you would use push_front instead of push_back. The pop function will use pop_front instead of pop_back. The top function will use front() instead of back(). Size will remain the same. Pop and push functions will have a O(1) best case time and O(n) worst case. The rest of the functions will all run in constant time O(1).",7.0,12
3991,3991,5673,38046b991658125dabc236638e4678ce8b6ce1a14066e89cee307b4ad43150545ef075aca8b10f61c4cd3909f6915397eea519e89ce5ad74fb62a1715837f925,"If you had used a vector that of the front being the top of the stack would change the time complexity of pushing and poping...

FOR ADDING TO THE STACK you will need to implement a push front function of which does not appear because it is highly inefficient. Since one will need to move every element 
in the array, one step over Thus time complexity is O(N) in every case.

similarly

FOR THE POPPING OFF THE STACK, one will still need to copy over every element still thus O(N)",5.0,12
3992,3992,5674,c3db465470d91ba6cd0242ed3a549831510dda1562b623b02e3665b5f6f9bac2d6ad4723d79407874899cc2fdd039731483c651b9cdef6d97acefd5884ce52f6,"I would create a function under the stack class which adds to the front,let's say we name it push_front and it will allocate the vector new memory double the size of the old block if the allocated memory is less than the items and shift each item in the old vector to the right in the contiguous memory block and add the new item at the start of the block then. This would take about O(n) time. With pop I would delete the first item in the vector then shift each of the remaining items to the left and this would take O(n). With the size function i would iterate through the vector and count the items and this will always take O(1). Then with the top function i would use the front function which return the item at the front and takes O(1).",11.0,12
3993,3993,5675,36dc611e5a5c4c004053dab4fefc6b9a5b0bc6b95bad46c0ada67bd1d7f42775da4dc0cb387f6915f676d0a13a5decf47d86380ae9bc1d77138d6578f380b0f1,I would use pop front to remove from the stack which would be O(1). I  would use push front to add to the stack which would also be O(n).,2.0,12
3994,3994,5676,ec395a3ecaad23df4073c1f706e156a2dc0df6ec9ab518f824a5ee32c21f2fee951d1dfe316e50e996ee47ec57ebf1b3a335db07c23fa71520fbcc864e608a4d,"-If the front of the vector corresponds to the top of the stack then then we will not be able to use push_back() or pop_back() as the front is now the top not the back.

- To insert items in the front we would have to reallocate all the elements to their new positions (moving them to the right) then adding the item to the front of the vector and if there was not enough space then we would have to reallocate the space.

- To remove from the front we would have to shift all elements to the left and then reallocate the size which will make the time complexity O(n) linear. 

- Therefore is inefficient in terms of time complexity such as push() will be O(n), pop() will be O(n), size() will O(1) top() will be O(1). For push() and pop() it will be the worst time complexity O(n) - linear",11.0,12
3995,3995,5677,4795114f3afe1274590e0a1f19de90527c5847fc255bd0189e17daffae55e382487cd961fd300bbb3c50ca9f987687623e87a7237bb50d7f5d0bd58f320efd98,"normally, the push front function for vectors is inefficient, however in this case we can use the push front function instead of our regular use of the push back function as the order is reversed. This push front function will allow us to add to the top of the stack. This will ALWAYS take constant time O(1)

similarly to remove an item from the top we can use pop front function and this will also ALWAYS  take constant time O(1)  

for the top or peek function we can use data.front and it will always take constant time to do this 

and finally to return the size of the stack we can use data.size and it will always take constant time to do so  ",7.0,12
3996,3996,5678,8c276f2a894ec8359a82f6a7f8b543cee4dafa5e339dd5fcbdd9b626de04d860f6a771f050054850d4263b60fc7c9e2f46a60c4568664a5f9854894846a3920d,"To push, we'd use the push_front operation. Time complexity is usually O(1) and in the worst case scenario, it's O(n).

To pop, we'd use the pop_front operation. The time complexity is always O(1).

To peek, we'd use the first index to show what is on top of the vector. The time complexity is always O(1).

To get the size, we'd have to transverse to through the whole vector. The time complexity would be O(n).",6.0,12
3997,3997,5679,31f89aaef7c39dc86c93cfdeddea5fc5554c3cbe3838d2616d1fbc1745414f7096809e9261e2fb009c92beaaac49eaef9633b3b3c92cef0606b8cfb14522414d,"In order to push, you'll have to move the everything one index to the right and add the object to the start of the index. In order to pop, you'll have to remove the object from the front and then move everything to the left. You'll just look at the first element to peek. You'll have to iterate through the vector to get its size unless there is a size variable which keeps track of the size.

Complexities:

Push: O(n)

Pop: O(n)

Peek: O(1)

Size: O(1) or O(n) depending on how the vector is implemented.",11.0,12
3998,3998,5680,922be3881d23d4f79d2fe24bf6321a23d63d950205b6ff6979047d1cc7c61465b9b18bdf8228c338eb886bb3010ea5578ec21cbc2819ca5ad2860838b719658d,"you cannot implement this; as stacks are always first in last out FILO & LIFO.

complexity remains the same as normal, with push and pop with best case of O(1) and worst O(n).",3.0,12
3999,3999,5681,c01425271443b193ce09add717a13c5f03e56291a15f580c8ffbb713e75d1afdc1826b33b91330419ca4db414a4703bd7b9474559be3d7689b82c2ecbf73906a,"When implementing a stack using a vector as the underlying data storage we would use 4 main functions: void push(value), which adds a value to the top of the stack. This would usually have O(1) time, however in the worst case it would have O(n) time. void pop(), which removes an item from the top of the stack. This would usually have O(1) time, but it would have O(n) time in the worst case. T& peek() which returns a reference to the top item on the stack. This would have O(1) time, and finally, size_t size, which returns the number of items in the stack. This would have O(1) time. 

By using these 4 functions we would be able to implement a stack.",7.0,12
4000,4000,5682,e5092ab1c7e17d25e5db9dfc9252b8c31679cb1e2b17a0be836efd97ce606988409f994ae92e4e1f795d2d139fe2c46eff4d5f244e605f9f08c46d7129da95d2,In order to implement a stack which uses a vector with the front of the vector corresponding to the top of the stack the top would have to initially set to one greater than the size of the vector. the program would then find the value one position back in the vector and it would add it yo the top of the stack. It would then decrease the position value of the top and repeat the process until it reaches the front of the vector.,2.0,12
4001,4001,5683,efd232e6edf06b095e712e68f8ce8701b452d03344874ec8e202c3b1c55dd0c8b72d40f2859eacbda02e8a7ae034ecba2b74f48d8999907073f237d2d351e8e6,We would need to reallocate and move each item up one spot either to the left or right with each push and pop so the time complexity would be O(n) for both.,7.0,12
4002,4002,5684,2ab3b11f5f1782f4246740fe903154429a2490492d0572263d7ff046cace7736e29d65d602215296304ea46aa69325f3d67b03459c0b518493888576c52ace89,"The first element on the vector i.e. v[0] ,, will correspond to the first element on the stack.

The very last element on the vector I.e. if we have n-items on the vector, the element at position n-1 ( v[n-1] ) ,, will correspond to the very top element of the stack.

As i add an element on the stack, I push back an element on the vector 

The complexity for the push back and pop back functions:

Best : O(1) ~ constant 

Worst : O(n) ~ linear

back and size functions:

O(1) ~ constant ",3.0,12
4003,4003,5685,249e9eaf48a6ca1524336796643b1021d4ea59f9ea64287d7770c8c08e88ca9d76b31f4d65b880c825f283c49f03d66834bc8a5aef3bcb8880daa0f21458adeb,"Since stack must be implemented so that the last item is the first one(top) .We can copy the vector in reverse to make the front ""back"". Hence this will allow for normal stack implementation on the duplicated vector.",0.0,12
4004,4004,5686,9dc85d5fc9d9d7b3ced470df92bc3f618b906428cc44daba96ce09d4da7c5e6251f817ad8b6d168d5489d3951e1d39f87f0ab87e50f2ae36060fe5a0c0501b6d,"The stack would require four functions: push, pop, peek, and size.

1. push: Because we are using the vector class as our underlying data structure and the vector class has a push front function (which adds a new element to the front of the vector), we can simply call this function in our push function. In the best case - there is enough memory allocated for another element to be added - the system simply has to move every element over by one and place the new item at index 0, which takes linear time/O(n). In the worst case - there is not enough memory allocated and the elements have to be copied into a new buffer with more space - all the elements are copied and then also shifted/are copied into an already shifted position, in either case still taking a linear amount of time/O(n). Thus, the time complexity is always linear/O(n).

2. pop: The vector class contains a pop front function, which removes the item at the front of the vector and this can just be called within the stack's pop function. This will usually take a constant amount of time/O(1) because it just involves moving the vector's pointer up by one item and freeing the memory at the old pointer (with use of a temporary pointer to refrain from leaks). But this can linear time/O(n) if the new size is too small, thus wasting allocated memory, and all the elements have to be copied over to a new, smaller buffer.

3. peek: The vector class's get function can be used to return the item at index 0. This will always be constant time/O(1) because it does not require any manipulation of the vector, just pointer arithmetic and fetching the element.

4. size: The vector class stores its size so its size function (which just returns this property's value) can be called for this function of the stack. Because it is just returning a stored value which is NOT recalculated every time via traversal, this will always take constant time/O(1).",11.0,12
4005,4005,5687,2aebde6b5faaed73a67c0847887873c4b7d8d2f0c1ec3c5d1ae00fb183c3e53559681b2ee97a4692d74712db8b222e3239fa5e199b01863e771a9daa54a4abee,"Top is a free first position ,  a push_front function will be utilized to an element at the front . It will take linear amount of time because a traverse of ith is required.",2.0,12
4006,4006,5688,dc016101375a4c30fa08c850e4ef82abdd66ca922170c25b2eda3c6f7009abcdda2dafb1c86a512fdd1b897c4c9da94be8f7047b535d50f3a259b1e698b13e05,"Using a vector as the underlying data storage while the front of the vector corresponds to the top of the stack means all the functions (pop, peek and push) will all take place at the front of the vector.

In order to implement the push_front function, we will first have to check if there is enough memory allocated. In the best-case scenario,  there is enough space and all we have to do is copy n items to the right and then add then add the new item at the front. This will take a linear amount of time - O(n). if there is not enough memory allocated, we will have to create a new vector with double the size of the memory allocated of the original vector, copy all the items across while leaving the first block free and then adding the new item to the front - this will take a linear amount of time O(n). In both cases, we have to increment the n-item counter by 1. 

To implement the pop_front function we will have to move all the items one block to the left and decrement the n_item counter by 1. This will take a linear amount of time O(n). In the worst case scenario, we will have to move all the items one block to the left and decrement the n_item counter by 1. This takes linear amount of time O(n). if the amount of items is less than a quarter of the memory allocated, we would then have to create a new vector with half of the memory allocated of the original vector and copy all the items into the new vector. This takes linear time O(n). 

In order to implement the peek function, we will just have to look at the top of the vector which is returning a pointer/reference to the first element of the vector. This will take a constant amount of time O(n). 

To implement the size_function, it will take a constant amount of time O(n) excuse in the vector class, the variable n_items keeps track of how many items are in the vector and all we have to do is return n_items.",11.0,12
4007,4007,5689,5602a599f37ceb4d3d0abbebb674a8cfae2a81d9f53137cfbc7a1bded150cbaa8a83e4431db27b0e21c60021690e3731e8677add172b47aa9e637944b71f019d,"I would create a push front function which adds item to the top of the stack

Create a pop function which will remove an item from the stack, the items would be popped in reverse order of the way of which they we pushed into the stack, in example the last item to be pushed would be the first to be popped.

I would create a peek function which would return the top element of the stack which is the front element of the vector

I would create a size function which returns the number of elements found in the stack

Complexity of push front, pop, and peek would be; O(1), O(1) but O(n) in worst cases , O(1) and O(1)respectively.",5.0,12
4008,4008,5690,9dfb1f3f8489eba0c312316ab375b0eb3fde4cc7c592108ea20fe9063368bfeafc3cfc95ddf50eff3397d93bb8f4939d82490505e330285e8ec3eab94f0e646a,"I would create a push_front() function to add an item to the top of the list ((O(n)), create a pop_back() function to remove the last item at the top of the stack, create a peek() function to return a reference to the top item, and a size() function to return the number of items in the stack. ",3.0,12
4009,4009,5691,ee66ed151b20f2c15b5115f8b2c4fd312cc74408ed945a84bb7f699ad1a7972c932ae28ae3a673ec55d38f3c6b49ab5107d141ab55e4e963155df1dc24bf5495,"we have to create a public class called stack that will have a vector type integer. The first function should be a void function called push and it should push front, the time complexity will be O(n). The second function should be a void function that will pop front and time complexity will be O(n). The last two functions will be size and peek function that will have the time complexity of O(1). ",7.0,12
4010,4010,5692,2e609516b3c283ff23ddaea06d0df01ad6175f48861d0223a4409ebe1c7df8e383fe146f147415f2605c7a0103b96921b1ffd763ab4924efe18fd229dedbae68,"Implemeting push function:

	* move all existing vector values one index forward and allocating new memory when needed, then inserting new value at index 0; (O(1) BEST CASE TIME COMPLEXITY WHEN VECTOR IS EMPTY,O(N) USUAL TIME COMPLEXITY WHEN MOVING VALUES ACROSS INDICES)

Implementing pop function:

	* move all existing values back one index eventually overwriting the front value of the vector(O(1) BEST CASE TIME COMPLEXITY ON VECTOR WITH SINGLE ENTRY, O(N) TIME COMPLEXITY USUALLY WHEN VECTOR IS LARGER THAN SIZE 1.

 Implementing peek function:

	* return the value at vector index 0 (O(1) TIME COMPLEXITY USING POINTER ARITHMETIC)

implementing size function:

	* return vector size function or return a kept variable that increments on push and decrements on pop (BOTH O(1) TIME COMPLEXITY)",11.0,12
4011,4011,5693,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,Using the underlying data as vector I would use the push  and pop front functions to add and  remove items from the stack because the top of the stack is the front. The time complexity for both these functions is always O(n) because when adding or removing an item because it would need to copy the items in the stack to the next memory ,3.0,12
4012,4012,5694,d9db0d62eb972d7cdf4f37e10bdbf3c1fe24b4325a048050d64042994d0e2a7ef0c9b1f76e9ab479bae9fb331e67c69ba4663f294fef8e66b6d36cb8560984ec,"We can create a class that is a Stack, within it we will have a public vector.Then we implement  the stack using a void of push, pop, size and peek with the referenced element ,then we push an item in the vector using push_back. ",1.0,12
4013,4013,5695,7fa0256939f3801d7cb837f49e23433b9e2c72a7153a75d58ee05f6ce597913275599303f990f67fdc180f91407271656e81578b90488fda76d6e550e9bb3533,"TO IMPLEMENT A STACK WE NEED THE FOLLOWING FUNCTIONS:

PUSH: each time we push, the vector has to copy the items over to the right one spot, and then insert the object at the front. Before we insert we need to check if the vector is full, if it is then we re-allocate space and push the item to the new bigger vector first, then copy over the items from the old vector. The time complexity will always be O(N).

POP: we delete the first item (optional if we copy over it), then copy over the items to the left by one spot. If the vector is less than a quarter full we delete the first item then re-allocate space and then copy the items to a newer smaller vector. The time complexity will always be O(N).

TOP/PEEK: we simply just return the item the header pointer is pointing at. The time complexity will always be O(1).

SIZE: returns the size of stack. Time complexity is O(1).",11.0,12
4014,4014,5696,95ec574d0b5e5bd453bdf228b8fd6b36983c901c9b25f9afd384cc03675a32e20d389dce83833059b544924f4ab4040a1eb7a22d75cffd2643cd89107295fe1a,"It would not be much harder than before as it would essentially just be swapping functions.
1. Push: For this we can just use the vector function push_front as the front will now be the top of the stack; This will be O(n) time as it will need to move each item one back.

2. Pop: For this we can use the vector function pop_front as this will be removing from the top of the stack; This will be O(n) time for the same reason stated before.

3. Peek: For this we can just use the standard vector function to look at the first element, vectorname[0]; this will be O(1) time.

4. Size: This will be the same as before and will just be the vector size function and will be O(1) time.",9.0,12
4015,4015,5697,d5acfd7b46a030b29f7c66a4b1581ff2012d0ccf49d5bca978171e9bdeb669a4e3f41049f7e32dc031f0947e94ce07cc6178891342c05dfe3c3aefc0b7389e15,"Push function: shift up every element when we insert an item which takes O(n). Reallocated list once it. Becomes too big.

Peek function: Always takes O(1) time to complete.

Size function: O(1) time is taken to get the size of a stack.

Pop function: takes constant time O(1) to remoVe items in list and O(n) on worst case scenario due to reallocation.",9.0,12
4016,4016,5698,a8b16fc0f5a2c752f3497016181c5ad9db439554c5d81073a232375aae20a22a97cca43a22eeec6af33455ba644c036ec4f0c737bb5b05eab312d892fb42141f,"push - we would use push_front to add something to the top. This would take O(1) time. 

pop - we're deleting the first value and have to use pop_front. This takes O(1) time.

peek - we'd return the last value in our vector. this would take O(1) time.

size - we'd return the size of our vector, this would take O(1) time. ",3.0,12
4017,4017,5699,7d8cef0de14cc2a74c530bc45e24878a9bc41b99484642b220015c976fedb5143bed1f3d3d656335fb8356093aebda35cf38a76a3da63375271eacce35baf518,"stack<Thing, vector<Thing>> data;

time for push function is O(1).

time for pop function O(n).

time for pick function O(1).

time for size function O(1).",5.0,12
4018,4018,5700,5ac95126c93bab762f619ae6d9e0457a3ae69e32d351c6f444adf2fed30efe3915f7f9845b1ec549d2f270b573f92967241b205877e7a669570b3a332b14617a,"For the push_front function I would create a new vector with the new element at the front, copy all the old elements over and then set that to the old vector. I would also make the peek function return a reference to the front of the vector and for the pop_front function I would make a new vector, copy the second and following elements over and then set this vector to the old vector. The size function would just use return the value of the vector's size function.

Pop: O(n)

Push: O(n)

Peek: O(1)

Size: O(1)",11.0,12
4019,4019,5701,a871558daae8ec7755dd112b899b7fd46e06cb2a4cebf4c0a75ca226dba4bf419ef0333177fa6862ca71f931535c6fb1250ed993a029aa9b63a8c18ad277bce2,I would delete the data using pop function to avoid memory leakage which takes constant time and will take constant time again for all push function and peek function and size function.,3.0,12
4020,4020,5702,ef56d487f412ffdca7b3412858b2ccd1fa21fc365016661f00994f5e06683c6e545b948b70c4775a9a839e6049995e36f03b1f06a7374933a80a9013b6052c37,One can use push front and pop back in order to remove or add from the stack and then the functions size and peek in order to get the size and first element needed of the stack,0.0,12
4021,4021,5703,fecc59057a0e209589be1452a92558843a93237db9707d9614670e76673fb2cec05cbca3488156012b8fb3cd1467b373d250bc116d0aec57eaa9cbe2d676c3fe,"in order to implement a stack using a vector with the front of the list as the top of the stack we could setup a class stack with the function being public and a vector being private in the class so that the vector cannot be accessed directly.

The functions needed would be:

pop{

In this function we would need a pop front but we would need to code this our ourselves as it is inefficient. The complexity of this function would be O(n)-linear time in the best case and worst case as in both instance we would need to make a full copy of the vector items

}

push{

We would need a push front function but again we would need to code a push front function ourselves as it is inefficient. The complexity of this would also be O(n)-linear time in the best and worst case as we always have to copy all items of the vector into a new vector

}

top{

this we just need to check the value of the first item in the vector. the complexity would be O(1)-constant time

}

size{

This is just returning a value corresponding to the amount of items in the vector. This will always be O(1)-constant time.

}",9.0,12
4022,4022,5704,64e451748c8e64219c1dcf31828cb7ded38a1447346285c9e9b6559aebe71fd6c492c0cffcdb5c0c6a652b339b2aa51ca0d8310a628f12a661261dc55ced044f,"stack of things,underlying container deque things,stack of things ,underlying container vector thing,stack of things ,underlying container list thing.",0.0,12
4023,4023,5705,93c90404569325fe60b728e076fbba3cf65e437046307f80389f0bc8991e0972c6f04c428807930e8f3ec23f714c2c1a1c5a69ba6ec135ea91d23224a8d3d68d,"For push_back I would transverse through the vector while updating the stack and go to the last element then push it to the back. This will take O(n) and O(n^2) if we had the number of spaces allocated equal to the number of elements.

For pop_back I would transverse through the vector and pop the last element. This will take O(n) and O(n^2) if the number of allocated space multiplied by 4 is less than the number of elements.

For pop_front I would simply go to the first element and pop it. This will always take O(1) time.",0.0,12
4024,4024,5706,eaf6c4c43d71c21a9611ab529dceabe1fb33ac3bf543bdbce13d249f7b6251a8ae478c786f76da007fed6f3e8c11ab62610c853fb7d3dd853fe2afc80fe40704,"I would create a vector of a given size , create a top variable = -1,then create a push function that takes in  on argument x  and we'll first increment top and fill x in top index , and call push function and first increment top and pass the argument at top index(0 index), and with each push id increment top, and for pop id just decrement top by 1 by calling the pop function for size of the function id just return the size function using the .size() function, for top element id return the element using the .back() function",0.0,12
4025,4025,5707,a83848dae9e11c32fb0fef1054c9f0420423c74efa66838a210a7774eb07b64f5a5df97bc2a33594ee565ea37cacb65f8fcddd5281fc0b93d6e6e1b0ba5da1ac,"a vector of a certain fixed-size , the variable at the front refers to the  top element in the stack and the capacity refers to the size. The variable change from -1 to size.when the variables reaches the size of the vector then the stack doubles the sizes. all this is done in constant time O(1)",3.0,12
4026,4026,5708,ee9a54c657ad0d8bba4bde06638e509cdb2a338e06761f819025e545929c0973eae422171c63064d2ec75c6fa5edd42d44dd67fd5b59e36f33fd89e07c72a43f,"Using a vector as the underlying data storage 

	* pushing front or adding to the vector will take O(n) time because I will always have to shift elements of the front to create space for what we are adding.
	*  Popping front of the vector will also take O(n) time because after every pop ,I have to shift front all elements of the vector ",7.0,12
4027,4027,5709,68f3486fba3e90fbb30d257d9f425b479699474b4734aedaec9e7b7e62738dec31c232429f41b1b79d289e2acf53beed558d49f905e55176ee54e1327b9aa184,"With a push_function, whenever we insert an item,we should keep shifting the rest of times in the vector one by one and when we reach more than a half  of the allocated memory we reallocate the new memory.

With a pop_function, whenever we pop an item we should keep shifting the rest of the items down by one and when we reach less than a quarter of the storage then we reallocate the old memory.

With a peek_function, the constant time will always be taken so we get the top item.

Lastly with a Size_function, the constant time will always be taken to get the size of the stack.",7.0,12
4028,4028,5710,22ce118158e8ed0c1187b952e36a1938ab0c22e942e01d9258ed224302f7ecf3665fc06c4060e629850d16f04e008f7cd12363e7f782d4370a1dd3b7af113bbe,"If vector is the underlying data storage and the front of the vector corresponds to the top of the stack:

Memory or space complexity is already taken care by the vector underlying data structure.

Both the push and pop functions would take linear time or have complexity O(n). This is because for push, we would have to move every item in the list over to the next block of memory in order to insert an item at the front of the vector (and if there wasn't sufficient space in the vector memory would be reallocated the items of the vector would be copied into the new memory, but this would also have complexity O(n)). There is no push_front function in vector so we would need to design this function ourselves.

For pop, we would have to remove the item at the front of the list and then shift all other items in the vector to the left by one, which would be a linear operation and thus the complexity of the pop function would be O(n). There is no pop_front function in vector so we would have to create one ourselves.

There is no best or worse case for pop or push, as the complexity is always linear. 

The size function will still be O(1) or constant time, because we are simply returning the size of the vector.

The top function would just use the front() function and would be O(1) or constant time as it simply returns a reference to the first item in the vector.",11.0,12
4029,4029,5711,43337822a8495f6346099bee6f1b1379846d1e116a80358eff95ac9a35a5e9db993d15f49931c7a4d1543bc7328dae0e418202f217ef071778281db16cfc2fe9,"To implement a stack one will need a push, pop, size and peek functions:

1. Push function - One will then have to move every item in the vector, one position over to the right in order to free up the first item then add the new item in the first position. It has a linear complexity of O(n).

2.Pop function - one will have to move every item in the vector to one position over to the right except for the first item so that the first item is removed and decrease the size of the vector by one. This has a linear complexity of O(n).

3. Size function - one will call the vector size function which return the amount of items in a vector not the allocated space for the vector. This is a constant complexity of O(1).

4. Peek function - one will call the vector front function which returns a a reference to the first item in a vector. it has a constant complexity of O(1).  ",9.0,12
4030,4030,5712,92a2ed8f4716bed3b0e0c50f4d71ca4d4c6f96e622febc9b471f947d10b8500c23531ab4582c0648a7ceef71efcbb7100102c2a6bd33328ed40abb07652829ad,"The stack will use most of the vector's functions such as ""push_front"", ""pop_front"", ""front"" and ""size"". The ""push front"" function will add items to the front of the vector(top of the stack) the function has a best and worst case. The complexity of the best case is O(1) and it will occur when there is already space so it will just simply add the item to the top of the stack. The complexity of the worst case is O(n) and it will occur when there is no pre-allocated space to add an item so copies of the items in the old memory need to be made to a newly allocated space. The ""pop front"" function will remove items from the front of the vector(top of the stack) and the function has a best and the worst case. The complexity of the best case is O(1) and it will occur when there is already space so it will just remove the item on the top of the stack. The complexity of the worst case is O(n).",3.0,12
4031,4031,5713,67d402955c162ab6452295b6b5d26eba2d31759d3c95b63363fb0f3d4d6e0b04ac632a790b3b479c13437abea8e6208b9e8122018f1333c3a720caa36adbe27b,"For the push_front function, if the current vector is not empty i would create a new vector, push_back the new thing that has to be inserted then copy all the old things into the new vector, this would have a time complexity of O(n) and if the vector was empty,push_back would work and this would have a time complexity of O(1).

For the pop front function i would use the begin function to call the front of the vector, and the erase function to remove it and this would have a time complexity of O(1).

For the peek function i would use the begin function to call the front of the the vector and return a reference to it, this would have a time complexity of O(1).

For the size function, i would use the size function which would return a value for the size and this would have a time complexity of O(1).",7.0,12
4032,4032,5714,f4baa24ad720b1250dc8a9d5d7170a55ee764630dc2c7f87292182bdad71ecf2851e6fec34c6913b3b5952d370fbd9d0459efe69a1541c4221908a8f498f268c,"SIZE: returning the size of the vector would be no different than usual and would simply use the size() built-in function with constant complexity i.e. O(1).

PEEK: this would simply require returning the item at index 0 and so you would just  use the front() function to find it with constant complexity i.e. O(1)

PUSH: like a normal vector this would require reallocation if n_items > n_allocated when trying to push.However, every item would need to be shifted by index by one by copying one block to the right and the last item at index n-1 moved to index 0. Complexity would be linear - O(n).

POP: the item at the front of the vector needs to be moved to the back and popped. In order to retain order, we'd need to copy every item one to the left and ensure the item at index 0 moves to index n-1. Reallocation may need to occur if enough of the vector's space is not being used, also requiring copying of items. Complexity is linear - O(n).",11.0,12
4033,4033,5715,135bdbdca9dab16566a02b87eb86b2b03e986360c36387bc6b252f2a7b0098a14637a43a9d1d68d223771b954b34555f039489b7af8726eba774f24a3c3a0d42,"Push: You will need to move every object one position back and add the new object to the first position. O(n).

Pop: You will need to move all the objects one position forward and delete the first object. O(n).

Peek: You would simply look for the first position in the vector. O(1).

Size: You would simply look for the size function of he vector. O(1).",11.0,12
4034,4034,5716,6faaf9b1d085a393b028ace82b2996765123fa315b9f4a8ed8db3a15b212a1737ea08b0cd8412ff053120963926bb68c4544ec749acc155d82f591062af2caa1,"push-function: when we insert an item we have to shift the rest of the items in the vector up by one and when we reach more than half of allocated storage then we should reallocate new memory. Time complexity is constant.

pop-function: when we pop an item we have to keep of shifting the rest of the items down by one and when we reach less than quarter of the allocated storage then we should reallocate to old memory. Time complexity is constant.

peek-function: to get to the top, constant time will always be taken.

size-function: constant time will always be taken to get the size of the stack.",7.0,12
4035,4035,5717,bb7a5218ab3dfcc0ac546d608943de6dcbb3727d09e6f5dbb5e885ea5b24939174aaaa40e8672ce63fa53f6af97ad899b29ea3229ae18c85c504ca3dcaa7d71a,"* Push - I would use the built in function ( push_front ) to add items to the front of the vector.
	* Time complexity(Push): O(n) it would be linear because we have to copy every item in the vector and move it 1 space  ahead to open space in front of the vector.* Worst case is also linear O(n).
	* Pop - use  the built in function (pop_front).
	* Time complexity(pop) : linear O(n) after removing an item in front we have to move all items in the vector 1 space in front.

	* Size - get the size of the vector
	* Time complexity(size): O(1) its constant time because it doesnt matter how big the vector is.
	* Peek - get the item in front of the vector.
	* Time complexity(peek): O(1) its constant time because we get the item in front of the vector.",9.0,12
4036,4036,5718,59d6b044c8e3defdb04ae33f65223b9a348ff28a2986757f1ff92456374522a233c59e08e3595ef590565b6c7312655ac0d183d5fa106548d9bdc3808d7fd503,"-The complexity would always be the worst case i.e. O(n)

-We would have a ""do"" and ""redo"" stack",0.0,12
4037,4037,5719,c4a46955ab90460a7f7ea08b20b02537758cd0f1f3801bb0b96314fe0ff9d069021459ba5c9b4434a1085ce9d389652fee31ac82384418540ac50a261c57a498,"For a pop function a counter will be kept of the number of items between the first place in the vector and the top of the stack. This will serve as a modifier pointing all references to the correct item at that point. Time complexity: O(1). Once this counter exceeds a point the vector will be reduced and the counter adjusted accordingly. Time complexity: O(n).
For a push, if the is an available space ahead of the current top of the stack it will be re-assigned. Time complexity: O(1). Should this space not exist the entire vector will be reconstructed to created empty space. Time complexity: O(n). in both cases the counter would be adjusted accordingly.

A peek would be accomplished by referencing the space counter to find the current top of the stack. Time complexity: O(1).

The sized would be obtain by find the size of the vector and and adjusting by the space counter value. Time complexity: O(1)",7.0,12
4038,4038,5720,307d8af1793926f21e6b4215d5b4182c112c0d4698d4832d0185b0d9535a011c7a888a921d240645fc84a5799fdd55910fe15a0615bdfb1a6fdb121e9cfcac36,"-The stack will contain four functions, namely the push back, pop back , size and peek. 

The push function has the time complexity of o(n) 

The pop function has a time complexity of O(n) 

The size function has a time complexity of O(1)

The peek function has a time complexity of O(1)",7.0,12
4039,4039,5721,a8e9f7af885a794cf115ef4ae2efb719a045fef1a67ed1ceb91d47fac21a3c207363f092625ba28d25fab14149b9e5cb63f7997360c20c56ec6163be05ed3db3,"Complexity of popping is O(1) and for pushing the constant time is O(1).

Pop an item at the back and push an item at the front ",0.0,12
4040,4040,5722,4c6f807c2ce1ab585dfa9622ceaade81e43b8fe88ba8af5d95eb11efdad75a8b1190eb5c2d48dff34f29ac730bf0895fdaf308c3995dbd7f2103246c342b70a1,inorder to implement this to add element to this type of vector we would add the element to the first position of the vector and push all the other elements back by 1 and increase the size by 1.if the are no elements we would simply just add an element to the vector and increase the size by 1. the time complexity for this would be (o)1 constant of worst case (o)N.,3.0,12
4041,4041,5723,dcb36512b447a313662d0f410494b8558ba9ebb01567bc86a95298f6904541d3214ff36bc5d7b6282877fc7d17b5d1d22bd45efc068f60d6574cc4f66e60986b,You could implement this using ,0.0,12
4042,4042,5724,7ad6b014f9c54f4af21e21f5ded12f480a954caacae0b1ae202d37d441149e00126be0ab20466a777e1dde3487a3cf0d1df830a29d9d1df5f045525d8082c235,"I would implement a stack that uses vector by introducing a null pointer named temp which would assist in making the front of the stack to be on top. This can be implemented in this way, when adding an item maybe k1, which is connected to the main frame, i  would then add a null pointer connected to the head pointer which will connect to the first item then create a new item that will connect to the first item, this will result in the null pointer to be a connection of the first item and second item by introducing a new item which will be on top of the stack. This can be shown with pan cakes, each stack has to be added on top of one another but if there were to be a source such as a sourcer which each new stack is put on, when all pan cakes have been placed on it then on the main frame, table, then the stack is flipped over for the first to be the last and the last to be the first.",0.0,12
4043,4043,5725,4fe3ddceb8532be5264d396e27eca9f3430928d2debfbdca391cfa468f769445f07ae40650717eb0131d20465c9068c4b8bf87a2c7932640884394a0094fc8e5,"push - Best case: O(1)

           worst case: O(n)

back - Best case: O(1)

           worst case: O(n)

peek - O(1)

size - O(1)",7.0,12
4044,4044,5726,a69deeb1d09b2c2f2efacf2adabcd40f91cbdaa6d8a94b958b4f80eb19e04ba4658d33a6b07d41e2293e3dc7c648d0c9d4ec03fdc6df749e7a11d1c6ae138068,Using a stack based vector with the front being the top item in the stack Means that every item added to the stack Will become the 1st item in the vector. Thus the functions that make up the stack will be data.push_front(); data.pop_front() and data.front(),1.0,12
4045,4045,5727,5221e1f3d933576f202c0725eb1b1536ee1b49681a3fc7d8f1a5f7ce021be47e8c2ad1016a78e47c8f005a4abc05514dc591b463cb92d3c640fd02125cf688e6,"Since the front of the vector is the top of the stack, this means the the last vector element is the bottom of the stack.

Implementation:

1. To push_front (), we would need to remove the first element and reposition of every other element by 1 (forward). This would require 1 action to remove, n-1 actions to reposition everything else, and would be O(n) time/linear time.

2. To pop_front (), we would need to add an element to the front of the vector; this requires n actions for repositioning everything 1 space back, and 1 action to add an element to the front, totaling n+1 actions or rather time complexity O(n) time/linear time.

3. Size () and indexing would remain the same as normal.",5.0,12
4046,4046,5728,b3916d46d881833f987b1688b8c10f933afdc9a4fa5bd760932846eb945fb5e69406c926d4b58830137510a4b06c87b7babebfdb5983ea8a0ed2ed2ae65cf4e6,"use a double-ended queue as the underlying container

pushing an item will usually be O(1), but worst case O(n)

popping an item will usually be O(1),but worst case O(n)

peek and size will always be O(1)",7.0,12
4047,4047,5729,5f1f239814321ab1f431320367ad013e94b2f66dc9f45345746644a7c6190c150b15690868f1b18e7468353f42b32ce7d5d9e6673f3e33a12996a386f5985adf,"push:

    since there is no push front function in vector we have to create our own. I would start off by shifting all elements over to the right(i.e towards the back of the vector).  I would then set the front of the vector to be the pushed item by setting data.front equal to the item we are pushing.

    Time complexity- O(n^2)

pop:

    Since there is no pop_front() function in vectors we have to create our own. I would start by shifting all the elements over to the left (ie towards the front of the vector). I would then pop_back() on the vector to remove the last block.

    Time complexity- O(n^2)

peek:

    I would return a reference to the front of the vector.

    Time complexity- O(1)

size:

    I would return the size of the vector.

    Time complexity- O(1)",7.0,12
4048,4048,5730,267e2a74684712f40153e983cf911454f693aaba7aeefb5a018f4e1b42bb05582faee8c5c865be8869988dea6e1c2f220a507c49209244aad2cd13359f2247d7,"Since the front of the vector is the to therefore we begin from the back and add till we reach the front of the vector and if we need to remove we start at the front of the vector going to the end or back of the vector. First in, last out.",0.0,12
4049,4049,5731,9403a6055052838effd7ee11ccb772d87904528f067a64dac873492ac316e3dec04949023db9aa2c93819f94c53c4c5c1b5e1941d51e786c3ee0dff6e062b7fc,"1) To add items at the top of the stack using a vector I can push to the front. The complexity is constant time if is best case otherwise linear time if no space allocated.

2) To remove an item from the top of the stack using a vector I can pop from the front. The complexity is constant time if is best case otherwise is linear time if more unused space is left.

3) To get the size of the stack I can use the size keyword present in a vector. The complexity is always constant time.

4) To get a referrence I can return the first item in the vector. The complexity is always constant time.  ",7.0,12
4050,4050,5732,9f85bd574a0fb5fa07c95cbd2dc5aa7f4cb77f83ea58b24cf50b8a111ddaa2e08d644409b7ea28dad73defdb2393c136cc039b51ec3ed144b40271a76c7c7470,"vectors store data like lists, if we were to use the front of the vector as the top we would have complexity function of O(n) because we would it would have been faster to start at the back.",0.0,12
4051,4051,5733,e8a6e8174a6dd6e314677435e7049c0e3009b13d8a5df4000710970679e38e84d121d59138dfaf7218a7bd9e9ad0ee03d92b55f5f1e73be1e9206de0707e798c,"Elements are added and retrieved from a stack in the opposite order (Last-in, First-out) and this is how the above would be implemented.

push(item) adds an element to the top of stack

pop() removes the top item and returns it

peek() examines the top item without removing it

size() tells how many items are in the stack

all these functions have a constant time complexity of O(1)",3.0,12
4052,4052,5734,744cc5a93fd7edad364406b30ceaa6836705a7419bd01ed97b04c61f1235130699ff789e400cc607e1772b19b35bf800957b6bd74b1e52cf1974d01500560533,"I would create a vector stack. Then the functions would work as follows:

Push: Best Case: O(n) each item needs to be copied back one space forward  to make space for the new element to be inserted at the front.

Worst Case: the vector is full and the elements need to be copied to a new array and then the element is inserted O(n)

Pop: O(n): All elements are copied over one block to the left (in the contiguous vector) 

Peek: O(1) constant time as the top of the list is the first element in the vector.

Size: O(1) Vectors store their size and this value can be called through the stack.",11.0,12
4053,4053,5735,1489eb158e53466602df55c1ff7f77273c9913450f0796e43815428214c7433748ab1168262af0196b8d73779fe2b0792d76aba9ed45066d1d5d48c57b55c0b6,Such a data structure could be implemented by adding stacks to the front of the list and popping the first item from the list. The peek function should then also peek the first item of the list. ,0.0,12
4054,4054,5736,2a0df219aac143a2ab259ed39069368d09faa1d674232d6d8a5a0299284966b0b712226c702276000af1418c0c7120be9e30f8742712afc25a87bebd377d57d9,You used O(n) memory in the worst case and O(1) in the best,0.0,12
4055,4055,5737,f0db6745b82c8442a04741f69d90ab699cfa4f3ce386836ba0d3ae6a18d50c9ca2d13114c6327692eaa69266b7b9c9c7378c99ca64e0ec19c0994415cc5bcc80,"Everytime an item is added onto the stack, it is popped to the front of the vector, with a pop front function. In the pop front function, the item is added to the back to the vector and every item is moved one place",0.0,12
4056,4056,5738,9607664f15775a14ee634c51fe9c149f525e26b98d5914c3165e84652908eb3f36dc6b5eb9602fdd2aa10815feb68c6202a768e4280fe2bc5565e0190f5672e7,You could implement it by using a vector as a vector has a push_back() function and Pop_back() function. A vector also has a Push_front() function and thus you can make the front of the vector stack the TOP of the stack.,0.0,12
4057,4057,5739,2752a012a3acfc041a30d5a655085eade0eb440b54f67d20ed248f27ebf41fd19d90129f4fd7d4c48bc1b7b721b3638118e357f1785837b03bc7def7da08253e,"We could implement this by reversing the vector and then using the back of the vector as the top as this would keep all the functions we usually implement for a stack the same and thus keep the time complexities the same.

Therefore:

	* push_back would have a best case time complexity of O(1) and worse case of O(n).
	* pop_back would have a best case time complexity of O(1) and worse case of O(n).
	* Peek would have a time complexity of O(1) as a constant amount of work is done.
	* Size would have a time complexity of O(1) as a constant amount of work is done.",7.0,12
4058,4058,5740,6a7a49da689922560451287b4e285dafdb4a0bfd283c9d3d5a6941f50de9e8434c4baab959d6ac95be4270bc3e3b12632437fec1cc1ffa0e88747c0a4bcc97e6,"TIME COMPLEXITY

push_back -linear

popback - linear

data.back - linear

size.data - constant",7.0,12
4059,4059,5742,b35e384f7c5ceb06d79c3b93cc63fcaa47042ffefb6b106d30f49be852e804e9feab1392cb217f65d7e7d63ec9914fbf325012c10f23427d79d4c0865092862e,"Assuming we used a vector<Thing> we would implement push, pop, peek and size as follows:

Push: use built-in Push_back function. Best case O(1) constant complexity (there is space for the new Thing), worst case O(n) linear complexity (no space for the thing, resize the vector)

Pop: code a pop_front function that copies everything apart from the first item into a new vector. O(n) linear complexity

Peek: use a built-in front function.  O(1) constant complexity

Size: use built-in size function. O(1) constant complexity.",9.0,13
4060,4060,5743,c52fe90555e82813bbf7f31602e97c4095475fbbf85ff26471f0158158110480233228486a71767a61c524c47fe301d427e9bdbb31f3216eb95878f59314ec4c,"If we are using queues with a underlying data storage being a vector. We would implement it the same except we would use both push_back a as while for data.front and pop_front functions so that it acts as a queue.

The complexity would still be for push_back O(1) as best case and O(n) as worst case.

Peek would be O(n) and pop_front would be O(1)",4.0,13
4061,4061,5744,dc116295695675ce8f8f9dcde7d1d181a1fc34469a4bd2a570b8ca26a7951f6381d662fe47ef41e490d057b64113abc45be11b89047c039c48685692d843ce1d,"With a queue, push will push to the back, to vector which is pushed-back, adding the items to the back of the vector. it has to travese to the last item and and then we added the item to the back of vector. But queue only allows oush back and pop front, which mean pop the first item of the vector and peek ,just see the first items. Size will just give you the number of items of the vector.

The complexity of push is usually O(1) for the best case ,memory allocated is enough , but worse case have to reallocate memroy and copy,therefore it will O(n). The complexity of pop is O(n), beacause it has to move all item one position, it noyt always have to resize. peek will be O(1), because it just return the first item on the vector. Size willl O(n) because it have to count all the items, for the n-items.",9.0,13
4062,4062,5745,cf96d5be5169d5386c2ce2a3ae914384cd3ff74c0ae41c6fc53cb4ef592a7f9882d33970f1f807fe79c0e961bedb5189d6cfa997817a7684663f34c5e5fffad2,"Pushback function with parameter of T type thing: 

The pushback function will add a thing to the back of the queue, if there is space in the allocation buffer. This will take a constant time O(1). However, if there is not space in the buffer, then the vector will have to be reallocated and copied over to make space for the new element. Copying the vector over will take a linear amount (O(n)) of time as it depends on the number of items in the list that have to be copied over. 

Popfront function: 

The popfront function will have to remove an element from the front of the vector. Since contiguous memory doesn't allow us to directly remove the first item (as this wouldn't permit pointer arithmetic), we would have to copy all items from the second item to the last item to a new array. This means popping from the front would always take a linear amount of time (O(n)) 

Peek function: 

The peek function will always take a constant amount of time since we can use pointer arithmetic along with the size function or use the back() function in order to return the last item in the vector. This will always take constant time O(1) 

Size function: 

The size function will always take a linear amount of time (O(n)) as we would have to loop through the whole vector (counting each element) to count the number of elements inside it. ",11.0,13
4063,4063,5746,1c067bf4dc46efea1d97764ec9e8512203198a06760dfe663905444adb3c11970401fd40f402aab42c0c01db7d7d76641060c3df878232bbed315bb7d13f0aab,"Push complexity is O(1)

Pop complexity is O(1)

Peek complexity is O(n) 

Size complexity is O(1)",1.0,13
4064,4064,5747,3b413468f9946530e16c6d2ced91ab45356664eb3ef35b2823043a9391b6766aeb5cd1cde7c7799a9976f4713f096989c7f13a6ea1b6e1be3f9af94b87e0d40a,"We can implement most of the functions using existing functions in the vector class. We can use push_back() for push, size() for size, and begin() for peek, and the complexity of all of these functions is constant O(1). We would need to implement our own pop_front() method to copy all the items down one element and reduce the size of our data structure. The complexity of this pop method will always be linear O(n), since we have to copy each item to the previous element (n-1 copies) to keep our memory contiguous.",9.0,13
4065,4065,5748,b65e52333a31f01a7d7a5dae0ff6fc8ed82b8b5283406f591e8d448f865292ea8162938b0259891df516358cc77c51dca3895b350dbb36cf96d6c23e9b3fa27a,"For the peek function it would take O(1) time since you are only accessing the item at the top/front of the queue, similarly for the pop function you are removing the item at the top of the queue thus it takes O(1) time. With adding to the stack it will take O(n) time, n being the size of the stack, since you may only add items to the end of the queue so the queue needs to be traversed entirely before the data can be added to the queue. ",9.0,13
4066,4066,5749,d7e19f96a6aba1e381d06c4d14cd8af55d98ac1778548325b5d3026d929df87b2abc3d523dd5623a58ab296187735de8598844f1ea29e935b29ced21ed87e297,"The peek and size functions can be used by calling the vector's front and size functions respectively. This means these functions should take O(1). The Push function will at best take O(1) and at worst take O(n) as although it will still be using the vector's push_back function, if the vector reaches the maximum allocated memory, the contents of the vector will need to be copied to a larger allocation. The Pop function will always take O(n) time as a temporary variable and looping through the vector will have to be used.",13.0,13
4067,4067,5750,a130bfe9418c91d178f590031c0c9939b5fca90db77973d7f6178ded40014a7172640da790c28b96fd7fb6c80913844b332b017840744966e0e7f4da01d28945,"A push function would add a new item to the end of the vector. This is simply a matter of assigning a value to the block of memory after the last one in use and incrementing the variable used to store the number of items in the vector. In the best-case scenario, there is space to do add an item to the end of the vector and this can be done in O(1). However, if the vector is full, we would have to allocate another space in memory, twice the size of the previous one, copy every item across and then assign the new Thing value at the end. This requires making n copies and is thus O(n).

The pop function would remove the first item in the vector. Hence, we copy every item back one block and then decrement the variable storing the number of items in the vector. In the worst-case scenario, there would now be only a quarter or less of the allocated space filled. Thus, we would reallocate a new space in memory, half the size of the previous one, and then copy every item across. Either way, this is O(n) since we make n reassignments of the Thing values. In the worst-case we would also make n copies, however, this doesn't change it from being O(n).

The peek function would be a simple pointer dereference of the first memory address of the vector. This will always be the same amount of work, regardless of anything. Thus this is O(1).

The size function will also be O(1) since we store the number of items in the vector in a variable which keeps track of any changes. Thus we would simply have to return this variable, which will always be the same amount of work.",13.0,13
4068,4068,5751,82694cf634b012a9b99356edee5aefc22b24ba7895f93507fd59a70aa1b507058de91ae69d4a669273414cbd851ebdc45bb8d210bcd7e76b8c63d620d83813d3,"push-O(1)

pop-O(n)

peek- O(1)

size-O(n)",2.0,13
4069,4069,5752,0745491c3d066e21ade2f2d4d85d4695dac91b9131eb26e8aed287a29c7e24ee4d3c6beb342324906b0ab6475785f0d2fea5c9799af48cbec9547c62e95d041e,"push will be implemented using a push back function with O(1) complexity

pop will be implemented using a pop_front function with O(n) complexity

peek will be implemented by using the front() function of the vector<Thing> with O(1) complexity

size will be implemented by simply keeping a track of the number of items being added to the vector and returning the value with O(1) complexity",11.0,13
4070,4070,5753,39f1ebb534a7edaa837d48cbd4115f72e8c5e63b7a4efafc271bf59036c6638038d9febb4eab796e3f3e68165bcbad6c2e1a9ad37eb71f421ecdb12f31f4f4c5,"push: we use the push_back() function of the vector class. Complexity is O(1) in best case and O(n) in worst case 

peek: we use the front() method of the vector class. Complexity is O(1)

size: we use the size function of the vector class. Complexity is O(1)

pop: We move all elements, besides first element, to the left, effectively overwriting the first element. If less than 1/4 of he allocated space is used, we reallocate a new memory buffer of half of the size of the original to the vector. We then copy items of the original memory buffer over to the i-1th position in the new one. we then delete the old memory buffer. Complexity is O(n)

We set the functions to be public and the vector to be private",13.0,13
4071,4071,5754,d42cf42830844a9ee1d0ff0af8c2f689af280ff8f6db853246aca542789b88210a975754cb807f66256c17bb8f0db7f822b9fd7b118d4ccaab17c4ee83f0a430,"push - requires O(1) 

pop - requires O(1)

peek - requires O(1)

size - requires O(1)",2.0,13
4072,4072,5755,5e36a0e7b93c9d082984c03228c748a0348993dbc7307752e7acfbf7e44b3df39b6aedb0dd5c68b0421254e8914343a9e052d4d15e260e3ecd7ef28810b12ec9,"Push back would be similar to that of a stack. Best case scenario efficiency would 0(1) and worst would be O(n) when there isn't sufficient space and additional space needs to be created.

Pop from the front is inefficient as the stack would be reversed first in order for the first element to be at the top of the stack and then removed. The efficiency would be O(n).

Peek from the front would require retrieving the size and then dereferencing the value. in a vector data type this is always quick due to memory being allocated contiguously. The efficiency would be O(n)",3.0,13
4073,4073,5756,297de9e92f0b5f666b5f42405cac621415fb2c64763fdc11b8d57538dae3ffa9e272dd3efdad0a974813033e43539624b9741e3632c9573318e9a12bea633c7a,"When pushing we would simply add to the back of the vector, this would be O(1)
Peaking would simply access the front of the vector and thus would also be O(1)

To pop at the front we would need to remove the first item and then move all of the other items forwards by 1 in order to correctly place the new front of the vector, this would be O(n)",7.0,13
4074,4074,5757,e40d8bf3b05bd8e034438beb235a1631a28b193d6edc5587f765a26d4981e60fae4fcb9a995036a1c2815f2073b85fc4667e3d6bbfc0e5a63b847c8fa219ba80,"Pushing could be implemented using the built in push_back function within the vector class, which stores memory in a contiguous location after the last space that is being used to store a Thing if there is space available. If there isn't, the vector is copied across to a new memory location and twice the space is reserved for its use. Generally, push_back would be an O(1) time complexity operation, but if there is no space available, then it becomes an O(n) operation. 

Pop would be implemented by moving all of the data forward by one space by copying the data from the n+1th index into the nth index. If the list is using up less than a quarter of its allocated space, the list is moved to a new memory location and is reallocated half of its previous space. In general, this operation would have a time complexity of O(n), even in the worst case. 

Size is a value that would be stored inside the object that manages the queue, so access times for the size function would always be O(1).

Peek would be implemented by returning a reference to the Thing in index 0, and would always have a time complexity of O(1).",13.0,13
4075,4075,5758,2a73fae534f6399be599dee1f1de2adaec9431f39943abeccc1ca0cc827521f43446d764a73ff779a0d169bd025aa1ff69232dd0892e2b573939bb6ed6281bd6,"1. I would use the push_back() function for push. Best case time complexity O(1), worst case O(n).

2. For pop I would remove the first Thing in the vector, then move everything in the vector to index n-1. Time complexity O(n).

3. For peak I would use the back() function. Time complexity O(1).

4. I would use the size() function.",11.0,13
4076,4076,5759,174e38c18f0521eafee3b73a0ffb8449a8c5784d547a0843ddac9c9176015fedd2516d8b3d18b017cc9000d2b315ebe1757a54b724f337f3a99202881366a527,"To PUSH an item into the queue, I would use the push back function to add it to the back of the list. Depending on how full the vector is, this would take O(1) if the list is relatively empty or has enough space but rather O(n) if it's full as we would have to resize it.
To POP an item, I would remove the first item in the vector using push front. This will take O(1) time always.
To PEEK, I would return a reference to the last item in the vector and therefore would take constant time to do this each time i.e. O(1)
To implement SIZE, I would return the number of items in the vector using the size() function. This would take O(n) time.",7.0,13
4077,4077,5761,16cb13e3f20264dff11bab6b4074b1ead9b8e1cf1d7a12dd1238f56fff77a643c79324083d48280a979ad65c97d7690c011f0b94300438693e7e3022511b7be3,"PUSH- Use vector push_back function, will be best case: O(1) if there is enough space, if not, all elements will have to be copied into a new vector, so worst case is O(N)
POP- Copy each item into the previous block of memory and decrease number of items allocated, if less than a quater of space is used the data will be copied into a new vector of half the size, both cases result in O(N) as all items except the item being deleted are copied 
PEEK- Call vector operator[](0)/ begin function to get pointer to the value at the first memory adress so O(1)
SIZE- Call vector size function, which just returns a value therefore O(1)",13.0,13
4078,4078,5762,d96af73b5be668f5dd689aeab89641b2c7231424c7456f3ea33f65b38aaefabde723924090d862562454b1c8a6f22cbeb22245f54dc09b6ff5593a40d39e2839,"push- add to the back of the queue- simply add the extra the item to the back of the vector-normally O(1) but worst case O(n)

pop-remove first item and move all remaining items in queue to the previous block - O(n)

peek- return the value in the first item of the vector -O(1)

size- return - the size of the queue - O(1)",13.0,13
4079,4079,5763,24404807247a19fa0eb28edfebfb33701c7bf0ce5da4f252098d5b07602e418852b18cd29763fdb981a6cf7530167e7c60c21dd57b0dd95a95c25a71b9515eda,"Using a vector as the underlying data storage type for a queue:

-the push function would either take O(1) time if an object were to be added to the back of the queue or O(n) time if the object were to be added to the front of the vector as all current objects would need to copied one space forward.

-the pop function would either take O(1) time if an object were to be popped from the back of the vector or it would take O(n) if the object were to be popped from the front of the vector as every other object would need to be moved one space backward.

-the peek function would take O(1) time as the last object in the vector would simply need to be returned without iterating through the entire queue of  objects.

-the size function would take O(1) time as the vector type in C++ stores a size variable that automatically is updated as objects are added or removed from the vector hence it would take O(1) time.",11.0,13
4080,4080,5764,8240603fa734ed603f090dc4c8bce2f226cd0f876026dfa595bd8492bf9acd3d4bb834f9651a57ba591889e5cf0e84e937e21bd54121dfe09399f647a5d4f575,"Use push_back to push to the back of the queue, Q(n)

Use pop_front to pop from the front of the queue, Q(1)

Use the front function to peek, Q(1)

Use the size function to get the size, Q(n)",7.0,13
4081,4081,5765,24ddd7a0d5b35a9bdbeb9a6cd62ada87a4901fab347efd86489f1b2e17964822556ee10a0103983d49fdf2477d3d64f6702d59741c364edd11f42906c3bdb067,"Use the push_back function to push to the back, the time complexity will be O(1) for best case and O(n) for worst case.
Use peek and size buit in function which will both give the time complexity O(1).

Then I will have to implement the pop_front function which have a very inefficient time complexity.",7.0,13
4082,4082,5766,dc28526a371ecd3cfbb01f874b966e2e2019f65befa98a250b0089b346a7e303549dac2ead3ffeef0d3b7ecff19ac3d890b35956aa010524ff365cf1275bd971,"PUSH - this would be implemented the same way a std::vector push_back function would, we would check if there is space in the container, if there isn't then new space is reallocated and items are copied from the new list into the one and the new item is added to the back and the size increased by 1. The time complexity would be constant O(1).

POP - to implement this function we would remove the first item in the container. The time complexity would be constant O(1).

PEEK - to implement this, we would return a reference to the first item in the container. The time complexity would be constant O(1).

SIZE - to implement this, we would return the number of elements in the list by setting a counter to zero then pop the front element an increment the counter whilst doing so. Time complexity will be linear O(n).

__",4.0,13
4083,4083,5768,d320af019b5c5fbf5996000b6f0c018e158d92ab05c3709236e5a03a6b328c59c1ab963403ff89c119e51b19d4eaa6320e2573a8bf4efb41ca5bbf92364ab8b6,"To implement a push one would simply call the built in vector function 'push_back' , this has a best case scenario where there is enough space to add another item, and therefore the complexity will be O(1)-constant time. However in the scenario where there is not enough space and all the items have to be copied over and the memory buffer has to be re-allocated will has a complexity of O(n)-linear.

To implement a pop_front, one would have to move each item in the vector one position to the left, and because of this n-operations have to be done, hence it has a complexity of O(n)-linear.

To implement a peek, one would simply use the built in vector function of vector.front(), this can be done in constant time no matter how many elements in the vector, hence it has a complexity of O(1)-constant.

To implement the size function, one would make use of the built in function vector.size(), this can be done in constant time and hence has a complexity of O(1)-constant.",13.0,13
4084,4084,5769,f786d4a53e476362ee6b6cac013b5aa057803211cb74556b039162da9be82c23d9395512d9e4320c69ff2f74e18df3e862b758b12f302cbbc8a9df857835a235,"initialising  my vector to be vector<Thing>data; push will be data.insert(data.end(),d) and pop will be data.erase(data.begin()) and size will be data,size() and peek will be data.back()",0.0,13
4085,4085,5770,a39aa34c391034439ba958ca98869143599e2cc20097d4066633e71706d0b615be58b0586a9143631148978c46ccf7746504f4abfa225c0f60b106eb68d6aeb5,"PUSHING TO THE BACK

Using the built in method of vectors, namely VECTOR::PUSH_BACK() we can add a Thing to the end in  O(1) - CONSTANT TIME as it must simply add a Thing to the end . In the worst case scenario if the vector running out of space, the built in function of vectors will reallocate all the Things to a new vector with double the size and insert the previous Things and new Thing to the new vector in O(N) - LINEAR TIME

POP AT THE FRONT

As there is no built in method of popping to the front of the method, the only solution would be to move every Thing up one space by using the 2nd value to override the first value, third value override the second value..... last value to override the second last value. This leaves us with a duplicate of the last value where we can then use the built in method of vectors VECTOR::POP_BACK(). In the best case scenario this is O(N) - LINEAR TIME as it needs to perform one copy for each Thing in the vector. In the worst case this is O(2N) - LINEAR TIME because it must perform two copy for each Thing in the vector. One to move each Thing up one space and another to copy the newly popped back vector into a new vector with less space assigned.

PEEK

This can be in O(1) - CONSTANT TIME by using the contiguity of vectors

SIZE

This can be done in O(1) - CONSTANT TIME by using the built in storage of size in vectors",12.0,13
4086,4086,5771,185dc4c21423a9741e871c6f410e59bdca77c391c194cec101c75b3cca04c937f124a0057340342b97dc026d09e5d98b6cb6fda9dab2b9032e1e211b08f87356,"I would think of a queue as something similar to waiting in a line at a pancake store, where first come, first serve.

Push

Every new customer would have to wait at the BACK and will be served last, so something like vector.push_back(). This is O(1) in most cases and O(n) in worst case.

Pop

The first customer that came would be attended to, this is a little inefficient for vectors, but its would be moving all the items in the vector after the first one 1 to the left, closer to the front. In all cases this is O(n)

Peek

We are looking at the customer at the front of the line, so this would be vector.front(). This will always take O(1) time.

Size

We are looking at how many hungry customers are waiting for these delicious pancakes, so this would be vector.size(). This is always O(1)",13.0,13
4087,4087,5772,e2110671a4eab220560a21f9e1e9feb257ad75ab23f504a892c8df780bcf445f866d86be0cb87936d65c86a82a0daabcca41a6174ec4192f8f61c7d3034cdab4,"Using a vector of type thing for a queue, I would treat the FRONT OF THE VECTOR  as THE FRONT OF THE QUEUE

stack.push() -> Push the new item at the back of the vector, IF THERE IS SPACE, this would take O(1) time (because of pointer arithmetic). IF NOT, a reallocation would need to happen - this being the worst case - and take O(N) time.

stack.pop() -> To do this, you would need to EITHER move all the items one place to the front (i-1) except for the first item in the vector (thus overwriting/ 'deleting' it), which would take O(N) time OR if the number of items after popping will be less than a quarter of the allocated size, we would need to REALLOCATE those items to a new vector of half the initial allocated size, ALSO taking O(N) time.
IN THE END, this means the queue will ALWAYS TAKE O(N) time to pop an item.

stack.peek() -> This is equivalent to just accessing the first item of the vector, which will ALWAYS TAKE O(1) time.

stack.size() -> The vector container always keeps track of its size, so all that's needed is to access this, which will ALWAYS TAKE O(1) time.",13.0,13
4088,4088,5773,49811d763ba759a50f2e0c233e15588b02d4f863f2daf7bb9891b1e7fc339a6758ecc3a62c1286ec47602b5e14c6edff45dda6e0d22355027319e6c73f32c285,the pop back function would remove the first item in the list then move every existing item backward one location as the list in contiguous and would take constant time O(n) due to this. the peek function would look at the first location and return it  in constant time with thanks to vector functionality  with the [] operators. pushback would in the best case  have constant time as using the [] operators will allow us to access and change the value of that location quickly however in the worst case where the list was full it would take O(n) time as the entire list would have to be reallocated to fit the space.,9.0,13
4089,4089,5774,6e1111ad11474e6379168f87057eae3076970c620dec3cffde8e98db6de9322b94aefef0b0414a791717f61331121e1ad9f15c607c1ff40afee80bcc8c3257b0,A vector is like a doubly linked list in which contains both a head and a tail pointer and we can easily move to the back and to the front. Popping and pushing things into the list will take constant time since the is no need for me to traverse from the head to the back of the list to pop or push an item there. Also getting an item at the top of the list will take constant time.,2.0,13
4090,4090,5775,5f1f48eaee5ac422a3c6fa6a37eae574e54bf5c31dcf24e0e6dda503da6ac10d5be4b86335df2a703c5cb0a92be355a3535eec42ddde1a798228e8594808928b,"For the push function of the queue, we would simply call the vector function push_back(). Due to this, its time complexity would be O(1) in the best case, if there is still space in the vector available; in the worst case, its time complexity would be O(n), as we would need to do n reallocations as the vector is full.

For the pop function of the queue, we would use a vector function, pop_front(). This function is not in the STL for vectors as it is inefficient. Thus, we would have to code it ourselves. The function would delete the 1st element in the vector (by calling its destructor) we would subsequently have to make n copies in order to move the elements one position back, in order to fill the gap created by the deleted element. If n_allocated/4>n_items, we would have have to copy reallocate the vector to a vector of size n_allocated/2. We would then copy all elements over to the new vector, however, since we want to delete the first element, we will skip the element when copying the elements over. Due to the copying, this case of the function would also take O(n) (linear time) Thus, it will always have a time complexity of O(n).

For the peek/top function of the queue, we would simply have to call the vector function front(), which returns an reference to the first element in the vector. Due to this it would have a time complexity of O(1).

For the size functions of the queue, we would use the vector function size(). This would have a time complexity of O(1) as we are simply just returning n_items, and not doing any traversals/loops.

We always cahnge the sixe of the vect",13.0,13
4091,4091,5776,fa243626fbe26ef57e9cb51b64e34cda34860d25833be057b8aacb2413654723774f7590965ed807a0415dd0e925f4717e86fc15d11f310737f703eab68fbabd,"I would make the back be the top of the stack. pop_back O(n), push_back O(1). i would also make the front be the back of the of the stack and use the top( ), O(1) and size O(1).",6.0,13
4092,4092,5777,0fa5d829ab37316f131667488ff6244b79b525ac275e022289de875a4f7426de94ef384d30176ee34a2851d47d343e62431c37057ae6054ad83ff76862ff86ab,"1.with push back function, we will just have to go through each item on the vector until we reach the last item using a loop,then add an item on the top.We will do this in a linear O(n) amount of time.

2.with pop front function, we are just gonna remove every item on the top until we reach the first item(item at the bottom) then remove it. We will do this in a linear O(n) amount of time.

3.with size function we can just use a loop to go through each item while counting the number of those items. We will do this in a linear O(n) amount of time.

4.with peek function we have to remove every item at the top until we reach the item at the bottom and return it's reference. We will do this in a linear O(n) amount of time.",2.0,13
4093,4093,5778,b3e3cb2c21ce148370b5e2f91fd1c15e350a5dbb48b70710937a60df00151bac26d80bc3a7bdad4c31eb69ebb35264a7c7773c7f45cef6e057b05eb18d125d01,"Push: O(1)

Pop: O(1)

Peek : O(n)

size: O(n)

Queues follow the first in first out arrangment. Elements are inserted at the back and deleted from the front.

Push inserts an element at the back of the queue and size of the queue is increased by 1.

Pop removes an element and decreases the queue by 1.

Peek returns the front element without removing it from the queue

size: returns the number of items in the queue.",1.0,13
4094,4094,5779,ee3d89b0d1151de34e3cf3043fc2b6592a400e8ce8a1d14d3b5e77f1fc57f3bb24de4a9c4426effca79ea565b502539dcf46a1f1d27d52e0d1e79029ce2f8aab,"With a stack we can only make changes to the top, but with a queue we can make changes to the top and the bottom. Think of a vector called data as the underlying data structure. Therefore we can use push_back and push_front for our push function. Both, push_front and push_back will be constant but linear in the worst case. For peek, we can see which item is at the the top or which item is the bottom and this will be implemented using data.front and data.back which will both be constant. The size function would remain the same as it is for a stack and that would be by using data.size  which is constant.",9.0,13
4095,4095,5780,e9f55a461571038daf39646f8c350339a639982fda3a68a7de2c663bf3b55fcfe5c2c1470245e6cd83dc29b1d2c16e474b9b4bcd8ac2d4eb9b9e2eef6125ba6e,"Since a queue is a stack where you can use both the items at the top and at the bottom the following functions would work

PUSH

Since the queue is of type vector you already got push_front() and push_back functions to use and the time would be best case O(1) and worst case O(n) for both

POP

You can use pop_front and pop_back functions and the time constraint would be O(1) best case and O(n) worst case 

Peek

You can use the .front and .back functions of a vector to return the first and last item in a vector respectively the time would be O(1) for both

Size

would use the vector function .size and this would be constant O(1)",9.0,13
4096,4096,5781,73f8ac3de0d9e29b34984491080a2a437e9d07081ef998fb53c2e73bde6a76efa33589c04809db77b67bfaaea71b13e4b7480f42fd75bb56aca6e9a4110b16f7,"For this implementation, the pop_front will once again be O(n) as we have to move all the items (n items) one space up once we removed the item at the front. The push_back function has a best and worst case scenario. If we still have space allocated for our vector, the complexity is constant, O(1), since you will use pointer arithmetic to get to the first open space. However, if you have to reallocate space as per the underlying code of vectors (add double the space if allocated space is used up, half the allocated space if 1/4 full), you will have an O(n) complexity, as you will have to copy all your items (n items) to the new vector. Peek has a constant complexity O(1) as it can be accessed using the built in [] operator that uses pointer arithmetic.",7.0,13
4097,4097,5782,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"a)(i)push-adds value to the top of the stack.

(ii)pop-removes the item from the top of the stack.

(iii)peek-returns a reference to the top item.

(iv)size-returns the number of items in the stack.

b)push,pop and peek all take O(1) time;size take O(n).",1.0,13
4098,4098,5783,b47128b210e7cc636fb0b5325c08248ffac624374ed1eaac62c3594d5f67da91cc887cbf07a6c3571b2149ad963910548cff788f165204f9df156115e859a64b,"Let the vector be named data.

pop - using pop_front() function. Best case- O(1), Worst case- O(n)

push - using push_back(t) function. Best case- O(1), Worst case- O(n)

peek - using data.front() function. Always O(1).

size - using data.size() function. Always O(1).",13.0,13
4099,4099,5784,17ea794106565b342d0071ecda1b602670f938db088b102cae298b8fa539f99c81604db8696804a94225d5fcb56b3538a2b45e5527c8d0a393e5e2aa5ae7c0be,"For the push function, we could use a vector.push_back function. Best case time complexity would be O(1), and worst case would be O(n).

For the pop function, we could use a vector.pop_front function. Best case would be if the vector has only 1 item, O(1), worst case would be O(n)

For the peek function, we could use the vector.front function. This would always be O(1)",9.0,13
4100,4100,5785,cbae5eeb6217dfd80bce3b9f9dcc6a487de93ab5d86c0254cee58b6e3923317f7e11f9c1e67f0e0269268aa476f5f7d41a06d2c8bc23012e2299f02af5f41761,"To push to our queue:

Push back the value to the vector. This will usually take O(1) but in worst case can take O(n).

Pop from our queue:

Erase the first value in the vector. This will take O(n).

Peek:
Return the front of the vector. This will take O(1).

Size:
Return the size of the vector. This will take O(1).",9.0,13
4101,4101,5786,d0487881fde4213facde4c9cd0143d5802f701e002f130b7eaa6dd04f68f58612ae33c39c89beceae1495437bbe2376be3003369a31f0f2bc6f9e0c5a369707a,"PUSH :

	* use the inbuilt _PUSH_BACK_ method.
	* the complexity would usually be O(1) but O(N) when the vector is full.

POP :

	* use the inbuilt _POP_FRONT_ method to remove the front object.
	* the complexity will be O(N) since the other items have to be copied over.

PEEK :

	* use the inbuilt _FRONT_ method to return the front object.
	* the complexity will always be O(1) since it is the first item in the vector and we can utilize pointer arithmetic.

SIZE :

	* use the built in_ SIZE_ method.
	* the complexity will be O(1) since the size is stored and monitored when the vector changes.",13.0,13
4102,4102,5787,ff8092e7aa4e021dd13cb98107d467aae4489986d4e06673b1b4c81ebb2bbfe82687888ce375f42c4423ae545a48ef629cc67802c799162dd6a5d1de2f545d85,"push function can be done by using the push_back() from the std::vector in O(n), pop can done using pop_back() from the std::vector in O(n), peek can be done using the back() from the std::vector in O(1), size can be done using size() also from the std::vector in O(n)",9.0,13
4103,4103,5788,5efe3fbf856ecf3a15a69292118ba94b4935a0dba8b272f0af264465d64a2e654697453d0e3e6e72201dc798f4cd3f27b28fbe0c2032a2a7784e39ed4c150909,"Push: 

The element (specified in parameters) is added to the queue containers. 

Increment size of queue by 1

Pop:

Removing an element from the front of queue you would remove element to queue container.

Decrement size of queue by 1

Peak:

Size:

Checks if empty and returns the size of the v",1.0,13
4104,4104,5789,52240fd5da488c8fea93f35bf4efe57000386d8c8d0c85c5b680c74f1a8feca90e13d4df01d1470660907e2655f277134bf53af33144e84c3793614abbdf6e99,"The size and peek functions would remain unchanged and will still take 0(1) amount of time. The pop_front function would now always take 0(n) amount of time while the push_back would usually take 0(1) time but in the worst case, it would take 0(n) time.",9.0,13
4105,4105,5790,66c130d147af93128f149a1c3cbc0822def0372144aa77769fad8d406e0bf1fdaea5c4080bf967de52230b79e34763f78e3d8c34ddd69955b5c9b8521c52443c,"As a result of using the vector class as the underlying data storage, the functions you would use from this class are the push_back to push, pop_front to pop, front for the peek, and size for the size function. The time complexity of these functions would be as follows: the push function would generally take 0(1) amount of time, but worst case (when the vector is too small it will reallocate itself into a new memory space that is double the size of it's previous one) it will be 0(n). The pop function would generally take 0(1) amount of time, but worst case (when the list becomes a quarter of it's size, it will reallocate itself a new memory space of half it's previous size) it will take 0(n) amount of time. The peek function will always take 0(1) amount of time due to the vector having the property of contiguous memory. Finally, the size function will take 0(1) amount of time as the vector class stores its size and therefore it will just be calling a stored value. ",13.0,13
4106,4106,5791,2ac52bf7176b74f783c4dc472a3ad61819784c24e47b750c3635810bda8131880643be2f953dc39facdc68dcec02aa6cc62d7628e7e8b294770838010259c464,"Size has n items, and its time complexity would be O(1). The peek function would always do the same amount of work O(1). The push and pop function has a best and worst case. The best time complexity would be O(1) and the worst time complexity would be (O(n)).",5.0,13
4107,4107,5792,cdf5a55df376657eda6b008ced4f7043cdba2f1d1b7da216b9e5df9fd11e894729a95890612c52ba24c8f6e0b1099b039f557d8043ee19615f361b8a60481af7,"A stack is an abstract data type. Lets say that the back of the vector corresponds to the top of the stack. To add to the stack, when we pushing, adding to vector we are adding to the back of the vector and the best case complexity would be O(1) and worst case complexity would be O(n). When we want to remove something from the stack, we remove it from the back of the vector and the best case complexity would be O(1) and worst case complexity would be O(n). When we want a reference to the top of the stack, we want to return whatever is at the back of the vector and the complexity will always be O(1). When we want to return the number of items in the stack, the vector does it for us and the complexity will always be O(1). ",7.0,13
4108,4108,5793,eacc5211df7d685afcc35802886c12863f0c8244351fcd398189af9fa9bf26e12a751640dd66f6200f43478fc4f6782d51b4f6c4a782ca1b75e12c96dded3eec,"For push: 

pushing an item to the back would require that you insert the item at the last index of memory of the vector which has a time complexity of O(n)

For pop:

You would insert the new object at the front of the vector but would be required to reallocate all other existing objects, ie: moving each object to the next block of memory. this would also have a time complexity of O(n)

For peek: 

this is using the built-in vector at() method. Since the object is at the front, this would be done in constant or O(1) time. 

Lastly, for size: this is can be done using the built-in vector size() method which has a constant time complexity: O(1). ",13.0,13
4109,4109,5794,4bccbfcaa9439271fb4e221590e1fd6768f9a6170a62193e2aa38f727ca7e838985ca00984f7b4a782149961c288a265aac8163c38e74ff4f6279a0f9baaec5e,"push, takes in Thing t as parameter : Push Back t into the vector - O(n) time. Best case, we need to find the last variable in the vector, and set the variable in the space after that. Worst case, there is not enough space, in which everything has to be re-allocated in a vector double the size, which also takes O(n) time.

pop : O(n) time. Best case, the variable at the start of the vector is deleted, and every other variable in the vector is moved one place back, taking O(n) time. Worst case, the variable at the start is deleted, and every other variable is moved one place back - but there is less than a quarter of the space being used - so we have to reallocate, which also takes O(n) time.

peek : O(1) time. Return the variable at the start of the vector.

size : O(n) time. Have to traverse through the vector to find the number of elements.",13.0,13
4110,4110,5795,8c4ece10bea4707d74ad8e485b192cf388c1aaad3dd5b625cadaaa6a947d3861bc0547f235d6ff3af091e10ce08cd771b73e98b692a991cef32a92e7b557b387,"PUSH

For the push function,  I would just use push() just like I use when implementing the stack since its almost the same concept. Since data is simply being added at the back regardless of number of elements, the time complexity is constant O(1) in the best case and and linear O(n) in the worst case.

POP

For the pop function, I would use pop() which will remove the first element in the queue. The address of the first element will then be [n_items-(n-items-1)]. Since the pop function will always remove the first element the complexity is constant O(1)

PEEK

 For the peek function, I would simply use front() sow that the first element is returned. The complexity of this function would be constant time O(1)

SIZE

For this function, I would simple use size() since the number of elements are pre-recorded. The complexity of this function is also constant time O(1). ",13.0,13
4111,4111,5796,8898c8dc647252a67895b09c0b6e1e1b46e9abbd7623ddf40416335c9bffe71bf94348a71bd79a7ce33d630fd22f8d8b30ee288c330b6c240bf1f662dbee2a5b,"For the Queue push, we would use the push_back vector function. With the complexity of O(1) in the best case and O(n) in the worst case

For the Queue pop, we would use the pop_front vector function. With the complexity of O(n)

For the Queue peek, we would use the front vector function. With the complexity of O(1)

For the Queue size, we would use the size vector function. With the complexity of O(1)",13.0,13
4112,4112,5797,7099f15d1fb337686bf427fedb824d4eefc2c359e7374f808226d1191d0f74342e42146c05dfa9cdc17fbdc8dce0a4cb75b417e6eb24978dd57c4773dec73b21,"I would implement the queue with the container = std::vector<Things> 

For push function it would require O(1) in the best case but if reallocation is required it would take O(n) amount of time which is the worst case.

For pop function it would always require O(n) amount of time because you would always need to shift the vector or reallocate.

For peek function it would always require O(1) amount of time to access to front item of the vector.

For size function it would always require O(1) amount of time as std::vector stores the amount of elements.",7.0,13
4113,4113,5798,ac00d5695452023736c168247b6e6e7ac1c86c1918ba65ce039a3ac355db0c0c6d3945a25b1f4c24df8db20417ffdf726ff5a44586e3fb4757147f393e36515b,"Since we push to the back, there'll be two cases the worst case and the best case. For the best case there's still space in the vector and we just insert the item at the back of the vector, this will take a constant amount of work. For the worst case the vector is full and we have to double the space and copy all the elements we had and this is going to take a linear amount of work. Since we are popping at the front, there are two case, the best case and the worst case. For the best case, we only have one item in the queue and we just pop it. For the worst case we have more than one element in the queue and to remove the element at the front we'll have to copy the others to another vector so this takes a linear amount of work. Since peek is at the front, we have to just use our front function instead of back, front() is going to give us a reference to the first item in the queue and this will take a constant amount of work. size is still the same and gives us a constant amount of work.",13.0,13
4114,4114,5799,16f82e0a87e8ddd62872296dc55051239fbed9bd7e989d4564eab3d0b0bd3dd97f30debd1ef7c57a72ffc4e972a5a710915f103218e9d2778be68d8b10a7d403,"We would implement the function pop at the front from the front (data.push_front( )/data.pop_front( ) )and the time complexity would be O(1).To push to the back you would use data.push_back and the time complexity would be O(n).

The functions peek and size using the usual functions such as back and size and it would be O(1)",9.0,13
4115,4115,5800,07ab043d70e14725f955703ce65a95b6912342e429a6c9a7dec43aacd53b63f2b0d3ebef4da8ffdff01a86c6c296ffe0e21e4d798223854fe6e651460e1d7280,"The size function would use the pre-existing vector class size function that would be O(1) as the vector will keep track of how many items are in the vector.

The push function would use the pre-existing push function from the vector class and so should be O(1) as a best case and O(n) as a worst case.

The pop function would need to be implemented as popfront does not exist in the standard vector library. The function should use the deconstructor on the first item and then update the vector by moving each item to one previous position. This would require going through the vector n times hence the pop function will be O(n).

The peak function would use the pre-existing front function in the vector class that is O(1) as it does pointer arithmetic since the vector is uses a contigous block of memory.",13.0,13
4116,4116,5801,14bf4a341dc9827953823163cd007e766c263b8c396bea85416367e8c4908e0df252e9e3ac38e08223a3bcc05a108adef9f1881af30b78d3c7220ceb7c6be157,"To push to the back of our vector, we need to check if there is enough space for an additional element. If there is, we insert the element at the back and this will take O(1) since we can simply access the position without making copies.If there is no longer any space in the vector, we reallocate twice the space,and make n copies and then insert element at the back of bigger vector,this takes O(n) time . 

To pop from the queue we need to check if any re-allocations are required , if not -we take O(1) and if we need to reallocate the space(if there's more space than what we need), this will take linear time O(n) , as it involves making n copies. 

To peek , we simply return a reference to the item which is on top of the stack, this takes constant time-O(1).

In order to find the size , we are simply returning the number of items which is already stored inside the vector , this will always take the same amount of time O(1). ",7.0,13
4117,4117,5802,128e2656328deed2d77d2ef28a4c653d82a40a62fd734c4ccb3dafb70805db8a812cccc608184c6cbda73e2bdda34e6f81ec5dacc95d16cb9a78cba4ff089ac5,"To add items to the queue, we would use push_back() to place each item in the last position in the vector. This would take O(1) time, unless the vector is full, in which case, it would take O(n) time. To remove items, we would use pop_front() to remove the item at the front of the vector. This would take O(1) time, until the vector is one-quarter full, in which case, it would take O(n) time. To see the item at the front of the queue, we would use the front() function, which would always take O(1) time. To find out how many elements are in the queue, we would use the size() function, which would always take O(1) time.",9.0,13
4118,4118,5803,1e30eb511c307c57041552d3f3ff58f0e01dff16b4bbeafb7e1426a20560b5727bf879a4c238af04f66b8c454f01b583c75d2d8fab510951c437d49081081f31,"To implement a push- we would push back in the vector and in the best case it would take O(1) and worst case would be O(n).

To implement pop- we would pop back in the vector and in the best case it would take O(1) and worst case would be O(n).

To implement peek- we would simply return the 1st element (index 0) in the vector and it would take O(1)

To implement size- we would loop through all the elements and set counter to keep track of the number elements in the vector and this would take O(n).",4.0,13
4119,4119,5804,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"push- Add a Thing to the end of the queue with a simple push back statement O(n)

pop- Remove the element at the first position of the vector O(n)

peek- Return the value at the first position O(1)

size- return the size of the vector O(1)",13.0,13
4120,4120,5805,2dec7d91f389ea815b08c16bf0ce77e60642ceca404945e8ad369e8ed82ed28e57d6cf12351d45add693d36c78a2ba5f4910e162bacba9689368c6699766d9b3,"Push: Push to the back of the vector O(1)

Pop: Pop from the front of the vector by using the begin and erase functions O(n)

Peek: Return the first element of the vector O(1)

Size: Return the size of the vector O(n)",9.0,13
4121,4121,5806,91ebe020e489f0682b9824bba92593f1328536973fcefa2088842b20b827aef8bdfb02c354fbd4b326e7989de48aea571427c17aa049b6dadee99c74f1c15bdb,"* Push()
We'd simply use the the push_back() and the worst case would be if we don't have enough space and we'd have to reallocate that would take O(n) then the best case would be if we have space the we just push Thing to the back of the list and that would take O(1) since vectors use pointer arithmetic
	* pop()
Use pop_back() from std::vector then the this would always take O(1)
	* peek()
This function should return the reference to the last item in the list should take O(1)
	* size()
We'd use size() from std::vector and this would always take O(n)",7.0,13
4122,4122,5807,0b4066304490dceaa89df857c52096e501a361b0158a4122fe0743ccedb637acfd51e379e86df6a8a4f667a87b6d33f81aa5b4a035dd7d71db1ee1c7171afd95,"For pushing items to the top of the function I would using the push_back() funiton, and the the time complexity would just be linear int the worst case but will use a constant time complexity in the best case senario 

For poping i would also make use of the pop_front() funiton which would also ultermately move everything to the front with one move, this would also use linear time complexity

For finding the peek i would the I would use the use the .back() function which would just give us the reference to the last element in the list this will just result in a constant time complexity

For finding the size of I would just use the .size() funiton since it will just return return a value it will use constant time complexity to execute",11.0,13
4123,4123,5809,8cfb9c3f85d9b6edb1f914f05f74928e81fe7cb4cefb95f1de4efb3fd1ac54a2356179dfe5b33b1cac09455e2960c015d866e1097ed5d7d20fbbdcb0d2aeee6d,"_Push:_

This would be implemented in the same way as the stack as it still adds to the item to the top of the ""pile"" thus in the best case it will be O(1) and in the worst case it will be O(n).

_Pop:_

This would be implemented by removing every item in the list one by one and adding them to an alternate stack/queue in that order to pop the first item in the list and then push all the items on the alternate queue back into the original queue. This would be done in O(n^2) time as you remove all items bar one and then push them back thus quadratic time.

_Peek:_

This would be implemented in the same way as the queue, removing all the items in the queue except the first item and adding them to an alternate queue and then you return a reference to the first/front item and add all the items back onto the queue. This will be (n^2) time as well.

Size:

This would be implemented the same way as a size function in a stack and thus would be O(1) time. ",2.0,13
4124,4124,5810,3dd0e6b0aa4ca279a9a8f781013cc1ffadd92a615d343d8f7162570e3cd2647c9fb452de2221fcafa1322a70dac1ad1ef68bd5efe79682df415f360b352ef94b,"Intialve a class of stack. The implement a void push_back, and a void pop_back function which will both be O(1). Then implement again peek a size functions within the class which will also be O(1) in their best case. ",2.0,13
4125,4125,5811,bd50a1f76e0acde64b2131110f2268f08aef333a162fed075d374337a58f0180c5f1efb88a7f6560e676d09d9ae71856da1ed18b029ff6c96af885a57d9fef75,"using a vector :

we are going to push at the back of the vector using the push_back() function which will take us linear time (O(n)) and that will be used as the top of the stack;

and since we are pushing at the back we are going to pop from the back following the rules of a stack using the pop_back() function which will take us linear time (O(n)).

and we are going to get the last data on the vector for the peek function using data.back() , for the size we are going to get the size of the vector using data.size() and both the functions will take constant time .",5.0,13
4126,4126,5812,c1e502cb9307976ed3c86bb3e1a2a0d1fad4d05b1ff3b6ca09a4a8992703680a55c9ae6e51c9417d756549fe340afbac12cdfcd3dbe4f6a560b6a171ce7f1eeb,"push: I would use the vector's push_back() function to implement this function with a Thing object as a parameter. The time complexity will be usually O(1) as the best case when there is space in the vector for more items and O(n) as the worst case when there isn't nough space and the vector has to reallocate space for new items.

pop: I would use a for loop to replace the first value with the second value and so on as the next value will be moved back in place of it's previous value. The time complexity will be O(n) since the bigger the vector the more items have to be moved over backwards.

Peek: I would just index the vector at 0 and attain the first value. The time complexity will be O(1) as this always takes constant time.

size: i would use the vectors size() function and the time complexity will be O(1) because vectors have a member variable that always keeps track of how many items are in the vector.",13.0,13
4127,4127,5813,8052ea5813981ce1b1dc18dcce8d4c10c33b769890ea3f35ecc1dc5a6465b4897efddc1a12c6d7a26b5d0da8ca3c779589f99331e5d2c411636cea22d157833a,"i could push thing value t at the back of queue, pop thing value t at the front, peek at the back and get size starting from the back.time complexity is 0(1) for push and pop and 0(n) for peek and size",2.0,13
4128,4128,5814,8fd97c5322558e2423003672fe174f30c080d208985516c4cd8749e1d3f072ac5736c633a74790122fa877f92436ac7777fc9cf9c36610a77bd1566b6903427e,"for push we would always add to the back of the vector and it will be O(1) in the best case and O(n) in worst, and on our pop function we would always remove our first item in the vector and it's O(n). Peek we always return the first element. our size function we find how many items are in the vector and return it. Both peek and size are O(1).",13.0,13
4129,4129,5815,eb636b71b69b444b76b68045ede7c5b96290b63dc94e90986ac7258b980a7f8df480d1b6926e41ac5186df7da647131dcbb111a84e28e5a68a37dc453c1f06bf,"PUSH: The complexity for _best case_ is O(1), when vector is empty. O(n) when the vector has items because each time a new vector has to be made to add to front. The push_front will be used to add to front.

POP: The complexity for the _best_ case when vector has one item or if the stack size is not _4 times_ the number of items in the stack. O(n) when stack size is 4 time the number of items in stack

PEEK: peek would be returning the first item in the list. This would take O(1)

SIZE: its returning size of the vector. This will take O(1) since it only requires the index of the last item +1",9.0,13
4130,4130,5816,1b24ef0d303f3078167a7dbca152a2c1d687ceab3654a2ae76bf73e5ee1cc0069be94db2fff74908c1492e9ab7afab08d7fd457a365a4c193c2adc5bcd9b850a,"i would push back into the vector at the back. This will take  constant time O(1).
when it comes to popping which is removing items from the front of the vector in the best case scenario this will take  ConstantO(1) time. in the worst cases scenario will be after removing the item at index 1 will have to move everything else to the left -1 of their original index.

for peek.the front of the stack will be the  back of the back of the vector.it will take constant time to return the index that's at the back because we can use operators such as the operator[] or the at.

The size will also take constant time as it's a built in function so we won't need to loop in the entire loop.",7.0,13
4131,4131,5817,fd6a36ea3be7fe00a0626c8ff80a591e0ee46b9eb9f16c4ccfb925e8237975ae584522b908d7f487d3fa4016ee5035673c870e0b6b78ebf935c75fa0905d0961,"Implementing Push: I would use a push_back() funtion which will push to the back of the vector which will be the top of my stack this will take O(1) for the best case and worst case O(n)

and the Pop: I would use a pop_back() function whcih will pop from the back of the vector which is the top of my stack and this will take O(1) for the best case and for the worst case O(n)

and the Peek: I would implement a function called Back which will return the item at the back of the vector which corresponds to the top of my stack this will always take O(1)

and lastly for the size: i would create a  function called size which will using  pointer arithmetic to get the size and return that; this will take always O(1)",9.0,13
4132,4132,5818,55fe3fe2f479a6880b0c712c4e8a68696125fae47531859339e76b32fd81a881527cd93fc43bbd4116f56991339ff706e490311026cb817361fafa6e47ec0b11,"* push

	* add item to back of vector
	* best case is O(1)
	* worst case is O(n) (if needs to resize)

	* pop

	* remove the first item
	* copy all items to the left(ie position 1 is now position 0, position 2 is 1,etc...)
	* best case is O(n)
	* worst case is O(n^2)

	* peek

	* return position 0
	* always going to be O(1)

	* size

	* return size
	* O(1)",13.0,13
4133,4133,5819,b62178f325a37f31c95fa1765add6431ffda3b6e9e137a6c1634820014c3bfc3f4c574a7130344e47d262896d038b700c7e7372470c7667fbf621506106a2a97,"push: adding an item to the size of the vector; usually O(1), worst case O(n)

pop: remove the first item: O(1);

peek: returning item at position 0, O(1)

size():return size of the vector, O(1)",7.0,13
4134,4134,5820,7c87322598f2ceacf4938051fa8e249fba61f740f1c131025859319c9334a0e7c5eed0d631406a69aaecd55c3154797379e9e557934a0c639e13848fc2a797db,Since a queue allows us to work easily to implement the push function I could just say push to the back and yo implement it would only take O(1) and to implement the pop and peek functions it would take O(1) as we only remove from the front and return a front reference.for the size function it would take O(n) as I would have to traverse through every element in order to acquire the size of the queue.,1.0,13
4135,4135,5821,9d9fbdb8f0b5a55cc81f40af01c24b37d17fe31db439c419f81b64ca34d8f4ebfcf1ed9c7ba472f3885693ca593e5565dfb6d3c7a7ecc8755427baec264e52b2,"To push to the back we could simply use the built-in push_back() function of the vector which adds the Thing to the back of the vector, since this just uses pointer arithmetic it would be O(1) time in the best case and O(n) in the worst case (when it has to reallocate).

Peeking at the front would also be simple, we could use the front() function of the vector which returns a reference to the first Thing in the vector, since it also just uses pointer arithmetic it would be O(1) time.

To pop at the front we would have to create our own function as the vector class does not support pop_front(). This would involve looping through and copying each Thing in the vector (after the first Thing) one place back, then popping the last Thing with pop_back() because it's a duplicate, due to this copying it would O(n) time usually and O(n^2) in the worst case (when it has to reallocate).

To get the size of the queue we could just call and return the vector's size() function, and since a variable is used to keep track of the size this would be done in O(1) time.",7.0,13
4136,4136,5822,8a8eb86cf56dd2444d2bc5441387c73e3fcbac4867da844d41e7ee67a78c9e8b163da9822047fef10101762a7abd4eba2ff040d29869420924f78a2c686ad858,"QUEUE -> FIFO

PUSH

this is a normal vector push back with complexity O(1) at best and O(n) at worst in the case where reallocation takes place

POP

Complicated as  you would need to reverse the vector and pop the back so the complexity is O(n)

PEEK:

this is the first item added and can be obtained through the first index. Complexity O(1).

SIZE:

this is the number of items in the vector i.e., the size of the vector. Complexity O(1)",11.0,13
4137,4137,5823,07076ad9a7e3813bce19a739ebedaab894d1a330269763e0925227d8822b601591c19afe0ea5ecf81637c9b73f442db6cacafab2329d262fef0fb68d97bef78a,"we can use push_front because we can only push to the back of vector

to pop a element in vector, we can traverse  the vector using a loop and remove the last element or use pop_back.

to find peek we can use a loop and traverse the vector and find last element of vector.

we can use ""vector name"".size() to find the number of elements in the vector.

the time is linear O(n)",7.0,13
4138,4138,5824,48452c6af5685c82851988d96add3ed11ed530ba837e28f21c3e92d7b83a44fbe9879abbcb6e1ae0256b1dc9b2ef98a34c294dacae561958335cfe0e83b08e8d,"pushing, popping and getting size happen on different ends by the principle of FIFO.

push - O(1)

pop - O(1)

size - O(1)",2.0,13
4139,4139,5825,999b8af04a99b1971783a730d1a109e30fdff2f88a1f40dc36731dceaa01148aef1c1f5d96b5999593020819ebc46f676235aa6d5dc12859b91750c9e8b5c9c4,"since memory of vector is contiguous when push is called ,I will only need to know the size of vector then use pointer arithmetic which is an instantaneous operation. the vector class has size() function which return size of vector every time push is call size will be incremented the time complexity of push is O(1)  but O(n) in worst case when space is not available and time complexity of size is O(1) .just having pointer to the first element in vector will increase functionality of peek.when peek function is called time complexity will be O(1). when pop is called given a vector of size n i will create a new vector copying n-1 items then decrement  size() thus the first item will be freed  which means time complexity of pop will be O(n) due to copies made.but when I'm wasting space the will be a need to reallocated and having an O(n^2).",4.0,13
4140,4140,5826,f64eaf53775ca019aa46e95d674f953f5fe42b8661af69f4cf932eb77a69c0b6057310158946905b9d5788a5b3a8acd5e3f0f489603023b3ef81fc676dabaddd,"push is to add from top of the stack with a O(n) in worst case and O(1) in best case.

pop is to remove from the top of the  with a O(n) in a worst case and O(1) in best case

peek is to return the top stack and its O(1) best case

size is to return the size of the stack and  its O(1) best case",7.0,13
4141,4141,5827,bee12730d57033f530e6d3af850b801527bbf28710ff5b08a5e590d280e30c6a0345b61d0e3b24cafaad1628aee3191406710ce83cd7009c586afaf78d031389,"Push:

 - I would implement something akin to a push front function that accepts a reference to the item been inserted

 - Because the function would have to loop through the vector, its complexity would be linear/O(n)

Pop:

- I would use the available vector::pop_back function

- The complexity would be constant/O(1)

Peek:

 - I would use the available vector::back function to return a reference to the last item in the vector

 - The complexity would be constant/O(1)

Size:

 - I would use the available vector::size function to return the number of elements

 - The complexity would be constant/O(1)",7.0,13
4142,4142,5828,0814448191d29da9008582aa1dc261271817cf4f70631f519f01177439d50267cb21e8d39c1f121e1aee03914798dbfab1836210758982742e26c801f01d7bc4,"create a vector of size n,

have two variables front and rear intialized to 0,front will be the index of first element

push o(1)

pop o(n)

peek o(n)

size o(1)",2.0,13
4143,4143,5829,d3ddf356f072bf43331098b8a43e33c8b3192b402decaa6c3b442e9385a8eff79ab7318fc38d8ae8da018a53bd14daa455a684126f1cf0ce97908dac2dc0af07,"Push in a queue

to push in a queue will take constant time , because we are always adding at the back , so as long as the back has space we can add ,but if there is no space in the back then thats linear time 0(n) for reallocation

that is by pushing back at the back of the vector

pop at the front 

will take linear time as we have to remove from the front and we shift everything to the left so that the vector will start at index 0

this is achieved by  poping front of the vector ",5.0,13
4144,4144,5830,e02b2e6799a632f8edf7a4522f9a996ef61735be79c062229a0e89a8ede6774052ec8736d48de69d3335b6ebe5ac154baf9a59c6f5866c7ad081372900ff0ff8,"First we would need to make all these 4 functions public. Then we can use the vector to push at front or at back, similarly we can  use the pop function to remove from front or back and both these functions would be constant time function 0(1). We can use the vector to iterate over the queue and so we can use the peek function which would be linear time 0(n). Similarly for the size function we would have to iterate over the queue and get the total size which would again be linear time 0(n).",4.0,13
4145,4145,5831,a837228a932a0a88d86d56984d3a65abcc9744de389dd1a09c0dbc6344b07254c5f44d2d0e035800fe07d8fd7ef535a3af313b16fa0ec5085dc57d2a491f0957,"implementing a back,peek and  function will have O(n) notation

however the pop and push function will have O(1) notation",1.0,13
4146,4146,5832,e669fcade771c8ac126f6aaaaaa9562b24a7e63cb2b8a26b67162e1919636fc9c8117e6d9c38b6dbe2b9896b1404543b4d1d48335aa3385388e129cb234e4996,"For push and pop, we create a tmp link that is pointing to the same value as the head link. We then check each of the links and check if they are equal to a nullpnt , if not we sequentially move to the next link. If it is , for push, we add another link and for pop we remove that link and set the previous one equal to the nullpnt. The time complexity of pop and push is O(n).

For peek , we search for the top value on the stack, thus the last value in the vector. Therefore, we also check each of the links and check if they are equal to a nullpnt, if not ,we sequentially move to the next link. If the link is the nullpnt, the value is the value we looking for. The time complexity is O(n).

Size function also works in the same way. A counter variable is created to count how many values before the nullpnt are there. The time complexity is also O(n).",4.0,13
4147,4147,5833,2a38888a8b80ad136312b78d25e48a8f2ffafd5c8eeba2c39a3cf4d0b1565a722030f9463fa977a5038fd88a16d989882eed3aeb8631f846fa1888531a07766e,"For push the first element to be inserted will be in the front of the list, the subsequent elements will be added after the first. The time complexity is O(1), in the worst case O(n). 

For pop the the first element is the first to be deleted, and the time complexity is O(1). ",2.0,13
4148,4148,5834,e23792b17279f93b3cce4dddca09079f761a6a0f2795c6c3c7434b417d9b72d4e94d0c740b318fb5b6d57338883455b8fe250e5759d4aa78bd8b7bd3bfed6a55,"I would keep the back of the vector as the front of the queue

push: add the element to the front of the vector, this will have a O(n) time complexity as we have to copy each item 1 space backwards and add the element to the front of the vector. If  the vector is already full, we make it such that when we are increasing the size of the vector we copy each element 1 space backwards therefore we will have an empty spot in the front of the vector thus keeping the time complexity to O(n).

pop: remove the element from the back of the vector, this will have a O(1) time complexity for the best case and O(n) for the worst case if we have to decrease the size of the vector.

peek: return the value from the front of the vector, this will have a O(1) time complexity as we can fetch any item at constant time using pointer arithmetic .

size: return the size of the vector, this will have a O(1) time complexity as the vector keeps track of how many items are in the vector.",13.0,13
4149,4149,5835,48b61851d938b41ee8c845154660df999994e48772e63eb0fc08241d1da91dd060085f370b13a4f968cd076d5b498fb619542e3786a80328ae705382da43a829,"push(): The queue allows us to push items to the back of the list and because we are using a vector we always operate at the back of our vector. In order to push_back in the best case there is enough space and the time complexity is constant O(1). In the worst case, there is not enough space and we have to reallocate and copy n items so the time complexity is linear O(n). 

pop(): Because we always operate at the back of the vector, in order to pop_front, we will need to shift every item one space to the right and then add the new item at the front. In the best case there is enough space at the back of the vector and the time complexity is linear O(n). In the worst case, there is not enough space at the back of the vector and so we need to copy all the items in a new bigger vector and add the new item and the time complexity is still linear O(n).

peek(): The top of the vector is the last item at the back and so getting a reference to this item will take constant time O(1).

size(): Constant time O(1)",11.0,13
4150,4150,5836,59ba65c517c334e25d3ae45ca0766a06b5a36061abfca1dd80f0f9e00eca00b8fc96224e4fcd721b2a66146a086c07a1cca9cf5028a8fc5d88a04890a96fe5a7,"To pop, one would need to remove the first item of the vector. The time complexity would be O(1).

To push, one would need to loop through the vector and add, after the last item. The time complexity would be O(n), where n is the size of the vector.

To peek, we would need to return the first item of the vector, where the time complexity is O(1).

To return the size of the queue, we would need to loop through the vector, while counting the number of items passed. Time complexity is O(n).",5.0,13
4151,4151,5837,0874df3f65542027273a16915ace9ed9ec51ca5d508f5bc4a25d6e8fb6352a668e9f762cc0692fb52fe5d216cf363f7813d3abecb5d910688f89eb0977699ad2,"pop O(1)

push O(1) or O(n) - worst case

peek-O(1)

size 0(n)",4.0,13
4152,4152,5838,072df8e3c1de059673d8b782c554cf64da21277fb2ba12d1d8f4ab73cd1269538ca3968b89e11ecaa84835030161cc68c0efae276a64b66f06c4f0c8a0d2ada3,"because we are trying to access the front of the list we will have to transverse through the entire list so it will take a linear O(n) amount of time to do push, pop and front.",4.0,13
4153,4153,5839,112623e30928da280b124065b33eb8360f6fe49f45f9b97cc7a540f6e550a5152dd7bbbd6ba167e88c839362c8fd2148a3e881c83493d58d2e9fd2216c604c8a,"To add to the queue I would use push back. To remove from the front of the queue, I would first erase and then shift all the items to the left. This takes O(n). In the past case pushing to the front takes O(1) and O(n) in the worst case when reallocation is needed. Peek and size have a time complexity of O(1). The advantage if using a vector is that it provides cache, however the time complexity increases as n grows.",11.0,13
4154,4154,5840,2c57052c92283203acd8d1c12f3f24bff9fcc6fc06d4ccaf21f6b88069300e298296f4f82426d3a1b2f0d2ff83e57ea1826f7e8e04b0393de99a4b442ad3afab,"Push back- create a link curr that will point to head, a new link tmp that will contain a thing for instance t. Create an if statement that will initialize head to be tmp, if that's not the case it must traverse untill curr points to the last thing on the list, the initialize curr->next to be tmp.

The time complexity is linear time O(n).

Size- create a link that will point to head, initialize a variable of an integer n to zero, traverse through the vector and increase n by one till the last thing in the list then return n at the end.

Pop front-  create a link that will point to head which is tmp, initialize head to the next thing in the list then delete tmp.",1.0,13
4155,4155,5841,a51b1137941b4a2c9fd6d66da41292b1d5da2b0315b3c4cbaa7f507deed0fbfe1d51f7372760847ad411ee0d78ff9de354c3d1a9bb27433af4b5f7b732027fa9,"To push to and pop from the back would have constant complexity O(1).

To push and pop from the front would have linear complexity O(n), unless (in the case of popping) you were willing to tolerate a memory leak by merely shifting your pointer one Thing-sized address along, in which case popping would take constant time O(1).

Peek and size would always have constant time complexity O(1).",7.0,13
4156,4156,5842,2bed72130045c9fb6315517a1cd0576fdbc71ee8714b8107f6ddc3d51fbc170cd1fbdf2110982b17b6e61a87f656eb89a47f0eef9a898bfa08b1c56801ac6236,"Push-I would use push_back to add the thing and then iterate the vector while interchanging the pushed back thing with thing before it,this will take O(n**2).

Pop-I would use the pop_front function.it will take O(n)

Peek-I would use the front function.it will take O(n)

Size-I would use the size function or iterate through the vector up until the end while incrementing my counter.it will take O(n)",7.0,13
4157,4157,5843,c1f6abfd4fc5318b969d8b42d7f10e1364425c616a8b69c8f8594b69d2c7a7743a83790314faf11cc3b382f3287fb00f531687f09a9146a00ce2dbe39062eeff,"push = to implement this function you would have to push t to the top of the vector based stack. Best: O(1), Worst: O(n)

pop = pop from the top of the vector based stack. Best: O(1), Worst O(n).

peek = return a reference to the top item in the stack. O(n)

size = return the numbers of items stored in the stack. O(1).",7.0,13
4158,4158,5844,2f496bb2a99de18fa436df0deced0620c47daee5ce37cf49cf6b3200c20eb84e5a9b7a47850d29ff143886bc9932f54f86b6a1101a1d0f70874e22b40b657cec,"push: adds new items at the top of the stack and has the best case (O(1)) when there is extra space allocated and the worst case (O(n)) when there needs to be reallocation. 
pop: removes the top element of the stack. Also has the best case when the item is right on top,no extra space(n_items = n_allocated) and the worst case when n_items < n_allocated.

peek: retruns the top element in the stack and has a constant time complexity. there is no worst or best case.

size: returns the count of elements in the stack and has a constant time complexity",8.0,13
4159,4159,5845,939ec9a57a50490db2733608917f50113db66f29232d7ede4b3f765d85522c6883d672d7c5bad821ddeab74dbf066c3294635d07979c4557288fa30e0ff3d929,I would implement push by pushing back which would be O(n).I would implement pop by popping to the front which would be O(1). I would peek by returning to the front which would be O(1). I would implement size by returning size which would be O(1) ,7.0,13
4160,4160,5846,11033a17d67159be6a6bbc8378c0392c95d06eb759a822fa4a4ab3fcd33a9e9c6b4e8e1a2ffedc295aecb757927d81558a966188674240b280a874a24f0debc2,"Push- to implement this function you would have to check the size of the vector and if there isn't space then you would move the data to a new vector that is double the size of the original. Then you would add the item to the back of the vector. worst case O(n) and best case O(1)

Pop- to implement this function you would decrease the allocated size of the vector by one.O(1)

Peek- to implement this function you would reference the last item of the vector plus 1.O(1)

Size- to implement this function you would traverse the vector whilst incrementing a counter variable and then return the variable.O(n)",7.0,13
4161,4161,5847,29fcf57bccb37a2f0d949733d7028b65c0e2df19a9ddbd0c547e57467d84c825defbaf635dea276a63c3d3e85a6fb4f7a84d6da08661ca46728f222c62700315,"The functions that will be coded are push_back(), pop_front() , size(), peek(). The push_back() function will add an item to the back of the queue, the pop_front() function will remove an item from the front of the queue, the size() function will return the number of items in the queue, and the peek() function will return a reference of the item in the queue. The complexity of the push_back() and pop_front() functions will have the best case being constant (O(1)) and worst case being linear (O(n)) and the size() and peek() functions will always remain constant (O(1)).",7.0,13
4162,4162,5848,20effcbf64917de69f0f441958ac819d52ad486a65f959444a5ddd14ca83a40e581709b6bb9eae431ca2dd02ce933a201bc9b7e43298585d0858d76601344ce0,"The push function would add an item to the back or front of the vector as well as the queue and in the best case will be constant and in the worst case it would be linear
The pop function would remove from the top of the list or back of the list and this in the best case will be constant and in the worst case would be linear 

The peek which would be used to get the reference of the first item would remain constant as well as the size which will also remain constant. ",9.0,13
4163,4163,5849,3e664d9b290450a26a44195a29971d5e7c7434afb68523c4038cc69f5c1285f4c94e2b62945fc7bf5800f3a5190a2876a925f82823b3806d9c640fa0e0d73571,"* to push an item wich is enqueue wich adds the item to the back, we would need to traverse through the vector until we reach the back to add the item wich would take linear O(n) amount of work.

	* poppig is dequeue, we would simply remove the item from the top without traverse through the vector popping would take constant O(1) time.
	* peek would return the item or reference to the item in the front of the list which would take constant O(1) time.
	* The size operator is contained in the vector and would simply return the size of the queue in constant O(1) time.",7.0,13
4164,4164,5850,d7ea0f2a38310b663df581928807c739d1135118819d5b7623733f4d054b7f50d32672538781df6012ffae2751400911c7d428efb70c05b3c3719b6aef5da475,"Since a queue is a First in first out. When we push we will push like how we usually do using a vector, why traversing and adding to an available space at the end of the vector ( time complexity O(1)) and in the worst case scenario where there isn't enough space we have to create a new queue and copy everything across , this will cost linear time O(n). When we pop, we will always remove the first element in the queue, which will be at position 0, this will cost linear time O(n) always because once we have popped from the front, we have to move the rest of the elements in the queue one position up to fill up the empty space at position 0.  When we 'peek' will be checking what will be popped first, this will always take constant time O(n) because we will be returning whatever is at position 0. In order to get the size of the queue we can use the built in function of size for vectors.",9.0,13
4165,4165,5851,21f09107df149216c5f40e2d6eaefa443c1ac6ce9ddec594661383f2e53455e2769bfb1bb81bee158e80bc0b01db2da739108bc4386c15bb286ac35afa1a5409,"In implementing a queue, by defining a class queue and using a vector as the underlying container, the functions push, pop, peek, and size are used. To implement push, there is a best case and a worst case. The best case is that there is space at the back of the vector and we simply add the new value to the next block in memory O(1). The worst case is that there is no space and memory needs to be reallocated, copied and the old buffer must be freed O(n). To implement the pop function, you simply remove the item in front and move over all the items one block forward in the vector O(n). To implement peek, simply return the value of the item in the first block of the vector O(1). To implement size, return the number of items in the vector O(1).",13.0,13
4166,4166,5852,3068685c76e4b2c329c64b4a981abf59ea0591abc5a7b11e62ce43c420b142b81f90f5e9d316d436b64235d5ad493fb04d7af76ae8a7eac84bd371103293e146,"Create the Queue class.

	* push - we use std::vector::push_back() which has time complexity of O(1)
	* size - we use std::vector::size() which has time complexity of O(1)
	* peek - we use std::vector::top() which has time complexity of O(1)
	* pop - we need to implement our own pop_front() function by copying all elements except the first to a new vector; time complexity of O(n)",9.0,13
4167,4167,5853,0a1eb6f30606d1f92d934eb03ca9d55d90d2ab3f505cdcb3ba02589cc6678998e8754ce7335373d6c01684ffed4a20fad8a976d2479c3f801a51d1c2b0d4ed50,"Since the data storage type is a vector, it already has built in functions to enable us to push and pop either at the front or the back of the vector . To do the push function ,  all you would need to do is use the built in push_back() function The time complexity would be O(1) in the best case and O(n) in the worst case for this. For pop however ,  we would need to create a function that removes the 1st item of the vector and moves each item 1 back ,  and would also reallocate memory in the same manner of a pop_back () function . The time Complexity for this would be O(1) in the best case but O(n) in the worst case. The peek would be used withe the built in front() function and would take O(1) Time. and the same applies fro the size function ,  use the built in size() function with a time complexity of this is O(1)",13.0,13
4168,4168,5854,eee70f1328b3cdb194af70a4822cc7feab4c1f2f6aa8f1c3d195e1593437b3077b36a3a63265ad79d2faed3c1dc2010c5f323409bdd6e1b2e860317721256dce,"The push will be used to insert any element at the top of the stack.

O(1)

The pop is used to remove any element from the top of the stack.

O(1)

Peek is used to fetch or retrieve the first element in the stack.

O(1)

The size will be used to tell us the current size of the stack.

O(1)",5.0,13
4169,4169,5855,f8ab0f6e15e6bf9e99acd11cfb6b5455d3c0019e87064465e59d88ccaf25c640a5ce1b900a6011a9e3fa052e11195ca6da9faf3eac510a5a07330facf6daee23,"To push an item to the back of the queue, we'd simply use the push_back operator, which will always take constant time[O(1)].

To pop an item at the front , we can use erase(0), this also takes O(1) time.

Returning the the front item(peek) , we can use vector_name.front(); , this also takes O(1) time.

To get the size, we can use the size() operator, which takes constant time as well[O(1)].",9.0,13
4170,4170,5856,276b4e11850dbed5adc6f0fd4249cf0b5f1cdc0a0dfd3d76321298301426fddeaa12e60021bdff5fc27802e2537ea3a2e891dc9c51166641bf68a7d7906d00b7,"->i would use the function push_back to add at the back of the queue , takes O(n) complexity due to iteration

->my peek would be the last element in , i could use an iterator to get to it or just use vector[vector.size()] , O(n) in worst case and O(1) in best case ( when the vector consist of only one element ) 

->i would copy the vector excluding its first element and then deleting the old one  , would take O(n) complexity due to copying elements one by one 

-> the size of the queue would be the size of the vector , found using the size function",4.0,13
4171,4171,5857,364ce0d9b555b7fbcffabb10a359d7f7e38b464e534b9a29447029ab1ebdabfad20a4341f04f3a61405ee0dc6245a44f1b6329878e01aafc141ca4d5cdb571fc,"To pop you would use .pop_back() and the last thing in the vector would be removed...the best case time complexity for pop_back() would be O(1) as it would take a constant amount of time to remove the last item if the size of the vector is greater than 1/4 and O(n) for the worst case as it would take a linear amount of time to copy the items to a much smaller vector

To push you would use  .push_back() and the thing would be the last thing in the vector. The best case time complexity for this function is O(1) if the memory buffer is not full and O(n) amount of time in the worst case if the memory buffer is full and we have to copy the items in the vector to another larger vector

To peak We'd use the .back() iterator to retrieve the last thing in the vector and this would take O(1) 

To find the size we'd use the .size() function and this would take O(n) amounts of time",5.0,13
4172,4172,5858,0ffad2820b9adf1fbb6d7105f83a5954e33ce5d91444ff2b6251d15d1a8c5a988e64634ca1a4f0e01e237f0fdb8290b82c533e1fa1a822b32c02e6052c618e98,"PUSH - Add an item to the back of the queue

            O(1) - Constant Time

POP - Remove an item from the back of the queue

           O(1) - Constant Time

PEEK - Return a reference to the top item

           O(1) - Constant Time

SIZE - Return the number of items in the queue (transverse)

          O(n) - Linear Time

           ",4.0,13
4173,4173,5859,f682ecdc1752e81b56fe41b112e9132a1831f14cd9ba0ec72eae2c8c098b94a2736f903a3211d58aeb928498913e4972f6d3f995b03aff3dca7903b620bfdd1e,"push -if the queue is not full , we use the modulus operator to advance the back of the queue(the last index) and we add a value at the advanced index.

         -time complexity is O(1)

pop - if the queue is not empty, we delete the item at the front and then use the modulus operator to advance the queue at the front in order to update our queue

       -O(1)

peek-we return the value at the front index O(1)

size-return the number of items in the queue O(n)",7.0,13
4174,4174,5860,1a588e676388eab699476b49a00fa1013110acdcf89dcc5a2ff2c6e7b4d1cc5fff03a1daa5e3f8069ad9a846f88030beb884f390c11da3f442ee0a6ebc1a9307,"For the push function, since we push to the back for queues, we would use the push front function from the vector class, but since we are not adding from the top but rather the bottom we would have to loop through the queue to get to the bottom, giving it a linear time complexity O(n).  

For the pop function, it would be the same as a stack using the normal pop back function from the vector class with a constant time complexity O(1) if there is enough memory or linear time O(n) if we need to allocate more space for the vector.

For the size function, it would also be the same as a stack since we can use a ready-made size function from the vector class which always uses constant time O(n).

For the peek function, is also the same as a stack since we return a reference to the top of the queue by using the back function from the vector class and uses constant time O(1)",7.0,13
4175,4175,5861,cface2ad53f19c6af9cf068c6ec714a5c87946703ffbbfbb9bed0b96fac38d6afbade6379b2026afdb4cfd3532727e46f1e78cef262470d7e8eac2090f8ff726,"Push - Simply use the push_back() function. In the worst case scenairo we'd need to allocate new space and copy everything so in the worst case it would be O(n) and in the best it would O(1) as we JUST at the back of a vector.

Pop - Simply use the pop_back() function. O(1) and worst case O(n)

Peek - use back(). O(1)

Size - use size function O(1)",5.0,13
4176,4176,5862,412b107ec0ff412753968aa6ffdad40da21fbfd59417aac428d07f6c064389cc24911eb533cf92e901bf7845b76400d7d3831fd1347350b39d220d9c58729d2b,"I would implement the vector using the back of the vector as the top of my stack making the run time for the push to be constant in the best case and linear in the worst case so is the same as pop function.The top function doesn't have the worst or the best case so is the size,they only use O(1) constant time. ",4.0,13
4177,4177,5863,c76ad062cb3f9ba2556bec1587c1d89b089f2df63d9bed184a50eead5884d030c988356231ec2465bf2dfe9d6ac011b44586a721987fbdacc7384e0d7bc1bf14,"I would implement push using push_back and the complexity would usually be O(1) but O(n) in the worst case scenario.

I would implement pop using pop_front() and the complexity would usually be O(1) but O(n) in the worst case scenario.

I would implement peek by using front() and the complexity will always be O(1).

I would implement size by using size() and the complexity will always be O(n).",11.0,13
4178,4178,5864,8498970fc897a847cb08416ff377f1fef48bec60ecb47ecc86ba0d40abc666899852250e00e887a707bf5de87564f205ddbe85abfd397367947073bde3e3789d,"Push function: I would make use of the vector push_back() function, to add an item to the back of the queue. The best case scenario would be having a O(1) time complexity and worst 

Pop function: As a queue makes use of FIFO principle, i would make use of the vector erase and front functions to access and delete the first item in the queue. This would make use of O(1) time complexity but because we gonna have to copy and basically shift all the items forward, we make use of O(n) time complexity.

Peek function: I would make use the vector front() function to access the corresponding queue item, which would give me O(1) time complexity.

Size function: I would make use of the vector size() function, which would give me a O(1) time complexity.",13.0,13
4179,4179,5865,90a8f27cfb71d61b9c73a7a8ab33730e3ebc85bfa97c54d9b613ce87b305b9e1aa432bcfbae1c2c5d2035b82671180a8d7f60a46fa0262145d5fd6b791318ce7,"Assuming that there would be a roughly equal amount of people joining the queue as leaving it, the front of vector (front of the queue) would be the bottom of the stack. This means that pushing to the back would mostly comprise of O(1) time as the back of the queue is at the top of the stack, unless a reallocation of the vector is needed for more space (more lines in the queue available), in which case it would be O(n) as it would traverse every element of the queue. Popping would always comprise of O(n) time as you would always have to reallocate the vector to avoid removing from the bottom of the stack. Peaking and size would both be O(1) time due to pointer arithmetic eliminating the need to traverse every element of the vector.",5.0,13
4180,4180,5866,a24d4454b3c0f0611764d00de2a1119612fa4ae5c81fcdcf3800d4c6304de97c1896fb4640ae9520917c1bfdc4dabf12f730cd0013b9af7ab3a73969db3c7eea,"PUSH() - COMPLEXITY O(N)

Add a new Thing to the back of the vector, this would require reallocation in most cases and hence is linear.

POP() - COMPLEXITY O(1)

Remove a Thing from the top of the queue which is the first accessible (at the top) hence only constant time

PEEK() - COMPLEXITY O(1)

Return the Thing at the top of the queue which is the first accessible (at the top) hence only constant time

SIZE() - COMPLEXITY O(N)

Cycle through the vector and return the number of Things in it, this will be linear as all (n amount) elements must be accounted for.",7.0,13
4181,4181,5867,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"push will be implemented by pushing the value back. The time complexity will be constant as a fixed set of operations are required to add an element at the back
pop will be implemented by popping(removing) an element from the  back. The time complexity will be constant as a fixed set of operations are required to remove an element.

peeking by returning the end value of the vector. The time complexity will be constant as a fixed set of operations are required to return the last element.",1.0,13
4182,4182,5868,f76d34739c22495666539e328b829579ffb8d2806837813ff647c9a67384130ec26d74d58bb855836384f12b1b3b03f93c1062fce50fa1b459dbac86affbee20,You would,0.0,13
4183,4183,5869,8b711f86a0e0fd2c39d5f02ba2888612f603b1e29ac872778bb22eb91072c41a1a4c3f396ac1783e4ea49d806b40a998dee128cf46fea841c4d6fa80f6f2360e,"for the push function we can simply use the push_back() function from the vector class

for pop we can use the pop_back() function

for peek we can use .front() function

size we can use the .size() function",4.0,13
4184,4184,5870,3d5672708313ecdecf3f1bac84303e47d2cb39b8840c7477b8533d1e068614b468fd7d22ee29e9082419dadb2d36cb98607131a6fdfff05e1696dee4c36a9722,"I would use a vector declare a new vector to pop a the  front. Then iterate over the old vector to add  the items to the new vector. The complexity would be O(n2).

The complexity of peep() would be O(1). I would return the first items.",0.0,13
4185,4185,5871,3ea55861b5c8eafb81b8565f1d54cc453a6c146015319e65651c96131a93fe003ed97c4b0e5ead0032066879ea3f910a9115040fa5bb190fe1c4bece13c4f763,"Pushing an item into vector Thing will take constant time, O(1). However to do the peek and pop operations, would require traversing to the front of the vector. This means that the time it will take to do these operations is O(n). The peek function will reveal the first item in the queue (this being the first item in vector Thing).",1.0,13
4186,4186,5872,86a089b08f86e9c1d63b469ed69474a00b3c8a302414b59395dac01ecff0bf909a9721c007531f0f7d3273bab8151790358055f69bbfd852502b400b0f09160c,"Push-function: takes constant time O(1), takes O(n) if we have to reallocate to different memory. 

Pop-function: takes O(n) always because we have to shift every item down by 1 and reallocate when quarter of memory is reached.

Peek-function: takes O(1) always 

Size-function: takes O(1) always",9.0,13
4187,4187,5873,dd4d3f7f0edeb1ac41639c249d21094a6b301b7b08a2b59f88a3c56108d3780e80f6d45ac6aad546dd8e534b771a87a6c21d9fd70855e1599b2fe31c102d2f10,"pop function->for every item that we pop, we will have to keep shifting the rest of the items down by one and if we get to less than a quarter of the storage then we reallocate to old memory

peek function-> a constant time will be taken to get to the top item everytime

push function->for every item we insert , we would have to keep shifting the rest of the items in the vector up by one and if we get t over half of the allocated storage , then we reallocate to new memory    ",2.0,13
4188,4188,5874,86eb6a509a4b81bb5d0775617d6b551b5529a8196aa8cfd54e1d4c97046fcb8692ee1866ca18888be1695e57bab3f84e888b219e99049227e002908717268d42,The deque vector will have a push function which will be implemented by the vector push back function that will add elements at the back.It will have  a pop function that will pop at the front of  the vector which will be implemented by a pop front.It  will a have a peek function which peek at the front using the vector peek function.it complexity in popping is always O(n) but when it comes to push it will be O(1),2.0,13
4189,4189,5875,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"Similar to the stack.

The push function would be used to insert a new item(enqueue) - for this we would have to increase the back index- this would require a linear complexity O(1)

The pop function would be used to remove(dequeue and item) - for this we would have to increase the front index - this would require a linear complexity O(1)

The peek and size functions will have a time complexity of O(n) as they would go through all items in the queue",0.0,13
4190,4190,5876,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"Similar to the stack.

The push function would be used to insert a new item(enqueue) - for this we would have to increase the back index- this would require a linear complexity O(1)

The pop function would be used to remove(dequeue and item) - for this we would have to increase the front index - this would require a linear complexity O(1)

The peek and size functions will have a time complexity of O(n) as they would go through all items in the queue",5.0,13
4191,4191,5877,2dc8bdb77e3c7ca65a7004fc81d01e201b72cc647f001393bf944c06617e5c35dc6d00cb13c94a98ad4a2b0a5135ab7e178732724d9ed1cd93c84c2d08c50e63,"We implement push we are using the push back vector function which adds an element at the back. For Pop we remove the first element in the queue and for peek we only return the value in the first element. The size would be the length of the vector. For time complexity, size and push are both linear time which is O(n). The peek and pop function are both in constant time O(1). ",4.0,13
4192,4192,5878,e297ac13d644c28497e53e0845b865aca91f53637da30cace639c33479dad1c99be8abd444014be886b73f635741e9cc8d11a7d33228fb4866fbadfc7725d88c,"To push an item at the back I would use a push back function and it is usually O(1) but in the worst case, it is O(n) because a vector has to copy all of its items if there is not enough space.

To pop an item at the front I would use a pop front function and it is O(n) because it copies all the items to the (n-1) index.

To peek I would use a front function that would return a reference of the item in the front and it is O(1).

To check the size I would use the size function that would return the number of items in the vector and it is O(1) because the vector stores the number of items. ",13.0,13
4193,4193,5879,7aa4a41956fb10b2ea3a02d2d85c1eec912704226ca5710248e26fa3e0fa199d5048abcac9423a11d00a49ffe75bdd51e2b3cd752d5f6899af51dc4b580afed1,"PUSH: I would use the push_back() function where we allocate double the space if needed (n_items = n_allocated) to push the item to the back of the queue. In the BEST CASE this will take O(1) where we don't have to reallocate any space, and O(N) in the WORST CASE when we do have to reallocate more space. 

POP: I would have to create a pop_front function where I would have to copy all the elements starting from index 1, to index - 1. This will remove the item at index 0 and I would then use the pop_back() function to ensure that the size of the vector is correct. This will take O(N) in time as we have to make n copies. 

PEEK: I would use the front() function which returns a reference to the first item in the vector. This will take O(1) in time.

SIZE: I would use the size() function, which will take O(1) in time as it returns n_items in the vector. ",11.0,13
4194,4194,5880,188f5f32ff22cc30082222ed760e5fe1e0a340d9ae7ecfafe10b384746f7f9c7803d064927e2b5ebaba803119e7d5eafdd11883d383dd0d5a80b8dfe524c593e,Using a vector to implement queue using push back would take us constant time O(1) in the best case scenario because we are only adding to the back of vector we do not have to reallocate space in memory and copy items on to the new allocated memory but in this case it will take us linear amount of time O(n) which is the worst case scenario .When popping at the front of the queue we have remove the first item of the vector and that would take us linear amount of time O(n) since we have shift every item in the vector to the left whenever we are popping at the front.When we want the value of the first item in the queue we have to return the value at the 0 index of the vector and this would take us constant time O(1) to complete.Finding the size of the vector will always take us constant time O(1) since we are only returning n items.,13.0,13
4195,4195,5881,385c7b29eec3366a404f1d7e1159d0447aefec67a3c8b61a32481883579eeb6ab7ee9fa654afbb7d3b9a4b7a30f0a2b32be3cbd9d9a3dfbfe943be567e01c394,"push- add value to the top of the stack(O(n))

pop- remove the item from the top of the stack(O(1))

peek - returns the reference of the top item without removing it

size - returns the number of items in a stack",2.0,13
4196,4196,5882,8d5ceb816f2781032ee62700b4d8e0c49eadb89db294dfede287a0eaeacf6b8016c744cd4dfe71d03f0f6caf776956147ca479b489362862217860010178b882,To push back elements we must create that function which is queue()  (its time complexity will be O(n) and to remove elements we create a function dequeue() and its time complexity is also O(n).To get the top element in queue we can use back() function which its time complexity is O(1).To get the size and find if a vector is empty we can use isEmpty() and size() and their time complexity is O(1).,7.0,13
4197,4197,5883,e06c3717f5eff40cf06c551e6ebf1004bb478bf8fc38ebcba99f54530677cde6de5ea93590e51ef3d1e09f18ed2aa22502c287548e3398f50b4cf8f8e940073d,"Size would be identical as it deals with the size of the queue not the position (Time complexity would still be O(1)). With the push back function it would be the same as we still push to the back as we do in a stack(Time complexity would be O(1) in best case and O(n) in worst case. However for a peek we will just return a reference to the data at the front as opposed to the back using return data.front()(Time complexity of O(1) as usual). For the pop function, we would need to pop_front() then shift all remaining vectors one space forward so that there is no missing data at the front of the queue. This time complexion would be O(n)",13.0,13
4198,4198,5884,df4be51196b13a9d9df6ef77eee120b801ef4ba7a8945fcd04077415ae29d58c8d1e0814291c20adeb94f43f2f99c6c2290c6dde5a70ac85841035ecc662212f,"To PUSH, the best case would simply be add a the new element to the back of the queue and this would be in constant time (O(1)). The worst case would be that there is not enough allocated space to add a new element and so n copies would have to be made into larger space in memory, making the complexity linear (O(n)).

To POP, the best case would simply be to remove the element from the front of the queue without wasting space and this would be in constant time (O(1)). The worst case would be that removing an element from the front would be a waste of space and so we'd need to reallocate the elements to a smaller space in memory making n-1 copies and making the complexity linear (O(n)).

To PEEK, the element at the front of the queue would be returned and this will always take a constant amount of time, O(1), no matter how big n is.

SIZE simply returns the number of elements and this is always in constant time, O(1).",11.0,13
4199,4199,5885,de345146608f48652cf9ec333ad07816bb0cf99089477ca7af207bce7f9f2c81b03f0e317efccc60f220182480d765ee6b6291c08b7723e7e91dd8402a584cdd,"To push to the back we would have to loop to the end of the queue before being able to add a new item, because this is a linear data structure, once at the end of the of the queue we add another item to the vector, making the complexity O(n)

To peek we would just return a reference to the first item in the vector, complexity would be O(1)

With pop you would just delete the first item in the vector, which is O(1) but to reduce memory usage you'd have to move all the items in the vector forward one which is O(n)

With size you would loop to the end of the vector counting each item in the list making the time O(n)",2.0,13
4200,4200,5886,7c7ea0f0ba70a5ea36a02ae9d7f97eb067c3d269f5589f4e06abe536b27c016f062f66e013c160a950a6482d28c9fd24dacd097df0afb924b649425eca6be261,"I would implement the push function with .push_back() and this would take O(1) in the best case and O(n) in the worst case.
I would implement the pop function using .pop_front() and it would take O(1) in the best case and O(n) in the worst case.

I would implement peek using .front() and it would take O(1) 

I would implement size using .size() and it would take O(1) ",11.0,13
4201,4201,5887,ba6cb46aa6ff6581fcd2828d6944742916cd44c20dbee87513cab04b763159ab5e8fcc20c0eaa029b5cead3d4e1911b67590f3a4b4a64f4e9fa942648249fc12,"* I would use push_back(Thing t) to push into the vector
	* I would use pop_front to pop since it only pops at the front
	* I would use front() to peek
	* it would take O(1) for the best-case scenario to push_back(), provided there is space and O(n) for the worst-case scenario if there's no space
	* peek would take O(1)
	* pop_front would take O(n) ",7.0,13
4202,4202,5888,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,push_back would push the thing to the back by traversing along the queue in o(n) complexity the pop would pop the thing at the top of the queue in O(1) while the peek is O(1) and the size function is O(n) as it will have to traverse along the queue ad count each element,2.0,13
4203,4203,5889,e8ac13437ca4eb4696e3ef433ae3842afba862c0118c6894733767a015023753193111e7d4c262c3227484acd644f4e441faf59e7cd3f61df893fbe34d31e198,For the push implementation ,0.0,13
4204,4204,5890,d10eb2653552348dd29e31d9127ca9b9ab3966f67dcfba3fbaef7bc1fba74c3549309defc8e00e457f7427150a3162c0ca17e3f3d6529fa8df4aa4e4195dbeec,"We could use the push_back() function to add an item to the queue which would take O(1) time
We could use the pop_front() function to remove an item from the queue which would take O(n) time
We could use the at() function to check which item is at the front of the queue which would take O(1) time
We could use the size() function to determine the size of the queue which would take O(1) time",9.0,13
4205,4205,5891,805e6508996d13ddf1a18b1d2e18c5a73d82b749916487ddfd386d326e8ba2b06a4521a365c23ea00b66ba06fb5efe331adbdc0f46e49478cb1d6923fb8a6c24,"with the queue well the push function will push to the front  of the queue

and the pop function will pop at the front of the queue

peek will be the front of the queue

and the size will look the same as that of the stack will be looking for the number of the items in the queue",1.0,13
4206,4206,5892,9d599f5b4528664877cde67e20618306dd9ba2d042eff74f086d6094f809424f26b3522b41500c22020384b725682a3a9de08fa52bd56f223acd18ce507d7fd6,"1) push - firstly you need to have checked vector size, if there is not enough space then move the data items to another vector twice                  the original size. Then you can implement this function 

             - secondly  proceed to add the data item to the back of the vector ( with best case being O(1) and worse case                                       being O(n) ) 

2) pop  -  reduce the allocated size of the vector (O(1)) by one to implement this function

3) peek -  reference the last item in the vector (O(1)) plus one to implement this function 

4) size  - traverse the vector(O(n)) with a counter that is an incrementing variable and then return the variable  ",4.0,13
4207,4207,5893,89daf5e5dd9d5cd464a1dba203796d2fcea5b46dd29cb10e72e0dd7e72373ac4fd8e96b5e3d9813a2ed44c552171318e265b869630b10e2e2b1c3ee4cc7320d3,"use the ""push_back"" function, with a time complexity of O(1) in the best case and O(n) in the worst case.

use the ""pop_back"" function, with a time complexity of O(1) in the best case and O(n) in the worst case.

use the ""back"" function to return the latest value, with a time complexity of O(1)

use the ""size"" function to return the size, with a time complexity of O(1)",7.0,13
4208,4208,5894,a300869c4f32047b23ac68a02d99d6a69e15fcc6cb6903bc4e640c72bf256b08b631e89f75d7f7263574f4383932390c2f4b98297d3a8bfdd9da2320bf30b053,"When using a vector as storage it already has push_back and pop_back features therefore push_back will be done in O(1) time

 A vector also has a front element access therefore peek could be done in O(1) time.

to pop at the front however, we would need to reverse iterate the vector, copy this vector, pop_back on the vector, reverse iterate it again and set the copy = to the original and delete the original, this will take O(n) time.

size is already a vector function and would be done in O(1) time.",7.0,13
4209,4209,5895,74d9bc92412f8c3ff2851eb60d7164b5df173c9c4dc214351b20de54e473afd02c6de0a58df8f38e8034cea31df2b0fd7682d3f538a4da451a42ed390cc33c67,"using a vector as the underlying data storage, to implement the push back function i.e. to add an element to the back- in the best case when there is enough space we merely insert the item to the back of the vector which takes constant time, i.e. O(1). however if there is  not enough space then you have to reallocate memory for a new vector with twice the amount of memory as that of the old vector, copy all of the  items across to the new memory and then insert the new item- this takes a linear amount of time O(n). to pop at the front i.e. to remove an element from the front we have to move all the elements of the vector to over by one (to the left) and then decrement n_items by 1- this takes a linear amount of time i.e O(n). after shifting the elements over by one and decrementing n_items if the amount of items is less than a quarter of the memory allocated you have to reallocate memory with half the memory of the original vector and copy the elements to the new vector which is linear time O(n) (so together is quadratic time O(n^2)). to peek is constant time O(1) as you simply return a reference to the first item in the vector and size is also constant time O(1) as the vector class stores a variable n_items which keeps track of the size of the vector. so just return n_items.",9.0,13
4210,4210,5896,b4e094c982f7331975cb926eaf035ebce731db0364374bd4c72773048d23a8f901eb66b98a1aa6744d785a2a739991dc6061132d03cc224ca0f87155c45d2fc3,"To implement push I would use push_back that has O(1) as the best case scenario and O(n) as the worst. The worst case scenario is when there is no space left in the allocated space. 

For pop I would use pop_back that has O(1) as the best case scenario and O(n) as the worst case.

For peek I would use data.back which is always linear O(n).

For size I would use Thing.size() which is also always linear O(n)",2.0,13
4211,4211,5897,b1a3a9f62a3efb88815155da55fbf2f2fafa14dd37234e9f11b5f00a231a31fde1494bd63f6ac5858aefb97ae2c7130be129cb66d65efd0dfa784ad99b296be3,"PUSH_-_  An element is inserted at the back of the queue and the size of the queue is increased by 1. It will take a constant amount of time and therefore in Big-Oh notation it would be O(1).

POP -  An element is removed from the front of the queue(the first or oldest element in the queue) and the size of the queue is decreased by 1. It will take a constant amount of time and therefore in Big-Oh notation it would be O(1).

PEEK - This returns the element at the front of the queue without dequeuing. It will take a linear amount of time and therefore in Big-Oh notation it would be O(n).

SIZE - The size function returns the size of the list container(vector<Thing>) or the number of elements in the list container(vector<Thing>). It will take a linear amount of time and therefore in Big-Oh notation it would be O(n).",5.0,13
4212,4212,5898,38046b991658125dabc236638e4678ce8b6ce1a14066e89cee307b4ad43150545ef075aca8b10f61c4cd3909f6915397eea519e89ce5ad74fb62a1715837f925,"Since we are using a vector as the data storage we can utilize some of its member functions already.

PUSH: Since will correspond to _push_back_ on vector the time complexity stays the same. i.e Best case _O(1) _and worst-case _O(n) _because of the _reallocation of space_.

POP_FRONT : Will not  corrospond to _pop_front _because there is not such...Thus one would have to copy over all n_items one step to the left _O(N) _

PEEK: will corrrespond to_ vector.back() _which is _O(1)_

SIZE : vector structure keeps tabs of_ n_items _thus _O(1)_",13.0,13
4213,4213,5899,c3db465470d91ba6cd0242ed3a549831510dda1562b623b02e3665b5f6f9bac2d6ad4723d79407874899cc2fdd039731483c651b9cdef6d97acefd5884ce52f6,I would implement push by  using a push back function which will take O(1) time at it's best case scenario and O(n) at its worst. With peek i would use the front function to return the first item and this has O(1) time complexity. With size i would use the size function of the vector and this takes O(n) time. With pop i would have to create a pop_back function and this would take O(n) time.,5.0,13
4214,4214,5900,36dc611e5a5c4c004053dab4fefc6b9a5b0bc6b95bad46c0ada67bd1d7f42775da4dc0cb387f6915f676d0a13a5decf47d86380ae9bc1d77138d6578f380b0f1,"The push back function would be the same. The I would use a reference to the front of the vector as the peek function, I would also use the pop front function for removing from the queue. The time complexities would be O(1), O(1) and O(n) respectively.",2.0,13
4215,4215,5901,ec395a3ecaad23df4073c1f706e156a2dc0df6ec9ab518f824a5ee32c21f2fee951d1dfe316e50e996ee47ec57ebf1b3a335db07c23fa71520fbcc864e608a4d,"-Implementing the push() function will using push_back() function to add element to end of vector / top of stack. Time complexity will be best case O(1) and worst case O(n).

- Implementing the pop() function will require us to remove the first element then shifting the elements to the left and reallocating the size. The time complexity is the worst case O(n) which is linear.

- Implementing the peek() function will require us to use the front() function which will make the time complexity O(1) constant time.

- Implementing the size will require us to use a counter and incrementing it as we transverse through the queue which the time complexity will be O(1) constant time.   ",13.0,13
4216,4216,5902,4795114f3afe1274590e0a1f19de90527c5847fc255bd0189e17daffae55e382487cd961fd300bbb3c50ca9f987687623e87a7237bb50d7f5d0bd58f320efd98,"for push back function nothing changes so we can still use the push_back() function to add items to the back . This will tkae O(1) in the best case and O(n) in the worst case 

for popping an item we can use pop.front and this will take O(1) in the best case and O(n) in the worst case 

for the top or peek funtion we can use the return data.back funtion and this will always take O(1) time 

and if we want the size of the stack we can use the return data.size function and this will take O(1) time as the stack always keeps track of the number of items for us ",11.0,13
4217,4217,5903,8c276f2a894ec8359a82f6a7f8b543cee4dafa5e339dd5fcbdd9b626de04d860f6a771f050054850d4263b60fc7c9e2f46a60c4568664a5f9854894846a3920d,"To push an item on a vector, we'd simply use the built in push operation for a vector with the item we want to push in the brackets. The time complexity is usually O(1) and in the worst case scenario, it'll be O(n).

To pop an item off a vector, we use the built in pop operation for a vector and it will delete the item from the top. The time complexity is usually O(1) and O(n) in the worst case scenario.

To peek, we would return the item on top of the vector by using the top index as a the position in the vector we want to see. The time complexity is O(1).

To get the size of a vector, we just use the size function. The time complexity is O(1).",9.0,13
4218,4218,5904,31f89aaef7c39dc86c93cfdeddea5fc5554c3cbe3838d2616d1fbc1745414f7096809e9261e2fb009c92beaaac49eaef9633b3b3c92cef0606b8cfb14522414d,"We will do the following:
When adding (pushing), we would use the size function to find out the index of the back of the vector and then add the Thing to that position. To pop, we would point to the first index, remove that Thing and then shift all the components to the left. To peek, we would simply point to the front of the vector. To implement size we would simply iterate through the vector and count the number of elements in the vector (or use the size variable in the vector class if it has one).

Time complexities:

Push: Usually O(1) but O(n) in worst case

Pop: O(n)

Peek: O(1)

Size: O(n) or O(1), depending if there is a size variable or not.",13.0,13
4219,4219,5905,922be3881d23d4f79d2fe24bf6321a23d63d950205b6ff6979047d1cc7c61465b9b18bdf8228c338eb886bb3010ea5578ec21cbc2819ca5ad2860838b719658d,"the push would be : data.push_back(t); with O(1) in best case and O(n) in worst 

peek : return data.front(); and is always O(n)

pop : data.pop_front(); with O(1) best case and O(n) worst ",2.0,13
4220,4220,5906,c01425271443b193ce09add717a13c5f03e56291a15f580c8ffbb713e75d1afdc1826b33b91330419ca4db414a4703bd7b9474559be3d7689b82c2ecbf73906a,"To implement push, we would create a new link with its value and set the next pointer to the first item in the list. Whilst pushing, we would normally have O(1) time, however in the worst case we would have O(n) time.

To implement pop, we would update the head to point to the next item and then delete the link that was at the front. Whilst, pushing we would have O(1) time.

To implement peek, we would simply return the first character on the stack without extracting the character. Peeking uses O(1) TIME.

To implement size, we traverse from the front to the back of the linked_list, counting each link until we reach the nullptr. We have O(1) time.",4.0,13
4221,4221,5907,e5092ab1c7e17d25e5db9dfc9252b8c31679cb1e2b17a0be836efd97ce606988409f994ae92e4e1f795d2d139fe2c46eff4d5f244e605f9f08c46d7129da95d2,"to implement push we would run push_back(). Since a queue pushes to the back This will take O(1) time.

to implement pop we would run pop_front(). Since we are popping from the front this will take O(1) time.

to implement peek we would return the front of the vector. Since we are peeking from the front. and we only have to look at a single value this will take O(1) time.

data size would  be implemented by returning data.size() of the vector. This would traverse the vector and increase a counter until it reaches the end of the vector when it will return the counter which by the end of the function is equivalent to the size of the vector. this would take O(n) time.",5.0,13
4222,4222,5908,efd232e6edf06b095e712e68f8ce8701b452d03344874ec8e202c3b1c55dd0c8b72d40f2859eacbda02e8a7ae034ecba2b74f48d8999907073f237d2d351e8e6,For the push function we would use the vector function push_back(Thing t) to push an element to the back of the vector best case O(1) worst case O(n). For the pop we would remove an element from the back of the vector via pop_back() best case O(1) worst case O(n). For peek we would want to see what data is at the back and would use data.back() which has O(1) complexity and size we would want the size of the vector via the size() function which would be O(1) complexity.,9.0,13
4223,4223,5909,158bc4a6a09d1d1f60a3174579dd63b17d40ca380bf126e52a49b005e6d33ba7bdbb0d4d003014825659fe0bdbb49f2fd5e45256e7b5b723af7ad889e792a934,"in a push the element that is inserted will be passed through a perimeter,",0.0,13
4224,4224,5910,249e9eaf48a6ca1524336796643b1021d4ea59f9ea64287d7770c8c08e88ca9d76b31f4d65b880c825f283c49f03d66834bc8a5aef3bcb8880daa0f21458adeb,"* Push- append an item to vector<Things> and increment the size by 1. | O(1)
	* Peek - return reference to the first value of vector<Things> | O(N)
	* Pop - remove an item from the reference (Peek) which is the fist element or item. | O(1)
	* Size - return the size of vector<Things> | O(N)",1.0,13
4225,4225,5911,9dc85d5fc9d9d7b3ced470df92bc3f618b906428cc44daba96ce09d4da7c5e6251f817ad8b6d168d5489d3951e1d39f87f0ab87e50f2ae36060fe5a0c0501b6d,"1. push function: For the push function, because each item is added to the back of the queue, the vector class's push back function should sufficiently implement this functionality. In other words, the push function would just call the underlying structure vector's push back function. The time complexity for this function will be constant/O(1) if there is memory available that has already been allocated, as the system would just need to write the new value to the latest (vector pointer+size) position, but it will be linear time/O(n) if the system has to reallocate memory and copy every item over to the new buffer, in the case that the new size of the vector exceeds its allocated memory size.

2. pop: The pop function should remove the item at index 0, which in terms of the vector class's functionality, would be the pop front function (which removes the item in the first position). This can be done by just calling the pop front function belonging to the vector class, in the stack's pop function. This action, if performed by redefining the pointer of the vector to its second element, will take constant time/O(1) but if the new size of the stack is wasting too much memory, then all the elements will be copied into a new, smaller buffer which will take linear time/O(n).

3. peek: The peek function will return the frontmost item. This can be achieved by calling the vector class's get function with 0 as the index passed through as a parameter. This will always take constant time/O(1) as it is just calling a value at a set location.

4. size: The underlying vector class has a size function (which just returns the size property) and this can be called to return the size of the queue. This will also always take constant time/O(1) because the size property is stored and does not need to be reevaluated every time the size function is called.",11.0,13
4226,4226,5912,2aebde6b5faaed73a67c0847887873c4b7d8d2f0c1ec3c5d1ae00fb183c3e53559681b2ee97a4692d74712db8b222e3239fa5e199b01863e771a9daa54a4abee,"For a push function , a traverse to the ith item must be made and use a push_back function to add an element at the back.This would require a linear amount of time and it is regarded as the worst case.

for a pop function , a pop_back function is utilized to remove a reference to the last item.Complexity is a constant amount of time and it is the best case.

For peek function , a return of a reference to the last element  is made. ",4.0,13
4227,4227,5913,dc016101375a4c30fa08c850e4ef82abdd66ca922170c25b2eda3c6f7009abcdda2dafb1c86a512fdd1b897c4c9da94be8f7047b535d50f3a259b1e698b13e05,"Using a vector as the underlying data storage while using a queue as the data structure means that the push_back function will take place at the back of the vector but peek and pop functions will take place at the front of the vector. 

In order to implement the push_back function we need to add an element to the back of the vector as well as push at the back of the queue. In the best case scenario, it will take content time O(1). However, in the the worst case scenario, there will not be enough memory allocated in the vector therefore we will have to create a new vector with double the memory allocated compared to the last, copy n items across to the new vector and then add an item - this takes a linear amount of time O(n).

To implement a pop_front function, we pop from the front ie, remove an item from the front of the vector or the top of the queue - this will take a linear amount of time O(n) as we have to copy all the elements one to the left and decrement n items by 1. In the worst case scenario, we have to copy all the elements on the the left and decrement n_items but 1 which takes a linear amount of time and n-items is less than a quarter of the memory allocated therefore we will have to create a new vector with half of the memory allocated compared to the last which takes linear time O(n). 

To implement the peek function, we peek at the front - this will therefore take constant amount of time O(1) as it is just returning a pointer/reference to the first item in the vector which is the top of the stack.

The size function will also take content time O(1) as the vector class has a variable inside which keeps track of the number of items in the vector and therefore we just have to return n_items. ",13.0,13
4228,4228,5914,5602a599f37ceb4d3d0abbebb674a8cfae2a81d9f53137cfbc7a1bded150cbaa8a83e4431db27b0e21c60021690e3731e8677add172b47aa9e637944b71f019d,"I would create a normal push back function which will add elements to the top of the stack.

I would create a pop_front function which would remove the top elements of the stack.

A peek front function would be created to return the top element of the stack.

A normal size function would be created to return the size of the stack.

complexity of push back would be O(1)

complexity of pop front would be O(n)

complexity of peek would be O(1)

complexity of size would be O(1)",7.0,13
4229,4229,5915,9dfb1f3f8489eba0c312316ab375b0eb3fde4cc7c592108ea20fe9063368bfeafc3cfc95ddf50eff3397d93bb8f4939d82490505e330285e8ec3eab94f0e646a,"Assume that T is the type of object stored in the list, eg. int

- void push_back(T value) to add on top of the stack, which will use linear

- void pop_front() to remove the item from the top, which will use constant (O(1)) time 

- T& peek() to return a reference to the top item 

- size() to return the number of items",5.0,13
4230,4230,5916,ee66ed151b20f2c15b5115f8b2c4fd312cc74408ed945a84bb7f699ad1a7972c932ae28ae3a673ec55d38f3c6b49ab5107d141ab55e4e963155df1dc24bf5495,For Push we would create a void function that that will push back Thing and the time complexity will be O(1) for the best case and O(n) for the worst case. For the Pop we would create a void function that will pop back of the vector and the time complexity will be O(1) for the best case and O(n) for the worst case. Foe the Peek will would create a void function that will return the data item at the back of the vector and time complexity would be O(1). For the Size will would create a void function that will return the size of the vector.,7.0,13
4231,4231,5917,2e609516b3c283ff23ddaea06d0df01ad6175f48861d0223a4409ebe1c7df8e383fe146f147415f2605c7a0103b96921b1ffd763ab4924efe18fd229dedbae68,"implementing a push and pop method:

Push, pop, peek methods:

Options:

	* push to the back(O(1) TIME COMPLEXITY USUALLY, O(N) IN WORST CASE WHEN NEEDING TO REALLOCATE SPACE), pop from the front (O(N) TIME COMPLEXITY DUE TO HAVING TO MOVE ALL VALUES ONE INDEX BACK), peek using pointer arithmetic with index as 0(O(1) TIME COMPLEXITY USING POINTER ARITHMETIC)
	* pop from the back (O(1) TIME COMPLEXITY USUALLY, O(N) TIME COMPLEXITY WHEN NEEDING TO REALLOCATE SPACE), push to the front(O(1) BEST CASE TIME COMPLEXITY ON EMPTY QUEUE, O(N) TIME COMPLEXITY USUALLY EVEN WHEN NEEDING TO REALLOCATE DUE TO HAVING TO MOVE EVERY VALUE ONE INDEX FORWARD), peek using pointer arithmetic with index as size-1(O(1) TIME COMPLEXITY USING POINTER ARITHMETIC)

size methods:

Options:

	* keep variable within queue class which increments with each push and decrements with each pop, function returns variable value, O(1) TIME COMPLEXITY
	* call vector class built in size function O(1) TIME COMPLEXITY
	* iterate over each vector item counting each term until the end is reached O(N) TIME COMPLEXITY

I WOULD PERSONALLY USE OPTION 1 IN OF THE PUSH POP AND PEEK METHODS DUE TO BETTER TIME COMPLEXITIES AND OPTION 2 IN SIZE METHODS DUE TO RESOURCE EFFICIENCY AND TIME COMPLEXITY ",11.0,13
4232,4232,5918,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,"For the push function I would use the void function that pushes an item into the back of the vector. Same as the push function will also be void which will pop out items from the back of the vector. For the peek function I would make a function that returns the item from the back of the vector. The size function I would create a function That returns the number of items in the vector. 

Time complexity for the push and pop functions is O(1) for the best case scenario and O(n) for the worst case scenario. The peek and size function are always constant in terms of time complexity O(1)",7.0,13
4233,4233,5919,d9db0d62eb972d7cdf4f37e10bdbf3c1fe24b4325a048050d64042994d0e2a7ef0c9b1f76e9ab479bae9fb331e67c69ba4663f294fef8e66b6d36cb8560984ec,"We create a class that is a stack, within the class we'll have a vector that is public, we then create a void of push, then we reference the element, then we use push_back() to add an element in the vector. We then create another void function of pop then we use pop_back() to remove an item from the vector, then we create another void function of the size then we return the size of the vector using nameofvector.size() then we use a void peek to return the data at the back of the vector.The time complexity for pushing back will be O(n) and the time complexity for popping an item will be O(n).",7.0,13
4234,4234,5920,7fa0256939f3801d7cb837f49e23433b9e2c72a7153a75d58ee05f6ce597913275599303f990f67fdc180f91407271656e81578b90488fda76d6e550e9bb3533,"TO IMPLEMENT THE ABOVE METHODS AND ITS TIME COMPLEXITIES:

Vectors store data contiguously and has a head pointer.

PUSH(TO THE BACK): so in order to push to the back we just insert at the nth location of the vector. The time complexity for a push_back function is O(1) USUALLY, and O(N) FOR THE WORST CASE (when the vector is full and needs to re-allocate space and copy).

POP(FROM THE FRONT): every time we pop from the front we have to copy everything in the vector one place to the left (taking the left as the front). To implement this we delete the object at the front and copy everything to one place to the left, before we copy we need to check if the vector is less than a quarter full after popping, if it is, then we re-allocate space push the new object to the bigger vector and then copy all the items from the old vector over. The time complexity will be O(N).

PEEK(AT THE FRONT): we just return the object the head pointer is pointing at. The time complexity will always be O(1).

SIZE: to implement this function we store size_t variable the stores the number of elements in the vector and increment and decrement when we add or delete from the vector respectively. We return the variable when the function is called. The time complexity is always O(1).",13.0,13
4235,4235,5921,95ec574d0b5e5bd453bdf228b8fd6b36983c901c9b25f9afd384cc03675a32e20d389dce83833059b544924f4ab4040a1eb7a22d75cffd2643cd89107295fe1a,"1. Push: I would use size() to find the last element then add the new element there; the time complexity will be O(1).
2. Pop: Since we are popping from the front, i would re-assign all of the elements from the second one, one forward and the use pop_back() to remove the last value after it has been copied to one place before; the time complexity of this will be O(n).

3. Peek: With peek you can just use the vector command to look at the first value, such as vectorname[0]; the time complexity will be o(1).

4. Size: For this we can just use the standard size function ( size() ) and the time complexity will be O(1).",11.0,13
4236,4236,5922,a8b16fc0f5a2c752f3497016181c5ad9db439554c5d81073a232375aae20a22a97cca43a22eeec6af33455ba644c036ec4f0c737bb5b05eab312d892fb42141f,"Push - we are adding from the back therefore for our push function we would use push_back. we'd go to the end and add the new value. This should take  O(1) time. However if there isn't enough space we'd have to reassign double the space and copy the vector over. This would take O(n) time.

Pop - We would have to copy our values to a new vector without the first value. This would take O(n) time.

Peek - this also looks at the front of the vector therefore we'd return the first value. This would take O(1 ) time as the list is not traversing through anything.

Size - We would return n_items, therefore it would only take us O(1) time. ",13.0,13
4237,4237,5923,7d8cef0de14cc2a74c530bc45e24878a9bc41b99484642b220015c976fedb5143bed1f3d3d656335fb8356093aebda35cf38a76a3da63375271eacce35baf518,"For push, since we are pushing Thing at the back of the vector it will take a O(1) constant time for the best case and O(n) linear time for the worst case.

For peek, since we are returning the reference of the Thing that is at the front of the list it will only take O(1) constant time.

For pop, it will be O(n) constant time because we are removing the first item and we have to shift all n items forward.

For size, it will take O(n) constant time because we traverse on every element in the vector.",8.0,13
4238,4238,5924,5ac95126c93bab762f619ae6d9e0457a3ae69e32d351c6f444adf2fed30efe3915f7f9845b1ec549d2f270b573f92967241b205877e7a669570b3a332b14617a,"For PUSH I would just use the vector's push_back function.

For POP I would make a new vector, copy the second and following elements over and then set this vector to the old vector.

For PEEK I would return a reference to the first element of the vector.

For SIZE I would just use the vector's size function.

Push: O(1) usually and O(n) in the worst case

Pop: O(n)

Peek: O(1)

Size: O(1)",13.0,13
4239,4239,5925,a871558daae8ec7755dd112b899b7fd46e06cb2a4cebf4c0a75ca226dba4bf419ef0333177fa6862ca71f931535c6fb1250ed993a029aa9b63a8c18ad277bce2,I would use push_back function to add the items at the top and this require constant time o(1) for the best case and for worse case it would require o(n) times .secondly will be popping the data to remove from the top in constant time for the best case and linear time for the worst case.thirdly I would peek and return the item that has been peeled from the top in a constant time .finally I would transverse the ith item by using the size function by returning the number of items in the stack by constant time .,8.0,13
4240,4240,5926,ef56d487f412ffdca7b3412858b2ccd1fa21fc365016661f00994f5e06683c6e545b948b70c4775a9a839e6049995e36f03b1f06a7374933a80a9013b6052c37,"One would have to push back , which means you have to transverse through the entire vector and this will cause time complexity of O(1) in the best case and O(n) in the worst case. With peek and pop front , we will not transverse as we can simply remove from the front and get out the first element hence a time complexity of O(1). The size function will work as normal and will have a time complexity of O(n)",5.0,13
4241,4241,5927,fecc59057a0e209589be1452a92558843a93237db9707d9614670e76673fb2cec05cbca3488156012b8fb3cd1467b373d250bc116d0aec57eaa9cbe2d676c3fe,"The function implementation would be:

push{

we would do a push back on the vector, The time complexity would be O(1) in the best case and O(n) in the worst case if there is no more space so we would have to copy all items. 

}

pop{

we would need to pop at the front so we would need to code a function that will allow us to do this. 

The time complexity will always be O(n) as we would always need to recopy all items of the vector

}

peek{

we would need to return the first item in the vector. this would always be O(1) time

}

size{

We would need to return the number of items in the vector. This would always be constant time O(1)

}",13.0,13
4242,4242,5928,64e451748c8e64219c1dcf31828cb7ded38a1447346285c9e9b6559aebe71fd6c492c0cffcdb5c0c6a652b339b2aa51ca0d8310a628f12a661261dc55ced044f,"input Tokens of the postfix expression,output evaluation of the expression, initialise empty stack s,for each token in the postfix expression,if token is a number ,push it to the stack,else if is an operator, pop k numbers off of the stack,perform the operation, push the result back onto the stack,then should be 1 number remaining on the stack ,return this number as the result of the expression. ",0.0,13
4243,4243,5929,93c90404569325fe60b728e076fbba3cf65e437046307f80389f0bc8991e0972c6f04c428807930e8f3ec23f714c2c1a1c5a69ba6ec135ea91d23224a8d3d68d,"Since we are using std::vector, I could use the push_back function to ""push to the back"". The time complexity will be O(1) in the best case, and it will be O(n) if allocated space is equal to the number of items in the vector.

I could use pop_back function to remove the item on the back. The time complexity will be O(1) in the best case and O(n) in the worst case as the allocated space multiplied by 4 is less than the number of items.

I could implement a function push_front that transverses through the whole vector. The time complexity will be O(1) if there is no single element and it will be O(n) (linear) if there are more than one element. However, the worst case can be O(n^2)  that we need to make copies because the allocated space multiplied by 4 is less than the number of items.

For the peek function I would access the element by referencing to the first (for peek_front) and last (for peek_back) element which will always be O(1).

For the size function I would just return the number of items in the vector (n_items) which is always O(1).",9.0,13
4244,4244,5930,eaf6c4c43d71c21a9611ab529dceabe1fb33ac3bf543bdbce13d249f7b6251a8ae478c786f76da007fed6f3e8c11ab62610c853fb7d3dd853fe2afc80fe40704,"i would implement push by using the .push_back(argument) function which will have a best case time complexityO(1) if there is enough space to add it and a worst case of O(n) time complexity if there is not, for pop id use the .pop_back() function  with the best case being 0(1) if the number of items is greater than a forth of the allocated space and a worst case on O(n) if its not.id implement the peek function by returning the .back() function which will always have a time complexity of O(1) and lastly id implement the size  function by returning the .size() function which will have a time complexity of O(1) since the vector keeps track of the size and pointer to the top element.",9.0,13
4245,4245,5931,a83848dae9e11c32fb0fef1054c9f0420423c74efa66838a210a7774eb07b64f5a5df97bc2a33594ee565ea37cacb65f8fcddd5281fc0b93d6e6e1b0ba5da1ac,"For push to the back we move the last item to become the second to last item, the time complexity would be O(1) is constant.
for pop  at the front we remove the first item from the vector, the time complexity is O(n) is linear.

for peek at the front we return a reference to the first item on the vector and time complexity is O(n) is linear.

for size we return the number if element we have on a vector and time complexity is O(1).                                                                                                                                                                                                                                                 ",11.0,13
4246,4246,5932,ee9a54c657ad0d8bba4bde06638e509cdb2a338e06761f819025e545929c0973eae422171c63064d2ec75c6fa5edd42d44dd67fd5b59e36f33fd89e07c72a43f,"* Push_back to the vector,it will take O(1) best case and O(n) worst case when I run out of space , I will have to create space
	* Pop_font of the vector, it will take only O(n) , because after every pop I will have to shift the elements of the vector to avoid memory leak
	* peek to the front of the vector will take O(n) , because after every peek I will have to shift every elements of the vector to the front to avoid memory leak. 
	* Checking and returning the size of the vector will take O(1)",9.0,13
4247,4247,5933,68f3486fba3e90fbb30d257d9f425b479699474b4734aedaec9e7b7e62738dec31c232429f41b1b79d289e2acf53beed558d49f905e55176ee54e1327b9aa184,"queue::push() :We insert and element at the back of the queue. We add  the element back to the queue container and size of the queue we increase it by 1.

queue::pop : We  remove the element from the queue that is the oldest ,We remove the element to the queue container and we decrease the size of the queue by 1.

peek_function: We get the front element of the queue at the constant time.

size_function: We return the the size of the queue at the constant time.",9.0,13
4248,4248,5934,22ce118158e8ed0c1187b952e36a1938ab0c22e942e01d9258ed224302f7ecf3665fc06c4060e629850d16f04e008f7cd12363e7f782d4370a1dd3b7af113bbe,"Push: Because we push to the back and vector is our underlying data storage, we could use push_back() function provided by vector which adds an element to the end of the vector. Time complexity would be O(1) in the best case (readily available space) or O(n) in the worst case (not enough space to add an item to the vector so memory needs to be reallocated and items copied into new memory).

Pop: We would have to create a function which removes the first item in the vector and then copies every item remaining in the vector one space to the left. Then the function would check the size of the vector and if possible reallocate less memory space. Time complexity would always be O(n) because regardless if memory is reallocated or not items are always copied.

Peek/top: We could simply return a reference to the first item in the vector using the front function. Time complexity would be O(1).

Size: O(1) time complexity as it simply returns the size of the vector. ",13.0,13
4249,4249,5935,43337822a8495f6346099bee6f1b1379846d1e116a80358eff95ac9a35a5e9db993d15f49931c7a4d1543bc7328dae0e418202f217ef071778281db16cfc2fe9,"push - one will check the size of the vector to see if you can add another thing to the vector if one is unable they will have to reallocate space. One will have to then add the new thing to end of the vector (the size of the vector plus one) and increase the size of the vector by one. This has a constant complexity of O(1) for the best case and for the worst case it has a linear complexity of O(n).

pop - one will have to decrease the size of the vector by one. This has a constant complexity O(1).

peek - this returns a reference of the the one item after the last item(one item after the last item so size plus one). This has a constant complexity O(1).

size - this return the size of the amount of items in the list that is a stored variable for the vector class. it has a complexity of O(1). ",7.0,13
4250,4250,5936,92a2ed8f4716bed3b0e0c50f4d71ca4d4c6f96e622febc9b471f947d10b8500c23531ab4582c0648a7ceef71efcbb7100102c2a6bd33328ed40abb07652829ad,"The queue will use most the vector's functions such as ""push_back"", ""pop_front"", ""front"", and ""size"". The ""push_back"" function will add items to the back of the vector(add to the back of the queue) and the function has a best and worst case. The time complexity of the best case is O(1) and the worst case is O(n). The ""pop_front"" function will remove items from the front of the vector(remove from the front of the queue) and the function has a best and worst case. The time complexity of the best case is O(1) and worst case is O(n).",3.0,13
4251,4251,5937,67d402955c162ab6452295b6b5d26eba2d31759d3c95b63363fb0f3d4d6e0b04ac632a790b3b479c13437abea8e6208b9e8122018f1333c3a720caa36adbe27b,"For the push back function, since the underlying data storage is a vector i would use the push_back function and the Big-Oh time complexity would be O(1) for the best case and O(n) for the worst case where we run out of memory and have to copy out all the values to a new vector.

For the pop front function i would use the begin function to call the first element and use the erase function to erase it, this would be a time complexity of O(1).

For the peek function i would use the begin function to call the front item and return a reference to it through using this function, this should also take a time complexity of O(1).

For the size function it should be easy to implement since the underlying data storage has the size function already, so this would also have a time complexity of O(1).",10.0,13
4252,4252,5938,f4baa24ad720b1250dc8a9d5d7170a55ee764630dc2c7f87292182bdad71ecf2851e6fec34c6913b3b5952d370fbd9d0459efe69a1541c4221908a8f498f268c,"_Using a queue:_

PUSH: Because a queue pushes to the back, we could use its built-in push_back() function to add an item to the top of the stack. Complexity is constant in the best case, given the underlying vector data structure - O(1), and O(n) in the worst case (i.e. when reallocation is needed for the vector size).

POP: Because we pop from the front, we'd need to move the last item at the top of the stack to the front of the queue, then use its built-in pop_front() function to remove it. This would require copying all the items one to the right, altering vector indices so that they all shift forward one and the last item becomes the first at index 0. If reallocation occurs, this would also require copying all items, now to a new vector and still shifting items. This would have a complexity of O(n) (linear).

SIZE: Because the underlying data storage is a vector, we can use its built in size() function to get the the number of items in a queue. Complexity is always constant - O(1).

PEEK: Similar to pop, determining the item at the top of the stack would require copying the vector but now shifting all indices to retain order and put the item at index n-1 at index 0 and then requesting to see the item at this index 0. Complexity would be linear because of the copying of the underlying vector of the queue and so is O(n).",9.0,13
4253,4253,5939,135bdbdca9dab16566a02b87eb86b2b03e986360c36387bc6b252f2a7b0098a14637a43a9d1d68d223771b954b34555f039489b7af8726eba774f24a3c3a0d42,"Push: Simply use vector's push_back() function. This has a O(1) as it does not have to traverse the vector.

Pop: You would have to move each Thing one position forward and remove the Thing in the first position. This has a O(n) complexity as you would have to traverse the whole vector.

Peek: Simply use vector[0] to see what is in the first position. This has a O(1) complexity.

Size: Use the vector.size() function. This has a O(1) complexity as no traversing is needed.",13.0,13
4254,4254,5940,6faaf9b1d085a393b028ace82b2996765123fa315b9f4a8ed8db3a15b212a1737ea08b0cd8412ff053120963926bb68c4544ec749acc155d82f591062af2caa1,"push-function adds elements to the queue. time complexity of push-function is 0(1)

pop-function removes elements from the queue. Its time complexity is 0(1)

peek-function returns the elements at the front of the container without removing it. Its time complexity is 0(1)

size-function: it is used to return the size(number of elements present in the queue). its time complexity is 0(1)",9.0,13
4255,4255,5941,bb7a5218ab3dfcc0ac546d608943de6dcbb3727d09e6f5dbb5e885ea5b24939174aaaa40e8672ce63fa53f6af97ad899b29ea3229ae18c85c504ca3dcaa7d71a,"* Push - The back of the vector is always going to be the top of the stack, so in order to add to the stack we going to use the built in function (push_back).

	* Time complexity(push) : it has the best case and worst case.  *Best case - When there is already space and we instantly insert the number therefore (constant amount of work)  - O(1). *Worst case - When we run out of space and we have to copy all of the things in the old vector to the new, bigger vector (Linear amount of work) - O(n).

	* Pop - we always operate at the back of our vector so we going to use the built in function (pop_back).
	*  Time complexity(pop): *Best case - we simply removing the items (constant time) O(1). *Worst case - (n_items < n_allocated/4)  so we starting to waste a lot of space (Linear amount of work) - O(n).

	* Peek - The top of the stack is at the back of the vector so we going yo return what ever is at the back of our vector.
	* Time complexity(Peek) : We will always do the same amount of work (constant time) - O(1).

	* Size - To get the size of the vector we going to return the size of the vector.
	* Time complexity: The is n_items in the vector, so we will always do the same amount of work (constant time) O(1).",9.0,13
4256,4256,5942,59d6b044c8e3defdb04ae33f65223b9a348ff28a2986757f1ff92456374522a233c59e08e3595ef590565b6c7312655ac0d183d5fa106548d9bdc3808d7fd503,"Big O-notation is O(1) for pushing and popping (if there is no added space) and become O(n) in worst case.

Peek is implemented by dereferancing (i.e using pointers)",1.0,13
4257,4257,5943,c4a46955ab90460a7f7ea08b20b02537758cd0f1f3801bb0b96314fe0ff9d069021459ba5c9b4434a1085ce9d389652fee31ac82384418540ac50a261c57a498,"For a push an item would be added to the vector using its parallel function. This would mean a time complexity of O(1) until the vector's memory allocation would need to be be expanded resulting in a time complexity of O(n).

For a pop a counter would be kept of the number of pops to date and this value would be used as a modify for all existing item references so that the existing structure would correspond the data as it should be. This would result in a time complexity of O(1) until the count reached a value that would justify a reset of the vector clearing ""popped"" items and the counter, the time complexity of this being O(n).

For a peek the counter used to track popped items would be used to identify currently infront of the vector with a time complexity of O(1).

Size would be a calculated from the vector's size function, which would find the base value, from which the pop counter would be deducted. The resultant time complexity being O(1).",9.0,13
4258,4258,5944,307d8af1793926f21e6b4215d5b4182c112c0d4698d4832d0185b0d9535a011c7a888a921d240645fc84a5799fdd55910fe15a0615bdfb1a6fdb121e9cfcac36,"Push function - we add an element and push the existing elements, the time complexity will therefore be O(n) since we have to push every element. 

Pop function - elements are removed at the front of the queue.The time complexity is O(1)

Peek function - check the item on the queue which is the last item in the vector. Therefore we will use the back function. 

The time complexity is O(1)

Size function - we check the size of the vector. The time complexity is O(1)",9.0,13
4259,4259,5945,4c6f807c2ce1ab585dfa9622ceaade81e43b8fe88ba8af5d95eb11efdad75a8b1190eb5c2d48dff34f29ac730bf0895fdaf308c3995dbd7f2103246c342b70a1,"inorder to push we would need to add an element to the font of the queue and increase the size of of the queue by 1. (o)n time complexity

inorder to pop we would need to remove the first element of the quenue, decrease every other elements place by 1 and decrease the size. (o)1 time complexity.

inorder to peak we need to return the top position of the queue. (o)1

inorder to get the size we would run through all the elements until the are no more elements and increase a counter everytime there is an element.(o)1",6.0,13
4260,4260,5946,7ad6b014f9c54f4af21e21f5ded12f480a954caacae0b1ae202d37d441149e00126be0ab20466a777e1dde3487a3cf0d1df830a29d9d1df5f045525d8082c235,"I would implement push to add any item on top of the stack which would take linear time 0(n) because of the traversal steps to arrive at the nth item. The pop would be good for removing items at the beginning because any item that we want to remove at the beginning is easy to access and would take a linear time 0(1). With peek/ top, it will be constant time 0(1) because the new item would be easily identified as the queue is able to keep track of both the front and back, by removing and adding items at both ends, this means that it has a pointer indicating the end of the stack, or rather top. Then finally with size, it would be constant time, specifically because items would be counted as new items are added. ",5.0,13
4261,4261,5947,4fe3ddceb8532be5264d396e27eca9f3430928d2debfbdca391cfa468f769445f07ae40650717eb0131d20465c9068c4b8bf87a2c7932640884394a0094fc8e5,"push - O(1)

pop - O(1)

peek - O(1)

size - O(n)",1.0,13
4262,4262,5948,a69deeb1d09b2c2f2efacf2adabcd40f91cbdaa6d8a94b958b4f80eb19e04ba4658d33a6b07d41e2293e3dc7c648d0c9d4ec03fdc6df749e7a11d1c6ae138068,"You should firstly construct queue, then test if container is empty. After that return size. Access the next element. To get  the push insert the element  and to get the pop remove the  next  element. 

 ",0.0,13
4263,4263,5949,5204f1bef2136d15a15e2bc81fec661c33bfcaa03530558479f291b586c10eaadde8b3f1da2bdb0c585b8e4de129c95a1cc00f8b5982206443ac7a6b2014c46d,"We can use forward lists to implement the push, pop, peek, size, so that we can either push to the back or peek to the front",1.0,13
4264,4264,5950,5221e1f3d933576f202c0725eb1b1536ee1b49681a3fc7d8f1a5f7ce021be47e8c2ad1016a78e47c8f005a4abc05514dc591b463cb92d3c640fd02125cf688e6,"Queue:

1. push_back (Thing &t) would be O(1) time /constant time as it requires 1 action of adding an element, worst case O(n) time when we need to reallocated.

2. push_front (Thing &t) would be O(n) time / constant time .

2. pop_back () would remove an element at the back, constant time O(1) and worst case O(n) when repositioning

3. pop_front () would remove the first item and require n-1 repositionings, therefore linear time O(n).

3. peek () would be O(1) time . constant time

4",4.0,13
4265,4265,5951,b3916d46d881833f987b1688b8c10f933afdc9a4fa5bd760932846eb945fb5e69406c926d4b58830137510a4b06c87b7babebfdb5983ea8a0ed2ed2ae65cf4e6,"pushing an item will usually be O(1),but worst case will be O(n)

popping an item will always be O(1),but worst case will be 0(n)

peek and size will always be O(1)",5.0,13
4266,4266,5952,5f1f239814321ab1f431320367ad013e94b2f66dc9f45345746644a7c6190c150b15690868f1b18e7468353f42b32ce7d5d9e6673f3e33a12996a386f5985adf,"push:

    make a push function and in it I would push_back to the vector, as that function already exists.

    Time complexity- worst case: O(n), best case: O(1)

size:

    I would make a size function,  In the function I would return vector's size as that is a built in function for vectors.

    Time complexity- O(1)

peek:

    I would create a peek function, in the function I would return a reference to the front of the vector.

    Time complexity- O(1)

pop:

    since there is no pop_front function in vectors we would have to make our own. I would start by shifting over all elements to the left(towards the front), and then pop_back() on the vector to remove the last block.

    Time complexity- O(n^2)",9.0,13
4267,4267,5953,9403a6055052838effd7ee11ccb772d87904528f067a64dac873492ac316e3dec04949023db9aa2c93819f94c53c4c5c1b5e1941d51e786c3ee0dff6e062b7fc,"1) To get the size i can use the size keyword present in a vector. Is always constant time.

2) To add I can push at the back. linear or constant time

3) To remove just pop from front is constant time.

4) referrence return first item. constant time",9.0,13
4268,4268,5954,27b7c01b5507de27227f1b4c06fa92833846a84fa96c3732f3663fb00fd83e6f0c7c3e711cd797752bf30bb3a828ffa9c255dc629b8adb95ea32e0eed6535409,a queue will involve the storage of the queue items in an array.,0.0,13
4269,4269,5955,9f85bd574a0fb5fa07c95cbd2dc5aa7f4cb77f83ea58b24cf50b8a111ddaa2e08d644409b7ea28dad73defdb2393c136cc039b51ec3ed144b40271a76c7c7470,"With queue to use push,pop,peek and size we would have the time complexity of O(1)

This would be because we are thinking of people standing in line and removing people from the front , we therefore use the first in first out method so in a code we would be pushing, popping, peeking from the front.",2.0,13
4270,4270,5956,e8a6e8174a6dd6e314677435e7049c0e3009b13d8a5df4000710970679e38e84d121d59138dfaf7218a7bd9e9ad0ee03d92b55f5f1e73be1e9206de0707e798c,"A queue retrieves elements in the order they were added (First-in First-out) and the elements are stored in order of insertion and don't have indexes. Below are implementation strategies for different functions using #include deque.h 

d.enqueBack(value);  places given value at back of the queue  and has time complexity of O(1)

d.peekFront() returns front value without removing and throws an error if queue is empty. Time complexity is O(1)

d.peekBack() returns back value without removing and throws an error if queue is empty. Time complexity is O(1)

d.size() returns number of elements in queue. Time complexity is O(1)",4.0,13
4271,4271,5957,744cc5a93fd7edad364406b30ceaa6836705a7419bd01ed97b04c61f1235130699ff789e400cc607e1772b19b35bf800957b6bd74b1e52cf1974d01500560533,"Push: we would use the vector to push the Thing to the back of the vector. In the Best Case Scenario the complexity would be O(1) as there would be enough space to add the element. In the Worst Case Scenario, the complexity would be O(n) as n copies would be made to a new array (vector) and then the element would be inserted at the back.

Pop: To pop we would copy each item over one to the left in the stack, thus overwriting the element at the front. Complexity: O(n) as there would be n copies. Unless there is only one element in the stack. Then the complexity would be O(1). In this case the standard vector pop_back method can be called in the stack implementation.

Peek: we would use the vector at(i) method, where i is always 0; This would be complexity O(1) as pointer arithmetic (which can be used in contiguous data structures such as a vector) in always constant time.",5.0,13
4272,4272,5958,aadeb4c6039dda00602078edb4dd6a2ba4db3a9feee681399a3fee2f757fe3dbefb04d7c93523ccccac1c802124b4fd37762f7d6434cb2806498d24d632de064,complexity of all functions would have the best case which is O(1) but would also have the worst case with is O(n,2.0,13
4273,4273,5959,1489eb158e53466602df55c1ff7f77273c9913450f0796e43815428214c7433748ab1168262af0196b8d73779fe2b0792d76aba9ed45066d1d5d48c57b55c0b6,"The built in vector has the methods push_front(), pop(), and size(). We would use built in push_front() to implement push O(1), built in pop(0) to implement pop O(1), we could use Thing[0] to implement peek O(1) and finally built in size() O(n).",2.0,13
4274,4274,5960,2a0df219aac143a2ab259ed39069368d09faa1d674232d6d8a5a0299284966b0b712226c702276000af1418c0c7120be9e30f8742712afc25a87bebd377d57d9,"push - would go to the front using O(n) memory

pop - remove from the front using O(n) memory

peek using O(n) memory",0.0,13
4275,4275,5961,f0db6745b82c8442a04741f69d90ab699cfa4f3ce386836ba0d3ae6a18d50c9ca2d13114c6327692eaa69266b7b9c9c7378c99ca64e0ec19c0994415cc5bcc80,The pushback function for vector will be used for Push. Complexity of this in the worst case is O(n) and best case is O(1). For pop we can use the vector pop back function. It the complexity would be O(n) in the worst case and O(1) in the best case. The peek function could be implemented using the vector.at() function and complexity is O(n). The size we can use vector.size and complexity is O(1).,5.0,13
4276,4276,5962,9607664f15775a14ee634c51fe9c149f525e26b98d5914c3165e84652908eb3f36dc6b5eb9602fdd2aa10815feb68c6202a768e4280fe2bc5565e0190f5672e7,You would be able to implement the push() function by using the Push_back() function of the vector which will add a value of type Thing to the back of the stack. The Pop() function may be implemented by using the pop_back() function of the vector class to remove the last element added to the stack. To peek() you would be able to use the vector class function back() to return the last element in the stack. The size() may also be found by using the vector class size() function.,2.0,13
4277,4277,5963,2752a012a3acfc041a30d5a655085eade0eb440b54f67d20ed248f27ebf41fd19d90129f4fd7d4c48bc1b7b721b3638118e357f1785837b03bc7def7da08253e,"If we are using a vector as the underlying data storage for our queue, we would implement PUSH by using the built in _push_back_ function which will add the Thing to the back of the vector which corresponds to the top of the queue.  This will result in a Best Case complexity of O(1) and a worse case complexity of O(n) if the vector runs out of space and a copy has to be made. 

The PEEK function will use the _.front_ function as we want to view the front of the queue. This will have a complexity of O(1) as a constant amount of work will be done.

The SIZE function will be implemented by using the built in _size_ function for vectors [i.e. size()] and will have a time complexity of O(1) as a constant amount of work will be done.

The POP function will be implemented by using _pop_front_ as we want to remove the item at the front of the queue. This will have a complexity of O(1) as a constant amount of work will be done. ",13.0,13
4278,4278,5964,6a7a49da689922560451287b4e285dafdb4a0bfd283c9d3d5a6941f50de9e8434c4baab959d6ac95be4270bc3e3b12632437fec1cc1ffa0e88747c0a4bcc97e6,"TIME COMPLEXITY

PUSH_BACK - 0(1)

POPBACK-0(1)

PEEK -0(1)

SIZE-0(1)",2.0,13
7139,7139,8828,3b413468f9946530e16c6d2ced91ab45356664eb3ef35b2823043a9391b6766aeb5cd1cde7c7799a9976f4713f096989c7f13a6ea1b6e1be3f9af94b87e0d40a,"You would use a doubly linked list. This data structure allows you to add to the back of the list, pop from the front of the list, get the size of the list and see the front of the list all in constant time. It's very easy to implement as all the functions are already there: push_back(), pop_front(), front(), back(), empty() and size(). You have all the functions you need to implement a queue.",12.0,25
7140,7140,8829,185dc4c21423a9741e871c6f410e59bdca77c391c194cec101c75b3cca04c937f124a0057340342b97dc026d09e5d98b6cb6fda9dab2b9032e1e211b08f87356,"You would use a doubly linked list.

The front of the doubly linked list is the front of the queue where you dequeue and call for the first item. pop_front() and front().

The back of the doubly linked list is where you enqueue by using the function push_back()

The doubly linked list already has a counter for the amount of items in the list. 

Therefore Size(), front(), push_back() and push_front() will be constant time.",11.0,25
7141,7141,8830,16cb13e3f20264dff11bab6b4074b1ead9b8e1cf1d7a12dd1238f56fff77a643c79324083d48280a979ad65c97d7690c011f0b94300438693e7e3022511b7be3,"You would need a doubly linked list that keeps track of it's size.

for queue push back: go to the item at the position of the tail pointer, add a new item on the stack and then make the old last item's next pointer point to this new item, the new items previous pointer point to the old last item and the tail pointer must now point to the new item, new item's next pointer point to null to indicate it is the end of the list. increment the size variable by 1. this can all be done in constant  time.

for queue pop_front: go to the item at the position of the head pointer,  make the head pointer point to the same item as first pointer's next item, make the second items previous pointer point to null and delete the old first item. Decrease the size variable by 1.  this can all be done in constant time

for queue front: get item that is pointed to by head pointer, this is constant time

for queue size: call doubly link lists size variable, which will take constant time",12.0,25
7142,7142,8831,b35e384f7c5ceb06d79c3b93cc63fcaa47042ffefb6b106d30f49be852e804e9feab1392cb217f65d7e7d63ec9914fbf325012c10f23427d79d4c0865092862e,"A doubly linked list would be most efficient as it already has a push_back function that takes constant O(1) time.

push/enqueue: use push_back function O(1) time (doubly-linked lists have tail pointers so no need to transverse to end)

pop/dequeue: use pop_front function O(1) time

peek/front: use front function O(1) time

size: use size function O(1) time

empty: use empty function or size == 0, O(1) time

front and back functions and also built-in for doubly-linked lists and are O(1) time",12.0,25
7143,7143,8832,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,Doubly Linked List,3.0,25
7144,7144,8833,7aa4a41956fb10b2ea3a02d2d85c1eec912704226ca5710248e26fa3e0fa199d5048abcac9423a11d00a49ffe75bdd51e2b3cd752d5f6899af51dc4b580afed1,"We would have to use a Doubly-Linked List for our implementation of the queue. 

A Doubly-Linked List contains head and tailing pointers while also keeping track of the number of items in the list. A single link has a value, a next pointer which points to the next link and a prev pointer which points to the previous link. 

ENQUEUE(T VALUE) : It will be easy to add to the back of the list because we have a tail pointer. We can create a temp pointer that points to the new link(value). We then make tail->next = temp. Then temp->prev = tail. Then make tail = temp.  This adds a new link to the back of the list.  This corresponds to the PUSH_BACK(T VALUE) FUNCTION IN THE STD::LIST. 

DEQUEUE() : To remove an item from the front of the queue we can use the POP_FRONT() FUNCTION FROM STD::LIST. This function creates a temp pointer and makes it point to the same thing that the head pointer is pointing to. We then say head = head->next. We then say n_items -- to decrease the size of the list. We then delete temp which will delete the first item in the list. 

SIZE() : The doubly linked list keeps track of the number of items in the list, therefore the SIZE() FUNCTION WILL JUST RETURN N_ITEMS. 

FRONT() :  The FRONT() FUNCTION returns a reference to the first element in the queue. This can be done by just RETURNING WHATEVER HEAD IS POINTING TO. ",8.0,25
7145,7145,8834,cf96d5be5169d5386c2ce2a3ae914384cd3ff74c0ae41c6fc53cb4ef592a7f9882d33970f1f807fe79c0e961bedb5189d6cfa997817a7684663f34c5e5fffad2,"In order to implement a queue with constant time O(1) for all operations, one would need to use a doubly linked list. 

In order to implement a queue using this underlying data structure, one would need to implement the 4 basic functions of a queue: push_back (enqueue), pop_front(dequeue), size(), and front() (peek()) 

Since a doubly linked list keeps track of the head, tail and size of list, and each link has a link to the previous and next node, we can implement each function in the following way (taking the front of the list as the front of the queue) without any traversing or re-allocating required: 

PUSH_BACK() / ENQUEUE():

Adding an item to the back of the list will be done in constant time since we keep track of the tail(back of the queue and list) and so we would create a temporary new link with the value of the current value being pushed, make tails next pointer point to the temp pointer, make the temps previous pointer point to the tails pointer and finally make the tail point to the temp node and increase the size counter. This can be done in linear time O(1) since no traversing is required 

POP_FRONT() / DEQUEUE():

Since we only remove from the front of the queue, poping from the front of the doubly linked list is constant time O(1) since all we need to do is: create a temporary link and make it equal to the head value. Then head will be changed to point to the heads next value. Then we would need to decrease the size and delete the temporary pointer. 

SIZE():

Returning the size is also constant time since our doubly linked list data structure will be keeping track of the number of nodes in the list, and thus this function will just return that value 

FRONT() / PEEK() 

This function is also constant time since it just returns a reference to the element at the front of the list (ie the heads pointer) and so it will be constant time O(1) since again, no traversing is required ",12.0,25
7146,7146,8835,dc116295695675ce8f8f9dcde7d1d181a1fc34469a4bd2a570b8ca26a7951f6381d662fe47ef41e490d057b64113abc45be11b89047c039c48685692d843ce1d,"Using doubly linked list ,all the operation will be at constant times.  i doubly linked list, it keeps track of size , head and tail. for pop front, we always have the head pointer which allows us change the next pointer to the next next position and then we can just remove the front value and all of this takes constant times, and for push back, we always have the tail pointer and when we want to push back the item , the pointer's next pointer points next to the item and the item previous pointer point to the tail pointer. then the item will the the tail pointer. since we have keeped track of size so when we want to return the size of the list, we just return and this will just take constant times. and the front will just be the head, so it take  constant times to return the front. ",12.0,25
7147,7147,8836,4795114f3afe1274590e0a1f19de90527c5847fc255bd0189e17daffae55e382487cd961fd300bbb3c50ca9f987687623e87a7237bb50d7f5d0bd58f320efd98,"For everything to be in constant time we would need a Doubly linked list ( a head and tail pionter)
we would need a temp variable as well 

so for push back in O(1) we could have something like tmp= new link (v);

                                                                                         tail -> next = tmp;

                                                                                         tmp -> prev = tail;

                                                                                         tail = tmp;

and for pop front in O(1) we could have somthing like tmp= head ;

                                                                                        head = head -> next;

                                                                                        delete temp;

                                                                                        n--;",9.0,25
7148,7148,8837,e23792b17279f93b3cce4dddca09079f761a6a0f2795c6c3c7434b417d9b72d4e94d0c740b318fb5b6d57338883455b8fe250e5759d4aa78bd8b7bd3bfed6a55,"I would use a Doubly Linked List to implement a queue. When adding to the back of the list, I would create a new link and use the tail pointer to fetch the last item for which the last item will then point towards the new link and update the tail pointer thus giving a constant time. When removing from the front of the list, I will update the head pointer to point towards the item that the first item was pointing to then delete the old first item, thus giving a constant time. The front operation will also be constant time as we just return the value that the head pointer is pointing to. As we are keeping track of the number of items there are in the list, we then can get the size in constant time.",12.0,25
7149,7149,8838,a130bfe9418c91d178f590031c0c9939b5fca90db77973d7f6178ded40014a7172640da790c28b96fd7fb6c80913844b332b017840744966e0e7f4da01d28945,"To create a queue using a linked list, one should use a doubly-linked list since that allows us to do all operations in constant time.

To push to the back of the queue we use the push_back function. Here we create a new link whose prev-pointer points to the current tail. Then the tail's next-pointer points to this new link. To finish it off we reassign the tail pointer to be this new link. This operation works in O(1) since it always takes the same amount of time.

To pop from the queue we use the pop_front function. Here we must simply reassign the link following the head link to be the head. This, however, causes a memory leak since we never free up the memory of the previous head link. To avoid this we assign a temporary link to be equal to the head link beforehand. We then delete this link after having reassigned the head link. This also works in O(1).

To return the front value we merely return the value associated with the head link. This is a single operation that always takes the same amount of time, making it O(1).

To return the size of the queue, would require us to keep track of the number of items in the queue during other operations with a variable storing this. Whenever we push from the queue, we would increment the variable, and whenever we pop from the queue, we would decrement it. This would not change the time complexity of those functions and would allow us to implement the size function in constant time since we simply have to return the value of this variable.

The empty function will be very simple: If the size is 0, then we return true. Otherwise we return false. This works in O(1) since we implement one if loop, and one return.",12.0,25
7150,7150,8839,276b4e11850dbed5adc6f0fd4249cf0b5f1cdc0a0dfd3d76321298301426fddeaa12e60021bdff5fc27802e2537ea3a2e891dc9c51166641bf68a7d7906d00b7,i would use a forward list where the start(head) is the front of the list and the end(tail) is the back of the list ,4.0,25
7151,7151,8840,fa243626fbe26ef57e9cb51b64e34cda34860d25833be057b8aacb2413654723774f7590965ed807a0415dd0e925f4717e86fc15d11f310737f703eab68fbabd,"we can implement the doubly linked linked. in this strategy, both head and tail point to the first item, if there is only one element in the queue and we update when there are more times to be added to the back, or we are removing from the front.",4.0,25
7152,7152,8841,c0046d9efb5ac101c14867d2717db3e08d6ef4577447593b970d77add7785e77e104d1c4da7ccd26febfc9dec54c612f8ab1164fc3489c3f123475dd1c711486,"a doubly linked list will be the best option to implement a Queue

the head and tail as well as the size of the list should be stored and maintained

thus enqueuing values would just be an adjustment of the tail pointer and add one to the stored size

and dequeuing will just mean removing and re-allocating the head pointer then reducing the stored size by one

thus all the operations on the queue can be achieved in constant time",11.0,25
7153,7153,8842,092586b17aeb228a8396915c438a564c216c3df48ac6ded66b121dcea5684d3dbe0caab83fcadb656d3a0a26a4c4e1546317909dd36270918915c4447ba4370c,I would need a doubly linked list,3.0,25
7154,7154,8843,2a73fae534f6399be599dee1f1de2adaec9431f39943abeccc1ca0cc827521f43446d764a73ff779a0d169bd025aa1ff69232dd0892e2b573939bb6ed6281bd6,"Use a Singly-Linked List with a tail pointer.

This will lead to push_back, pop_front and front functions being O(1)

To make size O(1), we would initialize a variable (int i = 0;) and increment it as we add an item and decrement as we remove an item.",10.0,25
7155,7155,8844,e2110671a4eab220560a21f9e1e9feb257ad75ab23f504a892c8df780bcf445f866d86be0cb87936d65c86a82a0daabcca41a6174ec4192f8f61c7d3034cdab4,"I would use a DEQUE, which will have a pointer to the front and the back of the list

For the queue

front() will be the same as the deque, O(1)

enqueue() will be O(1) since the deque will just insert another item at the back of the list, which it keeps track of.

dequeue() will be O(1) since the data is not contiguous, no reallocations will ever happen

size() and empty() are the same as the deque which is O(1)",8.0,25
7156,7156,8845,9607664f15775a14ee634c51fe9c149f525e26b98d5914c3165e84652908eb3f36dc6b5eb9602fdd2aa10815feb68c6202a768e4280fe2bc5565e0190f5672e7,"You would implement this type of linked list by using a dlist container and using a head and tail pointer with prev and next components. 

You would use a Doubly linked list.",4.0,25
7157,7157,8846,eacc5211df7d685afcc35802886c12863f0c8244351fcd398189af9fa9bf26e12a751640dd66f6200f43478fc4f6782d51b4f6c4a782ca1b75e12c96dded3eec,"In order to accomplish this functionality, one would require a singly linked list which will keep track of the head pointer and the tail pointer and a size variable counter. Since the list keeps track of head and tail pointer, adding a new link at the back of the list, as required in the queue will be O(1) time. This will also be the case for removing an element from the front of the list and accessing the front element as the value of the head pointer is stored. Lastly, in terms of size: since you are storing a size variable you can increment and decrement the value once elements are added or removed, and therefore, accessing size of the queue will also be constant time. ",12.0,25
7158,7158,8847,31f89aaef7c39dc86c93cfdeddea5fc5554c3cbe3838d2616d1fbc1745414f7096809e9261e2fb009c92beaaac49eaef9633b3b3c92cef0606b8cfb14522414d,"You would need a doubly linked list. This list will have pointers to the previous and next elements of the list at a point. It will also have a head and tail pointer as well as a variable to keep track of size. This way you can implement the queue using push_back, pop_front, front and size functions with constant time.",12.0,25
7159,7159,8848,66c130d147af93128f149a1c3cbc0822def0372144aa77769fad8d406e0bf1fdaea5c4080bf967de52230b79e34763f78e3d8c34ddd69955b5c9b8521c52443c,"You will need to implement a queue using a doubly-linked list so that you have access to the back of the list, the front of the list and the number of items in the list (the size). Using the double-linked list your functions would be quite simple. Your push() function you would just call on the push_back() function of the double-linked list, your pop() function you would just call on the pop_front() function in the double-linked list, the size() function you would just call on the size() function of the double-linked list and finally the front() function you would just call on the front() function of the double-linked list. Due to the fact that the double-linked list has a pointer to the front of the list, a pointer to the back of the list and records the size of the list, all of these functions would take O(1) amount of time.",12.0,25
7160,7160,8849,6e1111ad11474e6379168f87057eae3076970c620dec3cffde8e98db6de9322b94aefef0b0414a791717f61331121e1ad9f15c607c1ff40afee80bcc8c3257b0,I would use a doubly linked list which has both tail and head pointers. This will enable me to enqueue object in constant time at the back of the list. And I will be able to remove object from the front of the queue also in constant time. Meaning in that way I would have implemented the first in first out method.,9.0,25
7161,7161,8850,112623e30928da280b124065b33eb8360f6fe49f45f9b97cc7a540f6e550a5152dd7bbbd6ba167e88c839362c8fd2148a3e881c83493d58d2e9fd2216c604c8a,"I would use a singly linked list with a tail pointer, which would allow us to go from the tail directly to the next link, making push back constant time along with pop front and and peek front.",10.0,25
7162,7162,8851,e15ad332a60fd21f9642a607905bc6a0a968e3d65f0ab448161698266492242c990fc890cd09bab4dffa30a30230d6c043c42b0ef218d6e81e40a2206a0638d0,"I would need to use a Doubly Linked List which has a head and a tail, this will allow me to use pointers to easily add an link to the queue from the back and use the head pointer to pop directly from the front, this allow my operations to occur in constant time.",10.0,25
7163,7163,8852,158bc4a6a09d1d1f60a3174579dd63b17d40ca380bf126e52a49b005e6d33ba7bdbb0d4d003014825659fe0bdbb49f2fd5e45256e7b5b723af7ad889e792a934,"make a temp and point it to the front of the queue, store the value ""data"" of the temp in a variable and point the front pointer to the next current node then delete the temp using the free function",2.0,25
7164,7164,8853,188f5f32ff22cc30082222ed760e5fe1e0a340d9ae7ecfafe10b384746f7f9c7803d064927e2b5ebaba803119e7d5eafdd11883d383dd0d5a80b8dfe524c593e,i would use a doubly linked list since it takes constant time for all the functions needed to implement a queue .The push back function takes O(1) time as we will just add a new link at the back of the linked list and make the tail that will point to the previous link and also have a null pointer.The pop front function will also take O(1) time as we will just have to make the head point the the next link of the head and delete our previous head.The size function will take O(1) time as we will just return n items of which we keep track of.As for the front function it will also take O(1) time as we will only be return the reference to the first item in the list.,12.0,25
7165,7165,8854,042f0747487a4bd00158870bdd61aa0642e3092908b59c86040adb32b033044415ba779e2f72dddd4b2fd903b8027b6d8a9bbb87005066d4c2dd8814e02e0e21,"To implement an linked list with constant time I would use a doubly linked list. I would have to keep track of two pointers, e.g. head and tail where head is the pointer to the last link and head is a pointer to the first link. To insert at the back : Create new link and set it to temp. Set tail->next to temp and temp->previous to tail and update tail to temp. To pop at front: create temporary pointer and set it to point where head points. Set head to point to the next link and delete the temporary pointer. This will also take constant time as there is no traversing the doubly linked list. To find the first item I would basically return a reference to the first value in the first node(head->value) and to get the last item, I would also return a reference to the last value in the last node without traversing but by using the tail pointer( tail->value). All these will take constant time as no traversing or copying is required.",11.0,25
7166,7166,8855,39f1ebb534a7edaa837d48cbd4115f72e8c5e63b7a4efafc271bf59036c6638038d9febb4eab796e3f3e68165bcbad6c2e1a9ad37eb71f421ecdb12f31f4f4c5,"We would use a doubly linked list which is made available with a tail pointer and a size variable.

size: we simply return the size variable. Happens at O(1) 

pop: We have a temp pointer point to the head. We have the head pointer point to the next node. We then delete what the temp pointer points to. We decreace the size variable. Happens at O(1) as we call a destructor once and only do assignments. 

push: We create a new link with a tmp pointer pointing to it. We then make the node the tail pinter is pionting to have its next pinter pointing to this new node. We then make the tail pionter point to the new node and increment the size variable. Happens at O(1) as we call a constricter once and assign values to varialbes. 

Front: we simply return a refference to what the head pointer points to. Happens at O(1)",12.0,25
7167,7167,8856,5efe3fbf856ecf3a15a69292118ba94b4935a0dba8b272f0af264465d64a2e654697453d0e3e6e72201dc798f4cd3f27b28fbe0c2032a2a7784e39ed4c150909,"Type: Doubly Linked List

Requires: head, tail and link(that points forwards and points backwards)

Implementation:

(ADDING TO BACK)

tmp = new link(v)
tail -> next = tmp;
tmp ->prev = tail;
tail = tmp;

(PUSH)

data.push_back

(POP)

data.pop_front

tmp = head;

head = head.next();

delete tmp;

n--;

(FRONT)

t&front()

(SIZE)

Size_t",8.0,25
7168,7168,8857,8cfb9c3f85d9b6edb1f914f05f74928e81fe7cb4cefb95f1de4efb3fd1ac54a2356179dfe5b33b1cac09455e2960c015d866e1097ed5d7d20fbbdcb0d2aeee6d,We use a doubly linked list where we have a tail pointer and to add to the front we use a temp link. We then use a have the head point to temp->prev and temp->next is pointed at by the tail pointer and delete the temp link. To add again we use another temp link and have tail->next equal the new temp link and then have tail->prev = tail and then tail = temp and then delete the temp link.,6.0,25
7169,7169,8858,2edf0656134d19474a53dbbe5225dc2a3f4aaa1130b603fed547f4fc2584f94df9c6d11c108fecf09067c54daf57f86fbd618dbf612a4c65bf741c812ed66b6a,"You would have to use a Singly-Linked List with a tail pointer. This way the front of the queue can be the tail of the Singly-Linked List and the back of the queue would be the Head of the Singly-Linked List. Then pop_front, push_back, Front and Size would all take constant time.",9.0,25
7170,7170,8859,8c4ece10bea4707d74ad8e485b192cf388c1aaad3dd5b625cadaaa6a947d3861bc0547f235d6ff3af091e10ce08cd771b73e98b692a991cef32a92e7b557b387,"I would use the Doubly Linked List with a head and a tail and stores the number of items in it. Each time  a link is added, the link should point both backwards and forwards. For adding an element I would use push_back() and pop_front() for deleting. I would use size to check the number of elements. Lastly I would use front to check the first element. ",8.0,25
7171,7171,8860,de345146608f48652cf9ec333ad07816bb0cf99089477ca7af207bce7f9f2c81b03f0e317efccc60f220182480d765ee6b6291c08b7723e7e91dd8402a584cdd,"I would create the Linked list that has both a head pointer which will be updated when data is popped from the front and a tail pointer that also stores the size of the list that will be updated when data is pushed to the back.
This means all operations are constant time as pop front would be done by getting the pointer to the next link, deleting the current link and updating head, push back would be done by creating a new link, setting the link tail is pointing to, to the new one and updating tail to point to the new one, front would just be returning the data at the front, and size would just be returning the size that is stored with tail.",11.0,25
7172,7172,8861,cdf5a55df376657eda6b008ced4f7043cdba2f1d1b7da216b9e5df9fd11e894729a95890612c52ba24c8f6e0b1099b039f557d8043ee19615f361b8a60481af7,"You would need a double linked list.

Tail will point to new link. Head will point to previous pointer.

And we can then say:

tmp = new Link(value);

tail->next = tmp;

tmp->prev = tail;

tail = tmp;

To add to queue:

   push: data.push_back, which is in constant time.

To remove from front of the queue we can say:

    tmp = head;

    head = head->next;

     delete tmp;

and we can translated that into: pop: data.pop_front, which is in constant time. 

and front and size in a list is constant time. 

 ",10.0,25
7173,7173,8862,b65e52333a31f01a7d7a5dae0ff6fc8ed82b8b5283406f591e8d448f865292ea8162938b0259891df516358cc77c51dca3895b350dbb36cf96d6c23e9b3fa27a,You would need a backwards linked list so that all the functions would take constant time. Using a backwards linked list with a counter for size allows for the size function to take constant time. The pop_front will take constant time as there will be no values after the first one since the list is backwards meaning no copying or moving of values needs to take place and push_back always takes constant time unless the list is full and needs to be moved to a larger allocated space.,8.0,25
7174,7174,8863,24404807247a19fa0eb28edfebfb33701c7bf0ce5da4f252098d5b07602e418852b18cd29763fdb981a6cf7530167e7c60c21dd57b0dd95a95c25a71b9515eda,We can implement a queue using a doubly linked list which has a tail pointer in order to allow for all the operations to be of constant time.,8.0,25
7175,7175,8864,5f1f48eaee5ac422a3c6fa6a37eae574e54bf5c31dcf24e0e6dda503da6ac10d5be4b86335df2a703c5cb0a92be355a3535eec42ddde1a798228e8594808928b,"In order to use this strategy we must use a doubly linked list.

The size() function will have a time complexity of constant time, as there is a counter that is included in a doubly linked list, and we just need to return the value stored in that variable to get the size of the list.

The empty() function will take constant time as all we have to do is to check that the head pointer is not a null pointer and if it is we return true. 

The front() and back() functions will also take constant time as we just return a reference to what the head and tail pointers point to respectfully.

The pop_front() and push_back() functions are a little more complicated. In order to implement pop_front() we will have to create a temp pointer and point it to where the head pointer is pointing. We then move the head pointer to where the _first_ link will be after the popping. We then set the prev pointer of the new first link to be a null pointer. We can then delete the temp pointer which will remove the link that used to be our first element. We then reduce the variable that stores the size of the linked list by 1, in order to account for this change. As this process involves a constant amount of operations and all of then are either assignment, deletion or changing the value of a variable by a set value, it will take constant time.

In order to implement push_back() function, we will have to create a temp pointer that points to a new link. We then set the next pointer of the link that the tail pointer is currently pointing to, to point to the new link created by the temp pointer. Appropriately, we set the prev pointer of the link that the temp pointer points to, to point to the link that the tail pointer currently points to. We then set the tail pointer to equal the temp pointer in order to move the tail pointer to its appropriate position. We then increase the variable that stores the size of the linked list by 1, in order to account for this change. As this process involves a constant amount of operations and all of then are either assignment, creating a link or changing the value of a variable by a set value, it will take constant time.

Thus all functions that are needed to implement a queue using a doubly linked list will take constant time.",12.0,25
7176,7176,8865,6a7a49da689922560451287b4e285dafdb4a0bfd283c9d3d5a6941f50de9e8434c4baab959d6ac95be4270bc3e3b12632437fec1cc1ffa0e88747c0a4bcc97e6,"A doubly linked list would be most ideal for this strategy. With a head and tail pointer. Each link points forwards and backwards. This will help make all the operations(push_back(), pop_front(), front and size) constant time.",10.0,25
7177,7177,8866,f786d4a53e476362ee6b6cac013b5aa057803211cb74556b039162da9be82c23d9395512d9e4320c69ff2f74e18df3e862b758b12f302cbbc8a9df857835a235,"1.define a node structure with two members data and next.define two node pointers front and rear and set both to null.

2.For enqueue operation create a newNode with given value and set newNode->next to Null.check whether queue is empty and if it empty then st front to be newNode and rear to be newNode. If it not empty then,set rear->next to be new Node and rear to be equal to newNode.

3.For Dequeue operation create a newNode with given value and set newNode->next to be Null.check whether queue is empty.If empty then set front to be newNode and rear to be newNode.if it is not empty set rear -> next to be newNode and rear to be newNode.",4.0,25
7178,7178,8867,2f496bb2a99de18fa436df0deced0620c47daee5ce37cf49cf6b3200c20eb84e5a9b7a47850d29ff143886bc9932f54f86b6a1101a1d0f70874e22b40b657cec,"you would use a singly linked list with both a head and tail pointer. you will be able to enqueue

The new element will be the last element of the queue.Firstly, allocate the memory for the new node. when we insert element into an empty queue. the condition HEAD= NULL becomes true. Now, the new element will be added as the only element of the queue and the next pointer of front and rear pointer both, will point to NULL. otherwise, we need to update the tail pointer so that it will point to the new node ptr and update point to NULL.
 (add an element to queue) and your tail pointer should point to the last items in the queue this will be in constant time. you can dequeue(remove an element from the front ) and return the first item in the queue by having your head pointer point to the first items in the queue and this will therefore be in constant time. to find the size of the ",10.0,25
7179,7179,8869,55fe3fe2f479a6880b0c712c4e8a68696125fae47531859339e76b32fd81a881527cd93fc43bbd4116f56991339ff706e490311026cb817361fafa6e47ec0b11,"You could use a singly linked list with a tail and a counter.

Size which usually is the only O(n) time would become O(1) with a counter which would become counter++ for push_back and counter-- for pop_front.

pop_font(),push_front(),front(),size()(/empty()) will all be O(1) time therefore it would be constant time.

Alternatively you could use a doubly linked list.",11.0,25
7180,7180,8870,b62178f325a37f31c95fa1765add6431ffda3b6e9e137a6c1634820014c3bfc3f4c574a7130344e47d262896d038b700c7e7372470c7667fbf621506106a2a97,"We would implement the queue with: either a double linked list or a singly-linked list with a tail pointer and a size variable as our underlying data structure.

For the double linked list, all functions will be O(1), and for the singly linked list with a tail pointer will give constant time for push_back and a size variable will now give constant time for size() and empty().",10.0,25
7181,7181,8872,bd50a1f76e0acde64b2131110f2268f08aef333a162fed075d374337a58f0180c5f1efb88a7f6560e676d09d9ae71856da1ed18b029ff6c96af885a57d9fef75,"i will use a doubly linked list in this case.

for my push function i will have data.push_back() , for my pop i will have data.pop_front.",3.0,25
7182,7182,8873,c52fe90555e82813bbf7f31602e97c4095475fbbf85ff26471f0158158110480233228486a71767a61c524c47fe301d427e9bdbb31f3216eb95878f59314ec4c,You would need a doubly linked list or a SLL+tail(Singly linked list with a tail). We would use enqueue and dequeue to manage the nodes. The reason the complexity is only O(1) is beccause we only change a few pointers in both operations.,6.0,25
7183,7183,8874,dc016101375a4c30fa08c850e4ef82abdd66ca922170c25b2eda3c6f7009abcdda2dafb1c86a512fdd1b897c4c9da94be8f7047b535d50f3a259b1e698b13e05,"In order to implement a queue using a linked list where all the operations are constant time, we would use a doubly linked list. 

Implementing a queue using a doubly linked list, we pop from the front and push to the back. We have a variable which stores the number of links in the doubly linked list (n). We have both a head and tail pointer. 

In order to implement the pop_front function:

- we create a pointer pointing to the first item

- we make head pointer point to head->next

- we delete the first item

- we decrease n by 1.

- this all takes constant time O(1)

In order to implement the push_back function:

- You create a new link called tmp (tmp = new Link(value);)

- You make tail -> next = tmp;

- You make tmp -> prev = tail;

- You make tail = tmp;

- You increase n by 1.

This takes constant time. 

For size function you just return n which takes constant time O(1).

For the front function, you just return a reference to the first item in the list. This takes constant time O(1)",12.0,25
7184,7184,8875,e5092ab1c7e17d25e5db9dfc9252b8c31679cb1e2b17a0be836efd97ce606988409f994ae92e4e1f795d2d139fe2c46eff4d5f244e605f9f08c46d7129da95d2,In order to implement a queue where all the operations are in constant time a doubly linked list would need to be used. This allows a constant time run functions as each element in the list has a pointer to the element before and after it. This type of a list has both a head and a tail pointer which allows us to easily access the front of the data in order to remove or pop a value and it allows us to easily access the back of the data using the tail in order to push a new value. This keeps all the functions that need to be run at a constant time.,10.0,25
7185,7185,8876,072df8e3c1de059673d8b782c554cf64da21277fb2ba12d1d8f4ab73cd1269538ca3968b89e11ecaa84835030161cc68c0efae276a64b66f06c4f0c8a0d2ada3,"we would need to use a doubly linked list.

push:

tail -> next = new Link(v);

tmp-> next= tmp;

tmp-> prev = tail;

tail= tmp;

data. pop_front():

tmp = head;

head = head-> next;

delete tmp;",6.0,25
7186,7186,8877,d0487881fde4213facde4c9cd0143d5802f701e002f130b7eaa6dd04f68f58612ae33c39c89beceae1495437bbe2376be3003369a31f0f2bc6f9e0c5a369707a,"These would be done with the use of a doubly linked list so that all procedures for this are in O(1)

Peek : return the first item added using the peek procedure -> Always O(1) since this pointer is always available

Push : add an item or link to the back of the list using the push_back function -> Always O(1) because the pointer to the end of the list is always stored.

Pop : remove the first item in the list using the pop method -> Always O(1) since no copying has to be done.

Size : return the number of items in the list -> O(1) since the number is always updated when adding or removing items.

Empty : return whether or not the list is empty -> always O(1)",12.0,25
7187,7187,8878,73f8ac3de0d9e29b34984491080a2a437e9d07081ef998fb53c2e73bde6a76efa33589c04809db77b67bfaaea71b13e4b7480f42fd75bb56aca6e9a4110b16f7,"I will use a linked list that has a tail pointer to the last item. For a queue, we will add to the back of the list and remove from the front of the list. This mean that we can do everything in constant time as you only need to update the tail pointer when you add an item. If you had wanted to pop from the back and have the front of the list be the back of the list, we would have to traverse the list every time to update the tail pointer to the new front of the queue which would be very inefficient. Therefore, we will use the front of the linked list as the front of the queue and use pop_front to remove items; and the back of the list will be the back of the queue and therefore use push_back to add items, and also update the tail pointer to point to the last item to few the last element in the queue.",10.0,25
7188,7188,8879,ee3d89b0d1151de34e3cf3043fc2b6592a400e8ce8a1d14d3b5e77f1fc57f3bb24de4a9c4426effca79ea565b502539dcf46a1f1d27d52e0d1e79029ce2f8aab,you would need a doubly linked list to get all operations in constant time. push_back would be constant because  since you are keeping track of a tail pointer you can add an item to the back in constant time. pop_front is constant because since you have a head pointer you can remove the fist item in constant time too. front would be constant because of the head pointer and back would be constant because of the tail pointer. empty is always constant so that would be constant too. size would be constant since a doubly linked list keeps track of a the number of items in the list.,12.0,25
7189,7189,8880,e9f55a461571038daf39646f8c350339a639982fda3a68a7de2c663bf3b55fcfe5c2c1470245e6cd83dc29b1d2c16e474b9b4bcd8ac2d4eb9b9e2eef6125ba6e,"you would need a doubly linked list in order to get all the operations in constant time.

size would be constant because a doubly linked list has a built in counter 

push back would be constant because you store a tail counter and thus enque would also be constant ",9.0,25
7190,7190,8881,2dec7d91f389ea815b08c16bf0ce77e60642ceca404945e8ad369e8ed82ed28e57d6cf12351d45add693d36c78a2ba5f4910e162bacba9689368c6699766d9b3,You would use a doubly linked list to implement this queue. You would use push_back to add to the back of the queue and implement a pop_front function to remove from the front of the queue.,5.0,25
7191,7191,8882,a39aa34c391034439ba958ca98869143599e2cc20097d4066633e71706d0b615be58b0586a9143631148978c46ccf7746504f4abfa225c0f60b106eb68d6aeb5,"A doubly linked list would be needed to access the front and back in constant time (for pop front and push back respectively). 

Popping front is simple as accessing the head of the linked list, creating a temp variable to point to the second item in the list, removing the first item and pointing the head to the temp variable used then deleting the temp variable. Similarly for push back.

Similarly, the head is the front of the queue and can be accessed in constant time.

Inside the doubly linked list I would make sure to include a size variable. This means we can simply access the size variable in constant time.",12.0,25
7192,7192,8884,e40d8bf3b05bd8e034438beb235a1631a28b193d6edc5587f765a26d4981e60fae4fcb9a995036a1c2815f2073b85fc4667e3d6bbfc0e5a63b847c8fa219ba80,"If you kept a pointer to the last element of the doubly linked list — lets call it the ""end pointer"" —, you could push onto the queue in constant time. This can be done simply by adjusting the last element's ""next"" pointer, which would have been null, to point to the position of the new element added to the list, and then setting the ""previous"" pointer to point to the same place as the ""end pointer"", and then setting the ""end pointer"" to point to the same place as what the ""next"" pointer in the element it is pointing to, i.e. the newly added element. 
This strategy would also allow you to access the back element of the array.

If you also kept a pointer to the first element of the doubly linked list — lets call it the ""start pointer"" — you could pop from the front of the queue by creating a temporary pointer variable and setting it to the value of the ""next"" pointer in the front element. You can then use the ""start pointer"" to delete the former front element and free up that memory, and the set the ""start pointer"" to the value of the temporary pointer variable. Finally, you set the ""previous"" pointer of the front element to null.
This would also allow you to quickly access the front element of the array.

A variable tracking the size of the queue that is updated whenever an item is added or removed to the queue can be used to get the size of the array and subsequently check if it is empty of not.",10.0,25
7193,7193,8885,86a089b08f86e9c1d63b469ed69474a00b3c8a302414b59395dac01ecff0bf909a9721c007531f0f7d3273bab8151790358055f69bbfd852502b400b0f09160c,"Single linked list that stores the head, tail and size of the list.",4.0,25
7194,7194,8886,3d5672708313ecdecf3f1bac84303e47d2cb39b8840c7477b8533d1e068614b468fd7d22ee29e9082419dadb2d36cb98607131a6fdfff05e1696dee4c36a9722,"circular linked list. I will use head and tail pointer ,the tail will point to the head. and keep track of number of items in the list and the index of the current item. I would increment the index whenever an item is remove from the list. When the list is full I add the items in the front of the list.",5.0,25
7195,7195,8887,d5acfd7b46a030b29f7c66a4b1581ff2012d0ccf49d5bca978171e9bdeb669a4e3f41049f7e32dc031f0947e94ce07cc6178891342c05dfe3c3aefc0b7389e15,"You need a single linked list that can store the head, tail and size of the list.",5.0,25
7196,7196,8888,5b103254d925dd6e3b174e61c476c0236ecf2693d2ac2a0aa4d18d2cf221dba0746f3ab2a53cdbb7b2e2ec6bbec5ce7f7f68c55ddc1288518cce45cdf1989c43,"* Make a new node (node *tmp; tmp = malloc(sizeof(node))).
	* Give the ‘data’ of the new node its value (tmp -> data = value).
	* If the queue is empty then point both ‘front’ and ‘rear’ of the queue to this node (q->front = q->rear = tmp;).
[First node in queue]
	* If it is not, then point the rear of the queue to this new node and then make this new node rear (q->rear->next = tmp; q->rear = tmp;).
[Enqueue in C]
	* Increase the ‘count’ of ‘queue’ by 1.

void enqueue(queue *q, int value)
{
    node *tmp;
    tmp = malloc(sizeof(node));
    tmp->data = value;
    tmp->next = NULL;
    if(!isempty(q))
    {
        q->rear->next = tmp;
        q->rear = tmp;
    }
    else
    {
        q->front = q->rear = tmp;
    }
    q->count++;
}",1.0,25
7197,7197,8889,0299c9665122a8d00cc0df25e8e955973b075c02ae0224028d3e17e0f6c78e173fd5823d4f6996d851096c01dce443a63e66dd04d704cdc88987434a35c7ee6d,Enqueue ,0.0,25
7198,7198,8890,297de9e92f0b5f666b5f42405cac621415fb2c64763fdc11b8d57538dae3ffa9e272dd3efdad0a974813033e43539624b9741e3632c9573318e9a12bea633c7a,"We could use a Doubly Linked List. For this, we would simply need it to be able to reference the head and the tail. We would need to be able to, via the reference to the tail, add a new value to the end of the list by saving the current reference to the tail, inputting the new value and then resetting the reference to the new value. For removing a value from the front of the queue we would simply move the reference to the head of the list one value down.",5.0,25
7199,7199,8891,d7ea0f2a38310b663df581928807c739d1135118819d5b7623733f4d054b7f50d32672538781df6012ffae2751400911c7d428efb70c05b3c3719b6aef5da475,"In order to implement a queue using a linked list with a time complexity of O(1) , we would need to implement it using a doubly linked list with a head and tail pointer. When we use a doubly linked list with a head and tail , we gain access to the front/head (dequeue) in constant time , and we gain access to  rear/tail ( enqueue)  in constant time. In order to also get the size function in constant time we need to create a variable that we increment every time we add a new value in the queue and decrease by one , each time to dequeue a value from the queue. ",12.0,25
7200,7200,8892,b47128b210e7cc636fb0b5325c08248ffac624374ed1eaac62c3594d5f67da91cc887cbf07a6c3571b2149ad963910548cff788f165204f9df156115e859a64b,"A doubly linked list is required to do the operations in O(1) time. 

	* When using push_back(), one can take advantage of the tail pointer and simply add to the back in O(1) time.
	* When using pop_front(), one can use the head pointer to remove the first item and reallocate the head pointer to the next first item.
	* size is O(1), because there is a running counter as something is removed/added.
	* Front is O(1), because one can simply return the value that the head pointer is pointing to.",12.0,25
7201,7201,8893,38046b991658125dabc236638e4678ce8b6ce1a14066e89cee307b4ad43150545ef075aca8b10f61c4cd3909f6915397eea519e89ce5ad74fb62a1715837f925,"To implement a linked list for all constant-time you can use a DOUBLY LINKED LIST or a SINGLY LINKED LIST WITH A TAIL POINTER.

ENQUEUE

To enqueue on a normal forward linked list one would need to traverse through all the values in the list of all the links to add the next value i.e O(n). Therefore to compensate for this we can add a tail pointer that will keep track of the back of the linked list so whenever we need to add a value we just add upon the tail pointer. 

DEQUEUE

You just delete the head pointer but first, point the head pointer temp link and then update the head pointer to the next link, and then you can delete temp.

SIZE

should keep track of n_items therefore should not need to traverse through the linked list.

FRONT

returns the head of the ",12.0,25
7202,7202,8894,7c7ea0f0ba70a5ea36a02ae9d7f97eb067c3d269f5589f4e06abe536b27c016f062f66e013c160a950a6482d28c9fd24dacd097df0afb924b649425eca6be261,Such a queue can be implemented using a doubly linked list. When we do all our operations we won't have to traverse through the entire list.,4.0,25
7203,7203,8895,d7e19f96a6aba1e381d06c4d14cd8af55d98ac1778548325b5d3026d929df87b2abc3d523dd5623a58ab296187735de8598844f1ea29e935b29ced21ed87e297,"Taking a singly linked list, we know that the pop and front functions are already take O(1) time due to the head pointer. To make the push and back functions O(1), we implement a tail pointer. To make the size function O(1) we simply implement a counter that increases/decreases as items are added or removed.",10.0,25
7204,7204,8896,b3e3cb2c21ce148370b5e2f91fd1c15e350a5dbb48b70710937a60df00151bac26d80bc3a7bdad4c31eb69ebb35264a7c7773c7f45cef6e057b05eb18d125d01,"The queue can be implemented using a forward linked list in the following steps:

step 1: Allocating space for the new node.

step 2:Pointing a temporary node to the front node of the queue.

step 3:store the value of the content in the new node of this temporary node in a variable created.

step 4:Point the front pointer to the node next to the current front node and continue",5.0,25
7205,7205,8897,c718924f7c8d9a7a64a6ff4f30cf0bd792fd01badc8e93c67bb9f465f99e38ae7a35ce6981a32a52aefd75b95f9c2030a30069dc473e0db1d92882cea2629f0f,"I would use a Singly Linked List, as I would be able implement my own tail. I would use a Singly Linked List because when one is keeping track of the head and tail, inserting items at the back is really easy. By storing a tail and keeping it up to date - that allows me to go straight from tail to adding a new link and then updating  the tail to point to the last item. This makes all of the operations constant time.",8.0,25
7206,7206,8899,8898c8dc647252a67895b09c0b6e1e1b46e9abbd7623ddf40416335c9bffe71bf94348a71bd79a7ce33d630fd22f8d8b30ee288c330b6c240bf1f662dbee2a5b,"Using a ""Doubly Linked List"" which is a List in C++

This list has all the functions necessary and they are all in constant time namely

	* pop_front
	* push_back
	* size
	* empty
	* front",10.0,25
7207,7207,8900,bee12730d57033f530e6d3af850b801527bbf28710ff5b08a5e590d280e30c6a0345b61d0e3b24cafaad1628aee3191406710ce83cd7009c586afaf78d031389,"I would use a singly linked list with a tail pointer and variable to track the size - that way I can have access to the front, back and size of the list whilst avoiding travelsals that take O(n) time.",5.0,25
7208,7208,8901,d14b989bcb894978cca36e7e5f61001f5674d5a63e03700520c57accee4d5d7687b97d71bfffe56071d64d16c01c84e867fd79ad35b152d9c5667b7efa04e45e,"We need a doubly linked list, where we take the front of the list as the front of the queue. The use of a tail pointer allows the push_back() function to be executed in constant time. The same thing applies for a push_front() function with the use of a head pointer. The std::list keeps track of the numbeer of items int the list, so a size function takes O(1) time. Front and back functions also take O(1) time because of the head and tal pointers.",12.0,25
7209,7209,8903,f682ecdc1752e81b56fe41b112e9132a1831f14cd9ba0ec72eae2c8c098b94a2736f903a3211d58aeb928498913e4972f6d3f995b03aff3dca7903b620bfdd1e,"Use a doubly linked list

add an item at the back

remove from the front-(pop)",4.0,25
7210,7210,8904,7d8cef0de14cc2a74c530bc45e24878a9bc41b99484642b220015c976fedb5143bed1f3d3d656335fb8356093aebda35cf38a76a3da63375271eacce35baf518,"Doubly linked list is the best one to be used to have have constant time for operations, the best way is to keep track of the number of items. Push_front is constant time because we don't traverse. Then for pop_back we only say tail->next=new Link() and prev of the new link points to tail new link, size() and front() takes constant time in doubly linked list.",11.0,25
7211,7211,8905,d320af019b5c5fbf5996000b6f0c018e158d92ab05c3709236e5a03a6b328c59c1ab963403ff89c119e51b19d4eaa6320e2573a8bf4efb41ca5bbf92364ab8b6,"We would do this by implementing a doubly linked list.

A doubly linked list keeps track of the number of items stored, therefore calling the size function will be constant time O(1).

The Push_back (data.push_back) function, makes use of the Next pointer and the Previous pointers. By assigning the Next pointer of the current link to a new link and assigning the Previous pointer of the new link to the current link, and updating Tail to the new link, then incrementing the size pointer, the push_back function can happen in constant time O(1). 

The pop_front (data.pop_front) function, happens in constant time O(1), as we are simply changing the head pointer to point to the next item in the list, eg. if temp is a pointer pointing to the first item in the list we would say head = temp.next; and then we would delete temp and free that memory, and then we would decrement the size variable.

The front function will also happen in constant time as we have the Head pointer pointing to the first item in the list.",12.0,25
7212,7212,8906,0b4066304490dceaa89df857c52096e501a361b0158a4122fe0743ccedb637acfd51e379e86df6a8a4f667a87b6d33f81aa5b4a035dd7d71db1ee1c7171afd95,"For this task you should use the doubly linkedlist which has a tail and an additional counter variable which would return the size of the queue. This is the best structure for this task as it can enqueue(which is updating the tail to be the new item, making the last item to point to the new item and incrementing the counter variable) at constant time and dequeue(which is making the head point to the second variable in the list and deleting the first variable, while decrementing the counter variable) at constant time we would also be able to get the size(by just returning the counter variable) of the list at constant time since there is a variable which stores the size on every move we make",12.0,25
7213,7213,8907,24ddd7a0d5b35a9bdbeb9a6cd62ada87a4901fab347efd86489f1b2e17964822556ee10a0103983d49fdf2477d3d64f6702d59741c364edd11f42906c3bdb067,"I would use a doubly linked list with the push back function, the pop back function and, front function and the size function. All of these operations are in constant time. ",8.0,25
7214,7214,8908,f64eaf53775ca019aa46e95d674f953f5fe42b8661af69f4cf932eb77a69c0b6057310158946905b9d5788a5b3a8acd5e3f0f489603023b3ef81fc676dabaddd,"we need double linked list

enqueue(): this operation adds a new node after a rear and moves rear to the next node

dequeue(): this operation removes a new node after arear and moves to the next node.",5.0,25
7215,7215,8909,2752a012a3acfc041a30d5a655085eade0eb440b54f67d20ed248f27ebf41fd19d90129f4fd7d4c48bc1b7b721b3638118e357f1785837b03bc7def7da08253e,"We would use a singly linked list with a tail pointer and a size variable. This lets us go straight to the tail pointer to add a new item to the queue instead of making us traverse through the whole queue first.

This leaves us with O(1) for all the functions of the queue besides size as we have to traverse through the list to count the number of items making size O(n).",9.0,25
7216,7216,8910,21f09107df149216c5f40e2d6eaefa443c1ac6ce9ddec594661383f2e53455e2769bfb1bb81bee158e80bc0b01db2da739108bc4386c15bb286ac35afa1a5409,"To implement a queue using a linked list where all operations are constant time you would use a doubly linked list. In this implementation, the front of the list corresponds to the front of the queue and the back of the list corresponds to the back of the queue. The function push_back would create a new link and make a temporary pointer point to the new link. The tail->next pointer would then be updated to point to the what the temporary pointer points to. The temporary->previous pointer would be updated to point to what the tail pointer points to (points to previous link). And lastly, the tail pointer would be made to point to what the temporary pointer points to. This is done in O(1). The function pop_front would simply remove items from the front of the list. This is achieved by making a temporary pointer point to what the head pointer points to, then updating the head pointer to point to what head->next points to and then deleting what the temporary pointer points to. This is done in O(1). The function front will be able to access the front of the list in constant time as well. The function size will also have O(1) since a the number of items in the list is kept track of and can be easily accessed.",12.0,25
7217,7217,8911,07ab043d70e14725f955703ce65a95b6912342e429a6c9a7dec43aacd53b63f2b0d3ebef4da8ffdff01a86c6c296ffe0e21e4d798223854fe6e651460e1d7280,I would use a doubly linked list with a head and tail pointer so that all operations are O(1).,4.0,25
7218,7218,8912,11033a17d67159be6a6bbc8378c0392c95d06eb759a822fa4a4ab3fcd33a9e9c6b4e8e1a2ffedc295aecb757927d81558a966188674240b280a874a24f0debc2,I would need to implement a singly linked list that has a tail pointer and a size variable. This would allow us to go directly to the tail pointer to add a new item to the queue rather than making us go through the entire queue. All the functions would be O(1) besides size.,9.0,25
7219,7219,8913,dc28526a371ecd3cfbb01f874b966e2e2019f65befa98a250b0089b346a7e303549dac2ead3ffeef0d3b7ecff19ac3d890b35956aa010524ff365cf1275bd971,"I would implement it using a doubly linked list. This would make it easier to implement the following functions.

push_back - this would be implemented by creating a new link after the last item, (eg. tmp = new Link(var)), then update the tail's next pointer to point to the new link. The new link's (tmp) previous pointer should point to the tail and the tail should be updated, by pointing to the new Link.

pop_front - this would be implemented by creating a new variable that points to head. Then, head must be updated and point to the next item on the list. And, the new variable (pointing to the first item on the list) should be deleted.

front - the first item on the list, which head points to, it's value should be returned. ",6.0,25
7220,7220,8914,0745491c3d066e21ade2f2d4d85d4695dac91b9131eb26e8aed287a29c7e24ee4d3c6beb342324906b0ab6475785f0d2fea5c9799af48cbec9547c62e95d041e,"I would do this by again treating my linked list as a circular structure (circular linked list). When enQueing a value i will check to see if it is the first value and if it is it will get the front of the queue else it will be sent to the back.

the deque operation will check if it is empty, only one item or if there are multiple items and thereafter go on to delete accordingly.",5.0,25
7221,7221,8915,68fe12a6f9e2217ee251160c4237430d186ca3b8284710c350ca5f0256d2abc683b1a854a2f30cab6e69feb98c61fbf1aee4d6e9df2ab12a86588aec00a8c95a,"head = new Link(v);

tail = head;

tail->next = new Link(v);

tail =tail ->next;",2.0,25
7222,7222,8916,59ba65c517c334e25d3ae45ca0766a06b5a36061abfca1dd80f0f9e00eca00b8fc96224e4fcd721b2a66146a086c07a1cca9cf5028a8fc5d88a04890a96fe5a7,You would need to implement a doubly linked list that can point in both directions. ,4.0,25
7223,7223,8917,9dc85d5fc9d9d7b3ced470df92bc3f618b906428cc44daba96ce09d4da7c5e6251f817ad8b6d168d5489d3951e1d39f87f0ab87e50f2ae36060fe5a0c0501b6d,"Using a singly-linked list with the size and a tail pointer stored can achieve constant time complexity for all operations, but it is much cleaner to use a standard list, which is a doubly-linked list with the size stored. To fulfil the requirements of a queue, you can implement the list as such:

enqueue: this function is a problem for a forward_list because it would require traversing the list to get to the back and then pushing the new item, but a standard list has a tail pointer. Dereferencing the tail pointer and updating the item's next pointer to point to the new item will take constant time and is simply the list's standard push_back function (the same process for a singly-linked list with a tail pointer).

dequeue: popping from the front is easy as the head pointer simply needs to be updated to the first item's next pointer, making sure to free the memory the old front was using. This will take constant time and is the implementation of the pop_front function of the list class (the same applies to the singly-linked list).

size: because the list class stores its size, this value just needs to be returned, which will take O(1) time. Storing it for a singly-linked list will achieve the same thing.

front: simply return a reference to the first item by using the head pointer. This is a stored value so it will take constant time to return.

(empty: return if the size is equal to 0. This will take O(1) time)*

(back: return a reference to the last item, using the tail pointer. Again, O(1) time)*

*I've used rounded for these functions because they are not necessary to implement the concept of a queue, but C++11 requires their existence to use the class as an underlying data structure.",12.0,25
7224,7224,8918,b1a3a9f62a3efb88815155da55fbf2f2fafa14dd37234e9f11b5f00a231a31fde1494bd63f6ac5858aefb97ae2c7130be129cb66d65efd0dfa784ad99b296be3,"A Doubly Linked list would need to be used in order for all the operations to occur in constant time. The Doubly Linked list works in a way that every time a new link is added it would point both forward and backward. It also keeps track of the amount of items in the list as well as a head and tail pointer. If we needed to add an item(Push) we could simply use the push_back function and that would occur in constant time(O(1)). If we needed to remove an item(Pop) we could simply use the pop_front function and that would occur in constant time(O(1)). It keeps track of the amount of items in the list, therefore the size function would occur in constant time (O(1)) as no traversal is needed. If we needed the front of the list we would just return the value in the head pointer and that would also occur in constant time (O(1)).",11.0,25
7225,7225,8919,5ac95126c93bab762f619ae6d9e0457a3ae69e32d351c6f444adf2fed30efe3915f7f9845b1ec549d2f270b573f92967241b205877e7a669570b3a332b14617a,I would use a forward list which also stores the tail of the linked list. Push back will have previously been done in linear time but since we have no need to traverse the list to find the back it will now be done in constant time. For size I would initialize it to 0 and make sure to increment it whenever a new item is added. This means that the size function can now be done in constant time since there is no longer a need to traverse the list.,11.0,25
7226,7226,8920,ac00d5695452023736c168247b6e6e7ac1c86c1918ba65ce039a3ac355db0c0c6d3945a25b1f4c24df8db20417ffdf726ff5a44586e3fb4757147f393e36515b,"I'd use a doubly linked list. The front of the list will be the front of the queue and the back of the list will be the back of the queue. I will push elements to the back of the list, I will use a tail. I will update head to remove the front of the list.",5.0,25
7227,7227,8922,8a8eb86cf56dd2444d2bc5441387c73e3fcbac4867da844d41e7ee67a78c9e8b163da9822047fef10101762a7abd4eba2ff040d29869420924f78a2c686ad858,"I'd use a doubly linked list which keeps a head and a tail pointer as well as the size. The node includes data, a next and a previous pointer.

enqueue = data.push_back(Thing t)            O(1)

dequeue = data.pop_front()                        O(1)

size = doubly linked list stores size             O(1)

front = head->next                                     O(1)",10.0,25
7228,7228,8923,43337822a8495f6346099bee6f1b1379846d1e116a80358eff95ac9a35a5e9db993d15f49931c7a4d1543bc7328dae0e418202f217ef071778281db16cfc2fe9,"One can use a singular linked list that has a tail pointer. One can store the value of the size of the linked list in a variable to allow a constant time to return the size. The tail pointer will remove the process to traverse through the linked list and you can instantly add the thing at the end. The enqueue, dequeue, front and size functions are all constant time O(1).",11.0,25
7229,7229,8924,5e36a0e7b93c9d082984c03228c748a0348993dbc7307752e7acfbf7e44b3df39b6aedb0dd5c68b0421254e8914343a9e052d4d15e260e3ecd7ef28810b12ec9,"A doubly linked list needs to be used. 

As there is a tail pointer and a head pointer the linked list does not have be traversed in specifically for retrieving size() and push_back or pop (depending on which side you've decided to make the front of the queue), eliminating the possibility of operations taking place at linear time. 

A doubly linked list also keeps track of the size of a list, allowing for the size of the list to be retrieved in constant time (in comparison to singly linked lists which take a linear amount of time).",12.0,25
7230,7230,8925,105766c5f6c790d6dc620b520090a2b98c0a0346078f36035aaeb57fa8cf54742716f9a0480d2973b6fef7f78bbaa5ba4bda7aa17dd42f5bc2f195af88fa494c,"A doubly_linked list would be needed for this strategy

struct Node{

    int data;

    Node *next;

};

class Queue{

    public:
    Node *font, *back;

    Queue(){front = back = nullptr;}

    void push_front(int n)

    void pop_front();

   void dislay();

    ~Queue();

};",5.0,25
7231,7231,8926,ff19555f4968eaf6b17bb10af6db84bf6855788e0e3b7ee821c1ffda56b494a21c444a2b2d428df7663376a15417c71a0487c22f17f2e142320070a4287c2554,"Using a doubly linked lists, we then implement the push_back by tracking the tail using a temp  link which will be in constant time  since we can always track the tail of the lists. Also pop front , take constant time since we always have track of the head pointer. For doubly linked list accessing the front element and size of the list is done in constant time.",11.0,25
7232,7232,8927,17ea794106565b342d0071ecda1b602670f938db088b102cae298b8fa539f99c81604db8696804a94225d5fcb56b3538a2b45e5527c8d0a393e5e2aa5ae7c0be,"In order to implement a queue using a linked list where all the operations are O(1) time, a doubly linked list should be used

For the push back operation, we could simply say:

tail.next = new link(value);

tail = tail.next;

For the pop front operation, we could implement this as follows:

tmp = head

head = head.next

delete tmp;

For the front/peek function we could simply say head.value and for the back, tail.value

The doubly linked list also keeps track of the size of the data so we would be able to retrieve this in O(1) time as well.",12.0,25
7233,7233,8928,67d402955c162ab6452295b6b5d26eba2d31759d3c95b63363fb0f3d4d6e0b04ac632a790b3b479c13437abea8e6208b9e8122018f1333c3a720caa36adbe27b,"We would have to use a doubly linked list.
For the size function, we keep a size variable that we increment every time a new list is added and thus whenever we call for the size it will always be under constant time. The front function will be done by calling the head pointer which points to the front of the list. The push_back function will be done in a way that since there is a pointer to the front we can add in constant time same goes for adding to the back since there is a back pointer for push)back.",12.0,25
7234,7234,8929,efd232e6edf06b095e712e68f8ce8701b452d03344874ec8e202c3b1c55dd0c8b72d40f2859eacbda02e8a7ae034ecba2b74f48d8999907073f237d2d351e8e6,You could use a singly linked list with a tail pointer where you would push back and pop front.,4.0,25
7235,7235,8930,27b7c01b5507de27227f1b4c06fa92833846a84fa96c3732f3663fb00fd83e6f0c7c3e711cd797752bf30bb3a828ffa9c255dc629b8adb95ea32e0eed6535409,We would use a doubly linked list. We could have a head and a tail that points both forward and backward in a list. To add to the back we would create a new link then point the last link's tail to the new link's head and the other way around to have a doubly linked list.,6.0,25
7236,7236,8931,a44191cff1258114ca99a354cbcf13b3d3a3dcbbff75ad642f883f0afb3c431e62d034975452796897dce8086c431437065cbc80fc5ae095e71da50b0ce40ae0,"with a linked list we need a pointer which will point the the first element ,when we pop the pointer will be updated to the next element of the head pointer  and a pointer which will point to the last element ,when we add an element the tail pointer will be point to the new element then set the new element to be the tail pointer but we only have to keep track of the head and tail pointer at a time

we need a singly linked list for this strategy.",6.0,25
7237,7237,8934,a837228a932a0a88d86d56984d3a65abcc9744de389dd1a09c0dbc6344b07254c5f44d2d0e035800fe07d8fd7ef535a3af313b16fa0ec5085dc57d2a491f0957,use of a doubly linked list to get all operations in constant time. push_back would be constant time because of the use of a tail pointed you can add an item to the back in constant time. pop_front is in constant time because of the head pointer you can remove the first item in constant time. front function and back fuction would be in constant time due to the head and tail pointers. empty is always constant . size is also constant due to the fact that a doubly linked list keeps track of the number of items in the list. ,12.0,25
7238,7238,8936,8b711f86a0e0fd2c39d5f02ba2888612f603b1e29ac872778bb22eb91072c41a1a4c3f396ac1783e4ea49d806b40a998dee128cf46fea841c4d6fa80f6f2360e,"A doubly linked list would be required.

A doubly linked list has a head pointer and a tail pointer which would make it easier to access the the items in the list. The head would point to the first element in the queue and the tail would point to the back of the queue.",5.0,25
7239,7239,8937,8d5ceb816f2781032ee62700b4d8e0c49eadb89db294dfede287a0eaeacf6b8016c744cd4dfe71d03f0f6caf776956147ca479b489362862217860010178b882,"ENQUEUE(),This operation would add a new node after _rear _and moves _rear_ to the next node.

DEQUEUE(), This operation will remove the front node and moves _front_ to the next node.

The type of linked list is a linked queue.",3.0,25
7240,7240,8938,74d9bc92412f8c3ff2851eb60d7164b5df173c9c4dc214351b20de54e473afd02c6de0a58df8f38e8034cea31df2b0fd7682d3f538a4da451a42ed390cc33c67,"To implement a queue using a liked list and have all the operations take constant time you need to use a doubly linked list. A doubly linked list has pointers in both directions and has both a head pointer and a tail pointer. A doubly linked list also stores a variable which stores the number of items/links in the list (n_items).

Implementing a queue with a doubly liked list means popping (removing) items from the front of the queue at the front of the list and pushing (adding) items to the back of the queue  (at the back of the list).  

In order to pop/dequeue from the front you create a pointer pointing to the first item. We let a pointer tmp = head. Make head = head->next and we then delete the first item (delete tmp). We decrement n_items by 1. This takes constant time O(1).

To push/enqueue to the back of the list we create a new link with our desired value (v)  and we make tail-> next point to the new link, we say tmp= new Link(v), tail->next= tmp and tmp->prev= tail and then make tail=tmp. We increment n_items by 1. This takes constant time- O(1).

To implement the size function, you return n_items. This takes constant time- O(1). The empty function is also implemented in constant time (O(1)) as you simply return true if n_items=0 and false otherwise.

The front function returns a reference to the first item in the queue (first item in the list) .This takes constant time O(1).",12.0,25
7241,7241,8939,9dfb1f3f8489eba0c312316ab375b0eb3fde4cc7c592108ea20fe9063368bfeafc3cfc95ddf50eff3397d93bb8f4939d82490505e330285e8ec3eab94f0e646a,"We need to be able to push to the back by allocating a new link with the head pointing to that link. And then we start at the head and traverse again to the back of the list and pop from the front by assigning a pointer, update a pointer, deleting a block of memory to ensure we don't have a memory leak

There are 3 variables that mu

A doubly linked list can be used for constant time. (popfront)",8.0,25
7242,7242,8940,d96af73b5be668f5dd689aeab89641b2c7231424c7456f3ea33f65b38aaefabde723924090d862562454b1c8a6f22cbeb22245f54dc09b6ff5593a40d39e2839,"We need to use a doubly linked list with a variable that keeps track of the size of queue. This means we have a head pointer and tail pointer.

To add to the queue, we simply use the tail pointer, a temporary variable and some logic to add to the back and update the tail pointer AND the second last value.

To remove, similarity we use the head pointer, a temporary variable and logic to remove the value and update the head and second value.

viewing whats in the front of the queue is simply looking at the head pointer

seeing how large the size is, would simply be looking at the size variable.",8.0,25
7243,7243,8942,7fa0256939f3801d7cb837f49e23433b9e2c72a7153a75d58ee05f6ce597913275599303f990f67fdc180f91407271656e81578b90488fda76d6e550e9bb3533,"We will use a DOUBLY-LINKED list to implement a queue.

Using a doubly-linked list will always give all the operations in constant time.

There will be a tail and head pointer so when ever we push or pop it'll be constant time, and we just store size in a variable, and for empty we just check if the header pointer is pointing to null.",10.0,25
7244,7244,8943,2bed72130045c9fb6315517a1cd0576fdbc71ee8714b8107f6ddc3d51fbc170cd1fbdf2110982b17b6e61a87f656eb89a47f0eef9a898bfa08b1c56801ac6236,"Using the singly linked list,I would use the ",3.0,25
7245,7245,8944,52240fd5da488c8fea93f35bf4efe57000386d8c8d0c85c5b680c74f1a8feca90e13d4df01d1470660907e2655f277134bf53af33144e84c3793614abbdf6e99,"You can use a doubly linked list to implement a queue where all operations are constant time. the size, push, pop and front functions all execute in constant time.",8.0,25
7246,7246,8945,a300869c4f32047b23ac68a02d99d6a69e15fcc6cb6903bc4e640c72bf256b08b631e89f75d7f7263574f4383932390c2f4b98297d3a8bfdd9da2320bf30b053,"You would use a circular linked list where every point of storage (container) has a node pointing to the container before and after it. If there is only one container present its next node will point to itself and so will its previous node. If there is more than one container then the item at the end will point to the item at the front, this way push and pop will run in constant time.",9.0,25
7247,7247,8946,9d599f5b4528664877cde67e20618306dd9ba2d042eff74f086d6094f809424f26b3522b41500c22020384b725682a3a9de08fa52bd56f223acd18ce507d7fd6,"We need to keep track of the front and back items. Use enqueue to add an item to the back and dequeue to remove an item from the front.

We need to keep track of the front of the queue, the index of where we are in the queue and the size of queue that we are working with.

When an item is removed we update the position of the front of the list. Size needs to be updated when something is removed/added. If the list is full we need to keep track of the reallocated space compared to the original list space.

We can use the modules operator to keep track of list until it runs out of space, once space is depleted then we restart the loop again.",3.0,25
7248,7248,8947,16f82e0a87e8ddd62872296dc55051239fbed9bd7e989d4564eab3d0b0bd3dd97f30debd1ef7c57a72ffc4e972a5a710915f103218e9d2778be68d8b10a7d403,"A doubly linked list would be needed.

The front of the queue would be just accessing the first item using the head pointer.

The back or last item in the queue will be accessed using the tail pointer.

And from there in order to add a new item ,you would access the tail pointer, create a temp pointer to hold a new link and then update the tail pointer.

We would use pushback() to add.

To remove, you would use the front which is the head pointer, create a temp pointer to point to the head and then delete the first item. And that would be popback().

For the size of the queue we would use size()",8.0,25
7249,7249,8948,d677c40ee83c073e739609546ee27f2f0369bdfea2f9eb4c0be282329c3c282f85e22f67cd4095d13179a1dffcedf7b97c35e169242b176c21ab16ca909706cb,"head = new Link(v);

tail = head;

tail->next = new Link(v);

tail =tail ->next;",2.0,25
7250,7250,8949,82694cf634b012a9b99356edee5aefc22b24ba7895f93507fd59a70aa1b507058de91ae69d4a669273414cbd851ebdc45bb8d210bcd7e76b8c63d620d83813d3,"To implement a linked list with all operations in constant time , we will have to keep track of a head pointer and a tail pointer. This will be done using a forward singly linked list. In addition we may also use a doubly linked list but this will not have any cache benefits.",6.0,25
7251,7251,8951,2e609516b3c283ff23ddaea06d0df01ad6175f48861d0223a4409ebe1c7df8e383fe146f147415f2605c7a0103b96921b1ffd763ab4924efe18fd229dedbae68,"To implement a queue using a linked list you'd need to use a doubly linked list,

	* for Enqueue you'd push to the tail of the linked list ;O(1) time complexity
	* for Dequeue you'd change the header pointer to header.next and delete the previous header pointed address ; O(1) time complexity
	* for Front you'd return the header pointer value ; O(1) time complexity
	* for Empty you'd return whether header points to a null pointer O(1) time complexity
	* for Size to be constant time you'd have to keep a size variable (eg. integer) initialized to 0 and then increment the size variable by 1 whenever an item is enqueued, or decrement the size variable whenever an item is dequeued. When the function is called, return the size variable; O(1) time complexity ",12.0,25
7252,7252,8952,51b14b2f7889e1ac981e708359c401aa462001095a9f5423485f3bbb9e8ce44431d8f3cccca086e476a0ff46c4b6be46a5ea213e998e4c15dbacc349673103fb,"* Make   a temporary node point this temporary node to the front node of the queue, store the value of 'data' of this temporary node in a variable, point the 'front' pointer to the node next to the current front node delete the temporary node using the 'free' function.",2.0,25
7253,7253,8953,0a1eb6f30606d1f92d934eb03ca9d55d90d2ab3f505cdcb3ba02589cc6678998e8754ce7335373d6c01684ffed4a20fad8a976d2479c3f801a51d1c2b0d4ed50,"you would need to implement a doubly linked list as this would easily allow you to add to the back and remove from the front in a constant time as all that is needed is : whenever an item is pushed or popped then a temporary pointer would need to be allocated to the current item and then all you need to do is adjust the head or tail pointer depending on the case . it also has a counter which is perfect as you would not need to traverse through the list to find the size thus meaning the size function is always constant. Since it already has a head pointer which points to the front of the list , accessing the front of the queue would also be a constant time as all you would need to do is return what head points to.",12.0,25
7254,7254,8954,3e664d9b290450a26a44195a29971d5e7c7434afb68523c4038cc69f5c1285f4c94e2b62945fc7bf5800f3a5190a2876a925f82823b3806d9c640fa0e0d73571,"* by using a doubly linked list to implementation the queue which will have a head and tail pointer (a head to point to the first item and a tail to point to the last item in the list) and by keeping track of the number of items in the list

	*   since each link in the list can access the next and previous link, the push and pop function will be in constant time as there will be no need to traverse through the list",10.0,25
7255,7255,8955,0ffad2820b9adf1fbb6d7105f83a5954e33ce5d91444ff2b6251d15d1a8c5a988e64634ca1a4f0e01e237f0fdb8290b82c533e1fa1a822b32c02e6052c618e98,"Using a Doubly Linked List will be the most efficient compared to other Linked Lists. All the operations are constant time. 

push_back would be O(1) because we keep track of a tail pointer, this allows us to add an item to the back in constant time. 

pop_front would be O(1) because we have a head pointer pointing to the first item, this allows us to remove the first item in constant time.

front would be O(1) because of the head pointer.

back would be O(1) because of the tail pointer.

size would be O(1), the Doubly Linked List keeps track of the number of items in the list.

empty would be O(1) as it is constant.   ",12.0,25
7256,7256,8956,e02b2e6799a632f8edf7a4522f9a996ef61735be79c062229a0e89a8ede6774052ec8736d48de69d3335b6ebe5ac154baf9a59c6f5866c7ad081372900ff0ff8,"To implement a queue using a linked. list we would have to make use of the double linked list which would have both head and tail pointers. To push_back we would say

tmp = new link(a);

tail -> next = tmp;

tmp -> prev = tail;

tail = tmp; 

To pop we would say

tmp = head;

head = head -> next;

delete tmp;

n--;

To check for size we can use a counter in which whenever we add or remove southing we increment or decrement the counter respectively and to get the size we could simple call that integer.",8.0,25
7257,7257,8958,91ebe020e489f0682b9824bba92593f1328536973fcefa2088842b20b827aef8bdfb02c354fbd4b326e7989de48aea571427c17aa049b6dadee99c74f1c15bdb,"I would use a double linked list since it takes constant time to perform all the functions of a queue i.e push(),pop(),peek(),size() ",8.0,25
7258,7258,8959,e06c3717f5eff40cf06c551e6ebf1004bb478bf8fc38ebcba99f54530677cde6de5ea93590e51ef3d1e09f18ed2aa22502c287548e3398f50b4cf8f8e940073d,You could implement a doubly linked list. A doubly linked list has all functions working at constant time O(1). The front of the list would refer to the front of the queue which would make for the easiest access.,5.0,25
7259,7259,8961,22ce118158e8ed0c1187b952e36a1938ab0c22e942e01d9258ed224302f7ecf3665fc06c4060e629850d16f04e008f7cd12363e7f782d4370a1dd3b7af113bbe,"You would need a doubly linked list for this strategy. 

Because each link of a doubly linked lists points forward and backwards, the push_back function will be a constant time function because you can easily use the tail pointer and a temporary pointer to add a new link. You can do this in the following way:

	* create new link called temp
	* let the tail's next pointer equal temp;
	* let temp's previous pointer be equal to tail;
	* set tail equal to temp.

tmp = new Link(v);

tail->next = tmp;

tmp->prev= tail;

The above lines set up the double links. Then:

tail=tmp;

and then deleting tmp.

For a pop function we can do this:

	* create a temp pointer equal to the head
	* let head = head->next;
	* delete the temp pointer
	* decrement the variable storing the number of items in the array

Both of these operations will be implemented in constant time. There is no traversing required for either of them. Size will also be constant time because we are using a list, and front will also be in constant time because we are using a list. ",12.0,25
7260,7260,8962,ec395a3ecaad23df4073c1f706e156a2dc0df6ec9ab518f824a5ee32c21f2fee951d1dfe316e50e996ee47ec57ebf1b3a335db07c23fa71520fbcc864e608a4d,"-We could implement a double linked list which consists of a head pointer and a tale pointer.

- For the push function we would make temp equal to the new link, the tail point to the temp and the tail point to the previous thus creating a double link then we would update the tail to the temp. This would be constant time.

- For the pop function, we would make the temp equal head, head equal to the next point and then delete the temp. This would be constant time.

- For the front and size function it would be constant time as well. ",12.0,25
7261,7261,8963,fecc59057a0e209589be1452a92558843a93237db9707d9614670e76673fb2cec05cbca3488156012b8fb3cd1467b373d250bc116d0aec57eaa9cbe2d676c3fe,"there are 2 types of linked list which e can use for constant time on all operations. 

firstly we can use a singly linked list i which we store a tail pointer as well as a size variable. the back of the queue needs to correspond to the back f the list and the front of the queue needs to correspond to the front of the list. 

then push_back(v) will be O(1),

pop_front() will be O(1),

data.front() will be O(1) and 

data.size() will be O(1).

or we could use a doubly link list which has a head, and tail pointer and store the number of items in the list. then all the operations above will also be constant time O(1).",10.0,25
7262,7262,8964,48742644955ff1df5e9438b158fe5c8f20c2d07d0778b03adb953d373c991b6155a23d1f85c41ff0cc6c9d4311c4ad31f296412bee149a2c0eeac5233763ea82,"I would use a singly linked list with a tail pointer.

I would not need to traverse through the list  to add a new item into the queue,as I would have quick access through the tail pointer.",5.0,25
7263,7263,8965,697569647a6a588c9c373a5024008db721a653b65b6012b1420a317275c41e987a73e70671dd59ab61b2f3c74ff4747358e271031a490a1dc6b41faa87e269c1,Using a Singly linked list with a tail pointer,4.0,25
7264,7264,8966,249e9eaf48a6ca1524336796643b1021d4ea59f9ea64287d7770c8c08e88ca9d76b31f4d65b880c825f283c49f03d66834bc8a5aef3bcb8880daa0f21458adeb,"In a Queue, we maintain two pointers, _front_ and _rear_. The _front_ points the first item of queue and _rear_ points to last item.

ENQUEUE() This operation adds a new node after _rear _and moves _rear_ to the next node.

DEQUEUE() This operation removes the front node and moves _front_ to the next node.

we can use -> Forward Linked List",10.0,25
7265,7265,8967,14bf4a341dc9827953823163cd007e766c263b8c396bea85416367e8c4908e0df252e9e3ac38e08223a3bcc05a108adef9f1881af30b78d3c7220ceb7c6be157,This can be implemented using a doubly linked list. The doubly list allows enqueue and dequeue in constant time . Each node stores a forward pointer and a backward pointer and therefore both these operations are constant time. We need to create a new link and make that new Link our new tail and if we wish to pop we create a temporary pointer that points to the head and change our head to point to the next item in the linked list and that becomes our new head.,10.0,25
7266,7266,8968,5602a599f37ceb4d3d0abbebb674a8cfae2a81d9f53137cfbc7a1bded150cbaa8a83e4431db27b0e21c60021690e3731e8677add172b47aa9e637944b71f019d,"By creating a doubly linked list, having a head, a tail and temp which is used to alter position of previous and next function on my doubly linked list.

for push back, I will use the basic data.push_back(v) which is ran in constant time

for pop, I will make the temp equate to the head pointer, make the new head to be the next of the initial head by using head=head.next, decrease number of item by 1, delete the temp which was the head. Front item will be popped in constant time

for Size I will use the size() function which has constant time in a list

for Front I will use the front() function which is in constant time in a list",12.0,25
7267,7267,8969,a69e74ae8b4a039273c9779403a7bf9afeff6c0402c7c4b81445db3dcb6b7c6d2a0c70d795b1a5404bd22d002454afb4812336b41db02ff960eaf7c2625641fa,"foward list

we can build a queue class on top of forward_list. We’ll use the head of the list for the “front” of the queue (where elements are removed), because we can remove elements from the head of a singly-linked list in O(1) time (and likewise, add elements to the end).",8.0,25
7268,7268,8971,2a38888a8b80ad136312b78d25e48a8f2ffafd5c8eeba2c39a3cf4d0b1565a722030f9463fa977a5038fd88a16d989882eed3aeb8631f846fa1888531a07766e,"I would use a doubly linked list. The doubly linked list would need to have a tail, so as to allow for the push back to be in O(1). It must also have a tmp in order to point to the current node. the size function will also be O(1). I would to the front and then remove from there because its first in first out(FIFO). The head would be the front of the linked list and the tail would be the back.",11.0,25
7269,7269,8972,3dd0e6b0aa4ca279a9a8f781013cc1ffadd92a615d343d8f7162570e3cd2647c9fb452de2221fcafa1322a70dac1ad1ef68bd5efe79682df415f360b352ef94b,"* Use a doubly-linked list
	* use a head of a pointer to point at the next head 
	* And the tail of a pointer to point at the tail of the previous tail so that we may delete and add items in O(1)",8.0,25
7270,7270,8973,a145f431c410e1843f72d391833766088999724bb061c5de5f99600df8121e13bf82a081ec160d9db7d03b37234415de509f5f9b183164404c67b123311c46ff,"Use a tail pointer. Add at the back using rain pointer when enqueuing, remove from pointer from the front when dequeuing. Doubly Link List",4.0,25
7271,7271,8974,89daf5e5dd9d5cd464a1dba203796d2fcea5b46dd29cb10e72e0dd7e72373ac4fd8e96b5e3d9813a2ed44c552171318e265b869630b10e2e2b1c3ee4cc7320d3,"Use a doubly linked list.

With the link pointing both forward and backward and the previous link pointing to null and tail pointing to the new link.",4.0,25
7272,7272,8975,1a588e676388eab699476b49a00fa1013110acdcf89dcc5a2ff2c6e7b4d1cc5fff03a1daa5e3f8069ad9a846f88030beb884f390c11da3f442ee0a6ebc1a9307,"We would need to use a doubly linked list with a pointer to the front of the list (head) and a pointer to the back of the list (tail). To implement a push function you would need to create a new link then point the tail to that new link and point that new link to the last link and make tail the new link. 

To implement the pop function we would make a new link and make that new link the head. and then delete the new link.",10.0,25
7273,7273,8976,267e2a74684712f40153e983cf911454f693aaba7aeefb5a018f4e1b42bb05582faee8c5c865be8869988dea6e1c2f220a507c49209244aad2cd13359f2247d7,"For all operations to be in constant time we would need to use a doubly linked list because firstly, the size updates as we add to the linked list. Secondly, from a list we know that front will be constant. From the STL we also know that pop and push are in constant time. This is made possible due to the head and tail in the linked list.",10.0,25
7274,7274,8977,c3db465470d91ba6cd0242ed3a549831510dda1562b623b02e3665b5f6f9bac2d6ad4723d79407874899cc2fdd039731483c651b9cdef6d97acefd5884ce52f6,To implement a queue that uses a linked list with all operations having constant time I'd set the underlying container to be a doubly linked list which has both the head pointer and tail pointer both next pointer and prev pointer which allow the four essential functions to run at constant time.,9.0,25
7275,7275,8978,48b61851d938b41ee8c845154660df999994e48772e63eb0fc08241d1da91dd060085f370b13a4f968cd076d5b498fb619542e3786a80328ae705382da43a829,"I would use a Doubly Linked List which has a head and a tail pointer. In order to add to the back of the queue, I would push_back making use of the tmp pointer to update the tail pointer. And then to remove from the front of the queue, I would pop_front making use of the tmp pointer to update the head pointer. ",8.0,25
7276,7276,8979,d10eb2653552348dd29e31d9127ca9b9ab3966f67dcfba3fbaef7bc1fba74c3549309defc8e00e457f7427150a3162c0ca17e3f3d6529fa8df4aa4e4195dbeec,"By having two pointers, one to the head and one to the tail. You would need a doubly linked list.",4.0,25
7277,7277,8980,20effcbf64917de69f0f441958ac819d52ad486a65f959444a5ddd14ca83a40e581709b6bb9eae431ca2dd02ce933a201bc9b7e43298585d0858d76601344ce0,"You will implement a doubly linked list where the head will keep track of the first element and the tail will keep track of the last item and this will allow the list to traverse forward and backwards, we will also keep track of the number of items in the list. When pushing the tail pointer is used and when popping the head pointer will be used, keeping these two operations constant, the front operations will be constant as well as the no. of items which will be tracked through the process. ",12.0,25
7278,7278,8981,29fcf57bccb37a2f0d949733d7028b65c0e2df19a9ddbd0c547e57467d84c825defbaf635dea276a63c3d3e85a6fb4f7a84d6da08661ca46728f222c62700315,One could implement a queue using a linked list where all the operations are constant time by implemeting a doubly linked list in which the head pointer keeps track of the first item and the tail pointer keeps track of the item. One would also keep track of the number of items in a list which allows us to transverse froward and backward through the list.,10.0,25
7279,7279,8982,ba6cb46aa6ff6581fcd2828d6944742916cd44c20dbee87513cab04b763159ab5e8fcc20c0eaa029b5cead3d4e1911b67590f3a4b4a64f4e9fa942648249fc12,"* For linked list we will make structure of Node using class keyword.In which we here taking int data and one pointer of that class to point another Node.
	* First we will take two pointers of that struct Node, front=NULL and rear=NULL.",0.0,25
7280,7280,8983,0874df3f65542027273a16915ace9ed9ec51ca5d508f5bc4a25d6e8fb6352a668e9f762cc0692fb52fe5d216cf363f7813d3abecb5d910688f89eb0977699ad2,"You could use double linked list . We will have a head,tail.",4.0,25
7281,7281,8984,f03b1f416ca031a8c9d6db448d0d8439f9016edf947b1c8b45411ef2872c68250d908495b49ab16d7b6e23f038f5ac72fb1ec72bfe11a51db67cec76a8643ecb,I'd use a doubly linked list,3.0,25
7282,7282,8985,2aebde6b5faaed73a67c0847887873c4b7d8d2f0c1ec3c5d1ae00fb183c3e53559681b2ee97a4692d74712db8b222e3239fa5e199b01863e771a9daa54a4abee,"When adding to the queue , a push function is utilized and it will be constant time.

When removing items from from the queue , temporary link  will equal the next  is utilized and it will take place in constant time.Both front and size function will also be constant time.

The linked list type doubly linked list.",11.0,25
7283,7283,8986,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,"By using the linked list to get a constant time complexity one must use no for loops in the operations and only change pointers. Just a pointers for the first and last element in the queue

You would have to use a singly linked list",8.0,25
7284,7284,8987,d25db0824a9dd89b8306dc484932409aa0ac87f6e9cd46591627f8005d6820292ad0928aa72897c2e9719ede0b047240f3ae45e7cf394e50ddacecd0d21dbbfd,The type of list that would be needed for all operations to be in constant time is a Doubly Linked List,4.0,25
7285,7285,8988,59d6b044c8e3defdb04ae33f65223b9a348ff28a2986757f1ff92456374522a233c59e08e3595ef590565b6c7312655ac0d183d5fa106548d9bdc3808d7fd503,"We would need to set a few variables of the linked list to that of the queue. The new link=head, the head=tail. 

Tail->next= new link

Tail=tail-> next",1.0,25
7286,7286,8989,128e2656328deed2d77d2ef28a4c653d82a40a62fd734c4ccb3dafb70805db8a812cccc608184c6cbda73e2bdda34e6f81ec5dacc95d16cb9a78cba4ff089ac5,"A doubly linked list will be used to implement the queue. The front of the list will represent the front of the queue and the back of the list will represent the back of the queue. Because the front element points towards the back element, adding items to the queue, with push_back, will take O(1) time. Removing the front element, using pop_front, will also take O(1) time, since the back element will now point the element after the front, and the element that followed the front will now point to the back element.",10.0,25
7287,7287,8990,ef56d487f412ffdca7b3412858b2ccd1fa21fc365016661f00994f5e06683c6e545b948b70c4775a9a839e6049995e36f03b1f06a7374933a80a9013b6052c37,"Doubly linked list

For size I’d use the function size ()

To add an item, I would get to the last item of the list, being the tail point, create a temp pointer which then create a new link and thereafter update the tail pointer to the new tail. This is push back

To remove an item, I’d simply be removing the first link, the head pointer, so it will simply be pop back",12.0,25
7288,7288,8991,8c276f2a894ec8359a82f6a7f8b543cee4dafa5e339dd5fcbdd9b626de04d860f6a771f050054850d4263b60fc7c9e2f46a60c4568664a5f9854894846a3920d,A doubly linked list should be used.,3.0,25
7289,7289,8992,0814448191d29da9008582aa1dc261271817cf4f70631f519f01177439d50267cb21e8d39c1f121e1aee03914798dbfab1836210758982742e26c801f01d7bc4,"would use doubly linked list

enqueue(}; adds element to back of queue

dequeue(); removes first element from queue

first(); returns first element without removing it

size();returns number of elements

isEmpty();checks if queue isEmpty or not(false)",9.0,25
7290,7290,8993,a871558daae8ec7755dd112b899b7fd46e06cb2a4cebf4c0a75ca226dba4bf419ef0333177fa6862ca71f931535c6fb1250ed993a029aa9b63a8c18ad277bce2,I would use the doubly linked list to have the constant time throughout .We enqueue an item at the front end of the deque and dequeue an item on both rear of front end .They have to declare two pointers front and rear of the type of the doubly linked list and will initialise both of them with value  NULL.,8.0,25
7291,7291,8994,48452c6af5685c82851988d96add3ed11ed530ba837e28f21c3e92d7b83a44fbe9879abbcb6e1ae0256b1dc9b2ef98a34c294dacae561958335cfe0e83b08e8d,"Using a linked list we can create a queue of variable size and depending on our need we can increase or decrease the size of the queue.

Thus instead of using the head pointer with linked list, we will use two pointers to keep track of both ends of the list, so that we can perform all the operations in 0(1).
Singly linked list would be needed to implement a queue.",9.0,25
7292,7292,8995,72dd44c1821dd2a2380b55f5907e16bfe4370a758e591d726ccded6a8be12ed056b16e3fc6be17ba264f1643ae18b41b7fe1a5fa76a3d9621150f89706d252d5,"I will implement it by using a circular array since all the operators are at a constant time.

I will  use a doubly linked list.",4.0,25
7293,7293,8998,8049e1d0a5ce881b749a9c9461a73e821d1792fbc2adc39e1be0be7717d99f93abbe732f68ade8cbd01333fb3e4a5adeb13b3875a705e5218706e5b68e7e0885,"You could create your own list with its own associative pointers that will allow you to add at back, remove from front, find the size, and also if its empty all at constant time.

A singly linked list with a tail pointer.",9.0,25
7294,7294,8999,1e30eb511c307c57041552d3f3ff58f0e01dff16b4bbeafb7e1426a20560b5727bf879a4c238af04f66b8c454f01b583c75d2d8fab510951c437d49081081f31,"I would use a doubly linked which will be pointing forward and backwards. With this, any operation that I perform will be constant.",5.0,25
7295,7295,9000,ee66ed151b20f2c15b5115f8b2c4fd312cc74408ed945a84bb7f699ad1a7972c932ae28ae3a673ec55d38f3c6b49ab5107d141ab55e4e963155df1dc24bf5495,"To implement this strategy we will make use of a singly linked list. Create a new Node dynamically and insert a value into it, check if front is equal to a null value if true then the Node has been created successfully. Operations for linked list queue are Front, Size, Push Back and Pop Front. We inserting elements  using the function Enqueue. The function Dequeue it is used to remove the first element. ",9.0,25
7296,7296,9001,d9db0d62eb972d7cdf4f37e10bdbf3c1fe24b4325a048050d64042994d0e2a7ef0c9b1f76e9ab479bae9fb331e67c69ba4663f294fef8e66b6d36cb8560984ec,"To implement a queue using a linked list where all the operations are constant time, I would use a single linked list because we cannot use forward linked lists.",4.0,25
7297,7297,9002,939ec9a57a50490db2733608917f50113db66f29232d7ede4b3f765d85522c6883d672d7c5bad821ddeab74dbf066c3294635d07979c4557288fa30e0ff3d929,It would require a doubly linked list. Use the the head and tail to keep track and using that will give the constant time.,5.0,25
7298,7298,9003,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"i)*The queue which is implemented using a linked list can work for an unlimited number of values.In linked list implementation of a queue, the last inserted node is always pointed by 'rear' and the first node is always pointed by 'front'.

*We need to maintain pointer to the last node to keep O(1) efficiency for insertion.

ii)Doubly linked list.",8.0,25
7299,7299,9004,cec5c5d76a671273e0f9371ae893a0f4c2ff89a302afba60a55ed47df25e76493286a5dc1d008dcab637f3c3c155e4e5b2158e820a7aa91a63b886b5ee485778,You would have to use a doubly linked list with each link having a pointer to both the previous and next element. This would mean that a full traversal of the list to use push() and size() won't be necessary bringing linear complexity down to constant time.,3.0,25
7300,7300,9006,d3ddf356f072bf43331098b8a43e33c8b3192b402decaa6c3b442e9385a8eff79ab7318fc38d8ae8da018a53bd14daa455a684126f1cf0ce97908dac2dc0af07,"I would a doubly linked list data structure.

to push would require to push at the back of a doubly linked list then we use data.push_back for the queue thats constant time cause pushing back on a douby linked list would be 

temp = newlink(v)

tail->next = temp;

temp->prev = tail

tail = temp that takes constant

and popinng is deleting the head

temp=head

head=",9.0,25
7301,7301,9007,9403a6055052838effd7ee11ccb772d87904528f067a64dac873492ac316e3dec04949023db9aa2c93819f94c53c4c5c1b5e1941d51e786c3ee0dff6e062b7fc,"1) Doubly-linked list + tail

2) Push from the head

3) Pop from the tail

4) Get reference of the first item from tail

5) Keep counter for size",8.0,25
7302,7302,9009,d42cf42830844a9ee1d0ff0af8c2f689af280ff8f6db853246aca542789b88210a975754cb807f66256c17bb8f0db7f822b9fd7b118d4ccaab17c4ee83f0a430,By using a doubly-linked list,3.0,25
7303,7303,9010,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,Implementing queues I would start creating a class and use a doubly linked list so that all the operations will are constant time,6.0,25
7304,7304,9011,a8b16fc0f5a2c752f3497016181c5ad9db439554c5d81073a232375aae20a22a97cca43a22eeec6af33455ba644c036ec4f0c737bb5b05eab312d892fb42141f,"You could use a singly linked list that has a head and a tail. 

Push_back - You would use the push back function which makes a temp point at the last value, reassigns the tail point to at the new value and the makes the new value point at the old one.

Pop_front- Youd use the pop front function. A temp will point to first value, head assigned to new value, new value will point to old first value.

Front - head->next

size - you could keep a count  and return it",12.0,25
7305,7305,9013,eb636b71b69b444b76b68045ede7c5b96290b63dc94e90986ac7258b980a7f8df480d1b6926e41ac5186df7da647131dcbb111a84e28e5a68a37dc453c1f06bf," A singly linked list

The head pointer would be the back of the queue. The front of the queue would be the back of the list that way whenever we add and you will you we would need to iterate to the end of the list which would take constant time.

To return the front of the last we will need to use the back function. To add the queue we would need to add to the front",4.0,25
7306,7306,9014,8fd97c5322558e2423003672fe174f30c080d208985516c4cd8749e1d3f072ac5736c633a74790122fa877f92436ac7777fc9cf9c36610a77bd1566b6903427e,"would create a doubly linked list with a tail pointer, every time a new item is added number of items is updated.",6.0,25
7307,7307,9015,a83848dae9e11c32fb0fef1054c9f0420423c74efa66838a210a7774eb07b64f5a5df97bc2a33594ee565ea37cacb65f8fcddd5281fc0b93d6e6e1b0ba5da1ac,"I can use enQueue to add a new node after rear and move rear to the next node.
secondly I can use deQueue to remove the front node and move front to the next node.

We use singly linked list ",5.0,25
7308,7308,9016,e297ac13d644c28497e53e0845b865aca91f53637da30cace639c33479dad1c99be8abd444014be886b73f635741e9cc8d11a7d33228fb4866fbadfc7725d88c,I would implement a queue using a linked list with a tail so that I can  access the back of the list in constant time  and I would use a doubly-linked list with a tail  ,5.0,25
7309,7309,9017,07076ad9a7e3813bce19a739ebedaab894d1a330269763e0925227d8822b601591c19afe0ea5ecf81637c9b73f442db6cacafab2329d262fef0fb68d97bef78a,"you will need a doubly linked list and two pointers, one for the head and one for the tail. the head will point to the initial value as well as the tail. To add items our doubly linked list we add in the front and change the value the head pointer points to in our list and the new item will point to the value the head pointer was pointing to. To remove an item we delete the value at the back of our doubly linked list and change the value our tail pointer points to, which will be the value our deleted item pointed to.",9.0,25
7310,7310,9018,ee9a54c657ad0d8bba4bde06638e509cdb2a338e06761f819025e545929c0973eae422171c63064d2ec75c6fa5edd42d44dd67fd5b59e36f33fd89e07c72a43f,"I will implement a queue by adding at the back of the linked list(data.push_back) ,also by popping front ,peek front and returning the size.The type of linked list would be Doubly Linked list.",6.0,25
7311,7311,9019,385c7b29eec3366a404f1d7e1159d0447aefec67a3c8b61a32481883579eeb6ab7ee9fa654afbb7d3b9a4b7a30f0a2b32be3cbd9d9a3dfbfe943be567e01c394,You can only implement a linked list at constant time only when we are using the enqueue and dequeue functions.Single Linked List if the type of linked list we have to use.,5.0,25
7312,7312,9021,f76d34739c22495666539e328b829579ffb8d2806837813ff647c9a67384130ec26d74d58bb855836384f12b1b3b03f93c1062fce50fa1b459dbac86affbee20,"We need to be able to perform the following operations on our linked list:

push_back(), pop_front(), size(), front, back, empty.

The Doubly Linked List would be most efficient, because it stores the head pointer, tail pointer and the size of the linked list. Every time we add a link it points forward and backwards and the size is updated.

to push_back, we'd say data.push_back() and this happens in constant time in STL. O(1)

to pop_front, we create a temporary pointer, update our head pointer and size, then free memory which also happens in constant time in STL. O(1).

Since size is stored in our doubly linked list, getting the size will happen in constant time. O(1).

Front and Back will also happen in constant time.",12.0,25
7313,7313,9022,8052ea5813981ce1b1dc18dcce8d4c10c33b769890ea3f35ecc1dc5a6465b4897efddc1a12c6d7a26b5d0da8ca3c779589f99331e5d2c411636cea22d157833a,by using single linked list and I can do this by first making the head to point to the first index and increment it to the next .,4.0,25
7314,7314,9023,36dc611e5a5c4c004053dab4fefc6b9a5b0bc6b95bad46c0ada67bd1d7f42775da4dc0cb387f6915f676d0a13a5decf47d86380ae9bc1d77138d6578f380b0f1,The singly linked linked list,3.0,25
7315,7315,9024,8ef07cfaa662dbfc2a6f67c4eb6899f0aec0231f063886ccf26dc730e0a79b7cf9f7721c25d0389628fb118a214101e554b383179ae6195a341f858f22a17c0b,"a singly linked  list is the best. 

we first make a temporary node",4.0,25
7316,7316,9025,3143af8e534af5f9178a128c44433d6c35da771cbbc382af1235851f68f2e6c0baf6b6c7dc7aef9c829246db2be183570b22a8f6e1e10870c8fab148df9fe20f,"Initialise a variable to store the current size of the list and increment it as we add or decrement as we remove an item from the list.

Store the pointers to the front and the back of the list so that we can add or remove items in constant time

A singly linked list would be needed for this strategy.",10.0,25
7317,7317,9026,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"I'll make a temporary node
point the temporary node to the front of  the node

store the value",1.0,25
7318,7318,9027,f8ab0f6e15e6bf9e99acd11cfb6b5455d3c0019e87064465e59d88ccaf25c640a5ce1b900a6011a9e3fa052e11195ca6da9faf3eac510a5a07330facf6daee23,"This would require the use of a doubly linked list. We then maintain two pointers, front pointer and rear pointer ",4.0,25
7319,7319,9028,2a0df219aac143a2ab259ed39069368d09faa1d674232d6d8a5a0299284966b0b712226c702276000af1418c0c7120be9e30f8742712afc25a87bebd377d57d9,"tail->next = new link(lst);

tail->next=temp;

tmp->prev=tail;

tail=tmp;

To implement a queue using a linked list where all the operations are constant time we use a doubly linked list for this strategy.",8.0,25
7320,7320,9029,6faaf9b1d085a393b028ace82b2996765123fa315b9f4a8ed8db3a15b212a1737ea08b0cd8412ff053120963926bb68c4544ec749acc155d82f591062af2caa1,"Doubly linked list

Doubly Linked List contains a link element called first and last. Each link carries data field and two link fields named:next and previous. Each link is then linked with its next link using its next link and each link is linked with its previous link using its previous link. as a result, the last link carries a link as null to mark the end of the list.",6.0,25
7321,7321,9031,1c067bf4dc46efea1d97764ec9e8512203198a06760dfe663905444adb3c11970401fd40f402aab42c0c01db7d7d76641060c3df878232bbed315bb7d13f0aab,i would need a forward linked list ,3.0,25
7322,7322,9032,9a6d2e6e6e0c1b575d6fd6f9cd31a3d7ef05b9fbb8f9b527d2f24c66326f4e25fb885d747e3511e370820c0e5c65531a52fb8637b76c7b43895037c2420cfc80,"A queue data structure can be implemented using a linked list data structure. The queue which is implemented using a linked list can work for an unlimited number of values. That means, queue using linked list can work for the variable size of data (No need to fix the size at the beginning of the implementation). The Queue implemented using linked list can organize as many data values as we want. In linked list implementation of a queue, the last inserted node is always pointed by rear and the first node is always pointed by front. A cirular linked list can be used for this strategy ",4.0,25
7323,7323,9033,fd6a36ea3be7fe00a0626c8ff80a591e0ee46b9eb9f16c4ccfb925e8237975ae584522b908d7f487d3fa4016ee5035673c870e0b6b78ebf935c75fa0905d0961,"I would use a singly linked list where the head/front  of the linked list represents the front of the queue and the back or last node represents the back of the queue. This singly linked List  will have a tail pointer and use a temporary pointer to keep track of the size so as to increment and decrement the size when we  push or pop this will take constant time.

This is a singly Linked list",11.0,25
7324,7324,9034,805e6508996d13ddf1a18b1d2e18c5a73d82b749916487ddfd386d326e8ba2b06a4521a365c23ea00b66ba06fb5efe331adbdc0f46e49478cb1d6923fb8a6c24,"we will be using the single linkedlist tail implement our own tail we can say that tail dot next is equal to new link and we can update the tail to be equal to next 

and by storing the tail that allows us to go from tail and and add new link  if we use the single linked list that will mean push_back function will be in constant time ,pop_back function also in constant time ,front is also in constant time and and this case w not storing size so the size will be in a linear time",9.0,25
7325,7325,9035,aadeb4c6039dda00602078edb4dd6a2ba4db3a9feee681399a3fee2f757fe3dbefb04d7c93523ccccac1c802124b4fd37762f7d6434cb2806498d24d632de064,"you will use a singly linked list with both head and tail and you will also need a size variable which keeps track of the size.

tail points to the last item and whenever you add a new link, tail must point to that item.

when you pop, you create a new link e.g tmp which points to head, then head points to the second link and you delete tmp.",10.0,25
7326,7326,9036,4cd28cc2ad591ac499048f07ffdf4d516b0d616e007ea0ed86d6d8211078fbf6b0e376e19e715d3f5e8e0639e85069e7aadf7f7c053054c13b6c8367b692aade,Doubly linked list,3.0,25
7327,7327,9037,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,You need to implement a singly linked list with both a head and tail pointer. This allows for a constant time complexity as push_back moves from being O(n) to O(1).,3.0,25
7328,7328,9038,999b8af04a99b1971783a730d1a109e30fdff2f88a1f40dc36731dceaa01148aef1c1f5d96b5999593020819ebc46f676235aa6d5dc12859b91750c9e8b5c9c4,"I was going to use doubly linked list.because I can traverse backward and both forward direction by means of a head and tail pointer, pop will be constant and push will be constant.to get size to be constant I can keep a variable and increment it when push is called or decrement it when pop is called.",10.0,25
7329,7329,9040,307d8af1793926f21e6b4215d5b4182c112c0d4698d4832d0185b0d9535a011c7a888a921d240645fc84a5799fdd55910fe15a0615bdfb1a6fdb121e9cfcac36,"By using the doubly linked list you can implement a queue where all the operations are constant time. The doubly has pointers on adjacent links which are pointing at each other. As a result, we can add at the back and pop at the front in constant time. ",9.0,25
7330,7330,9041,c4a46955ab90460a7f7ea08b20b02537758cd0f1f3801bb0b96314fe0ff9d069021459ba5c9b4434a1085ce9d389652fee31ac82384418540ac50a261c57a498,If you were to implement a queue using any linked list but you added two variables. One that would point to the back of the list. This means enqueueing an item would take constant time. The second variable would track the distance between the front and the back of the queue constantly. It would be initialised with the list increasing with each value enqueued and decreasing with each value dequeued.,2.0,25
7331,7331,9043,0fa5d829ab37316f131667488ff6244b79b525ac275e022289de875a4f7426de94ef384d30176ee34a2851d47d343e62431c37057ae6054ad83ff76862ff86ab,"I would use a singly linked list which has both a tail and a head and also create a size variable which is an integer, which keeps track of the size of the list and initialize it to zero. The tail pointer points to the last link and whenever we add a new link, we also update tail to point to that link and add 1 to the size variable. When we delete the first link, we must create a new link e.g curr , which points to head, then head points to the second link ,then we delete curr and subtract 1 from the size variable.",12.0,25
7332,7332,9046,bb7a5218ab3dfcc0ac546d608943de6dcbb3727d09e6f5dbb5e885ea5b24939174aaaa40e8672ce63fa53f6af97ad899b29ea3229ae18c85c504ca3dcaa7d71a,"We could use a Double Linked List :its a list that links its previous node and the next node so that it can transverse forward and backwards.

it keeps track of the number of items in the list and we have a tail which makes it easy to Pop and Push without transverseing through the list. Head makes it easy to access the front item and all that gives use constant time O(1). It helps use access things with out tranversing through the list and this saves a lot of time.

Push: We at the position of the front to the number of items so that we get the first open space and we use 1 modulus and this gives us CONSTANT TIME O(1) unless if we have to relocate the elements this will give us linear time O(n)

Pop: he we add and use mod to remove the front item, which also gives us CONSTANT TIME O(1) unless if we have to relocate the elements this will give us linear time O(n)

Size: CONSTANT TIME O(1) because we keep track of the number of items in the array

Front: CONSTANT TIME O(1) because we keep track of the position front element.

Therefore if will give use CONSTANT TIME O(1)",12.0,25
7333,7333,9047,828a54706b7956f06065af9a928b49958122a77b54a5e0593021ac1ee5bfac90e0bf9488291ceaad9b7538bfadd4796253d8359db184b0bd7f7e1ed456e8f30c,"By getting the front and last item from queue. Using enQueue function to add an item at the back of the queue. Using deQueue to delete an item at the front of the queue.

A single linked list can be used.",5.0,25
7334,7334,9048,92a2ed8f4716bed3b0e0c50f4d71ca4d4c6f96e622febc9b471f947d10b8500c23531ab4582c0648a7ceef71efcbb7100102c2a6bd33328ed40abb07652829ad,The linked list will store both the front and back items of the queue which makes the pop front and push back functions in O(1). It will be a doubly linked list.,6.0,25
7335,7335,9049,8278e2d003c29d98e8cfc7117cefa90b7503054f5b50b162eaded6981387fa2f1b8b8f0ae2fa0d58942ac81f9cf7fda1cd474d106727d602bcd9f2d647883b50,"Two node pointers pointing to the front and back both set to NULL

Then have a struct node to enque at the end and deque at the front

Singly linked list would be used",4.0,25
7336,7336,9050,4c6f807c2ce1ab585dfa9622ceaade81e43b8fe88ba8af5d95eb11efdad75a8b1190eb5c2d48dff34f29ac730bf0895fdaf308c3995dbd7f2103246c342b70a1,we would implement a queue by having two main pointer. a front pointer to the first item in the queue. a back pointer to the last item. the type of linked list we would use is a singly linked list.,4.0,25
7337,7337,9051,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"A good implementation would be the doubly linked list as it would be most efficient - we need the same amount of time to complete the operation. 

With a doubly linked list the push_back function and pop_front function use constant time O(1) , with the latter functions size and front using constant time as well.",9.0,25
7338,7338,9052,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"A good implementation would be the doubly linked list as it would be most efficient - we need the same amount of time to complete the operation. 

With a doubly linked list the push_back function and pop_front function use constant time O(1) , with the latter functions size and front using constant time as well.",7.0,25
7339,7339,9054,a69deeb1d09b2c2f2efacf2adabcd40f91cbdaa6d8a94b958b4f80eb19e04ba4658d33a6b07d41e2293e3dc7c648d0c9d4ec03fdc6df749e7a11d1c6ae138068,Use a doubly link list.,3.0,25
7340,7340,9055,f4baa24ad720b1250dc8a9d5d7170a55ee764630dc2c7f87292182bdad71ecf2851e6fec34c6913b3b5952d370fbd9d0459efe69a1541c4221908a8f498f268c,"A doubly linked list would be needed for this strategy.

A head and tail pointer would be set, along with the number of items, n, being kept track of at ant given time.

When pushing back, we'd add a new link that would point to the previous link which would in turn point back to the new one. The new link would be set to the tail. We'd update n by increasing it by 1. This would all be done in O(1) constant time.

When popping, we remove from the front by creating a temporary link and setting it to head and setting head to the next link after head then deleting the temporary link to delete the original head. We'd update n by decreasing it by 1. This would all be done in O(1) constant time.

Because n is kept track of, we can simply retrieve it in constant time. The head pointer will point to the front and so we can retrieve that in constant time too.",12.0,25
7341,7341,9056,a8e9f7af885a794cf115ef4ae2efb719a045fef1a67ed1ceb91d47fac21a3c207363f092625ba28d25fab14149b9e5cb63f7997360c20c56ec6163be05ed3db3,"Start by creating a linked list. The next thing is to create a structure ‘queue’ which will store the front node, rear node and the total number of nodes in the linked list.

The next part is to initialize our queue and this will be done by making the count of the ‘queue’ 0 and pointing ‘rear’ and ‘front’ to NULL. Then create the enqueue and dequeue operations. 

Singly linked list ",6.0,25
7342,7342,9057,412b107ec0ff412753968aa6ffdad40da21fbfd59417aac428d07f6c064389cc24911eb533cf92e901bf7845b76400d7d3831fd1347350b39d220d9c58729d2b,"tmp=new Link(v);

tail->next=tmp;

tmp->prev=tail;

tail=tmp;

Doubly Linked list",4.0,25
7343,7343,9058,7b72a3cfa202855ca92e0c8594b6a4108a2a7362ff4fcc28ef2228b8b36b337e628baa0458dcafc8f661dd4fe06b22f28bb9bd3468afca5d2aaffb32f04408e7,Double linked list I'll use for this strategy .Its is easier the link  we add everytime points forward and backward.,4.0,25
7344,7344,9059,a51b1137941b4a2c9fd6d66da41292b1d5da2b0315b3c4cbaa7f507deed0fbfe1d51f7372760847ad411ee0d78ff9de354c3d1a9bb27433af4b5f7b732027fa9,Doubly-linked list.,3.0,25
7345,7345,9061,5221e1f3d933576f202c0725eb1b1536ee1b49681a3fc7d8f1a5f7ce021be47e8c2ad1016a78e47c8f005a4abc05514dc591b463cb92d3c640fd02125cf688e6,"The first way is a Singly Linked List with a tail, while also manually storing its size as a variable. Adding the tail results in the push_back function being O(1) or constant time, while storing the size as a variable results in the size function being O(1) or constant time. The pop_front and front functions are already O(1) or constant time, even without using a tail.

The second way is using a Doubly Linked List, since it stores a head pointer and a tail pointer, as well as two pointers (in both directions) for every piece of data, as well as the size (n_allocated). This means the the size function is O(1) - constant time, the pop_front and push_back functions are now also O(1) - constant time because it uses bidirectional pointers (meaning it takes a constant amount of work to either add a node or remove one) , and the front function is O(1) or constant time.",12.0,25
7346,7346,9062,df4be51196b13a9d9df6ef77eee120b801ef4ba7a8945fcd04077415ae29d58c8d1e0814291c20adeb94f43f2f99c6c2290c6dde5a70ac85841035ecc662212f,"We would need a doubly linked list for this strategy. This allows us to access the front and back of the list pretty easily and eliminates the need to traverse through the list because we can just access the head and tail pointers when we need values from the front and back. This is convenient because a queue is FIFO data structures, so easy access to the front and back is important.

Using the head and tail pointers of the list, the push, pop, and peek operations are all O(1). ",11.0,25
7347,7347,9063,5f1f239814321ab1f431320367ad013e94b2f66dc9f45345746644a7c6190c150b15690868f1b18e7468353f42b32ce7d5d9e6673f3e33a12996a386f5985adf,"I would use a doubly linked list with the front of the list as the front of the Queue and the back of the list as the back of the Queue. By using a doubly linked list all operations are in 0(1)  time due to the fact that we have a tail pointer that allows us to access the last element of the list and thus push_back in constant time, it also keeps track of the size which we can access in instant time.",11.0,25
7348,7348,9064,dcb36512b447a313662d0f410494b8558ba9ebb01567bc86a95298f6904541d3214ff36bc5d7b6282877fc7d17b5d1d22bd45efc068f60d6574cc4f66e60986b,for this we can make use of a singly linked list because the time will be the same independent of the number of inputs we have ,4.0,25
7349,7349,9066,3ea55861b5c8eafb81b8565f1d54cc453a6c146015319e65651c96131a93fe003ed97c4b0e5ead0032066879ea3f910a9115040fa5bb190fe1c4bece13c4f763,"You would need a doubly linked list for this. A doubly linked list supports all the important functions of a queue, this includes peek, size, enqueue and dequeue.",4.0,25
7350,7350,9067,31b91a2cbe9d38c5c018d832e6594c5b3ffdd38b6555291e43c52124c88f4048eafce37a5d4c9670e25f88cb39302cf31b3d02ee2f55200c7e6b2364a2a7b4e0,you need to keep track of the members are in your linked list then check that the first value is at which index. Keep track of the space available and check how much space is left every time you add a new object,1.0,25
7351,7351,9068,2c57052c92283203acd8d1c12f3f24bff9fcc6fc06d4ccaf21f6b88069300e298296f4f82426d3a1b2f0d2ff83e57ea1826f7e8e04b0393de99a4b442ad3afab,"I need to use a singly linked list to get a constant time for all the operations.

Enqueue - check if the queue is full, if it is not full, increment rear and add an element to the location pointed by rear.

dequeue - check if the queue is empty, if it is not empty, increment the front to point to the next accessible data.",12.0,25
7352,7352,9069,93c90404569325fe60b728e076fbba3cf65e437046307f80389f0bc8991e0972c6f04c428807930e8f3ec23f714c2c1a1c5a69ba6ec135ea91d23224a8d3d68d,"I could use a Doubly Linked List. 

This stores both the head and also the tail pointer. It allows us to easily go to the front or the back without transversing through the whole list. Pop_front function can be implemented in constant time by the use of the head pointer and temp, temp allows us to have no memory leak. Push_back function can also be implemented in constant time by the use of the tail pointer and temp. Other functions like Size and Front will always be in constant time in lists. ",12.0,25
7353,7353,9070,9f85bd574a0fb5fa07c95cbd2dc5aa7f4cb77f83ea58b24cf50b8a111ddaa2e08d644409b7ea28dad73defdb2393c136cc039b51ec3ed144b40271a76c7c7470,We could use enque and dequeue,1.0,25
7354,7354,9071,2dc8bdb77e3c7ca65a7004fc81d01e201b72cc647f001393bf944c06617e5c35dc6d00cb13c94a98ad4a2b0a5135ab7e178732724d9ed1cd93c84c2d08c50e63,"We would use a SLL+tail. The head is the back of the queue and the tail is the front queue. For the empty operation, we check if the head is null. For the Enqueue operation we add elements to the head. For the dequeue we remove the last item from the front of the queue/tail.",12.0,25
7355,7355,9072,c1e502cb9307976ed3c86bb3e1a2a0d1fad4d05b1ff3b6ca09a4a8992703680a55c9ae6e51c9417d756549fe340afbac12cdfcd3dbe4f6a560b6a171ce7f1eeb,"I would use a linked list whereby the number of links are stored, there's a head and tail pointer and there is a ""previous""component of the list that would point to the preceding link. 

The push( T value) function could be done in constant time because with a linked list, it would involve creating a new link and ensuring  the relevant pointers are directed/redirected accordingly (pointers such as the tail, next pointer of the last link, prev pointer of the new link)

The pop() function could be done in constant time because the linked list would involve constant time procedures such as as creating a temporary pointer to point to the first link and deleting it, not before  redirecting the head pointer and setting the new starting links prev pointer to null.

The size() would involve just getting the stored value of how many links there are.

The front()would involve getting the value of the link the head is pointing to.

- You would need a doubly linked list.",12.0,25
7356,7356,9073,5530a3289902a9b8046211b23e363c2d17c53d3dae60408ce782dad21065a511eb819cc437440b28be1c0ee28957c16d3c143820d415553d97979e1db0f64c5b,"You could declare the list and then declare the functions : enqueue(value), dequeue(), value() and size() 

You could use a doubly linked list",4.0,25
7357,7357,9074,b3916d46d881833f987b1688b8c10f933afdc9a4fa5bd760932846eb945fb5e69406c926d4b58830137510a4b06c87b7babebfdb5983ea8a0ed2ed2ae65cf4e6,"Create a node class which will form our linked list, then create a queue class then define a pointer, front , and initialise it to null Doubly linked list would be needed for this strategy.",3.0,25
7358,7358,9075,744cc5a93fd7edad364406b30ceaa6836705a7419bd01ed97b04c61f1235130699ff789e400cc607e1772b19b35bf800957b6bd74b1e52cf1974d01500560533,You could use a doubly-linked list to build the queue. This structure has a tail pointer and is doubly linked which means that data can be pushed to the back in constant time. It also has a head pointer so data can be popped off the front in constant time. The size of the queue is stored in a variable and can thus be accessed in constant time. The head pointer also allows for constant time access of the first element (Front).,12.0,25
7359,7359,9076,1b24ef0d303f3078167a7dbca152a2c1d687ceab3654a2ae76bf73e5ee1cc0069be94db2fff74908c1492e9ab7afab08d7fd457a365a4c193c2adc5bcd9b850a,"i would use a Doubly Linked List to implement a queue.The reason being it offers constant time when i pop front,push_back(enqueue) and i can also make a variable that will keep track of the size of my list each time that i push into my List.in implementing my doubly linked list i would keep track of my Previous node,next,tail using pointers as to allow me to pop front and push back in constant time",12.0,25
7360,7360,9077,86eb6a509a4b81bb5d0775617d6b551b5529a8196aa8cfd54e1d4c97046fcb8692ee1866ca18888be1695e57bab3f84e888b219e99049227e002908717268d42,Our linked list will require a head pointer  and a tail pointer.The head will point to the front of our queue and the tail will point to the back of our queue.when we push at the back we create a new link and we update the tail's pointer to point to pour new link and our link will point to a null pointer.when we pop at the front we update the head to point to the next link and we delete the link that was the previous front.Our new front is the link the head is pointing to.,10.0,25
7361,7361,9078,d91427bf4ad99661f4ac49ddce8054ec473a7fcef1ab133d8d24c3ab9e806480afe6773c225af63871bd9b36c6d59fe3d802d967ab7b71f90b46e5238ce08052,"i could implement a queue using a two pointers that will point at the head and tail of the list,to add an element i should create a new node and link it to tail of the queue,and to remove element from the head i advance the head pointer to next node,this method is called doubly-linked list",12.0,25
7362,7362,9079,98d78e9c828344508b695719d0252934ec81638b460881dd9abe0087d3148c90c09f4ac72696b8c6cb5d749b644a041f0fa7f6d6c483866227774b40bcf364d5,"tmp=new link(v);

tail.next=tmp;

tmp.prev=tail;

tail=tmp;

Doubley linked list",5.0,25
7363,7363,9080,922be3881d23d4f79d2fe24bf6321a23d63d950205b6ff6979047d1cc7c61465b9b18bdf8228c338eb886bb3010ea5578ec21cbc2819ca5ad2860838b719658d,"We would use a singly linked list with a tail point also storing size variable, incrementing & decrementing as we adding on to get size operation to O(1). We implement our own tail, keeping track of head and tail making inserting at the back easier. We can have t->next=new link(v); updating tail: tail=tail->next; . By storing tail and keeping it up to date allows us to go from tail directly to add new link wherever we want, updating tail to point to the last item. In this way all operations are constant time. ",12.0,25
7364,7364,9081,d5eef99882213e9e893ef6d31b163cddd65b11b328a038af368c63b9dea5c55582d674f73b7f44a7ffb0e808a2c14f224354666b5c8da68a3cf145583cdbcada,a double linked list should be used since it has a head pointer and a tail pointer which can help when we are pushing at the back near the tail and poping front near the head and these can be done in constant time. To check for number of items in the queue we can keep a counter which will increment when we push and decrement when we pop.,12.0,25
7365,7365,9085,4bccbfcaa9439271fb4e221590e1fd6768f9a6170a62193e2aa38f727ca7e838985ca00984f7b4a782149961c288a265aac8163c38e74ff4f6279a0f9baaec5e,"You could use a forward linked list with tail and size variables. The front of the list would be the front of the queue (oldest members) and the back would be the back of the queue, with the newest members.

Adding to the queue takes O(1) time: You would use push_back on the list, which takes O(1) time since there is a tail variable.

Removing from the queue takes O(1) time: You would use pop_front, which takes O(1) time because the head is the frontmost (oldest) member of the queue.

Peeking takes O(1) time : You simply have a look at the item at head, which takes O(1) time.

Checking the size takes O(1) time : There is a size variable, so you simply access that.",12.0,25
7366,7366,9086,7ad6b014f9c54f4af21e21f5ded12f480a954caacae0b1ae202d37d441149e00126be0ab20466a777e1dde3487a3cf0d1df830a29d9d1df5f045525d8082c235,"I would implement a queue using a linked list that has constant time in all it's operation by introducing a head and tail pointers, this would allow pushing back new items and popping items at the front much easier as the head pointer gets easy access to the front of the queue making it easy to remove by having a tmp pointer that will act as a standby for the head pointer to be allocated onto the second item following the one being removed, then with adding, the tail pointer just adds whatever item is being included onto the queue. With the pop and push happening at constant time, the front (peek) is quick to see as the head pointer indicates the item then the size is easy to tell because the pointers would have tracked the new items being added or removed. It would be a Single Linked List (SLL) tail.",12.0,25
7367,7367,9087,cbae5eeb6217dfd80bce3b9f9dcc6a487de93ab5d86c0254cee58b6e3923317f7e11f9c1e67f0e0269268aa476f5f7d41a06d2c8bc23012e2299f02af5f41761,"We would use a doubly linked list.

Keep track of the front, tail and n_items.

FOR PUSHING TO THE BACK:
Create a new link item. Set the tail link of the list to point to the new link item. Set the new link item's previous link to point to the tail of the list. Set the tail of the list to the new link item. Increase n_items.

FOR POPPING FROM THE FRONT:

Create a temporary pointer to the list's current head. Set the head of the list to the current head's next link. Delete the old head by referring to the temporary pointer. Decrease n_items.

FOR PEEKING AT THE FRONT OF THE QUEUE:

Just check the head of the list.

FOR GETTING THE SIZE OF THE QUEUE:

Just check n_items.",12.0,25
7368,7368,9088,76547c457fac096aa24860742165ce32f0a7082f7aeb253f2ff91571275838954033b1627523b79a6ff278d5ebec75d54fbefdc04c377a9da2d71a00fe00d461,"A queue using a linked list where all the operations are constant time would use a Doubly Linked List that contains a head pointer and a tail pointer. Every time you need to add an element:

tmp = new Link(value);

tail -> next = tmp;

tmp->prev = tail;

tail = tmp; ",5.0,25
9726,9726,11446,dc116295695675ce8f8f9dcde7d1d181a1fc34469a4bd2a570b8ca26a7951f6381d662fe47ef41e490d057b64113abc45be11b89047c039c48685692d843ce1d,"We visited each node two- three times, because each node has left and rigth node and corresponding to two times. When we do pre-order traversal, it is value -left and right so each node is visited twice because the node value is visited at the begining.  When we do in-order traversal, it is left-value and right so each node is visited twice because the node value is visited at the middle. When we do post-order traversal, it is left-right and valueso each node is visited three times because the node value is visited at the after the left node visited and the right node visited. 

the complexity of a bst travsel is O(n) because it prints all the value one times. ",1.0,35
9727,9727,11447,cf96d5be5169d5386c2ce2a3ae914384cd3ff74c0ae41c6fc53cb4ef592a7f9882d33970f1f807fe79c0e961bedb5189d6cfa997817a7684663f34c5e5fffad2,"When performing a Pre-Order traversal, we follow the order of: Value, Left, Right. Since we only look at the current node to decide if we should traverse the left and/or right. Since we are using a binary first search, we are backtracking certain elements (for example, we would print the current value, traverse left and repeat) meaning that, in the best case of the height, h = log2(n+1)-1, we would explore all child nodes until we encounter a leaf node and then backtrack, so every node, except the leaf node would be visited twice - as each child node would be visited, explored and then the recursive function would return back to the original node, thus the time for this would be linear O(2n) which is O(n) since we disregard constants. Even in the worst case scenario when the height of the tree is h = n - 1, each node would only be visited twice, since we would essentially be traversing a linked list and then backtracking back to the original element.  

Since the in-order and post order follow a similar approach to the pre-order, just traversing the tree in a different order with a similar recursive approach, these traversals will also take a O(2n) = O(n)  amount of work as the same method above would be followed. 

Thus, since all 3 of these traversals follow the same approach in a different order, we can conclude that the traversal complexity of a BST can be done in linear time O(n) ",3.0,35
9728,9728,11448,66c130d147af93128f149a1c3cbc0822def0372144aa77769fad8d406e0bf1fdaea5c4080bf967de52230b79e34763f78e3d8c34ddd69955b5c9b8521c52443c,"The number of times you visit a node depends on the number of children the node has. If the node has one child, you will visit it twice, once on your way to the child and once on the way back to the parent of the node. If your node has 2 children, you will visit it once on the way to the left child, again on the way to the right child and a third time on the way back to the parent of the node we are talking about. If the node is a leaf, and doesn't have any children, you will only visit it once to output its value and see that its left and right pointers are both to null pointers.

The complexity would be related to height and the number of nodes, so you would be able to work out what type of tree it is and therefore determine the complexity based on the type of tree and how many nodes there are.

Best Case = O(1) amount of work as the tree is either empty or only contains a root.

Worst Case =  I am unsure how to represent it in Big O notation unfortunately but I think the worst case will be when the tree is a perfect tree as then you would be revisiting all the parents 3 times as they would all have 2 children, instead of just visiting every node (except the leaf) twice for a degenerated tree where their is only one path.  ",4.0,35
9729,9729,11449,4795114f3afe1274590e0a1f19de90527c5847fc255bd0189e17daffae55e382487cd961fd300bbb3c50ca9f987687623e87a7237bb50d7f5d0bd58f320efd98,"In a pre order traversal we visit each node once. In an in order or post order traversal we visit all the leaves once but the internal nodes are visited once or more than once depending on how many children they have .
best cases are when the tree is complete or perfect and worst cases occur when the tree is skewed or degenerate.

complexity of a BST traversal is therefore O(n), where n is the number of nodes in the binary tree as you will have to visit every node in the tree to perfrom the travesal. ",1.0,35
9730,9730,11450,e02b2e6799a632f8edf7a4522f9a996ef61735be79c062229a0e89a8ede6774052ec8736d48de69d3335b6ebe5ac154baf9a59c6f5866c7ad081372900ff0ff8,"In all 3 transversal , pre, in, post, we transverse through the nodes once and so we visit each node once.

Therefore, the complexity of BST transversal is O(n) since we transverse through the nodes once in each case.",1.0,35
9731,9731,11451,eee70f1328b3cdb194af70a4822cc7feab4c1f2f6aa8f1c3d195e1593437b3077b36a3a63265ad79d2faed3c1dc2010c5f323409bdd6e1b2e860317721256dce,"The number of edges that originate from a specific node is capped, or limited, to 2 in Binary Trees, the maximum number of edges is (n-1), where n is the total number of nodes. Thus the complexity is O(n+n-1), which is simply O(n).",1.0,35
9732,9732,11452,a130bfe9418c91d178f590031c0c9939b5fca90db77973d7f6178ded40014a7172640da790c28b96fd7fb6c80913844b332b017840744966e0e7f4da01d28945,"In a traversal, we visit each node up to three times. If a node has no children, we visit it just once since we visit it, print its value and then backtrack to its parent. If a node has one child, we visit it, move to its child and eventually backtrack to it and then to its parent. If a node has two children, we visit it, move to its left child, backtrack to it and move to its right child and eventually visit it and backtrack back to its parent. (In the case of the root, backtracking to its parent obviously does not occur.)

This means that the complexity of a traversal is O(n). Even in the worst-case the amount of work is still a multiple of the number of nodes, not a power of it or some other more complex amount. For each node the number of times we visit it is a number up to three, meaning that it is independent of the number of nodes in the tree.",6.0,35
9733,9733,11453,a39aa34c391034439ba958ca98869143599e2cc20097d4066633e71706d0b615be58b0586a9143631148978c46ccf7746504f4abfa225c0f60b106eb68d6aeb5,"For all traversals

Nodes with 0 children will be visited once (visits, prints and backtracks)
Nodes with one child will be visited twice (first time traversal to the child, second time print)
Nodes with two children will be visited 3 times (first time traversal to first child, second time backtracked from the first child then traversing to second child. Third time print)

Thus the complexity for all traversals is O(vertices + edges) which accounts for backtracking and repeated visiting of a inner node",4.0,35
9734,9734,11454,ee3d89b0d1151de34e3cf3043fc2b6592a400e8ce8a1d14d3b5e77f1fc57f3bb24de4a9c4426effca79ea565b502539dcf46a1f1d27d52e0d1e79029ce2f8aab,"when traversing we need to visit every node in the tree. as a result, i think that the complexity of a BST traversal would be O(n).",1.0,35
9735,9735,11455,fad8ed201b5420145528f1f55dddd6df344bd6b8c41089ce34f690b1ada879c754292238d4020efb35d824794aea9c5b38d2a0434e36e803dd8ffcc5a8541493,"Traversing through an empty will do the least amount of work, it will take constant time O(1).
In the case of a skewed tree (one sub tree is empty and the other is not), the time complexity would be: T(n) = (n-1)T(0) + T(1) + (n-1)c. Which means that it would take some linear amount of work . 

In the case of both the left sub tree and the right sub tree having an equal amount of nodes, the time complexity would take: T(n) = 2T(|_n/2_|) + c.

The complexity of the BST traversal would be linear (O(n)), because the algorithm will have to traverse through every node at least once , and more than once in some cases.",1.0,35
9736,9736,11456,dc28526a371ecd3cfbb01f874b966e2e2019f65befa98a250b0089b346a7e303549dac2ead3ffeef0d3b7ecff19ac3d890b35956aa010524ff365cf1275bd971,The time complexity would be O(n). This is due to the fact that every node has to be visited at least once. These traversals would result in a linear function hence O(n) will be done.,1.0,35
9737,9737,11457,8898c8dc647252a67895b09c0b6e1e1b46e9abbd7623ddf40416335c9bffe71bf94348a71bd79a7ce33d630fd22f8d8b30ee288c330b6c240bf1f662dbee2a5b,"For any tree with _n _nodes, using a Depth First Search, a node with 0 children will be visited once, a node with 1 child will be visited twice and a node with 2 children will be visited thrice. And the total amount of visits to all nodes will be 2n-1.

In Big-O Notation, this is O(n). This is because whenever we add a node we will need to traverse to that node and to its parent node (two visits).

Therefore when we add a node we increase _n_ by 1 and increase the number of visits by 2. ",5.0,35
9738,9738,11458,fa243626fbe26ef57e9cb51b64e34cda34860d25833be057b8aacb2413654723774f7590965ed807a0415dd0e925f4717e86fc15d11f310737f703eab68fbabd,"we visit each node three times. 

the complexity is O(n).",1.0,35
9739,9739,11460,cdf5a55df376657eda6b008ced4f7043cdba2f1d1b7da216b9e5df9fd11e894729a95890612c52ba24c8f6e0b1099b039f557d8043ee19615f361b8a60481af7,"We visit each order only once in a pre, in and post-order transerval. The complexity of a BST transversal is O(n). ",1.0,35
9740,9740,11461,188f5f32ff22cc30082222ed760e5fe1e0a340d9ae7ecfafe10b384746f7f9c7803d064927e2b5ebaba803119e7d5eafdd11883d383dd0d5a80b8dfe524c593e,"when performing the pre-order traversal as depth first search since the depth fisrt search will start from the leaves and in pre-order we start from the root then it,s children we would have to visit each node once .
so using in order traversal the number of visits that we would do to each node will be 1.

using post-order traversal we would have visit each node once .

the complexity of a BST traversal is O(n) because we visit each node once.",1.0,35
9741,9741,11462,105766c5f6c790d6dc620b520090a2b98c0a0346078f36035aaeb57fa8cf54742716f9a0480d2973b6fef7f78bbaa5ba4bda7aa17dd42f5bc2f195af88fa494c,"When performing Preorder Traversal all nodes that have two children are visited 3 times and all leaves are visited only once.

When performing Inorder Traversal nodes that have 2 children visited 2 twice while all the leaves are visited only once.

In a Postorder Traversal, all internal nodes that have 3 children are visited 3 times while all the leaves are visited only once.",1.0,35
9742,9742,11463,2a73fae534f6399be599dee1f1de2adaec9431f39943abeccc1ca0cc827521f43446d764a73ff779a0d169bd025aa1ff69232dd0892e2b573939bb6ed6281bd6,"If the node has no children, we visit it once.

If the node has 1 child, we visit it twice.

If the node has 2 children, we visit it three times.

The time complexity would be O(2^n) because at each level we have at most 2^n number of nodes that we can visit.",4.0,35
9743,9743,11464,276b4e11850dbed5adc6f0fd4249cf0b5f1cdc0a0dfd3d76321298301426fddeaa12e60021bdff5fc27802e2537ea3a2e891dc9c51166641bf68a7d7906d00b7,"we visit the nodes twice

O(2n)",0.0,35
9744,9744,11465,1e30eb511c307c57041552d3f3ff58f0e01dff16b4bbeafb7e1426a20560b5727bf879a4c238af04f66b8c454f01b583c75d2d8fab510951c437d49081081f31,n-1 times. The complexity will always be O(n) because we need to traverse through all the nodes to perform the traversal.,1.0,35
9745,9745,11467,38046b991658125dabc236638e4678ce8b6ce1a14066e89cee307b4ad43150545ef075aca8b10f61c4cd3909f6915397eea519e89ce5ad74fb62a1715837f925,"How many times does the search visit one node depends on how many children does this node have. e.g. if node A has 2 children then through backtracking the search will visit node A twice ( 2 ) +1. The plus one is because of the initial trace since it will search a node at least once.

Summery

Node w/ 0 child = 0 +1=1 time visited
Node w/1 child = 1+1=2 times visted
Node w/2 child = 2+1= 3 times visited
NUMBERS IN BOLD^  INDICATE THE NUMBER OF EXTRA TIMES IT HAS VISITED A NODE

_COMPLEXITY _is O(n + EXTRAVISTED) =_O(n)_ since want the graph only. However, this really depends on how much children a node has and how
nicely a BST has been created. Since each tree would different complexity due to unique node placement and children. Thus for full mathematical expression, the tree would have some constraints such as a perfect tree. Because then one would know how many internal nodes there are and consequently how many extra times it has been visited since every internal node has 2 children( by constraint of tree to be perfect)",5.0,35
9746,9746,11468,e9f55a461571038daf39646f8c350339a639982fda3a68a7de2c663bf3b55fcfe5c2c1470245e6cd83dc29b1d2c16e474b9b4bcd8ac2d4eb9b9e2eef6125ba6e,"pre order-O(n)

in-order-O(n)

post order-O(n)

no matter what traversal we do we have to visit each node atleast once thus the time case would be O(n) time for BST traversals. ",1.0,35
9747,9747,11469,7d8cef0de14cc2a74c530bc45e24878a9bc41b99484642b220015c976fedb5143bed1f3d3d656335fb8356093aebda35cf38a76a3da63375271eacce35baf518,"For pre-order traversal we visit each internal node 3 times if node has two children, 2 times if node has one child and 1 time if the node is a leaf .

For in-order traversal we visit each internal node 3 times if the node has two children, 1 time if the node has one child or no child.

For post-order traversal we visit each internal node 3 times if the has two children,1 time if the node has one child or no child.

BST traversel complexity is O(n^3), because for internal nodes with two children the node is at most visited 3 times.",4.0,35
9748,9748,11470,d7ea0f2a38310b663df581928807c739d1135118819d5b7623733f4d054b7f50d32672538781df6012ffae2751400911c7d428efb70c05b3c3719b6aef5da475,"When performining pre,in, or post -order traversals as a depth first search we visit each twice, initially when we're going down the tree and secondly when we're backtracking. 

I think the time complexity of a BST Traversal :

Worst case O(n)  because the binary search tree is skewed , the height of the tree then becomes n .

Best case O(logn)  because the binary search tree is balanced, and the height of the tree is log(n)",0.0,35
9749,9749,11471,17ea794106565b342d0071ecda1b602670f938db088b102cae298b8fa539f99c81604db8696804a94225d5fcb56b3538a2b45e5527c8d0a393e5e2aa5ae7c0be,"In a BST with n nodes, in the pre, in and post-order searches, we would visit each node at least once. The complexity would then be O(n) as we would visit at least n nodes.",1.0,35
9750,9750,11472,ff8092e7aa4e021dd13cb98107d467aae4489986d4e06673b1b4c81ebb2bbfe82687888ce375f42c4423ae545a48ef629cc67802c799162dd6a5d1de2f545d85,"We visit either once if node has no child, twice if node has 1 child or 3 times if node 2 child. complexity of a BST traversal would be O(n).",5.0,35
9751,9751,11473,8498970fc897a847cb08416ff377f1fef48bec60ecb47ecc86ba0d40abc666899852250e00e887a707bf5de87564f205ddbe85abfd397367947073bde3e3789d,"We approximately visit each node once, best case. I believe the BST traversal complexity is O(n) (constant) because you're just going through each node and checking if it has a smaller or larger node before moving to the next.",1.0,35
9752,9752,11474,24404807247a19fa0eb28edfebfb33701c7bf0ce5da4f252098d5b07602e418852b18cd29763fdb981a6cf7530167e7c60c21dd57b0dd95a95c25a71b9515eda,In all of these traversals we visit each node once and hence the complexity of a BST traversal is O(n). ,1.0,35
9753,9753,11475,eacc5211df7d685afcc35802886c12863f0c8244351fcd398189af9fa9bf26e12a751640dd66f6200f43478fc4f6782d51b4f6c4a782ca1b75e12c96dded3eec,"When performing a pre-order and post-order traversal, you are performing a depth-first search. In general, we perform n +m steps. where n is the number of nodes and m is the number of edges. However, in a BST the number of edges is equal to (n-1). Therefore the time complexity of these traversals is O(n + n-1), which becomes O(n). 

When performing an in-order traversal, you have to access all nodes to access the elements in order, thus we visit each node N times. 

As a result, of the above, the time complexity of a BST is O(n). ",1.0,35
9754,9754,11476,d7e19f96a6aba1e381d06c4d14cd8af55d98ac1778548325b5d3026d929df87b2abc3d523dd5623a58ab296187735de8598844f1ea29e935b29ced21ed87e297,"For each traversal, the number of times a node is visited is based on the on the number of nodes it is connect to(including their parent). Eg. if a node on level 1 has 2 children then the number of nodes connected to that node is 3, meaning that node gets visited 3 times in a traversal.

Baes on this I would say the complexity of a a BST is logarithmic (O(log(n))",4.0,35
9755,9755,11477,8cfb9c3f85d9b6edb1f914f05f74928e81fe7cb4cefb95f1de4efb3fd1ac54a2356179dfe5b33b1cac09455e2960c015d866e1097ed5d7d20fbbdcb0d2aeee6d,"1)In the best case scenario you visit each internal node twice and every leaf twice and the worst case is when you have to visit each node twice.

2)The complexity of a depth first search Binary search tree is O(n) because the number of edges that can originate from a node is limited to two, thus the maximum number of edges in a binary tree is n-1. the total number of nodes subtracted by one.",1.0,35
9756,9756,11478,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"We visit each leaf node once, whilst we'd visit each internal node 3 times. The number of internal nodes is given by 2^h - 1 and the number of leaves is given by 2^h.

Since we visit internal nodes 3 times and leaves once, we'd visit a total of 3(2^h - 1) + 2^h. Since h = log(n+1) - 1 we can use that representation for h to get its form for big O.

In terms of h, the complexity is O(2^h)

In terms of n, h is n - 1 in the worst case therefore time complexity is O(2^(n - 1))",3.0,35
9757,9757,11479,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"We visit each leaf node once, whilst we'd visit each internal node 3 times. The number of internal nodes is given by 2^h - 1 and the number of leaves is given by 2^h.

Since we visit internal nodes 3 times and leaves once, we'd visit a total of 3(2^h - 1) + 2^h. Since h = log(n+1) - 1 we can use that representation for h to get its form for big O.

In terms of h, the complexity is O(2^h)

In terms of n, h is n - 1 in the worst case therefore time complexity is O(2^(n - 1))",4.0,35
9758,9758,11480,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"Since we're working out time complexity, we can consider the worst case for the properties of each node. So we can say that each internal node has at most 2 children. With considering backtracking, we visit each internal node 3 times, and we visit each leaf node once.

Using the height of the tree being h, the total amount of nodes in a tree is given by 2^(h+1) - 1, since there are 2^h leaves we can subtract 2^h from the total amount of nodes.

We then get 2^h - 1 for the number of internal nodes.

The number of leaves is given by 2^h

Since we visit each internal node 3 times at most and every leaf once at most, we can come with up the expression

Visits = 3(2^h - 1) + 2^h

Simplifying we get Visits = 4(2^h) - 3

But we know that h in terms of n is log(n+1) - 1

Substituting h = log(n+1) - 1 we get 

Visits = 4(2^(log(n+1) - 1)) - 3

Simplifying we get:

Visits = 2n - 1

This is a linear function and we can drop off the non-dominant terms for Big O notation. Hence a Depth First Search on a BST is O(n) time complexity.",3.0,35
9759,9759,11481,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"Since we're working out time complexity, we can consider the worst case for the properties of each node. So we can say that each internal node has at most 2 children. With considering backtracking, we visit each internal node 3 times, and we visit each leaf node once.

Using the height of the tree being h, the total amount of nodes in a tree is given by 2^(h+1) - 1, since there are 2^h leaves we can subtract 2^h from the total amount of nodes.

We then get 2^h - 1 for the number of internal nodes.

The number of leaves is given by 2^h

Since we visit each internal node 3 times at most and every leaf once at most, we can come with up the expression

Visits = 3(2^h - 1) + 2^h

Simplifying we get Visits = 4(2^h) - 3

But we know that h in terms of n is log(n+1) - 1

Substituting h = log(n+1) - 1 we get 

Visits = 4(2^(log(n+1) - 1)) - 3

Simplifying we get:

Visits = 2n - 1

This is a linear function and we can drop off the non-dominant terms for Big O notation. Hence a Depth First Search on a BST is O(n) time complexity.",4.0,35
9760,9760,11482,e06c3717f5eff40cf06c551e6ebf1004bb478bf8fc38ebcba99f54530677cde6de5ea93590e51ef3d1e09f18ed2aa22502c287548e3398f50b4cf8f8e940073d,We have to visit each node exactly once. However we might visit a specific node more than once (i.e if it has 2 children) when we backtrack to go to the other side of the tree. This would all be done in O(n) time. However if a node only has one child it would be visited once only.,1.0,35
9761,9761,11483,c01425271443b193ce09add717a13c5f03e56291a15f580c8ffbb713e75d1afdc1826b33b91330419ca4db414a4703bd7b9474559be3d7689b82c2ecbf73906a,"When performing a traversal you would visit each node at least once. All four types of  traversals require O(n) time as they visit each node once. However, if the parent node has two children that node will be visited twice to check the left child and the right child. This would still take O(n) time.",1.0,35
9762,9762,11484,7aa4a41956fb10b2ea3a02d2d85c1eec912704226ca5710248e26fa3e0fa199d5048abcac9423a11d00a49ffe75bdd51e2b3cd752d5f6899af51dc4b580afed1,"When performing any traversal as a Depth First Search, we visit all nodes at least once. We traverse through the tree recursively to get to each node. We traverse through both the left and right subtree's of a node. 

If a node has 0 children we would only visit it once as we wouldn't need to traverse to that node's left or right subtree. 

If a node has 1 child, we would also only visit that node once as initially when we visit that node we could tell whether the right or left pointers are null. Therefore, we would only visit that node once as we would only traverse to either the left or the right subtree. 

In the case of a node having 2 children, we would have to visit that node twice as we would have to traverse to both the left and right subtrees, backtracking to that node after visiting one of it's subtrees. 

Overall, the time complexity of the Depth First Search Traversals would be O(n) as each node will take a linear amount of time to be visited once. ",3.0,35
9763,9763,11485,b3e3cb2c21ce148370b5e2f91fd1c15e350a5dbb48b70710937a60df00151bac26d80bc3a7bdad4c31eb69ebb35264a7c7773c7f45cef6e057b05eb18d125d01,"For each of the traversals, you will have to visit each node in the BST. and traverse from left to right first . If there are n nodes in the binary tree each node will be visited (n-1) times Which means the runtime complexity is O(n) 

Time complexity of a BST traversal: O(n+m). n is the number of nodes and m is the number of edges.",1.0,35
9764,9764,11486,59ba65c517c334e25d3ae45ca0766a06b5a36061abfca1dd80f0f9e00eca00b8fc96224e4fcd721b2a66146a086c07a1cca9cf5028a8fc5d88a04890a96fe5a7,"I am not too sure about this one, although I believe it is necessary to visit each node only once with an efficient algorithm.

As a result, the complexity is O(n) as we visit each node, traversing across the entire height of the tree.",1.0,35
9765,9765,11487,c52fe90555e82813bbf7f31602e97c4095475fbbf85ff26471f0158158110480233228486a71767a61c524c47fe301d427e9bdbb31f3216eb95878f59314ec4c,"Since the number of edges that can originate from a node is limited to 2 in the case of a BST, the maximum number of total eges in a BST is n-1, where n is the total number of nodes. Complexity is then O(h+h-1), which is O(h). O(h) becuase you traverse each node once.",1.0,35
9766,9766,11488,16cb13e3f20264dff11bab6b4074b1ead9b8e1cf1d7a12dd1238f56fff77a643c79324083d48280a979ad65c97d7690c011f0b94300438693e7e3022511b7be3,"you would visit all internal nodes at least twice and the leaves only once for pre, in and post order traversal, these are both constant time, the root of the tree is only visited twice but for the rightmost leaf of each left subtree you have to traverse all the way back to the root of that subtree, revisiting nodes that already had been visited twice, this complexity would be equivalent to the height of the tree, best case O(logn) worst case O(n)  ,therefore the complexity of the overall DFS is  O(n) ",3.0,35
9767,9767,11489,e5092ab1c7e17d25e5db9dfc9252b8c31679cb1e2b17a0be836efd97ce606988409f994ae92e4e1f795d2d139fe2c46eff4d5f244e605f9f08c46d7129da95d2,"In pre order traversal we follow the pattern Value, left chid , right child. This mens that each node gets visited once 

In in-order traversal we follow the pattern Left child, Value, Right child. This means that once again each node gets visited once.

In post-order traversal we follow the pattern Left Child, Right Child, Value. every node gets visited once during this traversal.

In all the depth first search traversals Every node gets visited once meaning tat there is a tie complexity of O(n).",1.0,35
9768,9768,11490,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,Each node has the possibility of being visited a number of  times according  to its depth. This may range from log(n-1)-1 to n-1.,0.0,35
9769,9769,11491,5f1f48eaee5ac422a3c6fa6a37eae574e54bf5c31dcf24e0e6dda503da6ac10d5be4b86335df2a703c5cb0a92be355a3535eec42ddde1a798228e8594808928b,"For all traversals, we would have to visit all nodes thus we would have a complexity of O(n) by default. However due to the orders which they each do their own traversals it will result in a different amount of nodes being visited being slightly different due to the backtracking. Should we have used recursion, all the traversals would have had a complexity of O(n) as we simply pass the subtree until we get to a leaf, and then return/print the value at its required position. Thus we wouldnt need to revisit any nodes, and thus give us a time complexity of O(n). Now let us consider if we take backtracking into consideration for each of the traversals.

For the pre-order traversal, the order of the traversal would be value->Left->Right. This means that we essentially go to the left side of each subtree completely before we move onto the right side of the subtree. To do this, (with backtracking), it would require us to also revisit every internal node (height of that node +1) times, if we take into consideration the test if a left child node exist would require a backtrack. Thus we get that we would have to visit n+m nodes, where m is the number of internal nodes. And as n>m, we can state that the complexity of this traversal would be O(n).

For the in-order traversal, the order of the traversal would be Left->value->Right. This would essentially lead in the same repetition as before, as we would visit the most left node of a subtree, before going onto its equivalent subtree.  This we would also see that that we would have to revisit every internal node height of that node +1) times, if we take into consideration the test if a left child node exist would require a backtrack. This would then lead us back again with having to visit 

n+m nodes, where m is the number of internal nodes. And as n>m, we can state that the complexity of this traversal would be O(n).

For the post-order traversal, the order of the traversal would be Left->Right->value. This is a little different from the other two traversals. As the value is only stated after the respective subtrees have been followed, it would require us to go back to the node and print its value, after we have visited all of its descendants. For the most part, this is no problem as since we are backtracking, we will still have go back to the node in order to traverse to the the right subtree of the root. However, for the right subtree of the root, for the previous traversals we did not have to traverse back to the node after we got to the last node on the extreme right. Now we have to go back to the root from the maximum value of the tree, this requires us to go through at most (when the the tree is right heavy) h more nodes to get back to the root. Due to this we can say we have to visit n+m+h nodes, where m is the number of internal nodes. And as n>m and n>h, we can state that the complexity of this traversal would be O(n).

From this we can say that also doing the BST traversals via backtracking, it will have a complexity of O(n). ",1.0,35
9770,9770,11493,d96af73b5be668f5dd689aeab89641b2c7231424c7456f3ea33f65b38aaefabde723924090d862562454b1c8a6f22cbeb22245f54dc09b6ff5593a40d39e2839,O(n) time complexity,1.0,35
9771,9771,11494,bee12730d57033f530e6d3af850b801527bbf28710ff5b08a5e590d280e30c6a0345b61d0e3b24cafaad1628aee3191406710ce83cd7009c586afaf78d031389,"Because we visit each node exactly once in all traversals, the complexity is O(n)",1.0,35
9772,9772,11495,9d9fbdb8f0b5a55cc81f40af01c24b37d17fe31db439c419f81b64ca34d8f4ebfcf1ed9c7ba472f3885693ca593e5565dfb6d3c7a7ecc8755427baec264e52b2,"When doing a Depth First Search of a BST, we visit each node a certain number of times depending on how many children it has. If a node has 2 children we visit it 3 times, if a node has 1 child we visit it twice, if a node has no children we visit it 1 time. Now I'm not sure how to mathematically prove this, but for every type of tree I tried (degenerate, complete, perfect or none of these) where n is the number of nodes, the total number of visitations ended up being 2n - 1.

From this I conclude that the complexity of a BST traversal is always O(n).",6.0,35
9773,9773,11496,49811d763ba759a50f2e0c233e15588b02d4f863f2daf7bb9891b1e7fc339a6758ecc3a62c1286ec47602b5e14c6edff45dda6e0d22355027319e6c73f32c285,"In every case pre, in and post traversal you visit every node 3 times .I think its O(log(n)) cause depending on the position of the values being searched for the time changes from liner to exponential but is not solely on of these two",0.0,35
9774,9774,11497,f786d4a53e476362ee6b6cac013b5aa057803211cb74556b039162da9be82c23d9395512d9e4320c69ff2f74e18df3e862b758b12f302cbbc8a9df857835a235,"1.(Inorder Traversal) using left-root-right , the left child node is visited first then the the root node is visited and later we go  for child node. In this case we go far let till we reach a node that has a null pointer and we go back one step up before going to that right of node and each node if not the leaf node is visited twice if it has one leaf and three times if it has two leaves. Same applies to pre order and post order.

2.considering the observation above we will traverse with O(n) if we were to visit each node. ",5.0,35
9775,9775,11498,112623e30928da280b124065b33eb8360f6fe49f45f9b97cc7a540f6e550a5152dd7bbbd6ba167e88c839362c8fd2148a3e881c83493d58d2e9fd2216c604c8a,"Tree traversals require the visitation of each node. Resultantly, at least n operations are performed. In the case of depth first search traversals, each node is visited n times resulting in a complexity of O(n). Considering that a BST is a graph and graphs have a complexity of O(n + e), with n being the number of nodes and e being the number of edges, the complexity of a BST traversal is O(n). This is because each node can have a maximum of 2 edges resulting in n-1 representing the total number of edges in a BST. This then makes the complexity O(n+n-1) which simplifies to 0(n) as the constants make no difference in depth first search traversals. ",1.0,35
9776,9776,11499,a83848dae9e11c32fb0fef1054c9f0420423c74efa66838a210a7774eb07b64f5a5df97bc2a33594ee565ea37cacb65f8fcddd5281fc0b93d6e6e1b0ba5da1ac,"1. The each node is visited O(n + h) times.
2. I think it is O(n). since  the total number of edges is n-1 so O(n + n-1) which is O(n)",1.0,35
9777,9777,11500,174e38c18f0521eafee3b73a0ffb8449a8c5784d547a0843ddac9c9176015fedd2516d8b3d18b017cc9000d2b315ebe1757a54b724f337f3a99202881366a527,"Twice.
O(n) ",1.0,35
9778,9778,11501,d320af019b5c5fbf5996000b6f0c018e158d92ab05c3709236e5a03a6b328c59c1ab963403ff89c119e51b19d4eaa6320e2573a8bf4efb41ca5bbf92364ab8b6,"We visit leaf nodes only once. 

We visit parent nodes which have only one child twice, once when pushing it onto the stack and once more when backtracking from its left/right child.

 We visit parent nodes with two children three times, once when we push it onto the stack and once again when we backtrack from the left node and once more when we backtrack from the right node. 

Therefore in my opinion a BST traversal has a linear complexity O(n). ",5.0,35
9779,9779,11502,0b4066304490dceaa89df857c52096e501a361b0158a4122fe0743ccedb637acfd51e379e86df6a8a4f667a87b6d33f81aa5b4a035dd7d71db1ee1c7171afd95,"in all the pre,in,post orders we do the quadratic amount of work O(n^2)

it is also going to be quadratic because to do the orders we traverse through the whole tree ",0.0,35
9780,9780,11503,8fd97c5322558e2423003672fe174f30c080d208985516c4cd8749e1d3f072ac5736c633a74790122fa877f92436ac7777fc9cf9c36610a77bd1566b6903427e,we visit each node only once and the complexity is O(n),1.0,35
9781,9781,11505,3b413468f9946530e16c6d2ced91ab45356664eb3ef35b2823043a9391b6766aeb5cd1cde7c7799a9976f4713f096989c7f13a6ea1b6e1be3f9af94b87e0d40a,"All the different traversals visit nodes the same number of times. This is because all of the traversals will traverse the entire tree, the only difference is how they treat the current node with regards to outputting/returning a value. Since we traverse the left subtree first, backtrack to the root and then traverse the right subtree all the internal nodes in the left subtree will be visited an additional time compared to the internal nodes in the right subtree. Leaves will only be visited once regardless of which subtree they are in. Nodes with 1 child will be visited 2 times in the left subtree, once in the right subtree. Nodes with 2 children will be visited 3 times in the left subtree and 2 times in the right subtree. Considering this and looking at a perfect tree (this is where we do the most traversals) of height h. We have n nodes and we visit them each a constant number of times (1,2 or 3) this is a linear amount of work O(n).",5.0,35
9782,9782,11506,90a8f27cfb71d61b9c73a7a8ab33730e3ebc85bfa97c54d9b613ce87b305b9e1aa432bcfbae1c2c5d2035b82671180a8d7f60a46fa0262145d5fd6b791318ce7,"Without considering backtracking as visiting a node, each node will then be visited once in all traversals (n times). Taking into consideration backtracking, the ADDITIONAL number of nodes to be visited will be the number of edges that the tree has (n-1 times, considering the property of a BST). Therefore the total number of times we visit each node in a BST for any traversal is 2n-1 times

2n-1 is simply linear, and therefore so is the complexity of a BST traversal (O(n)).",3.0,35
9783,9783,11507,de345146608f48652cf9ec333ad07816bb0cf99089477ca7af207bce7f9f2c81b03f0e317efccc60f220182480d765ee6b6291c08b7723e7e91dd8402a584cdd,"Pre-Order Transversal: Each node is visited at least once and at most 3 (assuming you back track to go from a left sub tree to a right to a right sub tree) meaning it has a O(3n) time at worst case because you have to visit each node 3 times

Post-Order Transversal: Each node is visited at least once and at most 4 time (assuming you back track to change from a left sub tree to a right sub tree) this is because the node is visited once initially, then it is visited again when backtracking from the left branch, then again from the right branch, it then has to go up a level to print that value and visited a fourth time when it returns to get that value making it O(4n) in time

In-Order transversal: Each node is visited at least once and at most 3 (assuming you back track to go from a left sub tree to a right to a right sub tree) meaning it has a O(3n) time at worst case because you have to visit each node 3 times",0.0,35
9784,9784,11508,91ebe020e489f0682b9824bba92593f1328536973fcefa2088842b20b827aef8bdfb02c354fbd4b326e7989de48aea571427c17aa049b6dadee99c74f1c15bdb,You visit each node two times meaning the time complexity of it will be O(n^2),0.0,35
9785,9785,11509,d42cf42830844a9ee1d0ff0af8c2f689af280ff8f6db853246aca542789b88210a975754cb807f66256c17bb8f0db7f822b9fd7b118d4ccaab17c4ee83f0a430,"Each node is visited once, hence O(1)

Its complexity is O(n)

Since the number of edges that can originate from a node is limited to 2 in the case of a Binary Tree, the maximum number of total edges in a Binary Tree is n-1, where n is the total number of nodes, hence the complexity being O(n+n-1) = O(n)",3.0,35
9786,9786,11510,5efe3fbf856ecf3a15a69292118ba94b4935a0dba8b272f0af264465d64a2e654697453d0e3e6e72201dc798f4cd3f27b28fbe0c2032a2a7784e39ed4c150909,Each node would be visited at least 1 + (height-depth) number of times with the exception of the root which would be visited h number of times. I think the time complexity would be linear O(n) since you would have to visit each node minimum of once and maximum of the height of the tree.,3.0,35
9787,9787,11511,9607664f15775a14ee634c51fe9c149f525e26b98d5914c3165e84652908eb3f36dc6b5eb9602fdd2aa10815feb68c6202a768e4280fe2bc5565e0190f5672e7,We visit each node once in these transversals. i think the complexity of the BST transversal is O(n) because we as we visit each node once it means that the amount of work we preform is dependent of the number of nodes in the tree.,1.0,35
9788,9788,11512,e23792b17279f93b3cce4dddca09079f761a6a0f2795c6c3c7434b417d9b72d4e94d0c740b318fb5b6d57338883455b8fe250e5759d4aa78bd8b7bd3bfed6a55,When using Depth First Search we visit each leaf once and weather a node has 1 or 2 children will determine how many times that node will be visited. All non-leaves will be visited (number of children) x (constant time depending on transversal) . As the amount of times we visit a node does not rely on the rest of the tree except their own children we see the work done is linear therefore we have a complexity of O(n).,4.0,35
9789,9789,11513,5e36a0e7b93c9d082984c03228c748a0348993dbc7307752e7acfbf7e44b3df39b6aedb0dd5c68b0421254e8914343a9e052d4d15e260e3ecd7ef28810b12ec9,"For all traversals, the complexity is proportional to the number of edges and nodes.  If it is given that the number of nodes is n, the corresponding number of edges would be n-1. After visiting n nodes one would have to backtrack n-1 edges. This results in a complexity of O(n+n-1) which is approximately equal to O(n).",3.0,35
9790,9790,11514,dc016101375a4c30fa08c850e4ef82abdd66ca922170c25b2eda3c6f7009abcdda2dafb1c86a512fdd1b897c4c9da94be8f7047b535d50f3a259b1e698b13e05,"for each traversal, in-order, post-order and pre-order will take O(n) amount of work.

The complexity of a BST traversal is O(n) because the complexity of each depth first search traversal of a binary tree is O(n+m) where n is the number of nodes and m is the number of edges. Since the maximum number of edges that can come off a node is 2, the maximum number of total edges of a BST is n-1 where n is the total number of nodes. Therefore, the complexity becomes O(n+n-1) which is O(n). The complexity of a BST traversal is directly related to the number of nodes in the BST. ",3.0,35
9791,9791,11515,412b107ec0ff412753968aa6ffdad40da21fbfd59417aac428d07f6c064389cc24911eb533cf92e901bf7845b76400d7d3831fd1347350b39d220d9c58729d2b,"When doing a pre,in or post order traversal you visit a node many time until the condition for the BST is matched and all the backtracking is done.

The complexity of a BST traversal in is O(n) for the worst case and O(lgn) for the best case ",0.0,35
9792,9792,11516,16f82e0a87e8ddd62872296dc55051239fbed9bd7e989d4564eab3d0b0bd3dd97f30debd1ef7c57a72ffc4e972a5a710915f103218e9d2778be68d8b10a7d403,O(n) this is because you still have to visit each node.,1.0,35
9793,9793,11517,b47128b210e7cc636fb0b5325c08248ffac624374ed1eaac62c3594d5f67da91cc887cbf07a6c3571b2149ad963910548cff788f165204f9df156115e859a64b,"If the node has 2 children, it will be visited 3 times; if 1 child, it will be visited 2 times; if no children, the node will only be visited 1 time.

Taking the above into consideration, the complexity of the best case would be that of a degenerate tree where it would take O(n) work.

The worst case would be when there is a tree with large number of nodes with 2 children. This is a perfect tree. In this case, it would take O((n - 2^height)*3 + (2^n)*1). This relationship multiplies the internal nodes(with 2 children) by 3 and adds the leaves. Also, taken into consideration that the height of a perfect tree is log(n+1)-1. Simplified, it gives:

O( 3n-3/2( 2^log(n+1) ) ) = O(n-2^(logn))",5.0,35
9794,9794,11518,e2110671a4eab220560a21f9e1e9feb257ad75ab23f504a892c8df780bcf445f866d86be0cb87936d65c86a82a0daabcca41a6174ec4192f8f61c7d3034cdab4,"For a tree with optimal height, the internal nodes (including the root as this is called recursively) will be visited twice if they only have 1 child and 3 times if they have 2 children. The leaves of the tree will only be visited once.

For a completely degenerate tree, the internal nodes will only be visited twice, with the only leaf being visited once.

For a perfect/complete tree

There would be (3*2h-1*2h) < O(22LOGN) = O(N²) (apologies for notation)

For a completely degenerate tree resembles a linked list

There would be (2*2h-1) < O(2LOGN) = O(N) as well  (again, apologies)

Which means the Best case of a Depth First Search is on a degenerate BST being O(N)

AND the Worst Case of a DFS on a BST is O(N²)

(This makes sense, but seems wrong...)",4.0,35
9795,9795,11519,128e2656328deed2d77d2ef28a4c653d82a40a62fd734c4ccb3dafb70805db8a812cccc608184c6cbda73e2bdda34e6f81ec5dacc95d16cb9a78cba4ff089ac5,"When visiting each node to complete the search, we will have traversed a total of n-2 times. This means that the time complexity would be O(n).",1.0,35
9796,9796,11520,9dc85d5fc9d9d7b3ced470df92bc3f618b906428cc44daba96ce09d4da7c5e6251f817ad8b6d168d5489d3951e1d39f87f0ab87e50f2ae36060fe5a0c0501b6d,"All three types of traversals would involve the same number of visits given the same tree, as it will be the same steps, just in a different order. That said, you will visit each node at least once and at most three times according to these situations:

A node has zero children — only the value has to be processed and no backtracking through the node after visiting its children is necessary; ergo, you only visit it once.

A node has one child — the value will have to be processed either before or after (depending on which child is the null pointer and the type of traversal) visiting its child and then again when backtracking through it. In this case, it is visited twice.

A node has two children — the value of the node has to be processed before, between or after (depending on the traversal) visiting the children. Once a child has been visited, the parent node has to be revisited in order to access the second child and then again when the second child has been processed. This means that the node is visited thrice in this case.

We know that in a full tree — that is, a binary tree wherein every node has either no or two children — the number of internal nodes is (n-1)/2 and the number of leaves is (n+1)/2. Three visits per internal node plus one visit per leaf equates to 3(n+1)/2 + (n+1)/2 or, after simplifying, just n+1 visits. 

Because we are examining the time complexity, ignoring the case of nodes with one child shouldn't affect the answer here, as it will just add a different constant coefficient. As such, we can conclude that the traversals have linear time complexity as n+1 translates to O(n).",6.0,35
9797,9797,11521,a837228a932a0a88d86d56984d3a65abcc9744de389dd1a09c0dbc6344b07254c5f44d2d0e035800fe07d8fd7ef535a3af313b16fa0ec5085dc57d2a491f0957,"for the traversal of the tree the number of times of a leaf is visited is always one ,if you have a node on the left of the root then it will be visited two times, if the node is only moving  left of the root it  will be visited twice and also for visiting the right of the root. If the internal for example in a case  is added by moving right of the root and then left of the subtree, this will let the node be visited 3 times, whilst the same applies if this node is found on the left of the root and then to the right of the subtree

The complexity has to be linear so O(n).",5.0,35
9798,9798,11522,0a1eb6f30606d1f92d934eb03ca9d55d90d2ab3f505cdcb3ba02589cc6678998e8754ce7335373d6c01684ffed4a20fad8a976d2479c3f801a51d1c2b0d4ed50,"for the 3 traversals the number of times a leaf is visited is always 1 but the internal nodes are different , if you have a node on the left of the root then it will be visited 2 times ( so if the node is always only moving to the left of the root it will be visited twice) and the same applies for visiting a node that is always to the right of the root. if the internal node in a certain case has to be inserted lets say by first moving the right of the root and then the left of subtree root , this will cause the node to be visited 3 times ( the same applies if the internal node is found on the left of the root and then to the right of the root of the subtree.) 

Thus for a BST traversal complexity , it will be linear -> O(n)

 ",5.0,35
9799,9799,11523,b35e384f7c5ceb06d79c3b93cc63fcaa47042ffefb6b106d30f49be852e804e9feab1392cb217f65d7e7d63ec9914fbf325012c10f23427d79d4c0865092862e,"For a perfect binary search tree with nodes 1,3,7,15

Pre-order and in-order transversals visits 1,3,10,26

and for post-order transversals 1,4,12,29 nodes

all leaf nodes are visited once.

if a node has 2 children and is not the rightmost in its level then it will be visited 3 times.

if the node has 2 children and is the rightmost in its level then it will be visited twice(unless it is a post-order transversal in which case it will be visited 3 times)

this means the number of transversals is the number of nodes plus two times the internal nodes.

Therefore in order to transverse the entire tree using post-order transversals, it would take O(n+2(n-2^h))

h=height = log(subscript 2)(n+1)-1

For pre and in the order it would take O(n+2(n-2^h)-h)",1.0,35
9800,9800,11524,bd50a1f76e0acde64b2131110f2268f08aef333a162fed075d374337a58f0180c5f1efb88a7f6560e676d09d9ae71856da1ed18b029ff6c96af885a57d9fef75,"When it comes to traversal, there are 2 choices: either we visit the node first or the subtrees first.Tree traversal is a form of  graph traversal and has a process of visiting_ _(checking and/or updating) each node exactly once, in the best case.

O(n)",1.0,35
9801,9801,11525,185dc4c21423a9741e871c6f410e59bdca77c391c194cec101c75b3cca04c937f124a0057340342b97dc026d09e5d98b6cb6fda9dab2b9032e1e211b08f87356,"O(2^n)

To test this, I drew 3 trees, a perfect Binary Tree, a Degenerate Binary tree and an ordinary Binary Search Tree.

Surprisingly, on the Degenerate Binary Tree, you visit each node twice when traversing through the tree, this means that in total you do 2^n work. On the Perfect Binary tree, you visit each leaf twice and each internal node 3 times. this means you will do an exponential amount of work with base 2 again. An ordinary Binary Search Tree will have degenerate and perfect tree qualities, so you will visit a leaf 2 times, and if an internal node has 1 child, it will be visited twice and if it has 2 children it will be visited 3 times. 
This all in all, best and worst case, you will do an exponential amount of work with base 2. Hence the answer O(2^n)",0.0,35
9802,9802,11526,f03b1f416ca031a8c9d6db448d0d8439f9016edf947b1c8b45411ef2872c68250d908495b49ab16d7b6e23f038f5ac72fb1ec72bfe11a51db67cec76a8643ecb,We visit each node once when traversing a BST since the maximum amount of edges we can possible have is n-1 (which is linear). The complexity of  a BST is O(n) since we only visit each node once.,1.0,35
9803,9803,11527,0fa5d829ab37316f131667488ff6244b79b525ac275e022289de875a4f7426de94ef384d30176ee34a2851d47d343e62431c37057ae6054ad83ff76862ff86ab,"When performing those traversals we only visit the leaves once and we visit the internal nodes twice or three times depending on how many children they have.

The complexity will be linear O(n) since we will have to traverse though each item on the tree",4.0,35
9804,9804,11528,14bf4a341dc9827953823163cd007e766c263b8c396bea85416367e8c4908e0df252e9e3ac38e08223a3bcc05a108adef9f1881af30b78d3c7220ceb7c6be157,"We visit each node twice. We do this because we need to traverse both the left and right subtrees .With the post order traversal we traverse in the order Left-Right-Value , with the pre order traversal its Value-Left-Right. When we traverse through a tree the node where we are on currently is placed on the stack. We then traverse to the left and right subtrees , each successive traversal being placed on the stack . When we go back to the start node, the visited nodes are popped off the stack and the call is made recursively to keep searching through the tree. 

The complexity of a BST Traversal is O(n). This is because we need to traverse through the nodes to find our required node with the value we are looking for.",1.0,35
9805,9805,11529,922be3881d23d4f79d2fe24bf6321a23d63d950205b6ff6979047d1cc7c61465b9b18bdf8228c338eb886bb3010ea5578ec21cbc2819ca5ad2860838b719658d,O(n),1.0,35
9806,9806,11530,73f8ac3de0d9e29b34984491080a2a437e9d07081ef998fb53c2e73bde6a76efa33589c04809db77b67bfaaea71b13e4b7480f42fd75bb56aca6e9a4110b16f7,"When doing traversals in a DFS, we have three cases to consider: when the node has no children, when the node has 1 child and when the node has 2 children. 

The DFS algorithm involves adding values to a stack and then when you are done with them, to remove them from the stack. Depending on what you must do with the value in the stack ( in this case try to go left and right) , the amount of time the value spends on the stack and how many times it is visited, can be calculated. In the case of a DFS in a BST, it doesn't matter in which order (pre, post or in) the nodes are visited, they will be visited the same amount of times depending on the number of children they have.

When you visit a node, you will add it to the stack. This will be the first visit that each and every node will undergo. Now, we will look at our three different cases mentioned above.

Firstly, no children. You will check if you can go left, see that you cannot and then check if you can go right, and once again see that you cannot. Therefore, the node will just be removed from the stack and it has only been visited once.

Secondly, 1 child. This will either be the left or the right child. Firstly, you will check whether you can go left. If there is a left child, the left child will be added to the stack, and once all the traversals of the left subtree has been completed, the left child will be removed from the stack and the node will be visited for a second time. This would have a similar working if there had only been a right child. Therefore, no matter whether you have a left or a right child, the node will have been visited twice.

Lastly, if the node has 2 children. Then you will check if you can go left, the left child will be added to the stack, and once all the traversals of the left subtree has been completed, the left child will be removed from the stack and the node will be visited for a second time. Then you will check if you can go right, find that you can, the right child will be added to the stack, and once all the traversals of the right subtree has been completed, the right child will be removed from the stack and the node will be visited for a third time. Therefore, the node will have been visited 3 times.

To summarize: 

*A node with no children will be visited once

*A node with 1 child will be visited twice

*A node with 3 children will be visited three times

In the best case, the BST will only have a root and the complexity would be O(1). The other cases will be dependent on the shape of the tree. I think if the shape of the tree is reasonable, a good estimate would be O(n). This is because every node must be visited, there",5.0,35
9807,9807,11531,a51b1137941b4a2c9fd6d66da41292b1d5da2b0315b3c4cbaa7f507deed0fbfe1d51f7372760847ad411ee0d78ff9de354c3d1a9bb27433af4b5f7b732027fa9,"Each node is visited twice at maximum(internal), and once at minimum (leaf):

O(2n) = O(n) in asymptotic terms.",3.0,35
9808,9808,11532,11033a17d67159be6a6bbc8378c0392c95d06eb759a822fa4a4ab3fcd33a9e9c6b4e8e1a2ffedc295aecb757927d81558a966188674240b280a874a24f0debc2,We would visit each node twice.,0.0,35
9809,9809,11533,39f1ebb534a7edaa837d48cbd4115f72e8c5e63b7a4efafc271bf59036c6638038d9febb4eab796e3f3e68165bcbad6c2e1a9ad37eb71f421ecdb12f31f4f4c5,"We only visit leaves once. 
In the case of an internal node with one child, we only visit the node twice. 
In the case of an internal node with two children, we visit the node 3 times. 

In the best case, we do O(n) work as we traverse through a degenerate tree (then back to the root) where each node has 0 or 1 children. 

In the worst case, we have to traverse through a complete/perfect tree. In this case, we do O(2^n) work.   ",4.0,35
9810,9810,11534,a8b16fc0f5a2c752f3497016181c5ad9db439554c5d81073a232375aae20a22a97cca43a22eeec6af33455ba644c036ec4f0c737bb5b05eab312d892fb42141f,"The number of times that we visit a node would depend on whether its a leaf or an internal node. We would start at the root, go left, backtrack, then go right and backtrack once again. Therefore, we'd visit internal nodes with 2 children three times. If they have one child, then we'd visit it twice. We would visit a leaf once. 

As we would be going back and forth through the whole tree, the time complexity would be O(n), where n represents a node. ",5.0,35
9811,9811,11535,a44191cff1258114ca99a354cbcf13b3d3a3dcbbff75ad642f883f0afb3c431e62d034975452796897dce8086c431437065cbc80fc5ae095e71da50b0ce40ae0,"2

O(n) because we only visit each node twice which means if we have n nodes we traverse 2n times which is still linear.",1.0,35
9812,9812,11537,d3ddf356f072bf43331098b8a43e33c8b3192b402decaa6c3b442e9385a8eff79ab7318fc38d8ae8da018a53bd14daa455a684126f1cf0ce97908dac2dc0af07,"In any case all leaves would be visited once.

pre order-left and right nodes would be visited once .and the parents would be visited twice

in order -all nodes that are parents will be visited twice.

post order- all ",0.0,35
9813,9813,11538,0937f3be42654657ad069520ce77541d5a98ac5749be01a645bd806b70eacd3e8fd42ac59b2732fb7275b059278710559211b932636ce097f43773ecefbba842,O(n),1.0,35
9814,9814,11539,df4be51196b13a9d9df6ef77eee120b801ef4ba7a8945fcd04077415ae29d58c8d1e0814291c20adeb94f43f2f99c6c2290c6dde5a70ac85841035ecc662212f,"When performing a pre, in, or post-order traversal as a Depth First Search with n nodes, we'd visit each node exactly h+1 times where h is the height of the node. 

The complexity of BST traversal is O(n) because all nodes need to be visited in the depth first search in order to preform a traversal.",1.0,35
9815,9815,11540,5204f1bef2136d15a15e2bc81fec661c33bfcaa03530558479f291b586c10eaadde8b3f1da2bdb0c585b8e4de129c95a1cc00f8b5982206443ac7a6b2014c46d,"pre once

inorder twice

postorder three times

O(n)",1.0,35
9816,9816,11541,cbae5eeb6217dfd80bce3b9f9dcc6a487de93ab5d86c0254cee58b6e3923317f7e11f9c1e67f0e0269268aa476f5f7d41a06d2c8bc23012e2299f02af5f41761,"Best: Each node is visited once (all nodes in a straight line branch).
Worst: Leaves are visited once, Internal nodes are visited twice.

Best: O(n)

Worst: O(2n)",0.0,35
9817,9817,11542,c0046d9efb5ac101c14867d2717db3e08d6ef4577447593b970d77add7785e77e104d1c4da7ccd26febfc9dec54c612f8ab1164fc3489c3f123475dd1c711486,"O(n)

this is the case because in typical DFS traversals on a binary tree the call stack is used to traverse the nodes whereby each node is visited exactly once",1.0,35
9818,9818,11543,8d5ceb816f2781032ee62700b4d8e0c49eadb89db294dfede287a0eaeacf6b8016c744cd4dfe71d03f0f6caf776956147ca479b489362862217860010178b882,"We visit those nodes n times.

I think the time complexity is O(n) because we will only visit the node n times.",1.0,35
9819,9819,11544,2a38888a8b80ad136312b78d25e48a8f2ffafd5c8eeba2c39a3cf4d0b1565a722030f9463fa977a5038fd88a16d989882eed3aeb8631f846fa1888531a07766e,"pre once

inorder twice

post order three times

O(n) ",1.0,35
9820,9820,11545,c1e502cb9307976ed3c86bb3e1a2a0d1fad4d05b1ff3b6ca09a4a8992703680a55c9ae6e51c9417d756549fe340afbac12cdfcd3dbe4f6a560b6a171ce7f1eeb,"Each node is visited 3 times when traversing a BST.

The complexity of a BST traversal is O(n) since we have to visit every node and despite the number of times its visited, the complexity will still be linear",1.0,35
9821,9821,11546,f64eaf53775ca019aa46e95d674f953f5fe42b8661af69f4cf932eb77a69c0b6057310158946905b9d5788a5b3a8acd5e3f0f489603023b3ef81fc676dabaddd,"constant time O(1) , linear time O(n)  and quadratic time O(n^2). pre order traversal has constant time O(1)  because its does not backtrack, it print the value then look for the direction of the node which is left or right. best case
 

on order traversal has linear time O(n)  because it  must visit each left node then print else then back track to the parent then go to right node. worst case

	* pre order traversal has quadratic time O(n^2) because we visit two nodes in a same time then print the value before backtracking ,the nodes are left node and right node. worst case",0.0,35
9822,9822,11547,74d9bc92412f8c3ff2851eb60d7164b5df173c9c4dc214351b20de54e473afd02c6de0a58df8f38e8034cea31df2b0fd7682d3f538a4da451a42ed390cc33c67,"We traverse through each node once. Considering backtracking through a node to be visiting that node, we visit each node twice (push it to the stack and pop it from the stack).

The time complexity of a BST traversal is O(n)- linear time because it is proportional  to the number of nodes in the tree and traverses through each node once or visits each node twice so for a tree of n nodes it does 2n visits which is linear time O(n).",1.0,35
9823,9823,11548,b65e52333a31f01a7d7a5dae0ff6fc8ed82b8b5283406f591e8d448f865292ea8162938b0259891df516358cc77c51dca3895b350dbb36cf96d6c23e9b3fa27a,O(n) since you visit each node once,1.0,35
9824,9824,11549,07ab043d70e14725f955703ce65a95b6912342e429a6c9a7dec43aacd53b63f2b0d3ebef4da8ffdff01a86c6c296ffe0e21e4d798223854fe6e651460e1d7280,A BST traversal would be O(n) as you would have to visit each node n-1 times. As you go lower down the tree the number of times the traversal would have to back track decreases. ,1.0,35
9825,9825,11551,1a588e676388eab699476b49a00fa1013110acdcf89dcc5a2ff2c6e7b4d1cc5fff03a1daa5e3f8069ad9a846f88030beb884f390c11da3f442ee0a6ebc1a9307,The complexity is O(n) because we traverse through every node in the tree.,1.0,35
9826,9826,11552,13c060e9a128226d326b883081af9bf1d8d87f9594a5842046c134e481d515a3c3262c6c71b891f6321e7a0714b1981629c933e2f5180f487fe5e4ff9fbfb937,"pre order: once

in-order: two times

post-order: three times

O(n)",1.0,35
9827,9827,11554,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"O(n), because it would require us to search through every node in the tree. Ideally the DFS traversals can be in order to visit every node in tree.

In the pre-order case we would need visit the value then the left followed by right(VLR)

In the in-order case we would need visit the left then the value followed by right(LVR)

In the post-order case we would need visit the left then the right followed by value(LRV)",0.0,35
9828,9828,11555,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"O(n), because it would require us to search through every node in the tree. Ideally the DFS traversals can be in order to visit every node in tree.

In the pre-order case we would need visit the value then the left followed by right(VLR)

In the in-order case we would need visit the left then the value followed by right(LVR)

In the post-order case we would need visit the left then the right followed by value(LRV)",2.0,35
9829,9829,11557,e8a6e8174a6dd6e314677435e7049c0e3009b13d8a5df4000710970679e38e84d121d59138dfaf7218a7bd9e9ad0ee03d92b55f5f1e73be1e9206de0707e798c,"Each node is visited once, therefore the work done is linear.

Hence, I would assume the complexity of BST traversal is O(n).",1.0,35
9830,9830,11558,8c276f2a894ec8359a82f6a7f8b543cee4dafa5e339dd5fcbdd9b626de04d860f6a771f050054850d4263b60fc7c9e2f46a60c4568664a5f9854894846a3920d,"2 times. the notation is O(2^n) because the more nodes are present, we have to double the traversals done for each node and this results in that complexity.",0.0,35
9831,9831,11559,a24d4454b3c0f0611764d00de2a1119612fa4ae5c81fcdcf3800d4c6304de97c1896fb4640ae9520917c1bfdc4dabf12f730cd0013b9af7ab3a73969db3c7eea,"During any of the traversals, any given node is visited once if it is a leaf and either twice or three times if it is a parent of a subtree (excl. the root which is only visited twice for the general case that is assuming a tree has a height > 1 and is a perfect / full BST)

The tree expands exponentially (2^h), hence the time complexity will increase in relation to the size of the tree in a linear fashion. The time complexity is linear as a result O(n) however given it is a BST; it will become have time complexity grow quickly but linearly relative to the number of nodes.",5.0,35
9832,9832,11560,c1f6abfd4fc5318b969d8b42d7f10e1364425c616a8b69c8f8594b69d2c7a7743a83790314faf11cc3b382f3287fb00f531687f09a9146a00ce2dbe39062eeff,"Because a binary tree is limited to only have 2 edges originate from a node we can say that the maximum number of total edges would be n-1(n being the number of nodes). Thus the complexity would become O(n+n-1), meaning it is O(n).",3.0,35
9833,9833,11562,3143af8e534af5f9178a128c44433d6c35da771cbbc382af1235851f68f2e6c0baf6b6c7dc7aef9c829246db2be183570b22a8f6e1e10870c8fab148df9fe20f,Each node is visited at most 3 times in each of these traversals and a BST traversal would take O(n) time.,3.0,35
9834,9834,11563,eaf6c4c43d71c21a9611ab529dceabe1fb33ac3bf543bdbce13d249f7b6251a8ae478c786f76da007fed6f3e8c11ab62610c853fb7d3dd853fe2afc80fe40704,each node is vsited once and because of this we would have an O(n) complexity,1.0,35
9835,9835,11564,98d78e9c828344508b695719d0252934ec81638b460881dd9abe0087d3148c90c09f4ac72696b8c6cb5d749b644a041f0fa7f6d6c483866227774b40bcf364d5,"we visit each node once.

the time complexity of a BTS is O(n) because we are visiting each node once.",1.0,35
9836,9836,11565,135bdbdca9dab16566a02b87eb86b2b03e986360c36387bc6b252f2a7b0098a14637a43a9d1d68d223771b954b34555f039489b7af8726eba774f24a3c3a0d42,"Pre-order: Each node will only be visited once.

Post-order: 

In-order: ",0.0,35
9837,9837,11566,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"The nodes are visited 2(n) times
The complexity of the BST is O(n+m).Since the number of edges that can originate from a node is limited to 2",0.0,35
9838,9838,11568,061f56d837e6405fc3da18b48c234575e946e21c4f8a87e4ff0140618b0afc839b770f98def91d7072d96fe9e6cbacdd2d64a21bf2c7aaeab14c8c197a8e0535,"when performing traversals, we visit each node once meaning we will do n-1 work for traversing n nodes therefore it will take O(n) complexity since we care about the shape of function",1.0,35
9839,9839,11569,2f496bb2a99de18fa436df0deced0620c47daee5ce37cf49cf6b3200c20eb84e5a9b7a47850d29ff143886bc9932f54f86b6a1101a1d0f70874e22b40b657cec,"linear complexity( O(n)), depending on the number of nodes we have the number of transversals increase linearly. the complexity of a DFS Traversal is O(n + edges), where n is the number of nodes. The same applies to a binary tree. The complexity of each of these DFS traversals is O(n+edges). Since in a  Binary Tree, the maximum number of total edges is n-1, where n is the total number of nodes. The complexity then becomes O(n + n-1), which is O(n).",1.0,35
9840,9840,11570,bb7a5218ab3dfcc0ac546d608943de6dcbb3727d09e6f5dbb5e885ea5b24939174aaaa40e8672ce63fa53f6af97ad899b29ea3229ae18c85c504ca3dcaa7d71a,"* Pre-order: we visit each node once. Worst case O(logn) and the best case is O(n)
	* Post-order: we visit each node once. Worst case O(logn) and the best case is O(n)
	* in-order: we visit each node twice. Worst case O(logn) and the best case is O(n)",0.0,35
9841,9841,11571,e15ad332a60fd21f9642a607905bc6a0a968e3d65f0ab448161698266492242c990fc890cd09bab4dffa30a30230d6c043c42b0ef218d6e81e40a2206a0638d0,O(logn),0.0,35
9842,9842,11572,89daf5e5dd9d5cd464a1dba203796d2fcea5b46dd29cb10e72e0dd7e72373ac4fd8e96b5e3d9813a2ed44c552171318e265b869630b10e2e2b1c3ee4cc7320d3,"We visit every leaf once. O(1)

We visit every internal node a number of times equal to the number of children it has. O(n+1)",3.0,35
9843,9843,11573,d14b989bcb894978cca36e7e5f61001f5674d5a63e03700520c57accee4d5d7687b97d71bfffe56071d64d16c01c84e867fd79ad35b152d9c5667b7efa04e45e,"Every leaf will be visited once but the internal nodes will each be visited twice. This is the case for complete trees. We can do better when every internal node has exactly 1 child.  In this case we will not need to backtrack.

This will be O(n) time. This is because we visit each node (2n - leafs) times. ",4.0,35
9844,9844,11574,3dd0e6b0aa4ca279a9a8f781013cc1ffadd92a615d343d8f7162570e3cd2647c9fb452de2221fcafa1322a70dac1ad1ef68bd5efe79682df415f360b352ef94b,"When performing a traversal as a DFS, we would need to visit every single node in the tree at least once, and that therefore means we visit n nodes.
 The complexity of the traversal will be O(n) because we recursively visit each node and also back track in some cases.",1.0,35
9845,9845,11575,2d66cc49a7ffe05cc8bbfc302bcf20656e7f907877a7522f7da110ca45abf9d13e838fa2518e2db3e38e88bb214034f63934465720849e92200572791f51d840,O(n) ,1.0,35
9846,9846,11576,0c11d203426fce7b3dc05c5b901a557cc9648e7fd3384bd9d8800631c383636176c5236339b82c8cac354a014c4e904c016c4f55b6e4ea8b971819143c0b5cb5,n-1,0.0,35
9847,9847,11579,a300869c4f32047b23ac68a02d99d6a69e15fcc6cb6903bc4e640c72bf256b08b631e89f75d7f7263574f4383932390c2f4b98297d3a8bfdd9da2320bf30b053,"for pre-order traversal, if a node is a leaf then it has a ""visit count"" of 1 and  the internal nodes have a ""visit count"" of 2.

for an in-order traversal, if a node is a leaf then its ""visit count"" is 1, if it is an internal node ",0.0,35
9848,9848,11580,b1a3a9f62a3efb88815155da55fbf2f2fafa14dd37234e9f11b5f00a231a31fde1494bd63f6ac5858aefb97ae2c7130be129cb66d65efd0dfa784ad99b296be3,"You would need to visit each node once while doing the three traversals.

The complexity would then be O(n). The work is linear as you would need to visit each node once for every traversal. Therefore it would take O(n). ",1.0,35
9849,9849,11581,e40d8bf3b05bd8e034438beb235a1631a28b193d6edc5587f765a26d4981e60fae4fcb9a995036a1c2815f2073b85fc4667e3d6bbfc0e5a63b847c8fa219ba80,"The number of times a node is visited depends only on the number of children a node has. All of the traversals involve visiting a node, visiting it's left node and then traversing it's subtree and backtracking to the original node, and visiting the right node and traversing it's subtree and backtracking to the original node — not necessarily in the above order, the order depends on what type of traversal you are doing. If there is no left/right node, then no attempt to visit the node will be made and the traversal will stay on the original node. 

As can be seen above, the maximum number of times a node can be visited in a DFS traversal is three times, and that is only if it has 2 children nodes. If it has 1 child node, it will be visited twice; if it has no children nodes, it will only be visited once. So, in a BST, the function dictating the number of times a node is visited in a traversal is some constant function related to the number of children it has.

A traversal, by definition, goes through all of the nodes in a tree at least once. Even if it visits a node more than once, it will always visit a node a maximum of three times. Hence, the time complexity of a BST traversal will always be O(n), because the constant co-efficient that may go in front of the n becomes insignificant as n approaches infinity.",5.0,35
9850,9850,11582,744cc5a93fd7edad364406b30ceaa6836705a7419bd01ed97b04c61f1235130699ff789e400cc607e1772b19b35bf800957b6bd74b1e52cf1974d01500560533,"leaves will be visited once. 

internal nodes will be visited at least twice and a maximum of three times. Except for the root which is visited a maximum of two times.

the complexity would be worse than linear O(n) seeing as all nodes that aren't leaves are visited more than once. The complexity is O(n log n)",5.0,35
9851,9851,11583,8049e1d0a5ce881b749a9c9461a73e821d1792fbc2adc39e1be0be7717d99f93abbe732f68ade8cbd01333fb3e4a5adeb13b3875a705e5218706e5b68e7e0885,"We visit each node 3 times.

first when we arrive to the node, secondly when we traverse left and come back to the node, and thirdly when we traverse right and come back.

The complexity is O(n) because for each its 3 visits per node.",1.0,35
9852,9852,11585,93c90404569325fe60b728e076fbba3cf65e437046307f80389f0bc8991e0972c6f04c428807930e8f3ec23f714c2c1a1c5a69ba6ec135ea91d23224a8d3d68d,"Cases of visiting nodes:

Best case : O(logn)

Worst case : O(n)

The complexity of a BST traversal is O(n). This is because we have to visit each of the nodes in the tree,",1.0,35
9853,9853,11586,2752a012a3acfc041a30d5a655085eade0eb440b54f67d20ed248f27ebf41fd19d90129f4fd7d4c48bc1b7b721b3638118e357f1785837b03bc7def7da08253e,"For all of these traversals - whether done recursively or iteratively - we’ll have to visit every node in the BST. This will result in a runtime complexity of O(n)

Therefore, the complexity of a BST traversal is O(n) as we traverse over the tree and visit each node once.",1.0,35
9854,9854,11587,4c6f807c2ce1ab585dfa9622ceaade81e43b8fe88ba8af5d95eb11efdad75a8b1190eb5c2d48dff34f29ac730bf0895fdaf308c3995dbd7f2103246c342b70a1,we will atmost visit a node twice. i think the complexity would be O(n) because inorder to transverse the BST you would atleast have to visit each node once.,1.0,35
9855,9855,11588,ba6cb46aa6ff6581fcd2828d6944742916cd44c20dbee87513cab04b763159ab5e8fcc20c0eaa029b5cead3d4e1911b67590f3a4b4a64f4e9fa942648249fc12,the time complexity will be o(n) and visiting each node would just be O(n),1.0,35
9856,9856,11589,3068685c76e4b2c329c64b4a981abf59ea0591abc5a7b11e62ce43c420b142b81f90f5e9d316d436b64235d5ad493fb04d7af76ae8a7eac84bd371103293e146,"Let y = number of children on node

We visit each node (y + 1) times.

The time complex of of BST traversal is O(n):

	* Suppose we have ""n"" nodes. We have to visit them in order to traverse the entire tree. Therefore, we currently have ""n"" visits.
	* Based on the above explanation, we add an extra visit for each edge we have, which we need to pass through to get from node to node.
	* Therefore, complexity is O(n + (n -1)), which is simply O(n).",6.0,35
9857,9857,11591,b62178f325a37f31c95fa1765add6431ffda3b6e9e137a6c1634820014c3bfc3f4c574a7130344e47d262896d038b700c7e7372470c7667fbf621506106a2a97,"1)the number of times a node would be visited would be the amount of vertices + edges the tree has.
2)O(its vertices + its edges)",1.0,35
9858,9858,11592,6e1111ad11474e6379168f87057eae3076970c620dec3cffde8e98db6de9322b94aefef0b0414a791717f61331121e1ad9f15c607c1ff40afee80bcc8c3257b0,"we visit a node at most twice, and the complexity is O(log(n)). This is because in a post order traversal, when we get to a node we check its left and right sides before printing the value of that node.",0.0,35
9859,9859,11593,2ab3b11f5f1782f4246740fe903154429a2490492d0572263d7ff046cace7736e29d65d602215296304ea46aa69325f3d67b03459c0b518493888576c52ace89,"* We visit each node about 3 times because, 
	* firstly, when arriving on the node, 
	* traversing from it the left
	*  and right.

O(n), because we do 3*n work.",1.0,35
9860,9860,11595,ec395a3ecaad23df4073c1f706e156a2dc0df6ec9ab518f824a5ee32c21f2fee951d1dfe316e50e996ee47ec57ebf1b3a335db07c23fa71520fbcc864e608a4d,"-When performing a depth first search we visit each node exactly once.

- All traversals will require O(n) time as we transverse the height - longest route from root to leaf",1.0,35
9861,9861,11596,20effcbf64917de69f0f441958ac819d52ad486a65f959444a5ddd14ca83a40e581709b6bb9eae431ca2dd02ce933a201bc9b7e43298585d0858d76601344ce0,"So when preforming a preorder, in-order or post-order we will only visit each node once, so when we land on a particular node we preform the actions needed either to traverse left or right and print the node and these actions each take a linear amount of time so in totality the complexity of the BST traversal will be O(n) - linear.",1.0,35
9862,9862,11597,d10eb2653552348dd29e31d9127ca9b9ab3966f67dcfba3fbaef7bc1fba74c3549309defc8e00e457f7427150a3162c0ca17e3f3d6529fa8df4aa4e4195dbeec,"If a tree has n nodes, then each node is visited only once when performing a pre, in, or post-order traversal as a Depth First Search and hence the complexity is O(n)",1.0,35
9863,9863,11598,31f89aaef7c39dc86c93cfdeddea5fc5554c3cbe3838d2616d1fbc1745414f7096809e9261e2fb009c92beaaac49eaef9633b3b3c92cef0606b8cfb14522414d,"* Twice
	* The complexity of a BST traversal is O(n^2) because each traversal will take n work and we have to do this n times to go through the entire tree, hence n*n is O(n^2).",0.0,35
9864,9864,11599,2edf0656134d19474a53dbbe5225dc2a3f4aaa1130b603fed547f4fc2584f94df9c6d11c108fecf09067c54daf57f86fbd618dbf612a4c65bf741c812ed66b6a,"We visit each node once.

I think that a BST traversal takes O(n) times (linear time complexity) because the height of the tree is not controlled, thus a tree could have a height of h=n-1.",1.0,35
9865,9865,11600,3e664d9b290450a26a44195a29971d5e7c7434afb68523c4038cc69f5c1285f4c94e2b62945fc7bf5800f3a5190a2876a925f82823b3806d9c640fa0e0d73571,"* when doing a pre, in, post oder we traverse through the tree according to the height of the tree wich will either be O(log(n)) or O(n) as we follow an algo
	* we use a depth first search in oder to visit every node in the tree, where we use a stck to push numbers until we reach a dead end where we will retrace our steps so for e.g a pre oder we would start by processing the value then we go lest and right until we reach finish, so we visit every node once
	* the complexity is that we do O(n) amount of work as we  traverse throuh each value and push it to the stack and print it in a oder algorithm of pre,in or post",1.0,35
9866,9866,11601,f8ab0f6e15e6bf9e99acd11cfb6b5455d3c0019e87064465e59d88ccaf25c640a5ce1b900a6011a9e3fa052e11195ca6da9faf3eac510a5a07330facf6daee23,"in BST traversals, each node is visited once, hence the complexity is O(n).",1.0,35
9867,9867,11603,5602a599f37ceb4d3d0abbebb674a8cfae2a81d9f53137cfbc7a1bded150cbaa8a83e4431db27b0e21c60021690e3731e8677add172b47aa9e637944b71f019d,"In PreOrder- We visit the node only once

In In-Order- We visit the node twice

In Post-Order-It depends on the structure of the tree but in maximum 3 visits per node.

Complexity is O(n) because it depends on the number of nodes to be visited.",1.0,35
9868,9868,11604,1c067bf4dc46efea1d97764ec9e8512203198a06760dfe663905444adb3c11970401fd40f402aab42c0c01db7d7d76641060c3df878232bbed315bb7d13f0aab,"best case o(log n)

worst case o(n) because can be a large number",1.0,35
9869,9869,11605,8c4ece10bea4707d74ad8e485b192cf388c1aaad3dd5b625cadaaa6a947d3861bc0547f235d6ff3af091e10ce08cd771b73e98b692a991cef32a92e7b557b387,"When performing a pre-order traversal, we visit each node once hence the number of visits is N. When performing the in-order traversal, we visit each node at least once depending on the shape of the Binary Search Tree. When performing the post order traversal, each node is visited two times thus the number of visits is 2(N).

I think the complexity of the BST is O(n) because in each of the cases the lowest number of node visits is N and the highest is 2(N) because each node has to be visited at least once thus leading to O(n) which is directly proportional to n. ",1.0,35
9870,9870,11606,21f09107df149216c5f40e2d6eaefa443c1ac6ce9ddec594661383f2e53455e2769bfb1bb81bee158e80bc0b01db2da739108bc4386c15bb286ac35afa1a5409,"The number of times a node is visited is dependent of the number of children it has. If the node has 2 children, then the node will be visited 3 times. If the node has 1 child then the node will be visited twice. And lastly, if the node has no children then it will be visited once. The complexity of a BST traversal is O(n) because in a traversal every single node is visited, which is dependent on the number of edges there are in the tree (n-1). This is a linear function thus the traversal takes O(n).",5.0,35
9871,9871,11607,9dfb1f3f8489eba0c312316ab375b0eb3fde4cc7c592108ea20fe9063368bfeafc3cfc95ddf50eff3397d93bb8f4939d82490505e330285e8ec3eab94f0e646a,"Pre-order once

In-order twice 

Post-order three times 

The complexity is O(n)",1.0,35
9872,9872,11608,43337822a8495f6346099bee6f1b1379846d1e116a80358eff95ac9a35a5e9db993d15f49931c7a4d1543bc7328dae0e418202f217ef071778281db16cfc2fe9,"When performing pre, in, post-order traversal it traverses through each node only once.

In-order process is left then parent then right. Pre-order process is root then left then right.  Post-order process is left then right then parent. In each process you visit each node only once. In total one visits n nodes only once.

The time complexity of a BST traversal is O(n). This is because it traverses through each node once which results in n times due to the recursive calls and order is not important.",1.0,35
9873,9873,11609,0814448191d29da9008582aa1dc261271817cf4f70631f519f01177439d50267cb21e8d39c1f121e1aee03914798dbfab1836210758982742e26c801f01d7bc4,"-visit each node o(n) times

different cases might include repeating nodes

complexitiy of BST is o(n)",1.0,35
9874,9874,11610,d0487881fde4213facde4c9cd0143d5802f701e002f130b7eaa6dd04f68f58612ae33c39c89beceae1495437bbe2376be3003369a31f0f2bc6f9e0c5a369707a,"In each of the cases we would visit each node 2 times, once to reach its children and get to its value, then once again to when returning to its parent

Hence the complexity is O(n) because you would visit 2 times meaning that the total work would be 2n but is simplified to O(n) in big O notation.",1.0,35
9875,9875,11611,385c7b29eec3366a404f1d7e1159d0447aefec67a3c8b61a32481883579eeb6ab7ee9fa654afbb7d3b9a4b7a30f0a2b32be3cbd9d9a3dfbfe943be567e01c394,"When performing the transversals,all the nodes should be visited.We visit all the nodes in all the levels,from the left subtree to the right.In a best case scenario;we will do O(1) whilst in a worst case scenario;will be O(logn).

The complexity of a binary search tree depends on the type of transversal taking place but can be influenced by the number of nodes,edges and height.",0.0,35
9876,9876,11612,8a8eb86cf56dd2444d2bc5441387c73e3fcbac4867da844d41e7ee67a78c9e8b163da9822047fef10101762a7abd4eba2ff040d29869420924f78a2c686ad858,"Need to visit each node once, so the complexity for visiting all nodes would be O(n)",1.0,35
9877,9877,11613,2aebde6b5faaed73a67c0847887873c4b7d8d2f0c1ec3c5d1ae00fb183c3e53559681b2ee97a4692d74712db8b222e3239fa5e199b01863e771a9daa54a4abee,"Each node is visited twice from the root , which implies that we first consider the root  and next we go to 1st level and visit all the roots , and through this process each node will be visited once.In Big-O notation we backtrack o(n).",1.0,35
9878,9878,11614,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,"the complexity of a tree traversal is O(n) and can be expressed as

T(n) = T(k) + T(n – k – 1) + c

where k is the number of nodes",0.0,35
9879,9879,11615,999b8af04a99b1971783a730d1a109e30fdff2f88a1f40dc36731dceaa01148aef1c1f5d96b5999593020819ebc46f676235aa6d5dc12859b91750c9e8b5c9c4,"When traversing through the tree backtracking is used by following three step which is either print value,go to left child or go to right child. each of those three steps are considered to be a visit to a node.in all the traversals each node get visited 3 times which means total visit after each traversal is 3n.

since the work done is 3n the time complexity will be O(3n) but when n get large 3 can be ignored therefore time complexity is O(n).",3.0,35
9880,9880,11616,c76ad062cb3f9ba2556bec1587c1d89b089f2df63d9bed184a50eead5884d030c988356231ec2465bf2dfe9d6ac011b44586a721987fbdacc7384e0d7bc1bf14,"In the best case, O(log n).

In the worst case, O(n).

I think the traversal is, in the best case, O(log n) and in the worst case O(n).",1.0,35
9881,9881,11618,07076ad9a7e3813bce19a739ebedaab894d1a330269763e0925227d8822b601591c19afe0ea5ecf81637c9b73f442db6cacafab2329d262fef0fb68d97bef78a,O(n) = n we visit each node once ,1.0,35
9882,9882,11619,7fa0256939f3801d7cb837f49e23433b9e2c72a7153a75d58ee05f6ce597913275599303f990f67fdc180f91407271656e81578b90488fda76d6e550e9bb3533,"Using a Depth First Search for a pre, in, and post-order traversal, we will always visit a node exactly once each time. So following this logic, the time complexity will also always be O(n) where n is the number of nodes.

It does not matter if the tree is in its best case or worst case, because when doing a traversal we have to visit each node once.

Time complexity for a BST traversal will always be: O(n)",1.0,35
9883,9883,11620,2a0df219aac143a2ab259ed39069368d09faa1d674232d6d8a5a0299284966b0b712226c702276000af1418c0c7120be9e30f8742712afc25a87bebd377d57d9,"O(n) we end going to every node in the search tree

Based on your answer above, what do you think the complexity of a BST traversal is and why? [In Big-O Notation]

O(n), Linear time complexity",1.0,35
9884,9884,11621,2e609516b3c283ff23ddaea06d0df01ad6175f48861d0223a4409ebe1c7df8e383fe146f147415f2605c7a0103b96921b1ffd763ab4924efe18fd229dedbae68,"Each traversal, being Pre, In, and Post order traversals visit each node exactly once backtracking is done recursively, however each traversal traverses the nodes in a different order. When performing a depth first search, the best case scenario in the pre order case is O(1) time where in Pre order the value we search for is the root node,  for the In and Post Order case the best case complexity is O(log n) time if the value wanted is the lowest value in the tree.

The complexity of a BST search traversal depends of the shape of the BST, in the worst case where the BST is degenerate in shape, traversal would require visiting every single node when searching in the worst case.

The complexity of a BST search traversal when the BST is not degenerate would on average be logarithmic complexity.

In any case, when needing to traverse the whole tree, traversal costs O(n) time complexity as every node will be traversed once only.",1.0,35
9885,9885,11622,fd6a36ea3be7fe00a0626c8ff80a591e0ee46b9eb9f16c4ccfb925e8237975ae584522b908d7f487d3fa4016ee5035673c870e0b6b78ebf935c75fa0905d0961,"we visit each node O(logn) time in the best case and O(n) in the worst case

time complexity of a BST is O(logn)  because the height of a  BST will be log(n+1)-1",0.0,35
9886,9886,11623,29fcf57bccb37a2f0d949733d7028b65c0e2df19a9ddbd0c547e57467d84c825defbaf635dea276a63c3d3e85a6fb4f7a84d6da08661ca46728f222c62700315,"In a pre-order traversal, in-order traversal, post-order traversal with regards to backtracking,we will push the root onto the stack and then perform the functions, then push the next value onto the stack, if we reach the last node (dead end) once and then pop it. Then we will continue to to backtrack(undo) which means that we visit the other nodes twice. In conclusion, we visit the leaves of the tree once and the internal nodes twice.

The amount of work that is done is O(n) because we traversed through the entire tree(went through every node)",3.0,35
9887,9887,11624,fecc59057a0e209589be1452a92558843a93237db9707d9614670e76673fb2cec05cbca3488156012b8fb3cd1467b373d250bc116d0aec57eaa9cbe2d676c3fe,"Each internal node is visited twice and each leaf node is visited once. this would mean big O sits between n^2 and n. Therefor the order should be of 

O(nlogn) approximately. ",1.0,35
9888,9888,11625,7099f15d1fb337686bf427fedb824d4eefc2c359e7374f808226d1191d0f74342e42146c05dfa9cdc17fbdc8dce0a4cb75b417e6eb24978dd57c4773dec73b21,"O(n), as backtracking in a queue is constant O(1) and traversing through each edge and vertex you would get a linear amount of work therefore performing any of the traversals as a depth first search would also be linear",1.0,35
9889,9889,11626,a69e74ae8b4a039273c9779403a7bf9afeff6c0402c7c4b81445db3dcb6b7c6d2a0c70d795b1a5404bd22d002454afb4812336b41db02ff960eaf7c2625641fa,"we visit each node twice(2 times).

the complexity is O(n) ",1.0,35
9890,9890,11628,a871558daae8ec7755dd112b899b7fd46e06cb2a4cebf4c0a75ca226dba4bf419ef0333177fa6862ca71f931535c6fb1250ed993a029aa9b63a8c18ad277bce2,"In-order,Post-order and post order traversal are depth first traversals.So the complexity of the binary tree is O(n).Since this takes the linear time in the worst case and the logarithmic time in the best case .This is because the number of edges the can originate from a note is limited to 2 in the case of of a binary tree ,the maximum number of edges in a binary tree is n-1, where n is the total number of nodes.",0.0,35
9891,9891,11630,0ffad2820b9adf1fbb6d7105f83a5954e33ce5d91444ff2b6251d15d1a8c5a988e64634ca1a4f0e01e237f0fdb8290b82c533e1fa1a822b32c02e6052c618e98,"When we perform a pre, in, post-order traversal as a DFS, we visit each node at least once. When we backtrack then we visit the parent node twice due to backtracking. We always traverse to the left in all 3 orders first, once we reach a leaf (no children) we backtrack and traverse to the right. This is why we have linear time O(n).

The complexity of a BST traversal is O(n). O(n) is due to backtracking.",1.0,35
9892,9892,11631,9f85bd574a0fb5fa07c95cbd2dc5aa7f4cb77f83ea58b24cf50b8a111ddaa2e08d644409b7ea28dad73defdb2393c136cc039b51ec3ed144b40271a76c7c7470,"1. we visit each node once.

2.O(n), because the amount of work you do for each node is constant.",1.0,35
9893,9893,11632,bec70f18652f9b1ec67ee94e23471083fc0530aad868499d925d500e71ccfd4f82652eb49a909778379c4583e97ce1464a3ae78de3b07114cb3a9e4c1179d625,"When performing a pre-order, in-order and post-order traversal in a BST with n nodes, each node is visited once. Since the maximum number of edges in a BST is n-1, with n being the number of nodes, the time complexity is O(n+n-1), which is O(n), meaning that a constant amount of work is done.",1.0,35
9894,9894,11633,f4baa24ad720b1250dc8a9d5d7170a55ee764630dc2c7f87292182bdad71ecf2851e6fec34c6913b3b5952d370fbd9d0459efe69a1541c4221908a8f498f268c,"For each search, counting the initial time we visit a node and subsequent visits upon backtracking, we see that we visit each node c+1 times where c is the number of children that particular node has i.e.  we visit a node with 2 children 3 times (once initially and twice when backtracking).

The complexity is O(n). We visit each node at most 3 times and at least once because a BST must have a maximum number of 2 children. We must traverse all nodes for a DFS and so will perform a linear amount of work visiting each of them.",5.0,35
9895,9895,11634,22ce118158e8ed0c1187b952e36a1938ab0c22e942e01d9258ed224302f7ecf3665fc06c4060e629850d16f04e008f7cd12363e7f782d4370a1dd3b7af113bbe,"When performing a pre, in, or post-order traversal as a Depth First Search, we visit leaves once, nodes with one child twice, and nodes with two children three times. (I came to this conclusion by completing a traversal on a Binary search tree given in this quiz.)

This means that for every node, we visit it (number of children)+1 times. Because the number of children is just 0, 1 or 2 depending on the structure of the BST, and we are adding only one to it, we get something like n+1 which is a linear function. So the complexity of a BST traversal is probably linear, which in Big-O Notation is O(n+1), which is O(n) because both n and n+1 are linear.",5.0,35
9896,9896,11635,f76d34739c22495666539e328b829579ffb8d2806837813ff647c9a67384130ec26d74d58bb855836384f12b1b3b03f93c1062fce50fa1b459dbac86affbee20,"The amount of work you do on each node is constant. Therefore, the complexity of a BST traversal is O(n)",1.0,35
9897,9897,11636,92a2ed8f4716bed3b0e0c50f4d71ca4d4c6f96e622febc9b471f947d10b8500c23531ab4582c0648a7ceef71efcbb7100102c2a6bd33328ed40abb07652829ad,"We visit the leaves once. We visit internal nodes with 1 child twice and internal nodes with 2 children three times.

The complexity is O(1) because it traverses nodes either once, twice or three times.",4.0,35
9898,9898,11637,8052ea5813981ce1b1dc18dcce8d4c10c33b769890ea3f35ecc1dc5a6465b4897efddc1a12c6d7a26b5d0da8ca3c779589f99331e5d2c411636cea22d157833a,"when we perform pre, in or post-order transversal as a depth first search.in the pre order we visit each node multiple times depending on the number of children a node/root node have which sometimes 2 to the power of n.in order we do n(O) when searching for the left value and after the right.in post order we also do visit each node multiple times 2n(0)",0.0,35
9899,9899,11639,27b7c01b5507de27227f1b4c06fa92833846a84fa96c3732f3663fb00fd83e6f0c7c3e711cd797752bf30bb3a828ffa9c255dc629b8adb95ea32e0eed6535409,In BST with n nodes we can assume that we visit each each node 3 times. The complexity of the BST transversal would be O(log n) because if we assume that each level of the tree has the maximum number of nodes we would get that the root is 1 and its nodes are 2 and so on.,0.0,35
9900,9900,11640,76547c457fac096aa24860742165ce32f0a7082f7aeb253f2ff91571275838954033b1627523b79a6ff278d5ebec75d54fbefdc04c377a9da2d71a00fe00d461,"If we are using any form of traversal as a DFS , then each node will be visisted n times. The time complexity of this would be O(h) when searching where h is the height of the binary tree as well O(n) where n is node. ",3.0,35
9901,9901,11643,5221e1f3d933576f202c0725eb1b1536ee1b49681a3fc7d8f1a5f7ce021be47e8c2ad1016a78e47c8f005a4abc05514dc591b463cb92d3c640fd02125cf688e6,"DEPTH FIRST SEARCH: TRAVERSALS

GIVEN THAT THE BST HAS N NODES.

DEFINE V=VALUE, L=LEFT, R=RIGHT

_CASE: ONLY THE ROOT EXISTS (I.E THE LEFT AND RIGHT CHILDREN ARE BOTH NULL)_

In this scenario, the complexity, regardless of doing a pre, in, or post-order traversal will always be O(1) since you only visit the root, see that the left and right children are NULL, and return to the root. This is constant time.

_VISITED:_

In a pre-order traversal, which is in the order vLR, an in-order taversal (LvR), and a post-order traversal(LRv), when doing a task, such as printing the value contained in every node of a tree, we visit each node the following amount of times:

_Leaves: _exactly once, since when you reach it at the bottom, there is no need to come back to it.

_Internal nodes:_ exactly once, since we're using pointers, we would visit the node then visit the node-> left then visit the node -> right (for an post-order traversal, but for an in-order traversal it would be node->left, node, node->right, and for a post-order traversal, it would be node->left, node-> right, node).

_TIME-COMPLEXITY:_

The worst-case time complexity is O(n), which means we have visited every node exactly once.",3.0,35
9902,9902,11644,d91427bf4ad99661f4ac49ddce8054ec473a7fcef1ab133d8d24c3ab9e806480afe6773c225af63871bd9b36c6d59fe3d802d967ab7b71f90b46e5238ce08052,"we visit the node according to the height number of the tree

Time Complexity : O(N)",1.0,35
9903,9903,11645,3ea55861b5c8eafb81b8565f1d54cc453a6c146015319e65651c96131a93fe003ed97c4b0e5ead0032066879ea3f910a9115040fa5bb190fe1c4bece13c4f763,"A node is visited multiple times during traversals. The number of visits on a node are increased when we backtrack to it. In this case, we can consider that the node has one or two children, at which the travel path will be longer than nodes without children. A node with one child will be visited twice (maximum), a node without children can be visited once, while a node with two children, which may or may not have subtrees will be visited at least three times. The time complexity of a BST traversal is O(n) in the best case, because recursion is less complex and the tree would have been sorted.",5.0,35
9904,9904,11646,ee9a54c657ad0d8bba4bde06638e509cdb2a338e06761f819025e545929c0973eae422171c63064d2ec75c6fa5edd42d44dd67fd5b59e36f33fd89e07c72a43f,"n-times
I think the time complexity is O(v), because we have to visit each node n-times",1.0,35
9905,9905,11648,df1465243969e50a7c244171c33cdd8b84e73574759fd453aca87a46591b145e500e27e8f5be3935920bd9b19cabcd2edf5bdb2b726205f4ec6c454c76481975,Each node is visited three times. ,0.0,35
9906,9906,11651,86eb6a509a4b81bb5d0775617d6b551b5529a8196aa8cfd54e1d4c97046fcb8692ee1866ca18888be1695e57bab3f84e888b219e99049227e002908717268d42," When performing depth first search traversals such as pre, in or post order traversals we travel once through each node thus we a O(n) complexity .This tells us that from big o complexity chart the complexity takes linear time .This then becomes a best case complexity and the more accurate traversal that is useful.",1.0,35
9907,9907,11652,cec5c5d76a671273e0f9371ae893a0f4c2ff89a302afba60a55ed47df25e76493286a5dc1d008dcab637f3c3c155e4e5b2158e820a7aa91a63b886b5ee485778,"A depth first search visits each node once. Therefore the complexity in proportional to the number of nodes. Hence,  a BST traversal has O(n) complexity.",1.0,35
9908,9908,11655,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,The complexity is O(n),1.0,35
9909,9909,11658,68f3486fba3e90fbb30d257d9f425b479699474b4734aedaec9e7b7e62738dec31c232429f41b1b79d289e2acf53beed558d49f905e55176ee54e1327b9aa184," 1. Traverse the left subtree, i.e., call Postorder(left-subtree)
 2. Traverse the right subtree, i.e., call Postorder(right-subtree)
 3. Visit the root.",0.0,35
9910,9910,11659,a69deeb1d09b2c2f2efacf2adabcd40f91cbdaa6d8a94b958b4f80eb19e04ba4658d33a6b07d41e2293e3dc7c648d0c9d4ec03fdc6df749e7a11d1c6ae138068,"We visit every node exactly 2 times, once when we initially visit it and once when we backtrack.",0.0,35
9911,9911,11662,2dc8bdb77e3c7ca65a7004fc81d01e201b72cc647f001393bf944c06617e5c35dc6d00cb13c94a98ad4a2b0a5135ab7e178732724d9ed1cd93c84c2d08c50e63,"We are visiting each node at least once and at most n times, if you are back tracking for each and every node. The worst case scenario would be O(nxn) and the best case scenario is O(logn).",0.0,35
9912,9912,11663,dc116295695675ce8f8f9dcde7d1d181a1fc34469a4bd2a570b8ca26a7951f6381d662fe47ef41e490d057b64113abc45be11b89047c039c48685692d843ce1d,"The worst-case complexity of searching for a value v in the vector is O(n), this occurs when the value v is not in the list of n number. if we search n times, the number of works will be O(n^2).

Calling the insert function, the best case height is when the tree is a complete binary tree which means every level is completely filled it except the last level, the best case complexity is O(logn) times which is the shortest length. The worst-case occurs when each node has exactly 1 child and to get to the last node and insert, we must visit all the nodes before the insertion, and this takes O(n) times.

We have the worst case height after each insertion, the complexity(work) will be O(n^2) times. So the worst case of insertion one number is O(logn)- explain above. and we insert all n numbers and this takes O(n), therefore inserted all n numbers with the worst case, and we multiply the two complexity to show the total work, which will be O(n^2) times.

We have the best case height after each insertion, the complexity(work) will be O(nlogn) times. So the best case of insertion one number is O(logn)- explain above. and we insert all n numbers and this takes O(n), therefore inserted all n numbers with the best case, and we multiply the two complexity to show the total work, which will be O(nlogn) times.

the best case with construct tree and best case search is O(nlogn)+O(nlogn)

the worst case with construct tree and best case search is O(n^2)+O(nlogn)

the best case with construct tree and worst-case search is O(nlogn)+O(n^2)

the worst case with construct tree and worst-case search is O(n^2)+O(n^2)",36.0,36
9913,9913,11664,cf96d5be5169d5386c2ce2a3ae914384cd3ff74c0ae41c6fc53cb4ef592a7f9882d33970f1f807fe79c0e961bedb5189d6cfa997817a7684663f34c5e5fffad2,"1) The worst case for searching for an element in a vector would be if the element does not exist in the vector. In this case, every element would have to be checked taking a linear O(n) time. Searching n times would require us to compare every single element in the vector since the element we are searching for is not in the vector, we would end up looking through the entire vector before returning that the element was not found. Thus the worst case of searching n times in a vector of n elements would be n * n (which is quadratic O(n^2) amount of work) 

2)The complexity of the height of the tree depends on the structure of the BST. The best case tree would occur if the Binary Search Tree is a complete tree (meaning it is completely filled on every level except possibly the last) then the height of the tree would simply be O(log(n)) / O(lgn). However, if there is only 1 node in the BST (ie, the root node) then the absolute best case would be constant time O(1) since no traversal need be made and the element would just be inserted to the right or left of the node. The worst case would occur if the trees nodes has exactly 1 child each causing the insertion to happen in linear O(n) amount of time as at this point it is basically a linked list. This worst case would occur if each element to be added is less than the previous for every element or greater than the previous for every element (thus creating a ""straight line"" type of tree) 

3)Every single item would take O(n) / linear amount of time since in the worst case, the every node in the tree has a single child that has a single child and so on. If every number in n is less than the previous, each additional number would increase the time linearly as the height of the tree is now h = n-1. Each insertion would require n+1 amount of work to do compared to the previous insertion (the work that needs to be done grows linearly), Thus the total work for n numbers would be O(n) and inserting n items into a tree that takes O(n)  would take a quadratic amount of time O(n^2) 

4)[*]The best case would mean we have a perfect / complete tree where each insertion of a number from n would take O(lgn) time since the height of the tree now is h = log2(n+1)-1. Thus each insertion now would not have to traverse and compare every single node in the tree but rather follow the pattern of: if the number n to be inserted is less than the current node, it will traverse the left. If the current n is greater than or equal to the current node, it will traverse the right to be inserted. Thus inserting all n numbers in the worst case would mean each inserted nodes would maintain the ""complete"" BST structure meaning every insertion would take log(n) time. Inserting n amount of items into a best case tree would take nlog(n) amount of time, needing O(nlgn) work. 

5)In the best case, construction the tree would take log(n) amount of time(since it would be inserting n elements in the best case scenario stated above in [*]). After inserting n elements, in the best case we would have a complete/perfect tree. Thus searching for an element would take: O(1) / constant time (if the root is the value we are searching for), O(lgn) / logarithmic amount of time. Thus the total work needed to recreate a best case tree and then search a best case tree n amount of times is O(nlgn) 

In the worst case, constructing the tree with n elements would take a linear O(n) amount of time (if each nodes successor is constantly to the left / right) causing the search to take O(n) amount of times since every element would need to be checked n amount of times causing this search to be a quadratic search as in the case of a contiguous list above in question 1 (O(n^2)) total work. ",36.0,36
9914,9914,11665,66c130d147af93128f149a1c3cbc0822def0372144aa77769fad8d406e0bf1fdaea5c4080bf967de52230b79e34763f78e3d8c34ddd69955b5c9b8521c52443c,"Worst Case = O(n) when we have to search through the whole vector and the value is not stored in the vector. We do n amount of work if we search n times. 

Best Case = O(1) when you have an empty tree (i.e. when you first create the tree), the next best Case as you insert the values = O(log(n+1)-1 when you are creating a perfect tree and Worst Case = O(n) when you have a degenerate binary tree (every node only has one child).

We would be doing O(n) amount of work each time. This is because we would have to traverse along the longest path each time we insert a new value as we will only have one long path (i.e. Sort of like a fancy linked list).

We would be doing O(logn) amount of work each time we insert a value because the amount of work done is related to the height of the tree and as the tree would be perfect in the best case the amount of work done would be O(logn).

Best Case = O(1) when the tree is empty or you find your value in the root.

Next Best Case = O(logn) when you have your best case height of the tree and find the value in the root of the tree

Worst Case = O(2n) when you have a degenerate binary tree(worst case height) and you have to search through the whole tree only to find the value isn't in the tree.",34.0,36
9915,9915,11666,4795114f3afe1274590e0a1f19de90527c5847fc255bd0189e17daffae55e382487cd961fd300bbb3c50ca9f987687623e87a7237bb50d7f5d0bd58f320efd98,"Worst case for searching in a vector is O(n) and this occurs when the value v is not in the list or is right at the end of the list . We will do n*n amount of work if we search n time O(n^2).

If we have a tree that has 2^k nodes at the kth level we call it a perfect binary tree. This tree would have the best case height of a BST which would be[ log(n+1)-1] which is O(log n). The worst case height would be [n-1] or O(n) and this would occur when the tree is degenerate or not perfect (i.e kth level != 2^k nodes ).

In the worst case height we would do O(n) work when inserting n numbers into the binary tree. We would need to traverse every element in order to do an insertion therefore it will take a linear amount of time to do so.

For the best case height we would do O(log n) work when inserting n numbers into the binary tree. In this case we would not have to traverse every element in order to do an insertion as most of it would already be in order therefore we only need to do a logarithmic amount of work as it will be much easier to insert into a tree that is already sorted.

Best case : O(log n)

Worst case : O(n) ",15.0,36
9916,9916,11667,e02b2e6799a632f8edf7a4522f9a996ef61735be79c062229a0e89a8ede6774052ec8736d48de69d3335b6ebe5ac154baf9a59c6f5866c7ad081372900ff0ff8,"The worst scenario is O(h). Where h is the height and it occurs when we have a degenerate Binary tree and the value does not exist in the tree. So, we have to go all the way to the bottom.

The best height is O(logn) and the worst height is O(n). The best scenario occurs when we get a Perfect tree while the worst occurs when we get a degenerate tree.

In worst case height we would do linear work O(n), because every node would have one child and so we would need to just add after every node.

In best case height we would do O(logn). because every node would have 2 children except for the leaves and so are work would a function of log.

In total we would do O(n) work.",21.0,36
9917,9917,11668,a130bfe9418c91d178f590031c0c9939b5fca90db77973d7f6178ded40014a7172640da790c28b96fd7fb6c80913844b332b017840744966e0e7f4da01d28945,"When searching through a randomly-ordered vector, then the worst-case complexity is O(n). This occurs when the value is at the very end of the vector or when the value is not in the vector. Either way we check every single value in the vector, meaning that we do n checks (n being the size of the vector). If we search n times, then the complexity is O(n^2) as we do n checks n times.

The best-case height of the tree would be O(log(n)) - n represents the number nodes. This occurs when the tree is perfectly structured, meaning that every level of the tree is full, except for perhaps the lowest level. The worst-case height is O(n). This occurs when every level has just one node on it.

Since insertion is a recursive function, we call the function again for each new level we move to before inserting. Each time that we call the function we check whether we can insert the node and if not whether the new value is greater or smaller than the node we are currently at. When we find the spot where we insert it, we allocate a new place in memory for the node and assign the value. The pivotal element here is the number of checks we do, which in the given case is a multiple of the height of the tree. We have seen that height is O(n), meaning that the complexity of insertion here is O(n) as well. If we insert n times, then the complexity is of course n times the complexity of a single insertion: O(n^2).

If the height is best-case, however, then we still do a number of checks corresponding to the height of the tree, meaning insertion is now O(log(n)). Doing n insertions, the complexity is now O(n*log(n)).

The complexity for searching is the same as the complexity of insertion since we basically do the same process except that when we find the relevant node we return its value, instead of adding a new node. This means that the complexity of constructing the tree and searching n times is the sum of the complexities of each process: in the worst-case scenario it is the sum of O(n^2) and O(n^2), which is still O(n^2). In the best-case scenario it is the sum of O(n*log(n)) and O(n*log(n)), which is still O(n*log(n)).",36.0,36
9918,9918,11669,a39aa34c391034439ba958ca98869143599e2cc20097d4066633e71706d0b615be58b0586a9143631148978c46ccf7746504f4abfa225c0f60b106eb68d6aeb5,"WHAT IS THE WORST-CASE COMPLEXITY OF SEARCHING FOR A VALUE V IN THE VECTOR (IN BIG-O NOTATION) AND WHEN DOES THIS OCCUR? HOW MUCH WORK DO WE DO IF WE SEARCH N TIMES?

The worst case complexity would be O(n) which happens if the binary tree is badly laid out (Degenerate tree). For example: 

Root: 5
Values inserted 6, 7 , 8 , 9, 10
Value searched: 10

In this case the tree would be a straight line and the it would take a full traversal of the tree to find the value. If this is done n times then n^2 work will be performed.

IF WE CREATE AN EMPTY BST AND PROGRESSIVELY ADD EACH NUMBER TO THE TREE BY CALLING THE INSERT FUNCTION, WHAT IS THE BEST AND WORST-CASE HEIGHT OF THE TREE (IN BIG-O) AND EXPLAIN WHEN THESE CASES OCCUR.

The best case would be a perfect or complete tree in which case the height will be floor(log_2(n))
The worst case would be a degenerate tree in which case the height will be n - 1
where n is the number of nodes

Assuming that we have the worst case height after each insertion, how much work (in Big-O) would we do when inserting all n numbers? Explain how you came to this conclusion

O(n^2) as we will be required to perform n insertions and traverse the length of the tree each time

ASSUMING THAT WE HAVE THE BEST CASE HEIGHT AFTER EACH INSERTION, HOW MUCH WORK (IN BIG-O) WOULD WE DO WHEN INSERTING ALL N NUMBERS? EXPLAIN HOW YOU CAME TO THIS CONCLUSION.

O(nlog(n)) work would be performed since there are n numbers to be inserted and each insertion takes log(n) amount of time since in the best case the height of the tree is log_2 (n) height

In these two different cases, how much work would we do in total to construct the tree and search for different numbers n times",31.0,36
9919,9919,11670,ee3d89b0d1151de34e3cf3043fc2b6592a400e8ce8a1d14d3b5e77f1fc57f3bb24de4a9c4426effca79ea565b502539dcf46a1f1d27d52e0d1e79029ce2f8aab,"the worst case for searching for v in the vector would occur when v is not in the vector or if it is the last item in the vector. in this case, O(n) would be the complexity. if we search n times, we do n^2 work. If we create an empty BST and progressively add each number to the tree by calling the insert function, the best case height of the tree would be log2(n+1)-1 and this occurs when the tree is a complete tree. the worst case height of the tree would be O(n) and this would occur when the when we would need to traverse the longest path of the tree to until we can insert. if we have the worst case height after each insertion, we would do O(n^2) work after inserting all n numbers since each insertion would be O(n) work and we are repeating it n times. if we have the best case height after each insertion, we would do O(nlogn) work after inserting all n numbers since each insertion would be O(logn) work and we are repeating it n times. in the worst case we would do O(n) or O(nlogn) work to construct and search the tree n times and in the best case we would do O(n) work to construct and search the tree n times. ",33.0,36
9920,9920,11671,fad8ed201b5420145528f1f55dddd6df344bd6b8c41089ce34f690b1ada879c754292238d4020efb35d824794aea9c5b38d2a0434e36e803dd8ffcc5a8541493,"The worst case complexity for searching for a value (v) in a vector will take us a linear amount of work to do (O(n)). This worst-case occurs when the value (v) is not present in the vector but the algorithm had to search through out the entire vector (N times) first before it is able to tell us that the value is not present.

The best case height is when the tree is in log form ( O(log) ), and the worst case is when the tree is in linear form (O(n)). The best case occurs when the BST is well structured, for example, if it is the form of a perfect tree or a complete tree. In the worst case, the algorithm needs to traverse trough the tree along the longest path from the root to a leaf before inserting.

In this worst case we have to transvers through the longest path from root to a leaf before the next insertion, this will have to be repeated each for inserting all N values, and this worst case takes a O(n) amount of work.

In the best case, is when there is an available space for insertion directly after the root and the node is simply inserted, this has a complexity of O(log).

The amount of work done is proportional to the structure and height of the tree, so it will either do O(log) or O(n) (worst case) . In the best case the search key is the root, which will take O(1) amount of work.",17.0,36
9921,9921,11672,dc28526a371ecd3cfbb01f874b966e2e2019f65befa98a250b0089b346a7e303549dac2ead3ffeef0d3b7ecff19ac3d890b35956aa010524ff365cf1275bd971,"The worst-case is when we have to visit every node of the tree (the height of the tree), this will require O(n) work to be done.

The best-case is when O(logn) work is done and the worst-case is when O(n) work is done.

The worst case is when the height of the tree is n - 1 hence O(n) work is done.

The best-case is when O(logn) work is done.

O(n) would be done.",6.0,36
9922,9922,11673,8898c8dc647252a67895b09c0b6e1e1b46e9abbd7623ddf40416335c9bffe71bf94348a71bd79a7ce33d630fd22f8d8b30ee288c330b6c240bf1f662dbee2a5b,"1, The worst-case complexity of searching for a value _v _in the vector is O(n). This occurs when _v _is at the back of the vector and we start searching and traversing from the front of the vector. The total work done for searching _n _items is O(n^2),

2, Worst case height happens in O(n). This occurs when all the internal nodes have one child.

    Best case height happens in O(log(n)). This occurs for many cases but one case is when the tree from level 0 to the second last level is a perfect tree.

3, (For the worst-case scenario) When we insert an item we do O(n) work because we need to traverse through every node. So to insert _n_ items we need to do O(n^2) work.

4, (For the best-case scenario) When we insert an item we do O(log(n)) work because the maximum traversal we need to do is equal to the height of the root. And _h_ is O(log(n)) for the best case. So to insert _n_ items we need to do O(n*log(n)) work.

5, In general, the work required to construct a tree of _n_ items and search for _n_ items is in between O(n*log(n)) and O(n^2).",36.0,36
9923,9923,11674,fa243626fbe26ef57e9cb51b64e34cda34860d25833be057b8aacb2413654723774f7590965ed807a0415dd0e925f4717e86fc15d11f310737f703eab68fbabd,"The worst-case complexity of searching is O(n) and this occurs when the value v is not in the tree.

in inserting, best case O(lgh) and happens when there is a hole in a tree. the Worst case is O(h)and occurs when the tree is very long, when it is straight most of the time.

when inserting n numbers in worst case, the complexity is O(n), because there is a linear relationship between height of the tree and the number of nodes.

when inserting n numbers in best case, the complexity is O(lgn), because there is a logarithmic relationship between height and the number of nodes, lg(n+1)-1 <= h.

we would do O(lgn) amount of work.",15.0,36
9924,9924,11675,cdf5a55df376657eda6b008ced4f7043cdba2f1d1b7da216b9e5df9fd11e894729a95890612c52ba24c8f6e0b1099b039f557d8043ee19615f361b8a60481af7,"The worst case complexity of searching for a value v in the vector would be O(n). This occurs when the last value in the vector is v, the value you are searching for. 

The worst case height of the tree would be O(n), we would need to transverse the tree along the longest path from the root to a leaf before inserting each number. The best case height of the tree would be O(logn), where n is the number of nodes. 

The amount of work we would do when inserting all n numbers would be O(n) where n is the number of nodes. 

The amount of work we would do when inserting all n numbers would be O(logn) where n is the number of nodes. ",8.0,36
9925,9925,11676,188f5f32ff22cc30082222ed760e5fe1e0a340d9ae7ecfafe10b384746f7f9c7803d064927e2b5ebaba803119e7d5eafdd11883d383dd0d5a80b8dfe524c593e,"the worst case when searching for a value v in the vector that is not there and the complexity for that is O(n) as we have to search the whole vector for it and so we performed linear work that is proportional to the size of the vector.

the worst case height for inserting a number in an empty BST is O(h)/O(n) ,meaning that we would have to traverse h nodes before we can insert a number maybe when insert the the last number in the list and is the smallest out of all the numbers in the list or the numbers on the right subtree and also when the first number in the tree is the smallest and the best case height is O(log n) that is when insert the root /first number or a small list  which is dependent on the structure of the tree.

if we have the worst case height after each insertion the work the we have to do is proportional to the total height of that tree when we are done inserting which is O(n) /O(h) because have to traverse h nodes before we insert the numbers.

if we have the best case height after each insertion we would have to do O(log n) which will be dependent on the structure of the tree .

we would have to do O(n) work as in all we have to traverse all the nodes to get to our desired position",11.0,36
9926,9926,11677,105766c5f6c790d6dc620b520090a2b98c0a0346078f36035aaeb57fa8cf54742716f9a0480d2973b6fef7f78bbaa5ba4bda7aa17dd42f5bc2f195af88fa494c,"The time complexity of searching for a value in a vector is O(n). This occurs when the value we're looking for is at the back of the vector.

The best case height after the insert function on a BST is O(logN) and the worst-case is O(n).

To insert n numbers we will have to do in O(n) time because we would have to traverse through all the n nodes.",8.0,36
9927,9927,11678,2a73fae534f6399be599dee1f1de2adaec9431f39943abeccc1ca0cc827521f43446d764a73ff779a0d169bd025aa1ff69232dd0892e2b573939bb6ed6281bd6,"1. The worst case for searching for a value v in a vector in O(n) when the value is       at the back of the vector. We do O(logn) amount of work.

2. Best case height of adding numbers in a BST is O(logn); occurs when we do a level order insertion.

   Worst case height is O(n), occurs when the values are sorted in ascending or descending order.

3. Worst case height; we do O(n) work because every time we insert a new node we have to traverse through the entire tree.

4. Best case height; we would still do O(n) amount of work because we would need to traverse through a linear number of nodes every time we perform an insertion.

5. We would do O(n) amount of work.",14.0,36
9928,9928,11679,276b4e11850dbed5adc6f0fd4249cf0b5f1cdc0a0dfd3d76321298301426fddeaa12e60021bdff5fc27802e2537ea3a2e891dc9c51166641bf68a7d7906d00b7,"O(n) , this happens when the element we're looking for isn't in the vector.

 The best case of a height when adding to a BST occurs when the BST is full , that is , each node has 2 or 0 children which is O(n) and the worst case occurs when each node has exactly one child which is O(logn) in Big-O.",8.0,36
9929,9929,11680,1e30eb511c307c57041552d3f3ff58f0e01dff16b4bbeafb7e1426a20560b5727bf879a4c238af04f66b8c454f01b583c75d2d8fab510951c437d49081081f31,"The worst-case complexity of searching in a vector will O(n) and this will occur when the element we are looking for is not in the vector.

Best-case of inserting will require O(logn) when we are forming a complete binary tree  and worst-case will require O(n) when wa are forming a full binary tree.

The work we would do is O(n) because each time we must traverse along all the nodes (longest path) of a full binary tree.

The work we would do is O(logn) because we are just going to traverse with the tree and insert a node to form a complete binary tree.

O(logn)",11.0,36
9930,9930,11681,4bccbfcaa9439271fb4e221590e1fd6768f9a6170a62193e2aa38f727ca7e838985ca00984f7b4a782149961c288a265aac8163c38e74ff4f6279a0f9baaec5e,"Worst case complexity for searching for a value in a vector is O(n), since you are searching through all elements . Searching n times would lead to nxn = n^2 squared work.

Progressively inserting each number - best case height would be O(log n). This would happen when the tree is becoming full, with each insertion IE. if there is any ""gap"" in the tree, the next number(s) will fill those. worst case height would be O(n). This would happen when each new number is the new largest number in the tree and thus has to traverse n amount of times to the right each time the insert function is called, as all the previous numbers were also the largest numbers at the time of insertion. This could also happen with all numbers being the new smallest number in the tree.

Assuming worst case height after each insertion, the tree would have n nodes to traverse to the right every single time a new value was entered. This would lead to O(n) time, as the formula for work done in terms of nodes traversed would look like - 1 + 2 + 3 + ... + (n-1) + n. The result is thus constant time.

Best case height would mean that the tree is becoming full. Inserting all numbers would take O(log n) time as the numbers would ""fill up"" a level first, before moving onto the next. ",20.0,36
9931,9931,11682,38046b991658125dabc236638e4678ce8b6ce1a14066e89cee307b4ad43150545ef075aca8b10f61c4cd3909f6915397eea519e89ce5ad74fb62a1715837f925,"1) This would be the linear worst case: O(n) because no matter the order nor number the worst possible case is the number is at the end of the vector so we have to traverse through all the elements in the vector. The amount of work is also a linear amount of time.

2) Best case O(1) constant time because this is the first element and is the root of the tree. If not the root insertion then the best-case is  O(logn) which is the minimum hight to fit maximum nodes (a tree that is packed tightly). Whereas maximum hight to fight max nodes is O(n) example would be for a degenerate Tree.

3) This would lead to a degenerate Tree, almost like a linked list in disguise. Then big O would be linear O(n)

4) this would mean that we would be able to fight the maximum nodes in the minimum hight leading to a tightly packed tree.  for complexity O(logn)

5) for best-case hight insertion O(logn) and searching O(logn)= O(2logn)=O(logn)
   for worst-case hight insertion O(n) and searching is O(n)=O(2n)=O(n)",15.0,36
9932,9932,11683,e9f55a461571038daf39646f8c350339a639982fda3a68a7de2c663bf3b55fcfe5c2c1470245e6cd83dc29b1d2c16e474b9b4bcd8ac2d4eb9b9e2eef6125ba6e,"In the worst case the item we are searching(value v) for does not occur in the vector and the time complexity is O(n). If we search n times we do n^2 work. By creating an empty BST and using the insert function to populate the tree the best case height of the tree is log2(n+1)-1 and this occurs when it is a completely perfect binary search tree, the worst case height of the tree would be O(n) and this occurs when we need to traverse the longest path of the tree in order to insert a new value, if we have the worst case insertion in the binary search tree for each insertion the work we would be doing is O(n^2) after inserting all n number as each insertion takes O(n) time and there are n insertions to make. In the best case after all insertions we would have done O(nlogn) work after inserting all n numbers as each insertion is O(logn) work. In the worst case to construct and search a BST is would take O(n) and O(nlogn) time inorder to create and search and in the best case we would do O(n) work in order to construct and search the tree.",31.0,36
9933,9933,11684,7d8cef0de14cc2a74c530bc45e24878a9bc41b99484642b220015c976fedb5143bed1f3d3d656335fb8356093aebda35cf38a76a3da63375271eacce35baf518,"The worst-case complexity time of searching v is O(n) times, it is when we are searching for v and v is not in the vector.

The best case is when we have a perfect tree and complexity is O(logn), and for worst-case is when we are searching for a leaf in a degenerate tree and it complexity is O(n).

We would do O(n), because we would treverse in each element of the tree and the worst height is n-1.

We would do O(logn), because we would know which path to take and even if the value we looking is a leaf in a perfect tree it just be comparing values then take a path.

O(n) or O(logn).  ",14.0,36
9934,9934,11685,d7ea0f2a38310b663df581928807c739d1135118819d5b7623733f4d054b7f50d32672538781df6012ffae2751400911c7d428efb70c05b3c3719b6aef5da475,"When inserting into a bst, worst case time complexity is O(n) if the data is not sorted and balanced. The best time complexity is O(logn) if the data is sorted and balanced.

the worst time complexity when searching through an unsorted vector is O(n) , this occurs when the value we're looking for is found at the very end of the vector which would require us to traversal the entire vector. We do constant work.

Assuming we have the worst case height after each insertion , we would have to do O(h) / O(n) work. Because that is the time complexity for the worst case where the data is skewed.

Assuming we have the best case height after each insertion , we would have to do O(logh) / O(logn) work. Because that is the time complexity for the best case where the data is balanced and the tree has a height of logn",11.0,36
9935,9935,11686,17ea794106565b342d0071ecda1b602670f938db088b102cae298b8fa539f99c81604db8696804a94225d5fcb56b3538a2b45e5527c8d0a393e5e2aa5ae7c0be,"1. The worst case would occur where the value v is not in the vector or is at the very end and so we could have to search the entire vector. The complexity would be O(n)

2. For insertion into a BST, the worst case would occur when we have to traverse all the way from the root to the final node. If the structure of the tree is bad/degenerate the maximum height of the tree would be n-1 where n = the number of nodes in the tree. In a well structured tree, for example a perfect binary tree, the height would be less than log(n+1)-1

3. For insertion into a BST,  the amount of work done would be n-1 i.e. O(n)

4. In the best case, we would be inserting at the root - O(1), or where we have a well structured tree, we would do a logarithmic amount of work  i.e. O(logn)

5. In the worst case, insertion and search would be O(n) and in the best case, O(logn)",14.0,36
9936,9936,11687,ff8092e7aa4e021dd13cb98107d467aae4489986d4e06673b1b4c81ebb2bbfe82687888ce375f42c4423ae545a48ef629cc67802c799162dd6a5d1de2f545d85,"worst-case complexity is O(n) and occurs when the value is in last position in a vector. We do n*n work. The best case height is O(log(n)) which occurs when the height is short. The worst-case height is n - 1 which occurs when the tree is a vector(1 dimension) or the number to be inserted is greater than that was previously inserted. We will do O(n!) work because each time we insert, we traverse from the root to the previous node resulting in doing 1*2*3*. . .*n work.",12.0,36
9937,9937,11688,8498970fc897a847cb08416ff377f1fef48bec60ecb47ecc86ba0d40abc666899852250e00e887a707bf5de87564f205ddbe85abfd397367947073bde3e3789d,"The worst case of searching for a value in a vector is O(n) and this mainly occurs if the value v, being searched for, is at the end of the vector. We do n amount of work, if we search n times.

The best case of the height of this BST is O(logn) while the worst case is O(n). The best case occurs when we find an empty space and create a node for the value being inserted. While the worst case occurs when we traverse through the whole tree using the longest path from the root then add a node, meaning the amount of work is equivalent to the height of the tree.

Worst case height would occur after n-1 amount of work, meaning the worst case amount of work would be O(n)-1.

Best case height would occur with log2(n+1)-1 amount of work, meaning the best case amount of work would be O(logn)+1.

Worst case: O(logn) or O(n), logarithmic or linear amount of work.

Best Case: O(1) constant amount of work",8.0,36
9938,9938,11689,24404807247a19fa0eb28edfebfb33701c7bf0ce5da4f252098d5b07602e418852b18cd29763fdb981a6cf7530167e7c60c21dd57b0dd95a95c25a71b9515eda," If we search for a value v in the vector, the worst case complexity of searching would be O(n) and 

hence we would do a linear amount of work.

 The best case-height of the tree would be O(log n) which occurs when we have 

a perfect tree and a worst-case height of O(n-1) when the tree turns into a linear

data structure having each node consecutively positioned.

 With the height of the tree being worst-case, when inserting the nodes we would

have O(n) complexity as there would need to be a comparison when inserting a 

node with each present node in the tree.

 With the best-case height of the tree,  the work we would do for insertion would

be O(h) since we would only need to traverse down a single path which is the 

height of the tree.

 In the case of a tree with a best-case height we would do O(log n) work to 

construct the tree and O(h) work to search for a value.

 ",12.0,36
9939,9939,11690,eacc5211df7d685afcc35802886c12863f0c8244351fcd398189af9fa9bf26e12a751640dd66f6200f43478fc4f6782d51b4f6c4a782ca1b75e12c96dded3eec,"When given a list of n numbers in a random order vector: 

WORST CASE SEARCH IN A VECTOR: 

When searching for a value in the vector, we search for the value iteratively by traversing through the vector until we find the value we are looking for. Therefore, the worst-case time complexity is O(n) if the value is at the end of the vector or if the value is not present in the vector. The reason for this is that we have to iterate through every item present in the vector in order to find the value we are looking for. 

CREATING AN EMPTY BST AND ADDING VALUES USING INSERT: 

The best-case occurs when the BST is empty and we are adding value as the root node. When this occurs, the height of tree is O(log n). The worst case occurs when the value we are adding is less than or greater than all the other values present in the BST, thus the time complexity of this is O(n), where n is the number of nodes present in the tree. This is because we have to traverse the longest path present in the tree in order to add the value. 

ASSUMING THAT WE HAVE THE WORST CASE HEIGHT AFTER EACH INSERTION, HOW MUCH WORK (IN BIG-O) WOULD WE DO WHEN INSERTING ALL N NUMBERS? EXPLAIN HOW YOU CAME TO THIS CONCLUSION. [2 MARKS]: 

It is mentioned above that the worst-case height is O(n) for insertion. Furthermore, there is a relationship between the number of nodes in a tree and the height of a tree. Therefore the amount of work done to insert in the worst case is O(n)

ASSUMING THAT WE HAVE THE BEST CASE HEIGHT AFTER EACH INSERTION, HOW MUCH WORK (IN BIG-O) WOULD WE DO WHEN INSERTING ALL NN NUMBERS? EXPLAIN HOW YOU CAME TO THIS CONCLUSION. [2 MARKS]: 

Due to the aforementioned relationship between the height of the tree and the number of nodes in a tree, it is evident that the best-case amount of work needed to be done in order to insert in O(log n ). ",11.0,36
9940,9940,11691,d7e19f96a6aba1e381d06c4d14cd8af55d98ac1778548325b5d3026d929df87b2abc3d523dd5623a58ab296187735de8598844f1ea29e935b29ced21ed87e297,"For a the vector v, the worst case would be O(n), this would mean the work done is linear.

The Best case for the height of the tree would be O(log(h)) as the tree would be filled in one level at a time while for the worst case the height would be O(h) as the Tree would be a list of the values in ascending/descending order.

For a BST, the worst case would be O(n) and the best case would be O(log(n)). This is because in the worst case, the value we are inserting need to go down a line of nodes(similar to a vector) and in the best case all we need to do is determine if the number we are inserting is greater or smaller than the node we are currently on and traverse the tree accordingly before inserting the number.

Searching for values in each case would take logarithmic work for the best case and linear work for the worst case. ",12.0,36
9941,9941,11692,8cfb9c3f85d9b6edb1f914f05f74928e81fe7cb4cefb95f1de4efb3fd1ac54a2356179dfe5b33b1cac09455e2960c015d866e1097ed5d7d20fbbdcb0d2aeee6d,"1)The worst case would be O(n) and this is when the value v is in position n-1 of the given list.

2)The best case height for a BST would be h=log2(n+1)-1and the best case insert function complexity of O(logn) and the worst case height would be h = n - 1 and the worst case insert function complexity of O(n). The first case is when the added constraints to the adding of values to the tree is able to be added without having to traverse along any path and the worst case insert function occurs when the algorithm needs to traverse the tree along the longest path from the root to the leaf before inserting.

3)It would be O(n) because it is repeatedly adding numbers to the list which require the most amount of traversal at each insertion.

4)It would be O(logn) because this is the rate at which the numbers are being added.

5)In the best case it would be O(logn)+O(1)=O(logn + 1) and the worst case would be O(n)+O(logn or n)= O(logn + n) or O(2n).",11.0,36
9942,9942,11693,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"The worst Case for searching in an unsorted vector is O(n). This occurs when an item is not in the list. We do O(n) work.

Inserting all numbers in the worst-case height will take O(n(n-1)) time since the first insertion takes constant time, and the insertions afterward take 1 traversal, then 2 traversals, and so on, making a sum of the terms 1 + 2 + 3 summing until we reach the nth node's insertion.

Inserting all numbers in the best-case height will take O(nlog(n)) time since we're adding n elements, and the best case height is log(n). This means that we will add n elements, and traverse through log(n) elements to get to the position to insert the element in.

For the worst-case height, we'd do a total of 2n(n-1) work

For the best case height, we'd do a total of 2nlog(n)",17.0,36
9943,9943,11694,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"The worst Case for searching in an unsorted vector is O(n). This occurs when an item is not in the list. We do O(n) work.

Inserting all numbers in the worst-case height will take O(n(n-1)) time since the first insertion takes constant time, and the insertions afterward take 1 traversal, then 2 traversals, and so on, making a sum of the terms 1 + 2 + 3 summing until we reach the nth node's insertion.

Inserting all numbers in the best-case height will take O(nlog(n)) time since we're adding n elements, and the best case height is log(n). This means that we will add n elements, and traverse through log(n) elements to get to the position to insert the element in.

For the worst-case height, we'd do a total of 2n(n-1) work

For the best case height, we'd do a total of 2nlog(n)",36.0,36
9944,9944,11695,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"The worst-case time complexity for a search is O(n). This occurs when the element being searched is not contained in the vector so we search all elements. Doing a search n times will result in a worst-case of n^2 amount of work.

The best-case height would be when we're entering values in an order that forms a balanced tree. This will result in the best-case height of O(log(n)).

The worst-case height would be when we're entering values in sorted order, this will form a degenerate tree. This will result in the worst-case height of O(n).

The worst-case height is achieved in a degenerate tree. This means for each insertion we would have to traverse over 0 elements for the first insertion, 1 for the second, and so on up till n - 1 traversal(s). Since we're doing this n times we would do this in O(n^2) time.

The best-case height is achieved in a balanced tree. This means for each insertion we would insert in log(n) time, doing n insertions would result in O(nlog(n)) time complexity.

In the worst-case, we insert n items in O(n^2) time, and doing a search n times would result in O(n^2).

In the best-case, we insert n items in O(nlog(n)) time, and doing a search n times would take O(nlog(n)) time which results in overall time complexity of O(nlog(n)).",17.0,36
9945,9945,11696,a586034bc0ea3e0bd2a2b4dff219cf034cac97fa120c84c5593c25dffdc3f1a468fefc24bb2bdf98353fd0ea2b977b66567bd89a57f431c7aed14858a8d70ebc,"The worst-case time complexity for a search is O(n). This occurs when the element being searched is not contained in the vector so we search all elements. Doing a search n times will result in a worst-case of n^2 amount of work.

The best-case height would be when we're entering values in an order that forms a balanced tree. This will result in the best-case height of O(log(n)).

The worst-case height would be when we're entering values in sorted order, this will form a degenerate tree. This will result in the worst-case height of O(n).

The worst-case height is achieved in a degenerate tree. This means for each insertion we would have to traverse over 0 elements for the first insertion, 1 for the second, and so on up till n - 1 traversal(s). Since we're doing this n times we would do this in O(n^2) time.

The best-case height is achieved in a balanced tree. This means for each insertion we would insert in log(n) time, doing n insertions would result in O(nlog(n)) time complexity.

In the worst-case, we insert n items in O(n^2) time, and doing a search n times would result in O(n^2).

In the best-case, we insert n items in O(nlog(n)) time, and doing a search n times would take O(nlog(n)) time which results in overall time complexity of O(nlog(n)).",36.0,36
9946,9946,11697,e06c3717f5eff40cf06c551e6ebf1004bb478bf8fc38ebcba99f54530677cde6de5ea93590e51ef3d1e09f18ed2aa22502c287548e3398f50b4cf8f8e940073d,"The worst case scenario for searching for a value in a vector list is when the value is not present. The complexity of this would be O(n).

Best case for insertion is when the node to be inserted can be inserted at the next available level so the shortest number of edges are travelled. This occurs in O(logn) time. The height of the tree will be log2(n+1)-1. In the worst case, the tree is degenerate, so the insertion will take place after the longest path from a root to a leaf is travelled. This occurs in O(n) time and the height of the tree is n-1.

The worst case scenario would mean that O(n) work is done. This is because it takes the longest time, comparisons and traversal before the node can be inserted.

The best case scenario would mean that O(logn) work is done. This is because it takes the shortest time, comparisons and traversal before the node can be inserted.

We would do O(n) amount of work",14.0,36
9947,9947,11698,c01425271443b193ce09add717a13c5f03e56291a15f580c8ffbb713e75d1afdc1826b33b91330419ca4db414a4703bd7b9474559be3d7689b82c2ecbf73906a,"The worst case for searching for a value in a vector is O(n) and this occurs when the value is not in the vector so we would have to visit every value in the vector. Therefore, we would do n work in a vector of size n.

The best case height would be O(logn) and the worst case would be O(n). This occurs when the shortest number of edges have been travelled for the best case. And the worst case occurs when the tree is degenerate so each node only has one child node which means the height would be n-1.

The worst case time complexity would be O(n) when inserting our values. 

The best case time complexity would be O(logn) when inserting our values. 

We would do O(n) work in order to construct the tree.",11.0,36
9948,9948,11699,7aa4a41956fb10b2ea3a02d2d85c1eec912704226ca5710248e26fa3e0fa199d5048abcac9423a11d00a49ffe75bdd51e2b3cd752d5f6899af51dc4b580afed1,"The worst case when searching for a value in a vector would be when the value does not appear in the vector, and we would have to visit every element in the vector. This would be O(n) in time complexity as we would visit n amount of elements. 

In the best case the height of the tree will be log2(n + 1) - 1, where n is the number of nodes. This is the minimum height we can get when we pack everything close together where every nodes will have 2 children and we get a perfect binary tree. In Big-Oh notation, this would be O(logn). 

In the worst case, the tree is degenerate and so every node in the tree has only 1 child which gives the maximum height for the tree at n - 1, where n is the number of nodes in the tree. In Big-Oh this would be O(n). 

When the tree has a worst case height, we would take O(n) time to insert each number as we would have to traverse the height of the tree which is the longest path we can take. 

In the best case, we have 2 cases. The absolute best case is where we have a hole after the root which would give us an insertion time of O(1). However, if there is no hole no longer, the insertion will take O(logn) as each node will have 2 children and we have a perfect binary tree. 

In the absolute worst case it would take O(n) as we would have to traverse to every node and the value would not be in the tree. However, if the structure of the tree is a perfect binary tree, it would take O(logn) in the worst case. Overall to construct the tree and search for a node it will take O(n) time. ",14.0,36
9949,9949,11700,b3e3cb2c21ce148370b5e2f91fd1c15e350a5dbb48b70710937a60df00151bac26d80bc3a7bdad4c31eb69ebb35264a7c7773c7f45cef6e057b05eb18d125d01,"1. The worst case would be O(n). If we are looking for a specific element in the vector which turns out to be the last element/ an element not in the vector. Then we would have had to do 'n' search operations. Work will be done until the longest running time.

2.Best case: O(1)-if the BST is balanced. (nodes=edges+1)

Worst case: O(n)-if the BST is unbalanced/skewed.

3.O(log2n). For inserting elements from the right first, we need to traverse elements, which gives the worst time complexity.

4.O(1) is the best time complexity, while adding elements in-order.

5.O(log2n+1)",11.0,36
9950,9950,11701,59ba65c517c334e25d3ae45ca0766a06b5a36061abfca1dd80f0f9e00eca00b8fc96224e4fcd721b2a66146a086c07a1cca9cf5028a8fc5d88a04890a96fe5a7,"The worst-case complexity of searching for a value in the vector is O(n) and this occurs when the value we are searching for is at the end of the vector (last value in vector). If we search n times, we do a linear amount of work.

If we create an empty BST the best-case for height is O(logn), and this will occur when the nodes contain two children and are more complete. In the worst-case it is O(n), and this occurs when a series of nodes contain one child and we traverse all the way down. It traverses the longest height.

In the worst-case we do O(n) work because we traverse h nodes, before we can insert, thus traversing the maximum height of the tree.

In the best-case, we do O(logn) work, as we do not need to traverse the entire height of the tree.

All together we do a n*logn amount of work.",14.0,36
9951,9951,11702,c52fe90555e82813bbf7f31602e97c4095475fbbf85ff26471f0158158110480233228486a71767a61c524c47fe301d427e9bdbb31f3216eb95878f59314ec4c,"Since the count method has to check every value, the complexity will be O(n).

Searching in a BST has O(n) worst-case runtime complexity, where h is the height of the tree. Since a binary search tree wtih n nodes had a minimum of O(logn) levels, it takes at least O(log n) comparisons to find a particular node.",5.0,36
9952,9952,11703,16cb13e3f20264dff11bab6b4074b1ead9b8e1cf1d7a12dd1238f56fff77a643c79324083d48280a979ad65c97d7690c011f0b94300438693e7e3022511b7be3,"1. It could take O(n) to search for a value v in a  vector if they value we are searching for happens to not be present in the vector at all as we'd still have to compare to every other value in the vector , if we search n times we could do a maximum of O(n^2)

2.Best case height O(Log(n)) this occurs when a perfect/complete tree forms, worst case height is O(n) when the tree formed is a degenerate tree and acts basically like a linked list 

3.O(n) because it is worst case we have to compare the new node each time to every other node before it so we do, so for the nth item we do n-1 comparisons, for n-1th item we do n-2 comparisons and so on

4. O(logn) as it;ll be a complete binary tree you only have to the same number of comparisons as the height of the tree which is logorithmic,

5. for best case O(nlogn) worst case O(n^2)",25.0,36
9953,9953,11704,e5092ab1c7e17d25e5db9dfc9252b8c31679cb1e2b17a0be836efd97ce606988409f994ae92e4e1f795d2d139fe2c46eff4d5f244e605f9f08c46d7129da95d2,"The worst case complexity of searching for a value is when the tree is structure in an imperfect way and the machine to do O(n) work in order to find the value.

In the worst case the machine has to traverse through the longest path from root to leaf this occurs in a tree that has a height of n -1, this has a time complexity of O(n). The best case the tree have a perfect shape and will have a height of log2(n+1) - 1 This will have a time complexity of O(logn).

The machine has to do O(n) work. This is because the machine has to traverse through every inserted value before inserting the next value. This is because the shape of the worst case tree has one long branch from root to leaf.

The machine has to do O(logn) work to insert the values. This is because the shape of the tree is perfect and is logarithmic. Each node has two children until it reaches the leaves.

Depending on the shape of the tree the machine will have to O(logn) work to insert if it is the best case and O(logn) work to search is it is the best case but it will have to do O(n) work inserting if it is the worst case and O(n) work for searching if it is the worst case. ",14.0,36
9954,9954,11705,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"The worst-case complexity is linear with O(n). This occurs when the search occurs until the last value in the vector. If the search occurs n times, exponential work would be done O(n^2).

When progressively adding numbers, if a complete tree is formed the height would be logarithmic, limited to log2(n+1)-1 or O(log). The height could extend to a maximum of n-1 in the event of a degenerate tree.

The amount of work done would be O(n) as the would be  n node and n-1 edges linking those nodes.

The amount of work  done would be O(log). This is because the amount of nodes would be 2^(h+1)-1 and hence the height would be logarithmic as it forms the index of the sum of nodes.

The worst case scenario would provide O(n^2) exponential work whilst the best case scenario would be O(nlogn).",25.0,36
9955,9955,11706,5f1f48eaee5ac422a3c6fa6a37eae574e54bf5c31dcf24e0e6dda503da6ac10d5be4b86335df2a703c5cb0a92be355a3535eec42ddde1a798228e8594808928b,"Should we have to search through a vector for a value, in the worse case the value would not be present in the vector, thus we would have to do n comparisons, thus it will have a complexity of O(n). If we would have to search n times, then we would have to do n*n = n2 comparisons in the worst case. Thus in the worse case of doing n searches for a value in a vector, it would have a complexity of O(n2).

The best case height(h) of the tree would occur when we get a perfect tree. If this is the case there would be 2h+1-1 nodes, as in each level of a perfect binary tree there would be 2h nodes, and taking the sum of all of these at each height would result in 2h+1-1 nodes. Therefore we get that n+1=2h+1. We take the log base 2 of both sides, and after simplification we get that h=log2(n+1)-1, where we can convert this back into Big-Oh notation giving is a best case complexity of O(logn). For the worst case, this would occur when we have a degenerate tree (tree where all internal nodes only have 1 child), in this case we would have to go through n-1 nodes in order to get to the root of the tree from the root or vice versa. Thus it will give us a worst case complexity of O(n).

In order to insert new elements we would always have to traverse through the height of the tree in order to find the position where we could insert the new node. In the worst case, we we would have to traverse through the all the nodes and thus the tree is degenerate, which means that traversing through the height of the tree would have a complexity of O(n). Should we have to do this insertion n times, as traversing through the height of a degenerate tree takes n-1 comparisons, we would have to do n*(n-1)= n2 - n comparisons, thus we place this into the Big-Oh notation for the worst case being O(n2).

Should we always have the best case height after each insertion, it means that after each insertion we would have a perfect binary tree (which is not possible). We know that if we want to insert a node into the tree, we would have traverse through the height of the tree. And since we have the best case, it would have a complexity of O(logn), however, we know that we would have to log2(n+1)-1 comparisons from above. Thus if we had to do n inserts, we would have to do n*(log2(n+1)-1)= nlog2(n+1)-n comparisons. We can see that the graph of nlogn will be greater than n as we grow exponentially, thus we say for n insertions where after each insertion we have the best possible height, it will have a complexity of O(nlogn).

For searching we would have to once again have to traverse through the height of the tree, and if we do this n times, it will result in the same complexities for the best and worst cases as inserting n times. Thus we have to add them together, however since Big Oh notation is based off an upper limit, we won't consider constants, thus it will have the same complexities, i.e. best case: O(nlogn) and worst case: O(n2).",36.0,36
9956,9956,11707,d96af73b5be668f5dd689aeab89641b2c7231424c7456f3ea33f65b38aaefabde723924090d862562454b1c8a6f22cbeb22245f54dc09b6ff5593a40d39e2839,"In the worst case of searching through a vector of random numbers. The number we are looking for is at the back of the array, this means we will have to do O(n) amount of work.

If we create a BST from the vector of random numbers,-

the best case would be that we form a perfect binary tree, this has a height O(logn).

the worst case would be inserting values that are constantly increasing or decreasing. This will form a degenerate binary tree with height O(n).

If we have the worst-case scenario, we would have to make O(n) traversals every time we insert. So to insert the whole tree we would be doing O(n^2) work. This is from O(n) traversals * n insertions.

If we have the best-case scenario, we would have to make O(logn) traversals every time we insert. So to insert the whole tree we would be doing O(n*logn) work. This is from O(logn) traversals * n insertions.",30.0,36
9957,9957,11708,bee12730d57033f530e6d3af850b801527bbf28710ff5b08a5e590d280e30c6a0345b61d0e3b24cafaad1628aee3191406710ce83cd7009c586afaf78d031389,"1) In the worst case, the complexity would be O(n) - when every item in the vector is checked and only found on the last check.

2) In the worst case, the complexity would be O(n) - most trees height would be O(log_n_), but in the case of a degenerate tree with 1 leaf, every node would have to be checked, thus making it O(n)

3) In the worst case, the complexity would be O(n) - most trees height would be O(log_n_), but in the case, the operation takes time proportional to the tree's height, thus also making it O(n)

4) In the best case, the height of a perfect tree with two branches per internal node and symmetrical shape, because the values are ordered only relevant nodes need to be compared is O(log_n_)

5) in the best cases the complexity would be 2*O(log_n_), and the worst would be 2*O(n)",12.0,36
9958,9958,11709,9d9fbdb8f0b5a55cc81f40af01c24b37d17fe31db439c419f81b64ca34d8f4ebfcf1ed9c7ba472f3885693ca593e5565dfb6d3c7a7ecc8755427baec264e52b2,"The worst-case complexity of searching for a value _V_ in the vector is O(n), this occurs when the value we are searching for is not stored in the vector. If we search N times with the worst-case complexity each time then we do O(n^2) work.

The best-case height is O(lg(n)) (lg is log with base 2) and this happens when the BST is a complete tree or perfect tree. The worst-case height is O(n) and this happens when the BST is a degenerate tree. 

We would do O(n^2) work because we have to traverse to the bottom (which takes n-1 movements) n times. So n*(n-1) = n^2 - n, we drop the non-dominant term and hence we have O(n^2).

We would do O(n.lg(n)) work because we have to traverse to the last level of a complete or perfect BST (which takes at most lg(n+1) - 1 movements) n times. So n*(lg(n+1) - 1) = n.lg(n+1) - n, we drop the non-dominant terms and hence we have O(n.lg(n)).

In the worst-case we would do 2(n^2) work.

In the best-case we would do 2n.lg(n) work.  ",36.0,36
9959,9959,11710,49811d763ba759a50f2e0c233e15588b02d4f863f2daf7bb9891b1e7fc339a6758ecc3a62c1286ec47602b5e14c6edff45dda6e0d22355027319e6c73f32c285,"1)the worts case complexity is O(n^2) and it takes place when v is on the most right branch at the deepest depth.

2)best case height is a height is where the the tree becomes full tree with every insert and occurs when the inputs are sorted such every entry doesn't create a new level in the tree unless all the nodes on greatest depth have 2 children.

worst case height is a height is where the the tree creates a new level with every insert and occurs when the inputs are sorted such every entry create a new level in the tree by ordering the inputs in accending or decending order.
3)O(n) work because you always garantted go over every entry before you add the next item

4)O(log(n)) work because the shortest path is will be close to the root the amount of traversal will be low.

5)O(log(n))",4.0,36
9960,9960,11711,f786d4a53e476362ee6b6cac013b5aa057803211cb74556b039162da9be82c23d9395512d9e4320c69ff2f74e18df3e862b758b12f302cbbc8a9df857835a235,"1.Worst case is O(n) when the element being searched is at the end of the vector

2.the best case occurs  at O(log*n) when we insert while the tree is small and the value is to the left and the worst case occurs at O(n) when the value  being inserted is greater and the tree is big. ",8.0,36
9961,9961,11712,112623e30928da280b124065b33eb8360f6fe49f45f9b97cc7a540f6e550a5152dd7bbbd6ba167e88c839362c8fd2148a3e881c83493d58d2e9fd2216c604c8a,"The worst-case complexity of searching for v is O(n) and occurs when the v is the last item in the vector. We perform n searching operations.

The best case is that the tree is a binary search tree with a height complexity of O(log n) as items are ordered, making search operations easier. In the worse case the height complexity is O(n) and occurs when a degenerate tree binary tree is formed.

In the worse case height we do O(n) work because as we have to go down the whole tree to insert.

In the best case height we do O(1) work because we insert to the top of the tree.

We do O(n) total work.",11.0,36
9962,9962,11713,f0db6745b82c8442a04741f69d90ab699cfa4f3ce386836ba0d3ae6a18d50c9ca2d13114c6327692eaa69266b7b9c9c7378c99ca64e0ec19c0994415cc5bcc80,"The worst case complexity is when the value that we are searching is not in the tree and the tree is degenerate. It does linear O(n) work.

The best case is h = log(n+1) -1 . This occurs if the numbers are added in such a way that the binary search tree is perfect. The worst case is h = n-1 and occurs if the numbers are added in such a way that the tree is degenerate. This might occur if values are added in order.

O(n). At each insertion we would have to transverse every node currently in the tree and then insert the value which in linear time which increases by one with every value added.

O(logn). At each insertion we would traverse to the highest level order.

  ",12.0,36
9963,9963,11714,a83848dae9e11c32fb0fef1054c9f0420423c74efa66838a210a7774eb07b64f5a5df97bc2a33594ee565ea37cacb65f8fcddd5281fc0b93d6e6e1b0ba5da1ac,"1. worst case complexity in searching a value is  O(n) and this occur when we have a left or right skewed BST. We do a linear or n times amount of work  we search n times .

2The best case would be O(log n), this happen when we have a full binary search tree  and the worst case O(n) , this occur when we have a linear or unbalanced tree.

3.We would do linear amount of work O(n).  The worst case of of BST  is when we have an unbalanced tree which might be left or right skewed and the time complexity for that is linear.

4.We would do O(log n). work. When the tree has hieght log(n) that means we would do O(log n) time complexty when inserting.

5. O(log n) ",10.0,36
9964,9964,11715,174e38c18f0521eafee3b73a0ffb8449a8c5784d547a0843ddac9c9176015fedd2516d8b3d18b017cc9000d2b315ebe1757a54b724f337f3a99202881366a527,"O(n), when the value v is not in the vector. O(n^2).

Best case is when the list is that of a balanced tree which will take O(log n) and the worst case will be when the list is that of an unbalanced degenerate tree which will take O(n)

O(n^n) the worst time for height is O(n) and so is inserting a node. 

O(nlog n) the best time for height is O(log n) whilst for inserting is O(n).

it takes O(n^4) time to construct and search n times in the worst case and O( n(log n)^2 )

..",30.0,36
9965,9965,11716,d320af019b5c5fbf5996000b6f0c018e158d92ab05c3709236e5a03a6b328c59c1ab963403ff89c119e51b19d4eaa6320e2573a8bf4efb41ca5bbf92364ab8b6,"The worst case scenario when searching through a vector occurs when the item is right at the end of the vector or the item does not exist in the vector, the worst case will be O(n) as we have to loop through every item in the vector and check if its what we are searching for.

The best case height will be O(log(n)), this occurs when we have a properly structured tree, where the height is equal to log2(n+1)-1. This happens when we have a nice balance of numbers which are larger than the root and smaller than the root. The worst case height will be O(n), this occurs when we have a poorly structured tree, where the height is equal to n-1. This will occur when we have numbers which get progressively bigger than the root and bigger than the previous number, or when the numbers get progressively smaller.

If we have worst case height after every insertion to insert all n numbers the complexity will be O(n), this is because we have to traverse through the entire height of the tree every time we want to add a new number, and the worst case height is n-1.

If we have the best case height after every insertion the height of the tree will be log2(n+1)-1, so insert the next number we will only have to do log2(n+1)-1 traversals to traverse the entire height of the tree and therefore the complexity will be O(logn).

In the best case scenario to search for the item would be O(logn) and in the worst case scenario it would be O(n).",14.0,36
9966,9966,11717,0b4066304490dceaa89df857c52096e501a361b0158a4122fe0743ccedb637acfd51e379e86df6a8a4f667a87b6d33f81aa5b4a035dd7d71db1ee1c7171afd95,"The worst-case is O(n) and this occurs when we have to go through the whole vector meaning that the value we want is end the end of the vector, we do linear work

the best case for the height of the tree is logarithmic(O(log(n))) height and this occurs when you have and a somewhat evenly distributed number of values which are bigger and smaller than the root, and the worst case is the linear(O(n)) height which occurs when you have an uneven distribution of values which are greater and smaller than the root

we have to do O(n) work because we have to do linear amount of comparisons and traversals in order to reach our desired node

we do O(log(n)) on our best case because since its the best case it means that we have a perfect tree, meaning we don't have to visit all the nodes in order to reach our goal

we do a linearlogarithmic amount of work",11.0,36
9967,9967,11718,3b413468f9946530e16c6d2ced91ab45356664eb3ef35b2823043a9391b6766aeb5cd1cde7c7799a9976f4713f096989c7f13a6ea1b6e1be3f9af94b87e0d40a,"The numbers are unordered so we must perform a linear search, which takes O(n) time. The worst-case occurs when the value is not in our list of numbers, as we have to traverse through the entire list. If we do this search n times then we can expect a quadratic amount of work O(n^2) as we perform an O(n) search n times.

If we construct a BST by repeatedly calling insert in the worst case we would have h = n-1. Here each node has exactly 1 child and this happens when our list is in ascending/descending order (straight line) or numbers which result in some zig-zag pattern eg 2, 10, 7, 6. The best case is when h is logarithmic with regards to n. ie h = floor(log(n)). This occurs when our list results in a balanced binary tree.

For the worst case of repeated insertions, we do an increasing amount of work as we insert because we have to perform more and more traversals to get to the bottom of the tree. We would end up doing the sum of 1 to n-1 traversals which results in a quadratic amount of work O(n^2). For the best case we do O(nlogn) as we only have to do at worst h traversals and h scales logarithmically as we insert numbers, and we do this n times. Lastly, in the worst case we construct the tree in O(n^2) and we do searches in O(n), but we do n of them so we have O(n^2) which results in O(n^2) amount of work. In the best case we do O(nlogn) work to construct the tree and O(nlogn) work for n searches which results in O(nlogn) work.",36.0,36
9968,9968,11719,90a8f27cfb71d61b9c73a7a8ab33730e3ebc85bfa97c54d9b613ce87b305b9e1aa432bcfbae1c2c5d2035b82671180a8d7f60a46fa0262145d5fd6b791318ce7,"1) O(n) when the value does not exist in the vector. When searching n times, the work done is n^2

2) The best case height of the tree is h=log2(n) or O(log2(n) when the tree is perfect, and the worst case is h=n-1 or O(n), when the tree is only a single path between the nodes

3) Considering the height of the tree to be n-1, a full traversal through each node is required to add a new node, and therefore adding all of the n nodes is           n*(n-1), or in Big O: O(n^2)

4) Considering the height of the tree to be log2(n), and adding n new nodes, it would be of O(nlog2(n))

5) Best height case: construction is nlog2(n), searching is log2(n), and this is done n times, therefore the complexity is O((nlog(n))^2)

Worst case height: construction is n^2, searching through the tree would be n, and this is done n times, therefore the somplexity is O(n^4)",33.0,36
9969,9969,11720,de345146608f48652cf9ec333ad07816bb0cf99089477ca7af207bce7f9f2c81b03f0e317efccc60f220182480d765ee6b6291c08b7723e7e91dd8402a584cdd,"* The worst case time complexity for searching a vector is O(n), this happens when the thing we're looking for is at the end of the list and we have to check every single value in the in the vector, if we search n number of times, each time we search we are doing O(n) amount of work  so it would be n*n or O(n^2) amount of work.
	* The best case would be O(log(n)) and the worst case would be O(n). O(n) would occur when all the values are all either larger or smaller than their previous values because then as we create the tree all the values will have to go down the longest path to get added to the tree and all the values will be on one side of the tree meaning its basically a vector. O(log(n)) would occur when the shortest path can be taken to get to where it needs to be inserted, this happens if the tree is built properly with smaller values to left and larger values to the right.
	* It would be O(n^2) because to add an element in you have to transverse n number of nodes, and you have to do that every time you add a value, ie n number of times
	* It would be O(nlog(n)) time because the transversal time at best case scenario would be O(log(n)) and you have to do that n number of times
	* In worst case it would be O(n^2) to construct the tree and then O(n) to search it once and because it is being searched n number of times in total O(n^4) to create and then search it n number of times. In best case it would be O(nLog(n)) to construct and  O(Log(n) to search it once, so it would be O(n^2Log(n)^2) to create the tree and search it n number of times",33.0,36
9970,9970,11721,82694cf634b012a9b99356edee5aefc22b24ba7895f93507fd59a70aa1b507058de91ae69d4a669273414cbd851ebdc45bb8d210bcd7e76b8c63d620d83813d3,"1. The worse-case is O(n) for searching for a value v in a vector and this occurs when v is not an element in the vector or when v is the last element in the vector. If we search n time we do a quadratic amount of work.

2. Worse-Case Height :O(n), this occurs when forming a degenerate binary tree.

    Best-Case Height: O(logn), this occurs when forming a perfect binary tree.

3. If we have the worse case height, we will perform O(n*n) amount of work , this is derived using the binomial formula n(n+1)/2.

4 . If we have the best case height, we will perform O(nlogn) amount of work. The height increase by 1 after each insertion.

5. The total work will be O(n*n*n*n)",32.0,36
9971,9971,11722,91ebe020e489f0682b9824bba92593f1328536973fcefa2088842b20b827aef8bdfb02c354fbd4b326e7989de48aea571427c17aa049b6dadee99c74f1c15bdb,"* The worst case will be if v is at the back of the vector thus the time complexity will be O(n).
	* The worst case would be if every node has one child the the height of the tree would be O( n-1), the time complexity will then ne h(n).Then the best case would be if we get a perfect or complete tree then the height of the tree will be n*log the the time complexity each time the insert function is called will be O(logn).
	*  We would have to do O(n^2) because we would have to go through each and every node to the to the next empty sport.
	*  We would do have to do O(nlogn) because the height would be logarithmic.",30.0,36
9972,9972,11723,d42cf42830844a9ee1d0ff0af8c2f689af280ff8f6db853246aca542789b88210a975754cb807f66256c17bb8f0db7f822b9fd7b118d4ccaab17c4ee83f0a430,"1)  O(n)- This occurs if the list is unsorted

2) Best case- O(logn) when the h = log2(n+1)−1 

worst case- O(n) when h = n-1

3)  We will do O(n) work

4) We will do O(logn) work

5) It'll take O(n) times",10.0,36
9973,9973,11724,5efe3fbf856ecf3a15a69292118ba94b4935a0dba8b272f0af264465d64a2e654697453d0e3e6e72201dc798f4cd3f27b28fbe0c2032a2a7784e39ed4c150909,"SEARCH

WC: O(logn) or O(n)

When: the number is not in the vector or is at the end of the vector and you have to search through all the elements.

INSERT

BC: 0 -> inserting to a leaf

WC: n-1 -> inserting on root or internal nodes

WORK FOR WORST CASE INSERTION

O(n)

WORK FOR BEST CASE INSERTION

O(1)

TOTAL:

O(n) + O(1)",4.0,36
9974,9974,11725,9607664f15775a14ee634c51fe9c149f525e26b98d5914c3165e84652908eb3f36dc6b5eb9602fdd2aa10815feb68c6202a768e4280fe2bc5565e0190f5672e7,"1. The worst vase complexity will be O(n) and it will be when the value v is the last element in the vector.

2. The best case would be O(log(2)h) when there is an open space in the tree and the worst case O(h) would be when each insertion would be larger than the one before. 

3.O(n), we get this when the tree has parents with one right child each leaving the Big O to be O(h-1) which becomes O(h).

4. We would have O(log(2)h) where 2 is the subscript of the log function and not a multiplier of the n. We get this when the tree is structured with parents that have one or two children.

5.We would do O(n) amount of work.",6.0,36
9975,9975,11726,e23792b17279f93b3cce4dddca09079f761a6a0f2795c6c3c7434b417d9b72d4e94d0c740b318fb5b6d57338883455b8fe250e5759d4aa78bd8b7bd3bfed6a55,"1) For worst case when searching for a value in an random order vector, the value we are looking for is not in our vector therefore we would have to check every item in the vector, making us do (n) number of comparisons thus giving us a worst case complexity of O(n). If we search (n) number of times and the value is not in our vector every time so we do O(n) work per search then we did O(n^2) amount of work.

2) For the worst case height of a tree we might add values in a way that each node only has 1 child thus giving us a height of n -1 as the root has a height of 0, therefore O(n) height. For the best case we add values in a way that every node has 2 children therefore the number of nodes per level will increase by 2^n which results in achieving a height of O(logn).

3) For each insertion we would have to transverse through the entire tree to add the value to the end of the tree but when we start with an empty tree then the work to add the root we can do that in 1 step then to add the second value we transverse to the root and add so the number of steps is 2, this all adds up until we have reached (n) number of items that we need to transverse though and therefore the sum from 1 to n is n(n+1)/2 therefore we do O(n^2) work.

4) The height of the tree will O(logn) therefore we would only have to transverse through at most logn nodes and we do this n times therefore we do O(n logn) work.

5) Worst case height: n^2 + n^2  therefore 2n^2 amount of work

Best case height : n logn + n logn  therefore 2n logn amount of work",36.0,36
9976,9976,11727,5e36a0e7b93c9d082984c03228c748a0348993dbc7307752e7acfbf7e44b3df39b6aedb0dd5c68b0421254e8914343a9e052d4d15e260e3ecd7ef28810b12ec9,"1) The worst case complexity is O(n), which is proportional to the height of the tree. This occurs when we have a degenerate tree. If we search n times, the complexity would be O(n) x n= O(n^2).

2) The worst case scenario is O(n). This occurs when we have to traverse the height of the tree. Best case scenario is O(logn). This takes place when the tree full. The true best case scenario is O(1). This only occurs, however, when the insertion takes place by the root. 

3) The worst case scenario is O(n). Therefore n insertions at O(n) complexity would be O(n)xn= O(n^2) complexity. 

4)In the best case scenario, the complexity for n insertions of O(logn) would be O(logn^n)=O(nlogn).

5) The complexity will range from O(nlogn) to O(n^2) complexity.",36.0,36
9977,9977,11728,dc016101375a4c30fa08c850e4ef82abdd66ca922170c25b2eda3c6f7009abcdda2dafb1c86a512fdd1b897c4c9da94be8f7047b535d50f3a259b1e698b13e05,"The worst-case complexity of searching for a value v in the vector is O(n) (linear time) and occurs when either the value we are searching for is not in the vector or when it is the last item in the vector as we would have to do the same amount of work. We would do linear amount of work if we search n items (O(n)) and we search n its n times then it will take quadratic amount of time O(n^2).

The best-case height of a tree when inserting a number into a BST is O(logn) (logarithmic time) and this occurs when we pack everything together in a perfect binary tree. The worst-case height of a tree when inserting a number into a BST is O(n) (linear time) and this occurs when the hight is n-1 meaning our BST almost looks like a list.

Assuming that we have the worst-case hight after each insertion, our best-case height will take O(1) amount of work as we just insert the node as the root. However, the worst-case will take O(n) amount of work (linear) as we have to traverse through each node (as our BST tree almost looks like a list) and then only insert the new node.

Assuming that we have the best-case height after each insertion, in the best-case scenario it will take O(1) amount of work as we have to insert the new node as the root. However, in the worst case it will take O(logn) amount of work (logarithmic) as we have to traverse through a perfect binary tree and then insert the new node.

In total, if we have the best-case hight it will take O(logn) to build it (insert the new nodes) and O(logn) to search through the BST (logarithmic). If we have the worst case height, it will take O(n) to build the BST (to insert the new nodes) and O(n) to search through the BST (linear). ",24.0,36
9978,9978,11729,412b107ec0ff412753968aa6ffdad40da21fbfd59417aac428d07f6c064389cc24911eb533cf92e901bf7845b76400d7d3831fd1347350b39d220d9c58729d2b,"The worst case for searching for a value v in the vector is O(n) and it occurs when the value being searched is at the back of the vector and we do O(n) work if we search n times

The best is when you do O(lgn) work and this happens when you are adding the shortest path of the tree .The worst case O(n) occurs when you are adding to the longest path of the tree .

O(n) work because we will have to go through each node in the longest path.

O(lgn) work because we are inserting in the shortest path of the tree.

O(n) work ",8.0,36
9979,9979,11730,16f82e0a87e8ddd62872296dc55051239fbed9bd7e989d4564eab3d0b0bd3dd97f30debd1ef7c57a72ffc4e972a5a710915f103218e9d2778be68d8b10a7d403,"The worst time complexity for searching for a value is O(n).This will occur when the value you are searching for is in the last position of the vector or not even present in the vector.

When searching n times you will have to transverse the entire vector which means you will have to visit each element in the vector.

Best Case height would be O(log(n)) and worst case height would be O(n).This will occur due to the differences in the values some are greater than the others and will not be placed in the ""correct"" place always that will make it a best case.

Insertion for worst case in O(n) and this will occur when the tree is incorrectly balanced. This is because you will have to transverse all the elements.

Insertion for best case is O(1) which will occur when it is a perfectly balanced tree.

The best case search in a binary tree will be O(log(n)) and the worst case search will be O(n)",8.0,36
9980,9980,11731,b47128b210e7cc636fb0b5325c08248ffac624374ed1eaac62c3594d5f67da91cc887cbf07a6c3571b2149ad963910548cff788f165204f9df156115e859a64b,"* Worst-case complexity for searching for a value in a vector would be O(n) because we would have to traverse through n elements if _V_ is in the last element, or even not in the vector at all. If we were to search _N_ times, then our complexity would be O(n^2).
	* The best case for the height of the BST would be O(logn). This occurs when a complete, or perfect tree forms after all the insertions. Conversely, the worst case of the BST is O(n). This occurs when each node only has 1 child, and is regarded as a degenerate tree.
	* We would do O(n) work on a tree with a worst case height because we would have to insert from the root, to the furthest leaf of a degenerate tree, ie O(height)=O(n-1)=O(n). 
	* We would do O(logn) work on a tree with the best case height because we still have to insert from the root to the furthest leaf, but it would be a perfect or complete tree. The height of a tree is proportional to the work done. Thus O(h)=O(logn-1)=O(logn).
	* In the tree with worst-case height , our work would be O(n^2). In the tree with best-case height, our work would be O(nlogn).",20.0,36
9981,9981,11732,e2110671a4eab220560a21f9e1e9feb257ad75ab23f504a892c8df780bcf445f866d86be0cb87936d65c86a82a0daabcca41a6174ec4192f8f61c7d3034cdab4,"*  Worst case -> O(N). This occurs when either the value to be found is at the back of the vector, or when the value does not exist in the vector.
(I don't understand the second part well) Performing a search n times would -> O(N²) work in total has been done.

	* The best case would have a tree with O(LOGN) height. This would happen when the tree is a perfect or complete tree.
The worst case would be a degenerate tree of O(N) height.

	* We would have done O(N²) work. Since we have the worst case insertion each time, it would take (n-1) comparisons - the worst possible height of the tree - in the worst case before inserting the value in the last level of the tree. Starting from the first number, the tree is empty, so it is simply inserted. Inserting the 2nd number would have 1 comparison being done. Inserting the 3rd number would have 2 comparisons being done before inserting it. Inserting the 4th number would have 3 comparisons being done... Inserting the nth number would therefore need (n-1) comparisons being done, thus resulting in O(N²) work being done.

	* We would have done O(NLOGN) work. Almost similar to the above nserting the nth value would need to have O(LOGN) comparisons - the optimal height of a tree - in the worst case being done. Since we are inserting n values, this would result in a total of O(NLOGN) work being done.

	* (I also don't understand this fully...) constructing an optimal tree and doing n searches on that tree would need O(NLOGN)*O(NLOGN) = O(N²(LOGN)²) work in total. (apologies for 'wrong' notation)
constructing a degenerate tree and doing n searches on it would need O(N²)*O(N²) = O(N⁴) work in total",33.0,36
9982,9982,11733,128e2656328deed2d77d2ef28a4c653d82a40a62fd734c4ccb3dafb70805db8a812cccc608184c6cbda73e2bdda34e6f81ec5dacc95d16cb9a78cba4ff089ac5,"The worst-case complexity of searching for a value v in the vector would be if the element is not in the vector, in which case we will have done n amount of work and the time complexity would be O(n).

The best case height of the insert function would be when we insert a root, which would be O(1) time. The worst case height would be when adding the last element, in which case the height would be O(n-1).

The amount of work we would do for the worst case height would be O(n-1) as we need to add each element into the tree, one after the other.
The amount of work we would do for the best case height would be O(1) as we need to add only one element into the tree, the root.

In total, we would do O(n-1) amount of work.",1.0,36
9983,9983,11734,9dc85d5fc9d9d7b3ced470df92bc3f618b906428cc44daba96ce09d4da7c5e6251f817ad8b6d168d5489d3951e1d39f87f0ab87e50f2ae36060fe5a0c0501b6d,"Firstly, because the list isn't sorted, we can only search through the vector one element at a time. Therefore, the worst-case complexity would be O(n) and that would occur when the _V_ is not in the vector and we check every element up to the end. Searching n times would result in us doing n checks n times or n^2 work. This would have a complexity of O(n^2), naturally.

Conversely, if we constructed a BST, the best height would occur when we construct a perfect tree — but in the case of n not being a power of 2, a complete or full tree would suffice — which would occur by chance without enforcing an AVL tree structure. These cases would result in a height of log2(n+1)-1 -> O(log n). In the worst case, all of the values entered after the first are either smaller or larger than the root and each successive subtree, forming a degenerate tree of height n-1 -> O(n).

In the worst-case height, each insertion will require making a comparison for every previously entered node. Say we are on the _i_th node. We would have to compare the value to every node that has been inserted up to _i_-1 due to the degenerate structure. So, we end up doing _i_-1 comparisons, then _i_ comparisons, then _i_+1 comparisons and so on, resulting in the summation of n comparison. After some mathematical analysis, you can see that this can be expressed as (1/2)n^2 +(1/2)n which is equivalent to a complexity of O(n^2).

On the other hand, the best-case height would require filling up each level until every number has been entered. Level 0 requires 0 checks; level 1 requires 1 check and so on. The level you're on will correspond to the current height of the tree. If we are on the _i_th insertion, this will be level log2(_i_+1)-1 floored. It is clear from this that doing n insertions requires much fewer checks and the number of checks will increase less frequently as n increases, demonstrating O(n log n).

Thus, in the best case, constructing the tree would take O(log n) work and then searching would take O(n log n) work, resulting in O(log n + n log n) which is equivalent to the larger function, ie O(n log n). The worst case would include constructing the tree in O(n) time and then searching for O(n^2) time. So, O(n+n^2) which is equivalent to O(n^2) time.",35.0,36
9984,9984,11735,a837228a932a0a88d86d56984d3a65abcc9744de389dd1a09c0dbc6344b07254c5f44d2d0e035800fe07d8fd7ef535a3af313b16fa0ec5085dc57d2a491f0957,"1)  It takes O(n) amount of time and this happens when the number is not in the vector, we do a linear amount of work.

2)Best case height of the tree is O(logn+1)-1 whilst the worst case  would be O(n-1), the worse case can happen when you always adding nodes larger than the node of its parent, the same can happen when you always add nodes with values lower than their parents, for the best case the list will be in a form such that for each node it would keep adding left of the tree and when you no longer can you would add to the right of the root of the subtree until tree is done.

3)O(n) amount of time where we  always adding nodes larger than the node of its parent, the same can happen when you always add nodes with values lower than their parents.

4) O(logn) amount of time because the list will be in a form such that for each node it would keep adding left of the tree and when you no longer can you would add to the right of the root of the subtree until tree is done.

5) It would take a linear amount of work.",18.0,36
9985,9985,11736,0a1eb6f30606d1f92d934eb03ca9d55d90d2ab3f505cdcb3ba02589cc6678998e8754ce7335373d6c01684ffed4a20fad8a976d2479c3f801a51d1c2b0d4ed50,"(i) the worst case in searching for an item in a vector would be O(n) and this occurs when the item is the last item in the vector or not in the vector at all. we do a linear amount of work

(ii) best case: tree will be a perfect tree and thus the height of the tree will be O(log) , the list would be in a form such that for each node, it will keep adding left of the tree and then when you no longer can then, you add to the right of the root of the subtree and thus you would keeping doing this until the tree is a perfect tree. the work is logarithmic and is based on the number of nodes in the tree.

     worst case : the tree will be degenerate and thus the height will be O(n) , due to having to test each value in the tree as the tree would form a long straight line and thus would take a linear amount of work

(iii) the work is logarithmic and is based on the number of nodes in the tree. The list would be in a form such that for each node, it will keep adding left of the tree and then when you no longer can then, you add to the right of the root of the subtree and thus you would keeping doing this until the tree is a perfect tree

(iv) due to having to test each value in the tree as the tree would form a long straight line and thus would take a linear amount of work

 

(v) to do both searching and constructing a tree , it would take a linear amount of time",13.0,36
9986,9986,11737,b35e384f7c5ceb06d79c3b93cc63fcaa47042ffefb6b106d30f49be852e804e9feab1392cb217f65d7e7d63ec9914fbf325012c10f23427d79d4c0865092862e,"In an unsorted vector, the worst case is n transversal as the item you want is the last one in the vector. Therefore O(n). If you want to do that search n times then it would be O(n^2) complexity.

The best case height in a binary search tree is O(log(subscript 2)(n+1)-1) and occurs with a perfect binary search tree. The worst-case height is O(n-1) and occurs when the binary search tree is laid out like a list(each parent only has a single child).

Each insertion is O(n-1) (transverse whole height of the tree to reach eligible node) therefore if we insert n numbers it would take O(n(n-1))

Each insertion is O(log(subscript 2)(n+1)-1)(transverse whole height of the tree to eligible node) there if we inseert n numbers it would take O(n(log(subscript 2)(n+1)-1))

In each case setting up the tree would take n insertions. n searches mean overall we have O(n^2(log(subscript 2)(n+1)-1)) and O(n^2(n-1))",36.0,36
9987,9987,11738,185dc4c21423a9741e871c6f410e59bdca77c391c194cec101c75b3cca04c937f124a0057340342b97dc026d09e5d98b6cb6fda9dab2b9032e1e211b08f87356,"1. 

O(n), when the value we are looking for is at the back of the vector

If we search for the same number n times and it is the worst case, we will do n^n work

2.

Best Case Height

O(log(n)), this is when we make a perfect or complete binary tree.

Worst Case Height

O(n), this is when we make a degenerate tree.

3.

O(n),

we will look at an example where we adding 5 items

when adding the first item, we will do work = 1

when adding the second item, we will compare with the first item then insert, this will mean we do work = 2

when adding the third item, we will compare with the first 2 items then insert, this will mean we do work = 3

this cycle repeats, until we do a total of 5 + 4 + 3 + 2 + 1 = 15

this is a linear time, hence O(n)

4.

log(n)

if we are getting an optimum tree after each insertion, then at most we will do floor(log(n-1)) -  1 work, which is O(log(n)) time.

5.

Worst Case

n^n

Best Case

n*log(n)",27.0,36
9988,9988,11739,f03b1f416ca031a8c9d6db448d0d8439f9016edf947b1c8b45411ef2872c68250d908495b49ab16d7b6e23f038f5ac72fb1ec72bfe11a51db67cec76a8643ecb,"The worst case is O(n) and it occurs when v is the last item in the vector and we perform linear amount of work when searching n times. The best case when inserting to the tree is O(logn) and this occurs when the tree has height 0, and the worst case is O(n) which occurs when we have to traverse the longest path from the root node to the leaf. Even though we have the worst case after each insertion, the amount of work required would still be O(n). The amount of work done would be O(logn). In total we would do Linear amount of work O(n). ",6.0,36
9989,9989,11740,0fa5d829ab37316f131667488ff6244b79b525ac275e022289de875a4f7426de94ef384d30176ee34a2851d47d343e62431c37057ae6054ad83ff76862ff86ab,"When searching for a number in a given vector we have to traverse through each item(number) in the vector and check if it is the number we are looking for. If the number we are looking for is at the end of the vector or it is not on the vector, we will do a linear amount of work in the worst case O(n).

The best case height logarithmic O(log(n)). This happens when we have a perfect tree.

The worst case height is linear O(n). This happens when we traverse to the last node every time when we add a number using the longest path of the tree .

We will do a linear amount of work  O(n) because we will have to traverse to the last node using the longest path of the tree.

we will do a logarithmic amount of work O(log(n)) because we will be having a perfect tree and we don't always have to traverse to the last node using the longest path of the tree.

We do a constant amount of work O(1).",18.0,36
9990,9990,11741,14bf4a341dc9827953823163cd007e766c263b8c396bea85416367e8c4908e0df252e9e3ac38e08223a3bcc05a108adef9f1881af30b78d3c7220ceb7c6be157,"a)O(n),occurs when we perform a linear search in the vector. We do O(n) amount of work.

b)In the worst case, the height of the tree would be O(h), this occurs when the tree is degenerate(i.e the tree has the left or right subtree at each or most nodes being the nullptr). In the best case, the height of the tree would be O(logn),this happens when we do not have to traverse through all nodes to insert a new node in the tree. 

c)We would do O(n) amount of work . It's a linear amount of work because we need to traverse through each node for every insertion .

d)We do O(logn) amount of work because we only need to traverse either the left or right subtree only for each insertion 

e) O(n) ",15.0,36
9991,9991,11742,922be3881d23d4f79d2fe24bf6321a23d63d950205b6ff6979047d1cc7c61465b9b18bdf8228c338eb886bb3010ea5578ec21cbc2819ca5ad2860838b719658d,"1. O(n),  occurs when value searched is not in the list. Linear work done.

2. Best Case Height: O(log(n)), occurs when inserting into a BST of good structure. (the actual best for inserting is when theres                                   a hole)

    Worst Case Height: O(n), occurs when travelling from root to furthest leaf.

3. O(n), linear work done as we are traversing entire length of vector.

4. O(1), constant time as there is already space, inserting value in memory would take constant time.

5. O(n).",10.0,36
9992,9992,11743,73f8ac3de0d9e29b34984491080a2a437e9d07081ef998fb53c2e73bde6a76efa33589c04809db77b67bfaaea71b13e4b7480f42fd75bb56aca6e9a4110b16f7,"The worst case complexity when searching for a value in a vector, is when the value is the last item in this vector. If there are n items in the vector and you have to check each one for the value, you will end up with a time complexity of O(n). This means that you will make n comparisons to find the value. If we search n times in the worst case scenario, we will do nO(n) amount of work and therefore O(n^2).

The best case scenario for a BST will happen when you complete each level before you add another level to the tree. For example, you start with the root node, then have two leaf nodes before adding a new level, then have four leaf nodes before adding another level and so on. This would mean that there will always be a relatively short path to insert the node. The absolute best case for insertion, would be to insert a node that is a child of the root. The complexity for the best case will be O(logn). The worst case for height n a binary tree, is when a node needs to be added at the greatest depth of the tree. That means you will have to traverse the height of the tree and therefore the worst case will be when the height is equal to n-1. Therefore, the complexity will be O(n-1), but as we are not concerned with the small constant, we write it as O(n).

In the worst case, we will have to do O(n) work for each insertion. This means, that for n insertions, we will have to do nO(n) amounts of work. We can work this into the function by saying O(n^2).

In the best case, we will have to do O(logn) work for each insertion. Assuming that we have n insertions, we will have to do nO(logn) amount of work. We can work this out to be O(nlogn).

 For the worst case, we will do O(n^2) amount of work to construct the tree, and then also do O(n) amount of work per search. Therefore, nO(n) for n searches. So we will have a total of 2O(n^2). This can be written as O(2n^2). Depending on the size of n, to multiply it by two may or may not be significant. 

For the best case, we will do O(nlogn) amount of work to construct the tree, and then do O(n) amount of work per search and therefore do nO(n) amount of work for n searches. Therefore, the total complexity would be O(nlogn)+O(n^2). It is important to note that for both the best and worst case tree insertion, the worst case search was used. In the case of the best case, the best case would be similar to the thought process of worst case and would end with O(2nlogn). ",36.0,36
9993,9993,11744,a51b1137941b4a2c9fd6d66da41292b1d5da2b0315b3c4cbaa7f507deed0fbfe1d51f7372760847ad411ee0d78ff9de354c3d1a9bb27433af4b5f7b732027fa9,"a) Worst case: O(n); occurs when the value being searched for is the last element in the vector; n^n.

b) Best case: O(log n) occurs when the tree is balanced; 

Worst case: O(n) occurs when the tree is left heavy (or right heavy) by consistently inserting a smaller (or larger) number than the most recent one;

c) O(n^2); every (n+1)th insertion could only happen after having traversed n nodes.

d) O(n log n); every (n+1)th insertion would happen after having traversed log n nodes.

e) Worst case: O(n^2) + n; 

Best case: O(n log n) + log n;",32.0,36
9994,9994,11745,39f1ebb534a7edaa837d48cbd4115f72e8c5e63b7a4efafc271bf59036c6638038d9febb4eab796e3f3e68165bcbad6c2e1a9ad37eb71f421ecdb12f31f4f4c5,"The worst case of searching for a random value in a vector is O(n). This occurs when the value we are looking for is at the back of the vector. If we search n times, we do O(n^2) work. 

The worst case height is O(n), and this occurs when the numbers inserted are already ordered. This will result in us having a degenerate tree of length n-1. 

The best case height is O(logn), and this occurs when the values are arranged in such a way that they take the form of a complete/perfect tree once constructed. 

Suppose we construct a tree of n nodes,

We do O(n^2) work. On the first insertion, we do 0 traversals to insert the node. On the second, we do one traversal. Then we do 2,3,....n-1 traversals to insert the rest of our nodes. Using sigma notation and an equation we have proved in algebra, we get the the work done is (n-1)n/2, which simplifies to ((n^2)/2)-(n/2). In big-O notation, we ignore constants and only look at the dominant order, that being order 2. This, we do O(n^2) work. 

The insert function does O(logn) work for a tree of a good structure(a complete/perfect tree). This is because we have to traverse through the height of the tree, which is bounded by a logarithmic function. The amount of work done is linear in height, and since the height is logarithmic in the number of nodes, we have that to insert one node, we do O(logn) work. If we are inserting n nodes, we are doing performing a function that does O(logn) work n times. Thus, the total work done is linearithmic - O(nlogn)

In the first case, we do O(n^2) work, and in the second, we do O(nlogn) work ",36.0,36
9995,9995,11746,a8b16fc0f5a2c752f3497016181c5ad9db439554c5d81073a232375aae20a22a97cca43a22eeec6af33455ba644c036ec4f0c737bb5b05eab312d892fb42141f,"* The worst case complexity would be O(n). This occurs when we search through the whole vector and the number is at the end or not in it. The work done will be proportional to the size of the vector.
	* Best case - when you don't have to traverse through the entire tree (the height of the tree) to insert a node. The time complexity would be O(logn). Worst case - when you have to traverse through the whole tree (the height of the tree) to insert a new node. The time complexity would be O(n).
	* We would do work proportional to the height of the tree. This is because our tree would be in a line and every time we add a new node, we would be traversing through the height of the tree to add it at the very end. 
	* In the best case, the work done would be proportional to logh , where h is the height of the tree. 
	* worst - proportional to h. best - proportional to logh",10.0,36
9996,9996,11747,a44191cff1258114ca99a354cbcf13b3d3a3dcbbff75ad642f883f0afb3c431e62d034975452796897dce8086c431437065cbc80fc5ae095e71da50b0ce40ae0,O(n) which occurs when the item we are searching for is at the back of the vector .we do O(n) amount of work ,1.0,36
9997,9997,11748,d3ddf356f072bf43331098b8a43e33c8b3192b402decaa6c3b442e9385a8eff79ab7318fc38d8ae8da018a53bd14daa455a684126f1cf0ce97908dac2dc0af07,"1)Worst case when searching on a vector requires big O(n), that is when the item being searched is the last on in the vector.so searching for it would require linear time.

2)The best case height is big-O(logn) that that occurs when the numbers to be inserted form a perfect tree.

-worst case height of the tree is big-O(n) that is when all values to be inserted are less than the root or when all values to be inserted are greater then the root.

3)At worst case we would do big-O(n) work to insert all the the n numbers .because we need n time to insert n numbers since we are inserting them one by one.

4)in the best case we will also need to do a big-0(n) work to insert n numbers since we are inserting one by one we will need n time to insert n items

5)In worst case construction of a tree would take linear time and and searching for a number would take linear time = big-O(n)

-In best case tree construction world take linear time and insertion will take constant time =big0(n)",20.0,36
9998,9998,11749,0937f3be42654657ad069520ce77541d5a98ac5749be01a645bd806b70eacd3e8fd42ac59b2732fb7275b059278710559211b932636ce097f43773ecefbba842,"O(n)

Best O(1)

Worst O(n)

Worst case O(h)  because you always have to traverse to the end of the tree to insert a new value",2.0,36
9999,9999,11750,df4be51196b13a9d9df6ef77eee120b801ef4ba7a8945fcd04077415ae29d58c8d1e0814291c20adeb94f43f2f99c6c2290c6dde5a70ac85841035ecc662212f,"Worst-case complexity of searching for v in a vector of n numbers would be O(n). This would happen if v was at the end of the vector or not in the vector at all. 

The best-case height would be O(logn) and this would occur if the tree was balanced. The worst-case height would be O(n) and this would occur if the tree made a single straight line or a zig-zag pattern--i.e. every node only had one child.

If we had the worst-case height, we would do a linear amount of work each time we had to insert a number. This is because we would have to traverse the entire height of the tree in order to find an appropriate opening for the new number to insert.

If we had the best case height, we would do a logarithmic amount of work to insert the new number. This is because it would not be necessary to traverse the whole tree and we'd only be doing a really large amount if we had a significantly large tree.

In the best case, we'd do a total of O(1) + O(logn) work. In the worst case, we'd do a total of O(n) + O(n) work.",22.0,36
10000,10000,11751,5204f1bef2136d15a15e2bc81fec661c33bfcaa03530558479f291b586c10eaadde8b3f1da2bdb0c585b8e4de129c95a1cc00f8b5982206443ac7a6b2014c46d,"1. O(n), it occurs when the value v is at the back of the vector

2. Best case height will be O(logn); this occurs when the tree is a perfect.

    Worst case height will be O(n); this occurs when the tree is deranged/similar to a linked list

3. O(n); because the worst case occurs when the the tree is degenerate...

4. O(logn); because in the best case the the tree is perfect 

5. O(n) and O(logn)",16.0,36
10001,10001,11752,cbae5eeb6217dfd80bce3b9f9dcc6a487de93ab5d86c0254cee58b6e3923317f7e11f9c1e67f0e0269268aa476f5f7d41a06d2c8bc23012e2299f02af5f41761,"1. O(n)

2.

	*  Best: h = log2(n+1)-1 (When we make a perfect tree.)
	* Worst: h = n-1  (When we make a tree with nods in a straight line down 1 branch each.)

3. O(n) - When inserting into a tree, the work is done when traversing the tree down its branches. Thus the amount of work when inserting depends on the amount of nodes down a branch it needs to traverse (height). In the worst case, all the nodes of the tree are in a straight line and thus the amount of work will be O(n), with n being the amount of nodes.

4. O(log2n) - When inserting into a tree, the work is done when traversing the tree down its branches. Thus the amount of work when inserting depends on the amount of nodes down a branch it needs to traverse (height). In the best case we have made a perfect tree meaning we only have to traverse the minimum height which would be O(log2n)

5. 

	* Best: O(log2n)
	* Worst: O(n)",22.0,36
10002,10002,11753,c0046d9efb5ac101c14867d2717db3e08d6ef4577447593b970d77add7785e77e104d1c4da7ccd26febfc9dec54c612f8ab1164fc3489c3f123475dd1c711486,"1.) O(n), this occurs when the number we are searching for is at the very end of the vector

2.)h = (n-1); is the worst case height of the binary tree being formed which occurs when the values being inserted create a degenerate tree

h= log2(n+1)-1; is the best case height of the tree which occurs when the values being inserted create a full binary search tree

3.)O(n) this is the case because after each insertion we have the entire depth of the tree

4.)O(log2(n)), this is the case because after each insertion the tree has to traverse best case height

5.)O(n + log2(n))",15.0,36
10003,10003,11754,8d5ceb816f2781032ee62700b4d8e0c49eadb89db294dfede287a0eaeacf6b8016c744cd4dfe71d03f0f6caf776956147ca479b489362862217860010178b882,"The worst case  complexity of searching is O(log_2(n)) and it occurs when a recursive function has to iterate to every each element.

The best case is O(n-1) and the worst case is O(log_2(n)).",0.0,36
10004,10004,11755,2a38888a8b80ad136312b78d25e48a8f2ffafd5c8eeba2c39a3cf4d0b1565a722030f9463fa977a5038fd88a16d989882eed3aeb8631f846fa1888531a07766e,"1 O(n) occurs when the value v is at the back of the vector

2 Best case height will be O(logn); this occurs when the tree is perfect

The worst case O(n) occurs when the tree is deranged/similar to a linked list

3 O(n) since the worst case occurs when the tree is deranged

4 O(logn) because the best case occurs when the tree is perfect

5 O(n) and O(logn)",13.0,36
10005,10005,11756,c1e502cb9307976ed3c86bb3e1a2a0d1fad4d05b1ff3b6ca09a4a8992703680a55c9ae6e51c9417d756549fe340afbac12cdfcd3dbe4f6a560b6a171ce7f1eeb,"The worst case complexity of searching for v in a vector is O(n) as we do the most amount of work when we'd have to traverse every other value in order to reach v at the back of the vector. you do O(n) amount of work if we search n times.

The best case height is O(log(n))when the inserts lead to a perfect BST. The worst case height is O(n) when the inserts lead to a degenerate BS

The height would be n-1 and we'll have to traverse from root through all nodes in order to insert another one and so the amount of insert work would be O(n).

The height would be log2(n+1)-1 and so and so when traversing through a number of nodes in order to insert a new one, the amount of work will be O(log(n)).

Between O(log(n)) and O(n) times.",15.0,36
10006,10006,11757,f64eaf53775ca019aa46e95d674f953f5fe42b8661af69f4cf932eb77a69c0b6057310158946905b9d5788a5b3a8acd5e3f0f489603023b3ef81fc676dabaddd,"linear O(n)  when we pop and push the value v  from the front of the vector

best case logarithmic O(logn) ,worst case linear O(n) .if its a perfect or complete tree it will best case because it can traversed easily .if its a full tree its a worst case because we have to visit each linearly.

linear O(n) we have to visit each node and edge linearly

logarithmic O(logn) we can traverse each node",8.0,36
10007,10007,11758,74d9bc92412f8c3ff2851eb60d7164b5df173c9c4dc214351b20de54e473afd02c6de0a58df8f38e8034cea31df2b0fd7682d3f538a4da451a42ed390cc33c67,"The worst-case complexity for searching for a value v in the vector is O(n) – linear time. This occurs when the value is either the last item in the vector or when it does not occur in the vector- both require you to search through n items. If we search through n items this takes linear amount of time O(n) and if we perform that search n times it takes a quadratic O(n^2) amount of time.

When we create an empty BST and progressively add each number to the tree by calling the insert function, the best-case height of the tree occurs when we pack all the items as closely together as possible to form a perfect binary search tree. In this best case the height will be log(n+1)-1, which is O(logn) height- logarithmic height.

The worst-case height, h=n-1, O(n)- linear height, occurs when we stretch out the tree as far as possible, when it almost looks like a list or has a zig-zag shape (each node has one child).

If we have the worst-case height after each insertion, in the worst case we would do O(n)-linear work to insert all the numbers because we would have to travel from the root all the way down to the furthest leaf- we have to traverse through the entire height of the tree and so we do a linear amount of work in the height of the three O(h). the best case would occur when we have an empty spot at the root and so can directly insert a node there, which takes constant time O(1).

If we have the best-case height after each insertion, in the worst case we would do O(logn) – logarithmic amount of work because we would still have to traverse from the root to the furthest leaf and thus traverse through the height of the tree, which, in this case, has a height of log(n+1)-1 and so we do a logarithmic amount of work in the height of the tree O(h). the best case would occur when there is an empty space at the root of the tree and we can just insert the number there-this takes constant time O(1).

In the case of the worst-case height, it takes a linear O(n) amount of work to construct the tree and to search for an item would also take linear time O(n) and doing that n times takes quadratic time O(n^2) and so in total is linear + quadratic work.

In the case of the best-case height, we do logarithmic amount of work O(logn) to construct the tree and  to search for an item would also take a logarithmic amount of work O(logn) and doing that n times would take linearithmic amount of work O(nlogn)  and so in total would take logarithmic + linearithmic work.",27.0,36
10008,10008,11759,b65e52333a31f01a7d7a5dae0ff6fc8ed82b8b5283406f591e8d448f865292ea8162938b0259891df516358cc77c51dca3895b350dbb36cf96d6c23e9b3fa27a,"Worst case search: O(n) - this occurs when  the number bein searched for ,v, is at the end of the list

n^2

Best case height: O(n-1) this happens if the values are sorted with an inorder traversal

Wort case height: O(n-1) this is because the members to be inserted are all the same and its the same number of values to be inserted

Worst case  work: n^2

Best case work: n^2

Total work: n^2",9.0,36
10009,10009,11760,07ab043d70e14725f955703ce65a95b6912342e429a6c9a7dec43aacd53b63f2b0d3ebef4da8ffdff01a86c6c296ffe0e21e4d798223854fe6e651460e1d7280,"The worst-case complexity for searching for a value would be O(n) where the value that is being searched for is the leaf at the highest height of the tree. We would do a linear amount of work to find the value at a leaf at the highest height of the tree.

The best case height would be O(logn) when the tree is a perfect tree. The worst case height would be O(n) when the tree is left or right leaning.

We would do O(n) work as in order to have the worst height, the new node has to be inserted at the leaf with the highest height. This means we would have to go through the n height to add another node.

We would do O(logn) work if we had the best height as each node would have 2 or 0 children.

We would do a quadratic amount of work, O(n^2). ",23.0,36
10010,10010,11761,1a588e676388eab699476b49a00fa1013110acdcf89dcc5a2ff2c6e7b4d1cc5fff03a1daa5e3f8069ad9a846f88030beb884f390c11da3f442ee0a6ebc1a9307,"* The worst-case would be if the value is not in the tree or if the value is along the longest path from the node to the leaf of the tree. This gives O(n) complexity
	* The best case is when we have a perfect tree that would have a complexity of O(log2n). The worst case is when we would need to traverse through the longest path from the root to the leaf which has a complexity of O(n).
	* O(n) because we would need to traverse through the longest path.
	* O(log2n)
	* O(n)",13.0,36
10011,10011,11762,13c060e9a128226d326b883081af9bf1d8d87f9594a5842046c134e481d515a3c3262c6c71b891f6321e7a0714b1981629c933e2f5180f487fe5e4ff9fbfb937,"a. O(n), occurs when value v is at the end of the vector

b. i) Best case O(log(n)), occurs when the tree is perfect binary tree

    ii) Worst case O(n), occurs when the tree is deranged. 

c. O(n), it occurs when the tree degenerates 

d. O(log(n)), it occurs when the tree is perfect binary tree

e. O(n) and O(log(n))",13.0,36
10012,10012,11763,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"1)In the worst case the number, the number is not in the tree and the path we follow corresponds to the longest path from root to a leaf - that would require n times of work(O(n)).

2)The best case is if we have to do O(logn) amount of work. The worst case is if we have to do O(n) amount of work. The worst case would require us to traverse through the entire tree to insert the value - amount of work done is proportional to the height of the tree. The best case would have us inserting it  where there is a left or right subtree present.

3)O(n) - In this case, our algorithm needs to traverse h(height) nodes before we can perform the insertion.

4)O(logn) - In this case, our algorithm needs to traverse the minimum possible height before we can perform the insertion.

5)log_2 (n+1) - 1 <= h <= n-1",10.0,36
10013,10013,11764,e39d05b72f25767869d44391919434896bb055772d7969f74472032b03bc18418911f3b0e6dd47ff8f3b2323728225286c3cb36914d28dc7db40bdd786159c0a,"1)In the worst case the number, the number is not in the tree and the path we follow corresponds to the longest path from root to a leaf - that would require n times of work(O(n)).

2)The best case is if we have to do O(logn) amount of work. The worst case is if we have to do O(n) amount of work. The worst case would require us to traverse through the entire tree to insert the value - amount of work done is proportional to the height of the tree. The best case would have us inserting it  where there is a left or right subtree present.

3)O(n) - In this case, our algorithm needs to traverse h(height) nodes before we can perform the insertion.

4)O(logn) - In this case, our algorithm needs to traverse the minimum possible height before we can perform the insertion.

5)log_2 (n+1) - 1 <= h <= n-1",11.0,36
10014,10014,11765,e8a6e8174a6dd6e314677435e7049c0e3009b13d8a5df4000710970679e38e84d121d59138dfaf7218a7bd9e9ad0ee03d92b55f5f1e73be1e9206de0707e798c,"THE WORST COMPLEXITY OF SEARCHING FOR A VALUE IN A VECTOR is O(n^2) and this occurs when all the inputs/elements in the vector are unique and so you have to compare each one to the search value.

WHEN A BST IS CREATED ADDING VALUES USING THE INSERTION FUNCTION, 

THE BEST CASE HEIGHT of the tree is O(log _n_) or O(log2(n+1)-1), and this occurs when the path from the root to deepest descendent leaf is very short (a very shallow tree). When we have maximum number of nodes in tree. Therefore total work done will be O(log _n_) or O(log2(n+1)-1) as the height of the tree is the path traveled.

THE WORST CASE HEIGHT of the tree is O(n) or O(n-1), this occurs when the path to the furthest node is very long (a very deep tree) so linear amount of work of O(n) or O(n-1) has to be done. For example a degenerate tree. As this will be the furthest path travelled.

TO SEARCH FOR NUMBERS IN THE TREE:

IN THE WORST CASE O(n) or O(n-1) work if number value is not in tree, and leaf is in longest path. If dealing with a perfect tree then worst case would be O(log n).

THE BEST CASE is O(1) amount of work",19.0,36
10015,10015,11766,8c276f2a894ec8359a82f6a7f8b543cee4dafa5e339dd5fcbdd9b626de04d860f6a771f050054850d4263b60fc7c9e2f46a60c4568664a5f9854894846a3920d,"O(n). this occurs when we have to search through the whole vector because the element isn't there.

best case, the height of the tree will be O(logn), we'd be inserting the root

worst case, the height of the tree will be O(n), we'd have to travel down the longest path before inserting

O(n), the work done would be dependant on the nodes already entered.

O(logn), we wouldn't have to travel through the longest path before inserting

O(n)",6.0,36
10016,10016,11767,a24d4454b3c0f0611764d00de2a1119612fa4ae5c81fcdcf3800d4c6304de97c1896fb4640ae9520917c1bfdc4dabf12f730cd0013b9af7ab3a73969db3c7eea,"1) The worst-case complexity of searching for a value v in a given vector will be O(n), this will occur when the last value in the vector is the sought after value. We do a linear amount of work when we search once, so searching n times would be result in work done of n*O(n).

2) The worst case of an insert function will result in a height of h=n-1. This occurs when our numbers are given in descending order and our root is considered our initial input value. The best case of an insert function however will result in a height of h=log2(n+1)-1. This will occur when our input is a perfect binary search tree, each parent will have 2 children and there will be 2^h leaves.

3) Inserting n numbers in the worst case scenario would result in an exponential amount of work as the tree would become longer and hence more work would have to be done with each subsequent insertion. This then results in O(n2)

4) Inserting n numbers in the best case scenario would result in a logarithmic amount of work as the tree would grow in complexity more slowly as it fills out as it is a perfect BST. With each subsequent insertion, the time complexity differs less and less. This results in O(n*log(n)).

5) The work done in the worst case scenario would be exponential O(n2), whereas the best case scenario would be logarithmic O(n*log(n)).",36.0,36
10017,10017,11768,c1f6abfd4fc5318b969d8b42d7f10e1364425c616a8b69c8f8594b69d2c7a7743a83790314faf11cc3b382f3287fb00f531687f09a9146a00ce2dbe39062eeff,1) ,0.0,36
10018,10018,11769,3143af8e534af5f9178a128c44433d6c35da771cbbc382af1235851f68f2e6c0baf6b6c7dc7aef9c829246db2be183570b22a8f6e1e10870c8fab148df9fe20f,"1. Given a vector of n numbers, the worst case complexity is O(N) and the amount of work done if we search it n times is N!

2. Best case height of the tree is: O(N/2), This would occur if the tree is a perfect Binary tree.

    Worst case height of tree is: O(N-1), This would occur if the tree has all of it's nodes as a parent to only one child, causing the tree to resemble a list with many values stacked to one side.

3. We will have to do  O(N!) comparisons in the worst case to insert all numbers, this is because at first we compare the root and the new node (comparison = 1),

then for the next node we compare the root and the node at depth 1 (so comparison = 2) and so on, thus when inserting n nodes it takes factorial work.

4. In the best case O(N/2 +1) COMAPRISONS WOULD BE DONE, since the tree is a perfect tree of height n/2.

5.The total work done in therbest case would be O(n-1) and in the worst case O(n!).",15.0,36
10019,10019,11770,eaf6c4c43d71c21a9611ab529dceabe1fb33ac3bf543bdbce13d249f7b6251a8ae478c786f76da007fed6f3e8c11ab62610c853fb7d3dd853fe2afc80fe40704,"we would do O(n) work, this occurs when the number we are looking for isnt in the vector and we have to go through all the numbers in the vector

the best case is

the worst case is O(n) and occurs when every node has only one child, the best case is when we have a complete tree where we have a logarithmic complexity  O(log(n))

we would have a worst case  complexity of O(n) since we will have to traverse from the root to the furthest node every time we insert to the bst.

best case occurs when we have a space and each node has 2 children and have complexity  log(n+1)−1 

to construct the tree and search  we would do O(n) work",15.0,36
10020,10020,11771,98d78e9c828344508b695719d0252934ec81638b460881dd9abe0087d3148c90c09f4ac72696b8c6cb5d749b644a041f0fa7f6d6c483866227774b40bcf364d5,"O(n),  when the value is not in the vector

Worst case is  2h  and best case is when h=log2(n+1)-1 and the worst case is when we insert a value in a very long tree.",6.0,36
10021,10021,11772,135bdbdca9dab16566a02b87eb86b2b03e986360c36387bc6b252f2a7b0098a14637a43a9d1d68d223771b954b34555f039489b7af8726eba774f24a3c3a0d42,"1) The worst case would be O(n). This would occur if value v is the last value in a vector. To search n times we would do O(n^2) amount of work.

2) The best case would be h = log(n+1) -1. This occurs when we have a complete binary search tree.

    The worst case would be h = n-1. This occurs when we have a degenerate binary tree.

3) O(n). We would have to traverse through every node in the tree as the tree is in a form of a linked list.

4) O(log(n)). We would only be traversing through the minimum number of nodes to the new node.

5) To construct a binary search tree the complexity is O(h) so in the worst case it would be O(n) and in the best case O(log(n)). In the worst case a search would take O(n) as you would traverse every node, in the best case O(log(n)) as you would only have to traverse to where the node is while avoiding some nodes.",20.0,36
10022,10022,11773,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"Worst case complexity is O(n), it occurs 2(h) times.",4.0,36
10023,10023,11774,061f56d837e6405fc3da18b48c234575e946e21c4f8a87e4ff0140618b0afc839b770f98def91d7072d96fe9e6cbacdd2d64a21bf2c7aaeab14c8c197a8e0535,"O(n) - it will occur if the value we search for is either at the end of the vector or is not in the vector at all and we do n times searches

best-case height is O(log(n)) where the tree has a perfect shape or complete shape and worst-case height is O(n) where the tree is a degenerate

O(n) since the worst-case height is the n-1 which is a linear function

O(log(n)) since the best-case height is log2(n-1) where the shape of the tree is perfect or complete

O(n)",12.0,36
10024,10024,11775,2f496bb2a99de18fa436df0deced0620c47daee5ce37cf49cf6b3200c20eb84e5a9b7a47850d29ff143886bc9932f54f86b6a1101a1d0f70874e22b40b657cec,"the worst case is if we have a stretched out tree. we will have a linear complexity ( O (n)). we do linear work n times, depending on the number of nodes.

when creating a BST the worst-case height of the tree will be when each parent has only one child and thus the tree would be stretched out resulting in a linear complexity (O(n)) of height. the best case would be when the tree is tightly packed whereby each parent has two children and that results in a logarithmic complexity ( O (logn)) of height.

we will do linear work as we would have to transverse all previous elements in the list in order to insert.

with the best case, the tree would be tightly packed and therefore we will not need to transverse entirely through all elements. we would either transverse left or right of the current node",15.0,36
10025,10025,11776,bb7a5218ab3dfcc0ac546d608943de6dcbb3727d09e6f5dbb5e885ea5b24939174aaaa40e8672ce63fa53f6af97ad899b29ea3229ae18c85c504ca3dcaa7d71a,"* Search worst case is O(n) because  the number is not in the tree and the path we follow corresponds to the longest path from the root to a leaf. In this case, we traverse n times, so the amount of work done is proportional to the height of the tree. the work done is linear.
	* insert: In the worst case, our algorithm needs to traverse the tree along the longest path from the root to a leaf before inserting. In this case, we traverse h nodes before we can perform the insert. So in the worst case, the amount of work done is proportional to the height of the tree. O(n) . In the best case, the height of the tree will be log2(n+1)−1. big-O notation 
O(logn)
	* O(n): our algorithm needs to traverse the tree along the longest path from the root to a leaf before inserting. 

	* O(logn): because the height is short

	* 2O(n)",11.0,36
10026,10026,11777,e15ad332a60fd21f9642a607905bc6a0a968e3d65f0ab448161698266492242c990fc890cd09bab4dffa30a30230d6c043c42b0ef218d6e81e40a2206a0638d0,"The worst-case complexity for searching a vector is O(n) which is linear time, given that value v is at the back of the vector.

The best-case height of tree is O(log2(n+1)-1) which is when we have a complete tree and the worse-case  is O(n-1) which is when we have a degenerate tree that resembles a linked list data structure.

In the worst case height we will have to do work in O(n) linear time, this is due to the fact that we will always have to start our transversal from the root.

In the best case height we will have to do work in O(logn), this is because we are not required to start traversing from  the root of the tree but only the node which have values greater than or equal to the root which we desire to insert which breaks our time from n to n/2 to n/4 etc.",15.0,36
10027,10027,11778,89daf5e5dd9d5cd464a1dba203796d2fcea5b46dd29cb10e72e0dd7e72373ac4fd8e96b5e3d9813a2ed44c552171318e265b869630b10e2e2b1c3ee4cc7320d3,"1. Worst-case complexity: O(n) when the value is not there in the vector.

2. Best-case complexity: log(n+1)-1

    Worst-case: n-1

3. O(n)

4. O(log(n))

5. ",6.0,36
10028,10028,11779,d14b989bcb894978cca36e7e5f61001f5674d5a63e03700520c57accee4d5d7687b97d71bfffe56071d64d16c01c84e867fd79ad35b152d9c5667b7efa04e45e,"* We take O(n) to search for v in the vector and this occurs when v is not in the vector. So if we search n times, the complexity is O(n^2).
	* In the worst case insert n items into an empty BST we get O(n^2) time. This occurs when when every new entry is the child of the previous entry (which creates a tree with h = n -1). In the best case we get O(nlogn) time. This is when every level gets filled out before any entry gets children.
	* O(n^2). I got this by drawing a graph indicating how many traversals will be made for insertion. The graph is quadratic.
	* O(nlogn).  I got this by taking the height of the tree at each level as log2k where k is the number of insertion made thus far. Multiplying n by the sum of log2k from k=1 to n, we find that the greatest term is nlog2n. 
	* Searching through the trees n times takes approximately the same amount of time as building the tree. There for by big ) - notation, the complexity of this operation is the same as for just building the trees.",27.0,36
10029,10029,11780,3dd0e6b0aa4ca279a9a8f781013cc1ffadd92a615d343d8f7162570e3cd2647c9fb452de2221fcafa1322a70dac1ad1ef68bd5efe79682df415f360b352ef94b,"1. In the worst case searching would require an O(n) amount of work. That occurs either the value v is not in the list or at the lowest level of the tree.

2.-When inserting, in the worst case we would need to traverse the maximum height of the tree which will be O(n) complex, that would occur when we maybe insert  the smallest number of the given list.

-In the best case we would need to do a O(logn) amount of work.

In total , the amount of work needed to construct a tree and search for different values will O(n) + O(logn)",6.0,36
10030,10030,11781,2d66cc49a7ffe05cc8bbfc302bcf20656e7f907877a7522f7da110ca45abf9d13e838fa2518e2db3e38e88bb214034f63934465720849e92200572791f51d840,"1. O(n) it occurs if the value v is found at last vertex of a degenerate tree.

2. The best case height is given by O(logn) and occurs if out tree is a perfect binary tree. The worst case height is given by O(n) and occurs if our tree builds up to a degenerate tree.

3.O(n) work is done inserting all numbers since our worst case height is h=n-1 we ignore the 1 in Big O notation

4. O(logn) since our best case is h=log2(n+1)-1 we ignore the constants",13.0,36
10031,10031,11782,0c11d203426fce7b3dc05c5b901a557cc9648e7fd3384bd9d8800631c383636176c5236339b82c8cac354a014c4e904c016c4f55b6e4ea8b971819143c0b5cb5,"* O(n), it occurs when the value v is found in the last node of the Degenerate tree.
	* Best case height is h = log2(n+1), it occurs when the tree is a perfect binary tree & the worst case is h = n-1 , and it occurs should a tree be a degenerate tree.
	* O(n)
	* O(logn), after-all the best case would be h=log2(n+1)-1. Therefore we should ignore the second term which is -1
	*",13.0,36
10032,10032,11783,2ac52bf7176b74f783c4dc472a3ad61819784c24e47b750c3635810bda8131880643be2f953dc39facdc68dcec02aa6cc62d7628e7e8b294770838010259c464,"1)The worst-case complexity occurs when the algorithm needs to transverse the tree along the longest path from the root to the leaf before inserting it. In the worst case, the amount of work done is proportional to the height of the tree.

2)The best and worst case is O(logn) or O(n) respectively. In the best case we the search key value is stored in the root. The worst-case is that the number is not in the tree and we follow corresponds to the longest path.

3)The work used to insert n numbers is O(n).

4)The work used after each insertion is O(logn)",6.0,36
10033,10033,11784,a300869c4f32047b23ac68a02d99d6a69e15fcc6cb6903bc4e640c72bf256b08b631e89f75d7f7263574f4383932390c2f4b98297d3a8bfdd9da2320bf30b053,"The worst case scenario would be when the number is at the end of the vector and we would do O(n).

If we can create a complete tree the best height would be O(log2(n)). however if the numbers continually go on way in a tree then the worst case would be O(n-1).",10.0,36
10034,10034,11785,b1a3a9f62a3efb88815155da55fbf2f2fafa14dd37234e9f11b5f00a231a31fde1494bd63f6ac5858aefb97ae2c7130be129cb66d65efd0dfa784ad99b296be3,"1. Worst-case complexity would be if the item we are searching for would be the last element of the vector and we would need to traverse the entire vector to find the item. Therefore this would occur in O(n) time.

2. In the worst case of insertion, a traversal of the entire tree would be needed. This would be a traversal of the longest path of the tree, from root to leaf, and would therefore need a traversal of the height of the tree (h nodes). This worst-case would occur in O(n) time. Best case is when no traversal is needed and we can simply insert into the empty node and that would occur in O(log n) time.

3. Traversal depends on the height of the tree. We would do a linear amount of work as we would have to traverse the entire height of the tree and therefore visit each node along the longest path from root to leaf. It would there be in O(n) time.

4. Traversal depends on the height of the tree, in best case the height of the tree would be log_2(n+1)-1. Therefore the work will take O(log n) amount of time.

5. O(log n) in best case and O(n) in worst case.",10.0,36
10035,10035,11786,e40d8bf3b05bd8e034438beb235a1631a28b193d6edc5587f765a26d4981e60fae4fcb9a995036a1c2815f2073b85fc4667e3d6bbfc0e5a63b847c8fa219ba80,"The worst case complexity of searching through a vector is O(n) time, and if you search for n values in the vector, you do O(n2) work.

The best case height of a BST is O(log(n)); the worst case is O(n). Which case occurs depends on the order the inputs are given in. To get the worst case, the inputs need to be given in an order that is well sorted; to get the best case, the inputs would need to be in an order which is like the preorder traversal of the most perfect version of the tree that could possibly be made from the inputs.

It would be O(n2) work. The worst case of a BST would be the degenerate case in which the BST is like a forward singly linked list. Inserting a single element in this case would be similar to calling the push_back() function of a linked list without a tail pointer, which has a time complexity of O(n). Inserting n elements would mean doing O(n) work n times, which equates to O(n2) work.

The best case for an insertion is O(log(n)) time complexity. Making n insertions equates to O(nlog(n)) time complexity — linearithmic time. 

Best case — construction = O(nlog(n)), performing n searches = O(nlog(n)). If these operations are done sequentially, then it will take O(nlog(n)) time. Worst case — construction = O(n), performing n searches = O(n2). If these are also done sequentially, then it will take O(n2) time.",36.0,36
10036,10036,11787,744cc5a93fd7edad364406b30ceaa6836705a7419bd01ed97b04c61f1235130699ff789e400cc607e1772b19b35bf800957b6bd74b1e52cf1974d01500560533,"The worst case is when v is at the end of the vector. The complexity for this is O(n).

The Best case is O(log n). This is when the tree is well structured. 

The Worst Case for insertion into a BST is O(n). This occurs when the BST is degenerate and all the node have to be visited in order to insert the element into the BST.

The complexity would be O(n). This is because 'worst case height' means that the height is the maximum that it can be, meaning that we have a degenerate tree where each internal node only has one child. We are therefore visiting each node in the BST resulting in O(n).

If we have the best case height after each insertion then the complexity will be O(log2 n). This is because the tree is structured in a way which means we don't have to visit each node in the tree.

Total Work: Worst Case: O(n^2)

Best Case: O(2log2n)",17.0,36
10037,10037,11788,8049e1d0a5ce881b749a9c9461a73e821d1792fbc2adc39e1be0be7717d99f93abbe732f68ade8cbd01333fb3e4a5adeb13b3875a705e5218706e5b68e7e0885,"1.  The worst case is O(n) and it occurs  when the value we are searching for is the last element in a vector or if the element we are searching for was not in the vector in the first place. We do maximum work which is O(n) which is n traversals.

2. >The best case is when h = n-1 / O(n) , meaning that we each node is gonna have 1 child and we don't create a perfect tree.

   >The worst  case is when h = (logn+1)-1 / O(logn) , meaning that we have perfect a perfect tree.

3.O(n^2)

4..O(n)

5. O(n)",15.0,36
10038,10038,11789,52240fd5da488c8fea93f35bf4efe57000386d8c8d0c85c5b680c74f1a8feca90e13d4df01d1470660907e2655f277134bf53af33144e84c3793614abbdf6e99,"The worst case complexity is 0(n) and this occurs when the value v is not in the vector. this is a linear amount of work.

The worst case height is 0(n-1) and it occurs when every node only gets 1 child. The best case is 0(logn + 1) when you fill up the tree from the left giving each node 2 children before moving on the next level.

The worst case would also be 0(n) as n-1 traversals would be needed.

The best case would be 0(logn).",13.0,36
10039,10039,11790,93c90404569325fe60b728e076fbba3cf65e437046307f80389f0bc8991e0972c6f04c428807930e8f3ec23f714c2c1a1c5a69ba6ec135ea91d23224a8d3d68d,"1. The worst case complexity of searching in a vector is O(n) and it will happen when the value v is not in the vector. We will do n amount of work.

2. The best case of the height of the tree is O(logn) and this happens when we create our tree such that each node has no children at all or exactly two children. The worst case of the height of the tree is O(n), this happens when we have a root that has only one child and that child also has one child and so on.

3. In the worst case of insertion we would do is O(n) amount of work. The reason is that we had to transverse h times (the height of the tree) that need n -1 work ( O(n) ).

4. In the worst case of insertion we may do O(1) amount of work. This happens when we have a hole in our tree and the value to insert fits in that hole.

5. O(logn) or O(n) this depends on the structure of a tree.",14.0,36
10040,10040,11791,2752a012a3acfc041a30d5a655085eade0eb440b54f67d20ed248f27ebf41fd19d90129f4fd7d4c48bc1b7b721b3638118e357f1785837b03bc7def7da08253e,"The worst-case complexity of searching for a value _v _is O(n) and occurs when the value is not in the tree.  We do a linear amount of work if we search _n _times as the complexity is O(n)

The best case height of the tree is _h =_ log2(n+1) - 1 and it occurs when a tree is balanced.

The worst case height of the tree is _h = _n - 1 and it occurs when the tree is skewed and resembles a linked list.

For the worse case height, we would do O(n) work in order to insert values  as  the algorithm needs to traverse the tree along the longest path from the root to a leaf before inserting the value.

For the best case height, we would do O(log n) work in order to insert values. The best case for insertion occurs when there is place for the value on the left of the root.

Assuming we have the worst-case height after each insertion, we will have to do n(O(n)) work as we would have to do a linear amount of work to insert each value.

Assuming we have the best-case height after each insertion, we will have to do n(O(logn)) work as would have to do a logarithmic amount of work to insert each value.

In order to construct and search for different numbers _n _times in the worst-case, we would have to do n(O(n)) amount of work.

In the best-case, we would have to do n(O(logn) amount of work.",31.0,36
10041,10041,11792,4c6f807c2ce1ab585dfa9622ceaade81e43b8fe88ba8af5d95eb11efdad75a8b1190eb5c2d48dff34f29ac730bf0895fdaf308c3995dbd7f2103246c342b70a1,"- the worse complexity when searching for a value in a vector is O(n) and occurs when the value is the last element in the vector.

- the best height is 0 and occurs when we only have to add one element. the worst height would be h=n-1 (in big-o O(n) ) which occurs when the tree is completely unbalanced.

- O(n) it would be this because we would have to go through all the nodes of the tree. the -1 can be ignore because it is a small constant.

- O(1) it would be this because in the best case we only have to add 1 node.

- O(n)",6.0,36
10042,10042,11793,ba6cb46aa6ff6581fcd2828d6944742916cd44c20dbee87513cab04b763159ab5e8fcc20c0eaa029b5cead3d4e1911b67590f3a4b4a64f4e9fa942648249fc12,O(log2n)O,1.0,36
10043,10043,11794,3068685c76e4b2c329c64b4a981abf59ea0591abc5a7b11e62ce43c420b142b81f90f5e9d316d436b64235d5ad493fb04d7af76ae8a7eac84bd371103293e146,"* The worst-case occurs when the value is the last element visited in the vector (can be first or last, depending on where you start the loop) - which is of O(n) time complexity.
	* The best-case height is: h = log2(n + 1) - 1, which occurs when the values of the vector are sorted into a perfect  binary search tree. The worst-case height is: h = n - 1, which occurs when to values of the vector are into a degenerate binary search tree which is just a form of a linked list.
	*",13.0,36
10044,10044,11795,55fe3fe2f479a6880b0c712c4e8a68696125fae47531859339e76b32fd81a881527cd93fc43bbd4116f56991339ff706e490311026cb817361fafa6e47ec0b11,"1)O(n) this occurs when the number is last item in vector or it isnt in the vector.  once you searched it you wont have to search the vector again, so it will be one search of o(n) in worst case.  but if new numbers every time it would be O(n^2).

2)best case would be when you are at shortest path and that is where opening is (if making root then it is O(1)) but i think the question was asking if root is already there and it is O(logn) and worst case would be when you have to traverse from root to end via the longest path and it would be O(n).

3)O(n^2) because you have to do n worst calculations of O(n) and nxn=n^2

4)O(nlog(n)) because best case is O(log(n)) and you doing it n times 

5)worst case=O(n^3),

best case=O(log(n))",26.0,36
10045,10045,11796,b62178f325a37f31c95fa1765add6431ffda3b6e9e137a6c1634820014c3bfc3f4c574a7130344e47d262896d038b700c7e7372470c7667fbf621506106a2a97,"1)O(n) when the number is at the end of the vector. for searching n times o(n^2) for different numbers and if searching n times for the same number than O(n).

2)best case for the height is  O(1) - when the node one is adding to, is the root. worst case: O(n) - when the node one is adding to is a leaf at the longest distance possible from the root.

3)O(n^2) this is from the fact we are doing n calculations at the worst case of O(n)

4)O(n) as we are adding n at a constant time.

5)O(logn)",13.0,36
10046,10046,11797,6e1111ad11474e6379168f87057eae3076970c620dec3cffde8e98db6de9322b94aefef0b0414a791717f61331121e1ad9f15c607c1ff40afee80bcc8c3257b0,"1. Worst case time complexity when searching for a value in a vector is O(n). This happens when what we looking for is at the end of the vector or not in the at all. The number of operations to do will be n times.

2. Best height would be h = O(log(n)), this is when the tree has nothing and what we are entering is the first value in our tree. The worst height would be h = n - 1, where we enter a value at the end of our furthest leaf in the tree.

3. The amount of work done would be n, because before we enter a node in our tree, in the worst case the node is entered at a leaf level n - 1.

4. The amount of work we will do is n;

5. n^2",11.0,36
10047,10047,11798,2ab3b11f5f1782f4246740fe903154429a2490492d0572263d7ff046cace7736e29d65d602215296304ea46aa69325f3d67b03459c0b518493888576c52ace89,"1. Worst case : O(n) , and occurs when v is at the back of the vector. We do (n-1) work, which is the MAX work done

2. Best case: O(n), occurs when the trees is not a perfect tree, i.e. there are parents with 1 child and h = n-1 .

    Worst case: O(log(n)), occurs when the tree is a perfect tree, i.e. h = log(n+1) - 1.

3. Worst case: O(n^2)

4. Best case: O(n)

5. ",13.0,36
10048,10048,11799,3d5672708313ecdecf3f1bac84303e47d2cb39b8840c7477b8533d1e068614b468fd7d22ee29e9082419dadb2d36cb98607131a6fdfff05e1696dee4c36a9722,"1. O(n) it occurs when the value we are searching is the last value of the vector or when the values is not in the vector.

2. best case is O(logn) and worst case is O(n). The best case  occurs when the bst has -1 height or when the bst node each has at least two children.The worst case occurs when the bst has a child for all nodes.

3.O(n^2) the work done in a worst case is O(n). For every value we insert ,we would have to traverse n-times until there is no value to insert.
4. O(nlogn) in a best case the work done is O(logn),so we would have to traverse n-times to insert all the values.

5. O(logn) or O(n)",21.0,36
10049,10049,11800,ec395a3ecaad23df4073c1f706e156a2dc0df6ec9ab518f824a5ee32c21f2fee951d1dfe316e50e996ee47ec57ebf1b3a335db07c23fa71520fbcc864e608a4d,"-When searching the value v it will be the worst time complexity as O(n) as we have to compare the value against all other numbers.

- The best case for height of tree is O(logn) and worst case is O(n) these occur when the worst case is when we have to transverse the tree along the longest path from root to leaf before inserting and thus the worst case is O(n) and best case we find an open space such that the value is less then currents nodes value which will result in recursion and thus time will be O(logn).

- The amount of work will be directly proportional to the height of the tree so the worst case will be n-1 and time will be O(n).

- The amount of work for best case will be adding values recursively as the value inserted is less then current nodes so it will go to the left else the right, there is an open space without having to transverse through the whole tree so work is log2(n+1)-1.

- The work done in total for best case is log2(n+1)-1 and worst case is h=n-1.",10.0,36
10050,10050,11801,20effcbf64917de69f0f441958ac819d52ad486a65f959444a5ddd14ca83a40e581709b6bb9eae431ca2dd02ce933a201bc9b7e43298585d0858d76601344ce0,"So the worst case scenario is when the element is at the back of the vector so to retrieve it, it will take linear time. So the time complexity will be O(n).

So if we add these elements to a tree the best case for height is when the nodes are packed as tightly together as possible and each node fills up all its levels to the maximum number of children and that gives a complexity of O(log2n) and this will give us the smallest height. In the worst case scenario for height is when the nodes are packed loosely from each other where the maximum children of each node are not filled to capacity and this will give us a linear complexity - O(n)

So for insertion the worst case height will yield a linear time complexity - O(n) because for example when inserting the last element it will have to traverse all the way to the end of the tree to insert making it a linear amount of work 

In the best case height the time complexity for insertion will be logarithmic - O(log2n) but it will vary depending on the structure.

So for worst case in total we would take a linear amount of work O(n)

For the best case we will take a logarithmic amount of work O(log2n)",10.0,36
10051,10051,11802,d10eb2653552348dd29e31d9127ca9b9ab3966f67dcfba3fbaef7bc1fba74c3549309defc8e00e457f7427150a3162c0ca17e3f3d6529fa8df4aa4e4195dbeec,"* The worst-case complexity of searching for a value v in the vector would be O(n) and would occur when v is not in the vector

	* Best-case height would be O(logn) and would happen when the tree is empty and worst-case would be O(n) and would be when we need to first search through the entire tree

	* O(n) because n is the number of nodes in the tree at any time
	* O(logn) because n is the number of nodes in the tree at any time
	* O(n)",6.0,36
10052,10052,11803,31f89aaef7c39dc86c93cfdeddea5fc5554c3cbe3838d2616d1fbc1745414f7096809e9261e2fb009c92beaaac49eaef9633b3b3c92cef0606b8cfb14522414d,"* Worst-case: O(n). This occurs when the value searched for is at the last index of the vector. We would do a linear amount of work.
	* Best-case: O(logn). This will occur when insert until each level is perfect (has 2^k nodes), before moving to the next level. Worst-case: O(n). This will occur when all the nodes in the tree only have one child.
	* It would be a quadratic amount of work (O(n^2)). Each insertion will take a linear amount of work, and we would do this n times. n*n = n^2, therefore it will be quadratic O(n^2).
	* It would be a Linearithmic O(nlog(n)) amount of work. Each insertion will take a logarithmic amount of work and we will do this n times. n*logn = nlogn, thus it will be Linearithmic O(nlog(n)).
	* n* (The amount of work it takes to construct the tree)^2.",29.0,36
10053,10053,11804,2edf0656134d19474a53dbbe5225dc2a3f4aaa1130b603fed547f4fc2584f94df9c6d11c108fecf09067c54daf57f86fbd618dbf612a4c65bf741c812ed66b6a,"The worst-case time complexity of searching for a value v in a vector is O(1), constant time. This is because memory in vectors is stored contiguously and the operator[ ] function or the at() function use pointer arithmetic. We still do O(1) amount of work if we search n times.

The best case height, when adding numbers to a BST,  would be h=log(n+1)−1 (logarithmic),this happens when a tree has a triangular shape, but even more idealy, the best case is when the tree has a hole. The worst case height would be h=n-1, this happens when the tree is shaped like one long line (like degenerate tree).

In the worst case, O(n), amount of work must be done because we are then traversing the height of the tree.

The best case, after inserting a number is, O(logn) amount of work. This happens when the number is bigger or smaller than the vertex and is insterted to the right or the left, respectively. 

In total, O(h) or O(n) amount of work is done . ",11.0,36
10054,10054,11805,3e664d9b290450a26a44195a29971d5e7c7434afb68523c4038cc69f5c1285f4c94e2b62945fc7bf5800f3a5190a2876a925f82823b3806d9c640fa0e0d73571,"* worst case is when v is the last item in the vector and we have traverse n times and do n comparisons in order to reach v we end up doing O(n) linear amount of work.
	* The best case is when the number we insert is in the root requring only O(1) amount of work and the worst case is when we traverse through the tree in wich case two scenarios happen in terms of tree height with best and worse case, the best case in terms of height is when the structure of the tree is not linear this happens when there is number of nodes is greater than 1 at some levels. this structure will allow us to do O(log(n)) amount of work as we traverse h times proportional to the height of the tree, a worst case is when the tree structure is linear and we en up doing O(n) amount of work

	* in worse case height insertion we would do O(log(n)) amount of work as we traverse proportional to the height of the tree h, and since h is not linear the relationship of h=log[2](n+1) we end up with a logarithmic function
	* in best case height the length of the tree is a linear function as each node has only one child we traverse h times and do O(n) amount of work
	* the total time is a sum of both functions O9log(n)) + O(n)",10.0,36
10055,10055,11806,f8ab0f6e15e6bf9e99acd11cfb6b5455d3c0019e87064465e59d88ccaf25c640a5ce1b900a6011a9e3fa052e11195ca6da9faf3eac510a5a07330facf6daee23,"> The worst case occurs when the value we are searching is not in the vector or is at the last position, the we have to do n traversals(n being the number of elements in the vector)- O(n).

> with binary search trees insertion, the worst case is when we have to traverse the tree along the longest path from the root to a leaf before inserting. The amount of work depends on the structure of the tree, in the best case O(logn), in the worst O(n). The best insertion case happens when we are inserting the first value of the tree(the root), in this case we perform O(1) amount of work.

> we would perform O(n) amount of work n times, resulting in O(n^2) amount of work altogether.

> we would perform O(logn) amount of work n times, resulting in a total of O(nlogn) amount of work.",21.0,36
10056,10056,11807,5f1f239814321ab1f431320367ad013e94b2f66dc9f45345746644a7c6190c150b15690868f1b18e7468353f42b32ce7d5d9e6673f3e33a12996a386f5985adf,"O(n), it occurs when we have to check every item i.e n comparisons. O(n^2).

Best case will be O(1), which is when the tree is empty. Worst case is when we have traverse the height of the tree to insert ,O(n).

O(n), since we are traversing the height of the tree for n insertions and each insertion takes O(n).

O(logn), in the best case the height of the tree is log(n+1)-1, therefore in the best case we take O(logn) per insert.

in best case, it would take O(logn) to construct the tree, and to search for a number takes O(logn) since we do this n times it takes O(nlogn). and therefore in total it would take O(nlogn + logn) time.

in the worst case it would take O(n) to construct the tree, then O(logn) to search for a number => O(nlogn) to search n times. and therefore it would take O(n +nlogn) time.",10.0,36
10057,10057,11808,5602a599f37ceb4d3d0abbebb674a8cfae2a81d9f53137cfbc7a1bded150cbaa8a83e4431db27b0e21c60021690e3731e8677add172b47aa9e637944b71f019d,"The worst case for searching for v occurs when the value v is at the back of the vector. We will have to do O(n) amount of work. When we search n times we do linear amount of work.

The best case height in Big-O is O(logn), this only occurs when the tree is perfect. The Worst case height of the tree is O(n), this happens when the tree is similar to a linked list thus having a downward linear form. In Both cases, n is the number of nodes. 

In worst case we'd do linear amount of work since the tree would be having n-1 nodes to be transversed  . We'd have to transverse all the nodes thus in Big-O we would do O(n) amount of work 

In best case we would do logarithimic amount of work as the tree would be having height log2(n+1), thus in Big-O we'd do O(logn) amount of work.

O(n) and O(logn) amount of work",15.0,36
10058,10058,11809,1c067bf4dc46efea1d97764ec9e8512203198a06760dfe663905444adb3c11970401fd40f402aab42c0c01db7d7d76641060c3df878232bbed315bb7d13f0aab,"worst case O(n)

insert worst case O(n)

insert best case O(log n)",1.0,36
10059,10059,11810,8c4ece10bea4707d74ad8e485b192cf388c1aaad3dd5b625cadaaa6a947d3861bc0547f235d6ff3af091e10ce08cd771b73e98b692a991cef32a92e7b557b387,"The worst case complexity of searching for a value in  a vector is O(n). It occurs when the number we are looking for is not in the vector. The work we do is O(n).

The best case height of the tree is O(logan). It occurs when the Binary Tree is a Perfect Binary Search Tree. The worst case height is O(n). This worst case occurs when the Binary Tree is a Degenerate Binary Search tree.

If we have the worst case height, the work we would do is O(N). This is so because the shape of the Binary Search tree is like that of a linked list. The work done is O(h) but since (H = N-1), the complexity becomes O(N-1) which is just the same as O(N).

If we have the best case height, the work we would do is O(LOGAN). This is so because in the best case, the Binary Tree has to be a Perfect Binary Search Tree. The work done is still O(h) but for Perfect BST H= LOGA(N+1) - 1 which is therefore 0(LOGAN) complexity wise.

For the worst case the total case is 2(O(N)). For the best case the total work is 2(O(LOGAN)",21.0,36
10060,10060,11811,21f09107df149216c5f40e2d6eaefa443c1ac6ce9ddec594661383f2e53455e2769bfb1bb81bee158e80bc0b01db2da739108bc4386c15bb286ac35afa1a5409,"Part 1: The worst-case complexity is O(n) which occurs when the item that we are searching for is at the end of the vector i.e. it is the last element. If we search n times then we do O(n) work n times, which is a quadratic amount of time i.e. O(n^2).

Part 2: In the worst-case the height of the tree is O(n) which occurs when the nodes of the tree are not arranged in the most effective way (not the maximum number of nodes possible per level of the tree) i.e. skewed or degenerative. In the best-case, the height of the tree is O(logn), which occurs when there is a hole in the more tree effectively arranged tree (e.g. like a hole in a complete tree).

Part 3: In the worst-case the height is O(n). After n insertions, the amount of work done is O(n^2) since the height in the worst case is n-1 and we do n insertions then n(n-1) gives a quadratic function.

Part 4: In the best-case the height is O(logn). After n insertions, the amount of work done is O(nlogn) since the height in the best case is log(n+1)-1 and we do n insertions then nlog(n+1)-n gives a linearithmic function.

Part 5: In the case where the height is n-1 (worst) then we do O(n^2) amount of work and in the case where height is log(n+1)-1 then we do O(nlogn) amount of work.",36.0,36
10061,10061,11812,9dfb1f3f8489eba0c312316ab375b0eb3fde4cc7c592108ea20fe9063368bfeafc3cfc95ddf50eff3397d93bb8f4939d82490505e330285e8ec3eab94f0e646a,"1. O(n) is the worst-case complexity of searching for a value v in the vector. It occurs when the value v is at the back of the vector.

2. Best case height will be O(logn). It occurs when the tree is a perfect.

    The worst-case height will be O(n). It happens when the tree is deranged or like a linked list.

3. O(n) because the worst-case occurs when the tree is degenerate.

4. O(logn) is the best case because the tree is perfect

5. O(n) and O(logn)",15.0,36
10062,10062,11813,43337822a8495f6346099bee6f1b1379846d1e116a80358eff95ac9a35a5e9db993d15f49931c7a4d1543bc7328dae0e418202f217ef071778281db16cfc2fe9,"The worst-case complexity to search is O(n) and this occurs when the value 'v' is not in the tree and one has to traverse through the longest path in the tree. The amount of work we do if we search n times is the height of the tree 'h' so the work done is 'n'.

In a empty BST and call the insert function. The best-case height of the O(1) and this occurs when there is no root node and it is the first number to be inserted. The worst-case height of the tree is O(n) and this occurs when the number to be inserted is at the end of the longest path of the tree.

The worst-case height after each insertion is O(n) work and I came to this conclusion as the height of the tree is n-1. It does work equal to the height. Due to the minus one being a constant and is irrelevant in O(n-1) so this resulted in O(n) work.

The best-case height after each insertion is O(logn) work. I came to this conclusion due to the height equal to log(2)(n+1) -1. This process does work equal to height. Due to constants being irreverent in big O notion so the '2', '+1' and '-1' being constants thus resulting in O(logn) work.

In the best-case the total work would be O(logn). The worst-case the total work is O(n^2).  ",14.0,36
10063,10063,11814,0814448191d29da9008582aa1dc261271817cf4f70631f519f01177439d50267cb21e8d39c1f121e1aee03914798dbfab1836210758982742e26c801f01d7bc4,"worst case is o(n) this occurs if we looking for a number thats not in the tree or the child of the deepest node

2)best case is when h=0

worst case:o(h)-linear work

3)linear work.by inserting a node as a child of the deepest node or inserting the same node as the current deepest node

4)best case is when h=0

5)linear work o(n)",5.0,36
10064,10064,11815,d0487881fde4213facde4c9cd0143d5802f701e002f130b7eaa6dd04f68f58612ae33c39c89beceae1495437bbe2376be3003369a31f0f2bc6f9e0c5a369707a,"O(n) , this is when the number being searched for is at the end of the list or is not in the list. If search is done n times we will do O(n^2) work.

It will be O(log(n)) when the resulting tree is a perfect tree, because more nodes are packed into a smaller height tree. And it will be O(n) when each vertex has only one child because the height will essentially be equal to the number of nodes -1.

O(n^2), I came to the conclusion by using sums from the work that would need to be done at each insertion (0 + 1 + 2 + 3 ... n) then summing that with the reverse (n + n -1 + n - 2 .... 0) and dividing by 2 to get (n^2)/2 which simplified to O(n^2)

O(nlogn), It takes logn time to insert each node so doing that n times produces nlogn

O(nlogn) in the best case and O(n^2) in the worst case",36.0,36
10065,10065,11816,385c7b29eec3366a404f1d7e1159d0447aefec67a3c8b61a32481883579eeb6ab7ee9fa654afbb7d3b9a4b7a30f0a2b32be3cbd9d9a3dfbfe943be567e01c394,Worst case-log(n+1)-1;,0.0,36
10066,10066,11817,8a8eb86cf56dd2444d2bc5441387c73e3fcbac4867da844d41e7ee67a78c9e8b163da9822047fef10101762a7abd4eba2ff040d29869420924f78a2c686ad858,"worst-case complexity for searching a value v in a vector is O(n), linear amount of work as you have to look up every single value.

insert function

i) best-case - O(1) as we insert to the root

ii) worst-case - O(logn) or O(n) 

assuming worst case the amount of work would be propertional to the height of the tree. ",3.0,36
10067,10067,11818,2aebde6b5faaed73a67c0847887873c4b7d8d2f0c1ec3c5d1ae00fb183c3e53559681b2ee97a4692d74712db8b222e3239fa5e199b01863e771a9daa54a4abee,"1.The worst case is when the number is not in the tree and we have to follow the path that corresponds longest path with the value of the current node.

2.The best case occurs when there is a free space in the tree and i just create the node and  call the insert function and insert the value into the space.

The worst case when a traversal from the root to the leaf of the tree through the longest path occurs and after that i i use an insert function to insert the value.

3.We would have to traverse from the root through the longest path to the leaf and make an insertion. And the traversal equals the height of the tree.

4.Whenever a free space is found i just insert a new value which requires less amount of work.

5.A logarithmic amount of work will be done in the best case and (n-1) work will be done in the worst case depending on the height of the tree.",0.0,36
10068,10068,11819,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,"O(n) this will happen if v is the last element in the vector

The best case the height will be log(n+1)-1 in best case and n-1 in the worst case. the vest case is when v is the root and the worst case will occur when v is the last node of the tree and we have to travers the whole tree

O(LOG(N)) WORK 

WE DO O(N) WORK

we do O(n)2                                                                                                                        ",10.0,36
10069,10069,11820,999b8af04a99b1971783a730d1a109e30fdff2f88a1f40dc36731dceaa01148aef1c1f5d96b5999593020819ebc46f676235aa6d5dc12859b91750c9e8b5c9c4,"Given a vector when searching for a value v in the worst case the number is at the back of the vector then time complexity is O(n).if I search n times then the amount of work is  n*n which is n^2

for the hight of BST the best case occur if the value I'm inserting are not sorted,this occur if consecutive value are between root value this  also applies for internal nodes.the height becames O(logn).

for worst case the list is sorted so it may became a degenerated tree,where all node are in alignment only in the left or right.in this case the hight will be O(n-1) which is O(n).

when inserting in a situation of a worst case height the amount of work will depend of the current height of the tree by summing all the height as the tree grows the total work is 0 +1 +2 + 3+ . . . + n-2 + n-1",15.0,36
10070,10070,11821,092586b17aeb228a8396915c438a564c216c3df48ac6ded66b121dcea5684d3dbe0caab83fcadb656d3a0a26a4c4e1546317909dd36270918915c4447ba4370c,"* O(n)      
	* worst-O(n),when you try to insert largest number in a trees which is complete ; best-O(log2n)
	* O(n)-it would be n work +n work .......until the last node                                    ",6.0,36
10071,10071,11822,c76ad062cb3f9ba2556bec1587c1d89b089f2df63d9bed184a50eead5884d030c988356231ec2465bf2dfe9d6ac011b44586a721987fbdacc7384e0d7bc1bf14,"The worst case complexity of searching for a value v in a vector is O(n) and this occurs when the value is the last value in the vector. if we search n times we do O(n^n) work.

The best case height of the tree is O(log n) and this happens when the tree is a complete binary search tree. The worst case is O(n) when the tree is a linear chain.

O(n) work because we would have to pass through all the values.

O(log n) because the binary search tree would be complete.

In the best case scenario, O(log n). In the worst case scenario, O(n).",14.0,36
10072,10072,11823,48452c6af5685c82851988d96add3ed11ed530ba837e28f21c3e92d7b83a44fbe9879abbcb6e1ae0256b1dc9b2ef98a34c294dacae561958335cfe0e83b08e8d,"The worst-case time complexity of searching in BST is O(n) and this is the case when the BST is either left-skewed or rightly-skewed. We do n work if search n times.

The best-case height is: O(log n) and this occurs when we have a balanced Binary Tree.

The worst case height of the tree is O(2log_ n), that is the case with the tallest tree._

_We will have to do O(n) amount of work in the worst-case height, because we have to traverse all elements._

_We will have to do O(log n) amount of work in the best-case._

We will do O(n) amount of work in total.

_
_",10.0,36
10073,10073,11824,07076ad9a7e3813bce19a739ebedaab894d1a330269763e0925227d8822b601591c19afe0ea5ecf81637c9b73f442db6cacafab2329d262fef0fb68d97bef78a,"1 O(n) = n when v is the last element in vector and it would be linear work.
2 worst case is when the tree is degenerate and will have O(h) = n- 1 best case wen we have a complete tree O(h) = log base 2(n - 1) - 1

3 worst case after insertion will O(n) = 2^(h + 1) -1 we will have a degenerate tree.

4 O(n) = O(log base2(n)) when we have the perfect tree

5 ",14.0,36
10074,10074,11825,7fa0256939f3801d7cb837f49e23433b9e2c72a7153a75d58ee05f6ce597913275599303f990f67fdc180f91407271656e81578b90488fda76d6e550e9bb3533,"1. Worst case complexity of searching for a value v in the vector is O(n). This occurs when the BST is degenerate. In other words its in a straight line. If we search n times the time complexity will be quadratic or O(n^2).

2. The best case height of the a BST is log(n+1)-1 and in the worst case the height is n-1. So in Big-O it would be O(logn) for best case and O(n) for worst case.

The worst case happens when we insert and the tree ends up being degenerate. In other words each node has only one child excluding the leaf node (since the leaf node will have no children). This means we do a linear amount of work when we want to insert a new value into the BST.

For the best case, the BST is complete/perfect, so inserting is logarithmic.

3. O(n) since we have to visit each node once before we are able to insert.

4. O(logn) since we know that the BST is pefect/complete. The amount of work it will take is log(n)

5. Worst case: Insertions will take linear time, n searches will take linear time. In total: quadratic

Best case: Insertions will take nlogn time, n searches will take linear time. In total: nlogn time.",15.0,36
10075,10075,11826,2a0df219aac143a2ab259ed39069368d09faa1d674232d6d8a5a0299284966b0b712226c702276000af1418c0c7120be9e30f8742712afc25a87bebd377d57d9,"The worst case complexity for a value v in a vector using a big-O is O(1), this is constant runtime, regardless of where the value is in the vector, the runtime will be the exact same. The work done is log(n).

worst-case O(n), this is because every node in the tree will end up being visited when using Big-O notation.

best-case O(log n)

O(n)this is because every node in the tree will end up being visited when using Big-O notation.

O(log n)

log(n)",4.0,36
10076,10076,11827,2e609516b3c283ff23ddaea06d0df01ad6175f48861d0223a4409ebe1c7df8e383fe146f147415f2605c7a0103b96921b1ffd763ab4924efe18fd229dedbae68,"* The worst case complexity of searching for a value in the vector would be O(n) and would occur when the value v is the last item to be searched in the vector. If we had to repeat the search n times when the value that we are looking for is the last value, the searching complexity would be quadratic.
	* The best case height of the tree would be the floored square root of values entered (TRAVERSAL COMPLEXITY IS O(LOG N)), and occurs when the values are inserted in an order which creates a binary tree where the height difference between any two branches is at most one. The worst case height of the tree would be the number of values entered minus one (n-1) (TRAVERSAL COMPLEXITY IS O(N)), and would occur when values are inserted in such a way to create a degenerate binary tree.
	* When you have the worst case height after an insertion you'd have a degenerate tree and thus would require traversing every node once to get to the bottom level for the next insertion, therefore the complexity (in big O notation) would be O(n) to insert.
	* The best case height after each insertion would be inserting into a complete binary tree and sometimes a perfect binary tree where the tree's height is the best case height, and thus you'd only need to do log n traversals to insert a value into the tree, and is thus complexity of O(log n)
	* Constructing the tree: in each case would require a traversal for inserting into the tree and also a traversal for each instance of searching the tree.
Therefore constructing the tree and searching the tree in the best case would require N^LOG TIME.
And in the worst case scenario would require QUADRATIC TIME to search n times with linear time each.",17.0,36
10077,10077,11828,fd6a36ea3be7fe00a0626c8ff80a591e0ee46b9eb9f16c4ccfb925e8237975ae584522b908d7f487d3fa4016ee5035673c870e0b6b78ebf935c75fa0905d0961,"worst case O(n), This occurs when the value we are searching is at the end or not in the vector. we do this O(2n)

best case is O(logn) when we traverse h nodes before we can perform insert , the amount of work done is proportional to the height of the tree

worst case is O(n) when our algorithm needs to traverse the tree along the longest path from the root to a leaf before inserting 

worst case height is n-1 which takes O(n) when we traverse along the longest path from root to a leaf before inserting

best case height is log(n+1)-1 which takes O(logn) when we traverse h nodes before we can perform the insert, the amount of work done is proportional to the height of the tree

O(logn)",8.0,36
10078,10078,11829,29fcf57bccb37a2f0d949733d7028b65c0e2df19a9ddbd0c547e57467d84c825defbaf635dea276a63c3d3e85a6fb4f7a84d6da08661ca46728f222c62700315,"1. The worst-case complexity is O(n). This occurs when we are looking for a value that isn't in the vector. We do a linear amount of work if we search n times.

2. The best-case height of a tree is O(logn). This occurs when the tree is perfect. The worst-case height of a tree is O(n). The occurs when the it starts from the root all the way down to the furthest leaf like a degenerate tree, the most work is done by traversing through the entire height of the tree.

3. In a worst-case height we do O(n) as you traverse through the entire height of the tree(longest path).

4. In a best-case height we do O(logn) and this is when the nodes are tightly packed together and can be accessed easily.

5. In total, the work we do is for the worst-case, O(n), and best-case O(logn).",14.0,36
10079,10079,11830,fecc59057a0e209589be1452a92558843a93237db9707d9614670e76673fb2cec05cbca3488156012b8fb3cd1467b373d250bc116d0aec57eaa9cbe2d676c3fe,"the worst case of searching a vector for a number is O(n) when the value we searching for is not in the tree. 

the best case is when the tree is empty and we insert at the root and height is zero so we do O(1) work. 

otherwise the height will be somewhere between O(log(n+1) -1) <= h <= n-1

The worst case height is n-1, therefor big O work would be O(n) since w ignore the contant

The best case after inserting all numbers would be O(logn) since we ignore the constants again

The total amount of work to construct the tree and search for every number would be of the order O(2^n). ",11.0,36
10080,10080,11831,7099f15d1fb337686bf427fedb824d4eefc2c359e7374f808226d1191d0f74342e42146c05dfa9cdc17fbdc8dce0a4cb75b417e6eb24978dd57c4773dec73b21,"O(n) is the complexity when we search for a value v in a vector in the worst case and it occurs when the value we are looking for in at the end of the vector. We do n amount of work for searching n times.

The best case complexity for the height is O(logn) and it happens when the binary search tree is a complete tree and the height is equal to log(n+1)-1.

The worst case complexity for the height is O(n) and it happens when the BST nodes all only have one child and the height is equal to n-1.

O(n) as in the worst case you would have to insert the number at the last depth node which would be the height of the tree which is n-1 work

O(logn) as the best case you would only have to insert the number in the lase level and since it is a complete tree it is only going to take log(n+1)-1 work

In both cases it would be a linear amount of work",14.0,36
10081,10081,11832,a69e74ae8b4a039273c9779403a7bf9afeff6c0402c7c4b81445db3dcb6b7c6d2a0c70d795b1a5404bd22d002454afb4812336b41db02ff960eaf7c2625641fa,"O(n^2). this happens when there are no duplicates-unique values-in the vector.  The output will grow by 1 every time through the loop.

worst- O(h) this happens when we are travelling from the root to the deepest leaf.

best- O(n) this happens when we are NOT travelling from the root to the deepest leaf.

O(n)-The binary search tree is a skewed binary search tree. Height of the binary search tree becomes n. So, Time complexity of BST Operations = O(n).

The binary search tree is a balanced binary search tree. Height of the binary search tree becomes log(n). So, Time complexity of BST Operations = O(logn).

O(n) and O(logn)

 ",10.0,36
10082,10082,11833,a871558daae8ec7755dd112b899b7fd46e06cb2a4cebf4c0a75ca226dba4bf419ef0333177fa6862ca71f931535c6fb1250ed993a029aa9b63a8c18ad277bce2,"1.The worst-case complexity is O(n).it takes linear time of work.

2.The best case  height is O(Log n) and worst case height is O(h) where h is n-1 which it become O(n).This cases occurs when the binary tree has a long path way in the process of BST.

3.The process took a long path or long time .The worst case run time ids dependent on the height of the tree.

4.After insertion or deletion the the height in the best case is O(log n)and this means the process was faster and better and it didnt take much time to complete the process of the BST.",6.0,36
10083,10083,11834,0ffad2820b9adf1fbb6d7105f83a5954e33ce5d91444ff2b6251d15d1a8c5a988e64634ca1a4f0e01e237f0fdb8290b82c533e1fa1a822b32c02e6052c618e98,"1) The worst case for searching for v in the vector could occur when v is not in the vector or if it is the last item in the vector. O(n) Complexity would be linear in this case. If we search n times, we do n^2 work.

2) If we create an empty BST and progressively add each number to the tree by calling the insert function, the best case height of the tree would be log2(n+1)-1 and this occurs when the tree is a complete tree. The worst case height of the tree would be O(n) and this would occur when we need to traverse to the longest path of the tree to until we can insert.

3) If we have the worst case height after each insertion, we would do O(n^2) work after inserting all n numbers since each insertion would do O(n) work and we are repeating it n times.

4) If we have the best case height after each insertion, we would do O(nlogn) work after inserting all n numbers since each insertion would do O(logn) work and we are repeating n times.

5) In the worst case we would do O(n) or O(nlogn) work to construct and search the tree n times. In the best case we would do O(n) work to construct and search the tree n times.",28.0,36
10084,10084,11835,9f85bd574a0fb5fa07c95cbd2dc5aa7f4cb77f83ea58b24cf50b8a111ddaa2e08d644409b7ea28dad73defdb2393c136cc039b51ec3ed144b40271a76c7c7470,"1. The worst case would be O(n) since it will be a linear search. It will make at most n comparisons, where n is the length of the vector list/elements.

2.Worst case height would be O(n-1) and this will occur when we do a linear amount of work to insert, which also depends on the structure of a tree.

Best case height would be O(logn) and this occurs when the tree is structured well ,it happens when we have an empty space where we can easily insert.

3. Linear amount of work which is equal to n.

4.we would have a constant .

5.",11.0,36
10085,10085,11836,bec70f18652f9b1ec67ee94e23471083fc0530aad868499d925d500e71ccfd4f82652eb49a909778379c4583e97ce1464a3ae78de3b07114cb3a9e4c1179d625,"The worst-case complexity of searching for a value _v _in a vector is _n_ comparisons. O(n) will be done.

In the BST, in the worst case, the path followed is the longest path from the root node to a leaf. If this happens, we traverse the tree _n_ times before a number can be inserted. Meaning that the height will be _n-1_ or O(n). In the best case, the the number being inserted will be inserted in the root node of the tree. This means that the height will be _log(n+1)-1 _or O(logn). 

If we have the worst case height after each insertion, the amount of work done is equal to the number of numbers inserted into the tree/ the height of the tree. This means that the amount of work that will be done when inserting all _n_ numbers would be O(n).

If we have the best case height after each insertion, the least amount of work possible will be done. This means that the amount of work that will be done when inserting all _n_ numbers would be O(logn).

The total amount of work that would be done in constructing the tree and searching for different numbers n times would be O(n)+(n-1)+log(n+1)-1+O(n)+O(logn).",8.0,36
10086,10086,11837,f4baa24ad720b1250dc8a9d5d7170a55ee764630dc2c7f87292182bdad71ecf2851e6fec34c6913b3b5952d370fbd9d0459efe69a1541c4221908a8f498f268c,"The complexity of searching for v is O(n) linear complexity in the worst case. We do O(n2) work to do n searches.

The best case height for the BST is O(logn) and the worst case is O(n). The worst case height occurs when every value is to the right of the previous value (or alternatively every value is to the left of the previous value). The best case height would occur with a perfect tree or a tree that is perfect up to level h-1, with level h being the final level only containing leaves.

We do O(n) work in the worse case. This is based on the fact that we'd have to traverse the height of the tree each time we would want to search with the height increasing by 1 each time we search. We would do O(h)= O(n-1) = O(n) work, where h = n-1 is the worse case height.

We do O(logn) work in the best case. Given the best case height of h =  log2(n+1)−1, it would take O(h) = O(log2(n+1)−1) = O(logn) work to do.

To construct and search, in the best case we do O(nlogn) linearithmic work. In the worse case we do O(n2) quadratic work.",17.0,36
10087,10087,11838,22ce118158e8ed0c1187b952e36a1938ab0c22e942e01d9258ed224302f7ecf3665fc06c4060e629850d16f04e008f7cd12363e7f782d4370a1dd3b7af113bbe,"The worst-case complexity of searching for a value v in the vector is O(n) because you would just have to compare each item in the vector to v. This would happen when v is the last item in the vector or is at the end of the vector.

If we create an empty BST and progressively add each number to the tree by calling the insert function, we'd have the worst-case if when adding something we have to traverse the whole height of the tree. So the worst-case complexity would be O(n+1) in terms of nodes. In terms of height, it would be O(h) because height = n+1. Either way it's O(n) or linear. The best-case would be complexity O(log(n)) or logarithmic which is when we don't have to traverse the whole height of the tree. But technically if we had a hole in our tree where we could easily insert a value, that would be the best case, so it also depends on the structure of the tree. 

Assuming that we have the worst case height after each insertion, we'd likely end up doing quadratic work or O(n^2) because we'd do linear traversals (such as n) n times, and n*n is n^2. 

Assuming that we have the best case height (O(log(n))) after each insertion, we'd do logarithmic work n times and have a linearithmic amount of work, so O(n(log(n)).

Overall, we'd do a linearithmic amount of work O(n(log(n)) to construct the tree and look for numbers n times.",25.0,36
10088,10088,11839,92a2ed8f4716bed3b0e0c50f4d71ca4d4c6f96e622febc9b471f947d10b8500c23531ab4582c0648a7ceef71efcbb7100102c2a6bd33328ed40abb07652829ad,"The worst-case complexity is O(n) and it occurs when the number is last in the vector. We do a O(n) amount of work.

The best-case height of the tree is O(logn) and it occurs when the BST is a perfect BST. The worst-case height of the tree is O(n) and it occurs when the BST is not perfect and the height is n - 1(n represents the nodes of the BST).

It will be O(n) amount of work since we traverse h(height of the tree) nodes and the height of the tree is n - 1.

It will be O(logn) amount of work since we traverse h(height of the tree) nodes and the height of the tree is log2(n+1) - 1.

For the worst-case, it will be O(n) amount of work. For the best-case it will be O(logn) amount of work. If the number being searched is stored in the root, the amount of work will be O(1).",14.0,36
10089,10089,11840,8052ea5813981ce1b1dc18dcce8d4c10c33b769890ea3f35ecc1dc5a6465b4897efddc1a12c6d7a26b5d0da8ca3c779589f99331e5d2c411636cea22d157833a,The worst case is to search value v that is in the longest path or height weather left or right and this occurs when we transverse in all values in a tree and the time complexity is n(O). when calling the insert function the best case which is the linear amount of work occurs when the node is exactly on the left or right of the root node and in the worst case its when we backtrack in all of the inserted nodes. when inserting nodes in the worst case our code must backtrack in all nodes and the amount of work we need to do is o(n) of which in the best case we do linear amount of work this because we have to search each and every node before we find the place where it suits according to the rule of binary search tree.so in the best case we do the linear amount of work o(1).it the best is linear amount and in the worst case is o(n) amount of work,1.0,36
10090,10090,11841,307d8af1793926f21e6b4215d5b4182c112c0d4698d4832d0185b0d9535a011c7a888a921d240645fc84a5799fdd55910fe15a0615bdfb1a6fdb121e9cfcac36,"-The worst case is O(n), this happens when we are searching for a value which is not in the tree.
-The worst case is O(n),we have to go through the whole tree  .The best case is O(1), this happens when the value we are searching for is just below the root.
-O(n), we have to traverse to the deepest leaf.
-O(log(n))",1.0,36
10091,10091,11842,27b7c01b5507de27227f1b4c06fa92833846a84fa96c3732f3663fb00fd83e6f0c7c3e711cd797752bf30bb3a828ffa9c255dc629b8adb95ea32e0eed6535409,"In the worst case O(n) transversals will be made, depending on the structure of the tree. This occurs when the number is not in the tree and the followed path corresponds to the height of the tree.

In the best case the height is log2(n+1)-1, in the worst case the height is n-1 and occurs when we need to traverse our tree along the longest part from root to a leaf before inserting. 

The work we do will be O(n) since it takes at least O(n) comparisons.

In the worst case we will do O(1) amount of work.

In both cases we will do O(log n) amount of work.",4.0,36
10092,10092,11843,76547c457fac096aa24860742165ce32f0a7082f7aeb253f2ff91571275838954033b1627523b79a6ff278d5ebec75d54fbefdc04c377a9da2d71a00fe00d461,"Worst case: work = O(n)
Worst case: height = O(n). this occurs when each node has exactly one child.

Best case: height = O(log n). this occurs when each node has two children.",12.0,36
10093,10093,11844,5221e1f3d933576f202c0725eb1b1536ee1b49681a3fc7d8f1a5f7ce021be47e8c2ad1016a78e47c8f005a4abc05514dc591b463cb92d3c640fd02125cf688e6,"ANSWERS

_QUESTION 1_

The worst-case is O(n) [linear time] and this is when the value ν is not found, since it is not an element of the vector.

Now, if we search _N_ times, the amount of work becomes O(n2 ) [i.e. quadratic time].

_QUESTION 2_

Insert: Best case for height: h = log2(n+1) -1 thus O(logn) when the tree is balanced and nothing needs to be changed.

Worst case for height: h = n - 1 thus O(n) and this occurs when every value inserted is either greater than the previous, or the opposite case (i.e. every subsequent value is lesser than or equal to the previous value up to the root), resulting in a straight line, which resembles a linked list.

_QUESTION 3_

We would need to do O(n^2)work sinceevery value inserted is either greater than the previous, or the opposite case (i.e. every subsequent value is lesser than or equal to the previous value up to the root), resulting in a straight line, which resembles a linked list. We insert n values in total.

_QUESTION 4_

We would need to do O(n) work since we insert n values in total, and in the most optimal positions, thus making it a proper/full tree.

_QUESTION 5_

Searching
Best case: O(logn)

Worst case: O(n)",25.0,36
10094,10094,11845,d25db0824a9dd89b8306dc484932409aa0ac87f6e9cd46591627f8005d6820292ad0928aa72897c2e9719ede0b047240f3ae45e7cf394e50ddacecd0d21dbbfd,"O(n). It occurs when we want to find out if an item is present or not in a vector. we do a linear amount of work if we search n times.

Best-case of insertion is O(logn) and it occurs when height of the tree is log2(n+1)-1. Worst case of insertion is O(n) and it occurs when the height of the tree is n-1. The best case occurs when our algorithm needs to transverse through the shortest path. While worst case occurs when our algorithm needs to transverse through the longest path.

We would do O(logn) work. 

Best Case: Logarithmic amount of work 

Worst Case: Linear Amount of work",11.0,36
10095,10095,11846,d91427bf4ad99661f4ac49ddce8054ec473a7fcef1ab133d8d24c3ab9e806480afe6773c225af63871bd9b36c6d59fe3d802d967ab7b71f90b46e5238ce08052,"worse case for searching for a value in a vector is O(N),this occur when the value we searching for is not in the vector or it is a last index,so we need to traverse all /go all over the vector in order to see that,work is O(N);

The best case when inserting in the tree uses O(logN) this occurs when u can make a full binary tree ,where u insert by comparing  and insert i the correct node.Worse case when inserting in the tree uses O(N);this occurs when the values you inserting are always greater or less than the root ,which then will make a linked list chain,and to insert , u must go through all the node,untill the end.

Worse case when inserting in the tree uses O(N);this occurs when the values you inserting are always greater or less than the root ,which then will make a linked list chain,and to insert , u must go through all the node,untill the end.

The best case when inserting in the tree uses O(logN) this occurs when u can make a full binary tree ,where u insert by comparing  and insert i the correct node.

O(logN)",14.0,36
10096,10096,11847,3ea55861b5c8eafb81b8565f1d54cc453a6c146015319e65651c96131a93fe003ed97c4b0e5ead0032066879ea3f910a9115040fa5bb190fe1c4bece13c4f763,"The worst-case complexity for searching for v is O(n). It occurs when the value v is not in the tree, or it is the very last value found when searching. We do 2^n work when searching. 

If we have the best case height, the work will be done in logarithmic height.",5.0,36
10097,10097,11848,ee9a54c657ad0d8bba4bde06638e509cdb2a338e06761f819025e545929c0973eae422171c63064d2ec75c6fa5edd42d44dd67fd5b59e36f33fd89e07c72a43f,"* worst-case complexity of searching for a value v in the vector is O(n)

	* The  best case O(1) ,when there is number ordering of numbers and the worst case is O(n),when there is number ordering
	* The worst case height O(n) because we have to compare each number first
	* The best case height is O(1)",6.0,36
10098,10098,11849,8b711f86a0e0fd2c39d5f02ba2888612f603b1e29ac872778bb22eb91072c41a1a4c3f396ac1783e4ea49d806b40a998dee128cf46fea841c4d6fa80f6f2360e,"The worst-case case complexity occurs when we loop through the whole vector & the value we are looking for is not there. Time complexity would be O(n).

Worst-case for insertion occurs when we have to traverse through the whole length O(n) of the tree and insert. Best-case occurs when we have a place where we can insert the value and is reached without traversing the whole length of the tree. Time complexity of best-case would be  O(log(n)).

The work we would do when inserting all n numbers would be O(n) because we have traverse through all the numbers that are already there in order to insert since we have the worst-case height.

The work we would do when inserting all n numbers would be O(log(n)) because we do not have to traverse through the whole tree since we have the best-case height.

In the to cases, the amount of work we do is linearithmic. 

 ",11.0,36
10099,10099,11850,86eb6a509a4b81bb5d0775617d6b551b5529a8196aa8cfd54e1d4c97046fcb8692ee1866ca18888be1695e57bab3f84e888b219e99049227e002908717268d42,"Is a vector is a linear data structure its worst case of searching  a value  v is O(n).This is because by incrementing the index constantly move towards the end of the structures until  we find our value v .This becomes a linear complexity .The work performed is n times on a worst case provided our v is at the end of the vector.

When inserting in a binary search tree the best complexity is O(log (n)) but on the worst case it is O(n) complexity .this is because when inserting a value each single node that already exists is visited ",11.0,36
10100,10100,11851,cec5c5d76a671273e0f9371ae893a0f4c2ff89a302afba60a55ed47df25e76493286a5dc1d008dcab637f3c3c155e4e5b2158e820a7aa91a63b886b5ee485778,"The worst case complexity when searching a vector of n items in O(n) because you have to check n values before finding the correct one as the final value( as it is worst case).

The worst case scenario in a BST is when every internal node only has 1 child. As a result the height of the tree would be the number of nodes minus one to account for the root, which is h=n-1 which is gives us O(n). The best case scenario would be in a perfect tree where, as seen in the mathematical induction proof, h=log_2(n+1)-1 which gives us O(log(n)).

The worst case work when inserting would be O(n) as the entire tree of h = n-1 would have to be traversed.

The best case would be be O(log(n)) as that is the complexity of the height and therefore the nodes that will have to be traversed to insert the values.

The total work would be O(n).",14.0,36
10101,10101,11852,5530a3289902a9b8046211b23e363c2d17c53d3dae60408ce782dad21065a511eb819cc437440b28be1c0ee28957c16d3c143820d415553d97979e1db0f64c5b,O(n) - 2 times the work ,1.0,36
10102,10102,11853,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,O(n),1.0,36
10103,10103,11854,68f3486fba3e90fbb30d257d9f425b479699474b4734aedaec9e7b7e62738dec31c232429f41b1b79d289e2acf53beed558d49f905e55176ee54e1327b9aa184,"1. it occurs when O(log2​n)  and  it runs O(1) times.

2. best case scenario O(1)   and worst case scenario O(h) ",0.0,36
10104,10104,11855,a69deeb1d09b2c2f2efacf2adabcd40f91cbdaa6d8a94b958b4f80eb19e04ba4658d33a6b07d41e2293e3dc7c648d0c9d4ec03fdc6df749e7a11d1c6ae138068,"O(n) and when v is not found. If we search n times, then O(n^2).

Height: best: h=log(n+1)-1, h=worst: n-1

O(h)=O(n-1) since we need to go through all numbers in a line

O(log(n)) since we go through the shortest height

Work: O(nlogn) - best and O(n) - worst",11.0,36
10105,10105,11856,86a089b08f86e9c1d63b469ed69474a00b3c8a302414b59395dac01ecff0bf909a9721c007531f0f7d3273bab8151790358055f69bbfd852502b400b0f09160c,"1) Worst case scenario is when the value v we are looking for in the vector is not there and we would have to do a linear amount of work O(n).

2) Best case scenario is if the tree is a complete tree, then on that case we have to do O(logn) amount of work at worst while on the other hand we can have a case where the tree is a degenerate tree and the amount of work we have to do is linear O(n).

3) Linear amount of work O(n), this is because the tree would be degenerate not the worst case scenario.

4) Logarithmic amount of work O(logn), this is because the tree would be a complete tree in the best case scenario and its maximum height is logarithmic.

5)O(n) amount of work.",15.0,36
10106,10106,11857,2dc8bdb77e3c7ca65a7004fc81d01e201b72cc647f001393bf944c06617e5c35dc6d00cb13c94a98ad4a2b0a5135ab7e178732724d9ed1cd93c84c2d08c50e63,"The Big-O notation for searching the a value v would be O(n) and this occurs when the value v is at the end. If we search n times it will be O(n x n).

The best case for an insertion is O(1) and this occurs when you insert into the root. The worst case for an insertion is O(n) if the tree the tree is not balanced. 

For the worst case height the complexity is O(n), therefore inserting n times it would be O(n x n).

For the best case height the complexity is O(1), therefore inserting n times it would be O(n).

To construct the tree and search for the numbers n times the complexity would be O(n x n). ",14.0,36
10107,10107,11858,efd232e6edf06b095e712e68f8ce8701b452d03344874ec8e202c3b1c55dd0c8b72d40f2859eacbda02e8a7ae034ecba2b74f48d8999907073f237d2d351e8e6,"1)The worst case given an n number vector is doing n traversals when v is at position n-1 which gives us O(n-1) = O(n) complexity.

2)Worst case is when we do a linear amount of work O(n) as in h<= n-1 this occurs when the number is added to the 2^n height of the tree.

Best case is when log2(n+1)<= h

3)We would have O(n) amount of work.

4)log2(n+1)",7.0,36
11805,11805,16026,615a61127c6c0ce82fff3b905af9891145f1a8b7de3c813ff28357e83206738e51030e5e11f925cb1ff08e1e1848b449cb4a5ebd866eaf249477de58f163ccf4,"1. have a pointer point to what the address of the object that the head is pointing too

as the address of the tail object is stored in the next of the previous link, I would just need to check whether the next value of the link object I'm currently on is the value of the tail pointer
of the previous link

2. use a while loop with the conditions

if objects that's being pointed too's, next address does not equal to the tail pointer

have the pointer update its value to the next address.

else the next objects address is equal too the tail pointer address, then the loop will break leaving the pointer currently pointing to the previous object.

it would take n-1 to traverse the lists
therefore the complexity would be O(n)",6.0,44
11806,11806,16027,6faeacee0c2269025dd90b7721d39fd6ea59274d1116063ca6e894050048f55cfc48de8438d931d22afb7e2c6e6e2971358b83dd0ec2d867cc557d7b6b500315,"* Initialise a pointer (e.g. curr) that will start pointing at the head and thereafter point to the current link in the list as it traverses through the list.
Use a while loop that has a condition to check whether the current pointer's next address is not equal to the tail pointer. The body should update the pointer to the next address.
If the condition is not met (i.e. curr->next == tail) exit the while loop.
We will now have the pointer (curr) pointing at the second last item.
	* We do n−1 traversal steps (curr = curr->next). This is a linear function, therefore the time complexity would be O(n)",8.0,44
11807,11807,16028,3227954877ff6b3d6e5d415eabaacb6ee56a5809874f349fcc72cbd6b74b9924802065f3198d52fa435eef46404fa2ce0465698400217a4b7b18ef03d8cc91ec,"ACCESSING SECOND LAST ITEM:

Traverse to the second last item in the list by following the pointers and stopping once the current pointer's next's next is the null pointer as we will then have reached the second last item, since the last items next is the null pointer. The code is as follows:

Link* getSecondLast(){

  Link* curr = head;

  //Assuming atleast 2 items in the list

  while (curr->next->next != nullptr){
    curr = curr->next;

  }

  return curr;

}

Now curr should point to the second last item in the list and we have successfully accessed it. The tail pointer is inconsequential since the list is Singly Linked so we cannot use it to move backwards to access the second last item.

COMPLEXITY:

We will always have to traverse to the second last item of the list in order to access it and thus we perform (n - 2) operations (following the pointers) which is ~n operations each time in order to reach it. Therefore the complexity of the function is O(n), which is linear.",8.0,44
11808,11808,16029,828a54706b7956f06065af9a928b49958122a77b54a5e0593021ac1ee5bfac90e0bf9488291ceaad9b7538bfadd4796253d8359db184b0bd7f7e1ed456e8f30c,"I need two pointers, curr and prev.
Use a while loop with a condition that (curr->next != nullptr).
At each iteration I update prev to point to curr then update curr to point to curr->next.
At the end of the loop prev will be my second last item.

Since the worst case is traversing through the entire list then the time complexity will just be linear O(n).",6.0,44
11809,11809,16030,74594d76e743115e9e80c4119a5039c4fec5aed2b1eb9af70c89d53a42b69ad2163ffd8ce8a40f97632e4be0cb18aad097e1d70fac3137214bb4656688c9555b,"You would still need to traverse the link from the first link (head link) because even if we can access the tail link in constant time, the lack of a reverse pointer to the previous link in the list means we cannot traverse the List backwards.

Given that a forward traversal to the last element has a complexity of O(n) then the forward traversal to the second last element complexity of O(n-1) which can be simplified to O(n) meaning that accessing the second to last link of a Singly Linked List with a tail pointer has the same complexity as accessing the second to last link of a Singly Linked list without a tail pointer.",6.0,44
11810,11810,16031,aba8ccda4763601c960552191c4b4ea7d3e94521d25f84c03f905aac0bf9578acabd1a7e87e98918c1a32dbc6bc0f00b14222dbc9e37a19a4efb13f1c52924d7,"Since we have a tail pointer, this means we do not have to traverse to the second last item. We can find the end of the list in constant time, because we have the tail pointer. Once we are at the end of the list, we can start at the back of the list and move  one step backwards to the second last item in the list.

Link* end = tail;

for(int c = 0; c < -1; --c){

                                       end = end -> prev;

}

 return end;

End points to the 2nd last link/item, we return it.

This takes O(1) - constant time.

 ",0.0,44
11811,11811,16032,be6529d2c60e9c3e44398e6d6378522b796199a001be8bd7e7bf876610ef85fd8204961bc4cabc5a2506d1dd5b074658c765a8f7b3311d9493c6efa1d870167b,Link * curr = head; int count = 0; for ( curr ->next != nullptr){ curr = curr -> next; ++count; } Link * second = get_link(count-1) cout << second -> value ; the time complexity would be 0(n),4.0,44
11812,11812,16034,efe8bbe0531a8edbaeccdc4f50ad7d19da4ae088aef554a1013cb2ff8b78ba31a24fa0e8f957d84b8c738910275c42c68da1550413f3ef77aa9c38fb88257b54,"To access the second last item of a Singly Linked List with a tail pointer, you could declare a new pointer (sat, Link *curr) and initialise it to point to the same link as the head pointer. Thereafter, you can traverse through the list using a while loop whose statement checks whether or not the next link in the list is equivalent to the tail pointer (while curr->next != tail). If it is not, we update our curr pointer to point to the next link. Implementing it this way, our curr pointer should point to the second last item at the end of our traversal.

The time complexity of this function would be O(n) time since we would need to do n - 2 traversal steps to reach the second last item.",7.0,44
11813,11813,16035,c2a635a9bcf4ad40fa50102eeb50a8298caf1f43a284d43931e8d6ff78372592382df0d5a087e759cf9a231e99eb6b2b3a8890e03edb12bf9295b2611174eebb,"We need to traverse the list to the last node. Then use to pointers to store the address of the last node and the address of the second node. We can then make the last->next point to head to make it the first item on the item. Eventually we can make secondlast->next = NULL, then return the last node in the last(secondlast).
Time Complexity = O(n) (if n items in a list)",3.0,44
11814,11814,16036,725a0125b367c6f17c35c11b2109d01e495cc98a9983ee64edff98f1e31691682af784e585cb9ffd4450baefac075cf1659b1b9f4409ec665f5bbef7fd4002df,"You would start by checking if the item you are currently on is the second last item by checking if the current_item->next->next == nullptr. If the item you are on is not the second last item then you would start traversing through the list by moving onto the next item in the list. You will repeat the process of traversing through the list until you find the second last item in which you would access the item and the program would stop.

The time complexity would be O(n).",6.0,44
11815,11815,16037,b62aa4d567faf4c8c2d7b435cab87c30c9d1e6af89f8a0e3d7867630ef600446840f333742c814bc8a0c9d2f0ab23474abdecc13d41d7312f08a47b7fc5bb67c,"Since it is singly linked I would perform a traversal.

Then ensure we are on the second last item by implementing code like (the pseudo code):

within a for loop:
if (thisIteration -> (next-next) = NULLPTR)

*then print the item stored or make other changes once accessed (if by reference).

else continue the iteration.

This would have a time complexity of O(n) as it depends on the size of the n list.",5.0,44
11816,11816,16038,f1847bb5d29f39224664df29173ee4eea8241f8aa777b795f86bafdb3b6165e8679750df7902af2beb1387f258e9970c22324224cff020b701254fc8b35d988f,To access the second to last item you would have to create a temporary link element that points to the tail of the list and then traverse to the element that the tail is pointing to. ,1.0,44
11817,11817,16039,ab914ab560d18c5aef3e43bda3ed23f3106afabfcaabd71fb45ebbdc423746252b1d705ea396aa70f877858829d5c8d335f73b945106c9ea584789a7d7f0ea77,"The tail pointer takes us to the last item of the list. We want to access the second last item.Since we have a Singly Linked List we only have next pointers and no previous pointers. So we can't traverse through the list backwards, thus the tail pointer is of no use. So we must start at the head and traverse through our Linked List using the next pointers. So if we have N items then we traverse through N-1 to get to the second last item in the list. Therefore we can say that our time complexity is linear, or in Big-Oh notation it is O(n).",8.0,44
11818,11818,16040,6c39b5e6a07e95287c054b22b9b14ae724def23d44c2473ffa57fa66d0dc3ed81fdc207205fd37cd3342b92b02f8364dc720791f8b6724f778e183c98d663fa5,"Assuming that the Linked list has at least 2 links. Iterate from the head using a link pointer variable(e.g curr) until the iterating pointer's link's next value and the tail pointer value are equal.

The time complexity is O(n)",10.0,44
11819,11819,16041,74ac16aad9cffebc9a82a3d84552ea746b2a726fb003881a5a45ccd11c8a938caed3d1a49b6f0f3b5bc663c85f99ca3ae1d10cb0f79247d51859bb82beada81b,"We first create a temporary Link that points to the first item in the list(head).While we are not at the back of the list we must traverse to the next thing.The last Link in the chain has a null pointer.So we create a while loop that says that our temporary Link is not equal to null pointer. This will traverse from next link to another until it reaches the last link which has a null pointer.From there we pop_back so we get our second last item in the list

The time complexity is O(n).",4.0,44
11820,11820,16042,17af69de9b004cebc772407eb454a4695fd215d61e6315c9d12ef0dd3a08b8a8642b4cc8dfc787e7755ff0571045a1730ffe50dbf1069009256ea87e870d4fed,"The tail pointer would point at the last item in the linked list. However, it is not possible to traverse backward as it is a single link list and there is no previous pointer. Thus, one must traverse from the head pointer until the second last item. The while loop will end when the link's next pointer is equal to the tail pointer. This operation would take linear time.",8.0,44
11821,11821,16043,666d09a4d8260961dbb488b896e8680fe46f9012a9bfa6adbe518edfaed179e00538132a0e660a988cc51e3f8b8695b7b78d6679f0a1e7d0f26361ce20a96384,"Link *curr = head;

Link *prev = nullptr;

while(curr->next != nullptr){

prev = curr;

curr = curr->next;
}

prev is now the second last item

Considering that there are n items in the list

The time complexity is O(n) - linear;",8.0,44
11822,11822,16044,f7bbac457e26e926aa83f65c706f322284bcae4a69df367438ec5060865432bf63d2eef51ed308d86119a8e1745e619fe74662cd103d43378e65328b7630ff57,"You would first need to create an iterator to iterate through the list. 
Then you would create a pointer to the link whose ""next"" value is linked to the nullpointer. You would then return the pointer. The time complexity is O(1)",0.0,44
11823,11823,16045,6a787853e1f57b2d3b0d74f5ae62b179adb7413dd588b37a8f7082bdd65e471590c4f39498c937e59e73bcf33962fea95df098117d05b73852f11db547a99d9b,"Link *curr=head;

for (int c =0; c<i-1 ; ++c){

curr =curr ->next;

}

return curr;

time complexity = O(n)",1.0,44
11824,11824,16046,d34efe98a2513ac08acc6faef18dfc38310a4938c3e2400c3ec9b606c14e0455c45534357347e63004ac9d2c3c1e1d7805afa99ff5f4d271c3dc0f7c2153d7d4,"* You would create a temp pointer (*tmp)
	* and make it points to what the prev pointer of the last link (tail -> prev) is pointing to

	* *tmp = tail -> prev;
	* then to access the value in the second last link you would say
	* cout << temp -> value ;

Time Complexity

	* the time complexity is O(1)",1.0,44
11825,11825,16047,a0052d1186f3fa53f67763ddf5dc1148fc540657d42f0891ff3ac99ce8c9f5c8c2cc81fa44f5583e909b3bdda1a0f1e6a21067a67ce2ede8b9d60f7eef57955f,"I would declare a Link pointer cur to the head of the list.
I would traverse the list until cur->next equals the tail pointer.

At this point cur would point to the second last element. 

The time complexity: 0(N)",8.0,44
11826,11826,16048,88e4f79f72acbc7dd458837989d41695a9b36b9c96cdb3ba66c7b90921d69150d478abfb1ed6fc7e89594f6b4ccd5c2a5625a644a888136358b59b68dc7b8205,"check if the current node is the second last node of the list and if it is, print the  node.

if it is not the second last node , the current node must be updated to the next node until it is the second last node

time complexity is O(n)",6.0,44
11827,11827,16049,e8ac13437ca4eb4696e3ef433ae3842afba862c0118c6894733767a015023753193111e7d4c262c3227484acd644f4e441faf59e7cd3f61df893fbe34d31e198,"In order to access the second last item in the list we will have to implement the (prev) function that points to a previous link to the one we currently pointing to. So that we can use (tail -> prev) thus accessing the link previous to the last link.
This function will take linear amount of time since before using the tail pointer to perform (tail -> prev) function, we will need to iterate throughout the linked-list. ",3.0,44
11828,11828,16050,5d0d60194fd1b05c809499adb963afbac0ab800c552d7666ea7779f6183d17839f234e9ecee3ed11e567d9e2e5d5f869bc08bd2cc74894f9ca624282e8055b10,"Since the data structure is a _Singly _Linked List, the direction of traversal is only in one direction, from the first link to the last link. Therefore, we would be unable to traverse backwards. 

Thus, to access the second last item in the list, we would have to traverse the Linked List from the first link to the link whose 'next' attribute points to the the last link, i.e is equal to the tail pointer of the Linked List

As code, it would look like:

// Begin code
Link* current = head;
while (current -> next != tail){

     current = current -> next;
}
return current -> value;
// End code

The time complexity of this function would be O(N), or LINEAR",7.0,44
11829,11829,16051,66ba5975b098f5fa2bae0b86dceb6b280b99b8f4c6fff5dafe0a067b8a9153b49a39abe1525261732c63d25886c01c121ff46cf2ab2721a603f04674ea202257,"Because it is a Singly Linked List, meaning that each link does not contain a pointer to the previous link but only the next link, we are unable to perform a backwards traversal and therefore would need to traverse from the beginning until we reach one before the tail pointer. 

//Traverse until the second last link

Link *curr = head; 

while(curr->next != nullptr){

curr = curr->next;

}

return curr->value;

The time complexity in Big-O notation is O(n). The time complexity of returning the tail pointer is O(1). ",6.0,44
11830,11830,16052,8988e05f865164f4560af96560c21e55905eac0bb5f61f3d6e278f9698c3b2aef4e2c138e098da5e867aaa523133fd657970eaa9429e994d798d7fd717f54fcc,"Since it is a Singly Linked List (meaning we only store a value and a next pointer in each node, not a previous pointer) we would still have to traverse the list from the first item to the second last item because even  though we have a tail pointer to the last node, the last node does not have a pointer to the second last node. Therefore, the time complexity of accessing the second last item would be Linear Time - O(n).",7.0,44
11831,11831,16053,9140ffa3b52741e2ae246773dfeed94b1141ba7c3dc70e8cb17fb6410cd6b017d81c18ceaa0264d9c4b8354cae095d12f4a720da352b65b62d37bdd0fc9fdc69,"link *curr=head;

link *prev=nullptr;

while(curr->next!=tail){

prev=curr;

 curr=curr->next;

}

return prev;

we would create a new link that will point to whatever the head is pointing to, then we would traverse the list from the head to the tail while keeping track of the position before the head using the prev pointer. Then when the curr->next pointer is at the tail our loop will stop and the prev pointer will be pointing at the second last item since the tail points at the last item in the list. Because of the while loop will run n comparison, the program will have a linear complexity O(n).    ",8.0,44
11832,11832,16054,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,"First I would create a temporary link that would point to the head, create a while loop that would traverse until the second to last like or until the second to last link is equal tail . Traverse to the next link until I get to the second to last link  . After that return the temporary link.
Link *tmp = head;

while(tmp ->next->next != tail){

      tmp = tmp -> next;

}

the time complexity is O(n)

 ",6.0,44
11833,11833,16055,16f09d60ea55f541a3437e3e2ab8e9c69f838f50f98dec712996c73779cd9f654e7fa72007ae7a3b8d9cb813c8fad8d686dc40ba57c222e292c85b1a88fc8b53,"Traverse through the linked list. Check if the current link(node) is the second last item of the list or not: If (current_node ->next-next == null). Then if the current node is the second last link then return or print it. If it is not the second last node then move on to check if the next one is. Repeat till the second last link is reached. 

time complexity: O(n)",7.0,44
11834,11834,16056,2639eb56a1989682f1b8fb8c5a3437ea6a5d663be094f02f4aaae47dc57a1af7165cfaae33d61d670e26c96083744d494e42187a468df938459fc0c70030a175,To get the value of the second last item we need to transverse to the second last link in the chain. This will take O(n) operations.,4.0,44
11835,11835,16057,ec66e4473040e8ee3556fe295a682aef55293bdc440d5beebc8fb799f1964c0abc0afc761e0c9e5b3dec6cb5d26467ba51d5e312925807725d0b86097bb74bce,"create a temporary link called current and set it to the head, traverse through the list until current->next->next = nullptr, this would give you the second last item in the list. The tail pointer cannot be used to make this faster as it is a singly linked list. The time complexity of this is O(n) or linear",8.0,44
11836,11836,16058,a0a0e3863f2cfe81dc13120d1d5fb28060efbca078cff0afc0ca4a53755acf909a3b28053a432d02251e8d53776e3aedf7eeff75f48fc36029b0d4fb7d46aa25,"The tail pointer points to the last item, however we will not be able to use pointer arithmetic to access the second last item. As a result, we will need to traverse the linked list while keeping track of the previous link. The following code will achieve this:

//Create a new pointer which equals head i.e. it points to the first Link

Link* curr = head;

//Create a nullptr called prev. This will point to the previous Link

Link* prev = nullptr;

//While the next member of curr is not a nullptr

while(curr->next != nullptr){

//Save the location of the current Link

prev = curr;

//Move to the next Link in the LinkedList

curr = curr->next;
}
Once we have reached the end of the while loop, the variable called prev will be a pointer to the second last item in the linked list. The time complexity of this function would be O(n).",8.0,44
11837,11837,16059,c7d75d976a010a38db71e259afee15ce7c42ba18fa8ef2214021124356299e2bc696f235d69042a2e7d6021b611ee4096167f90988dc7b1e755fca98c40f31fd,"I would use a while loop to traverse through the list while the pointer of our current node is not pointing to a pointer that is null. Since we would have to traverse through the whole list, the time complexity will be O(n).
In the case where we only have two items in the list, our second last item would be the head and therefore we could access it with a time complexity of O(1) as it would be the first item in the list.",6.0,44
11838,11838,16060,1d469feec8dabc8efe190b91bf2431897a77efbd16b2d85bdc6124d89beaeb95e4c3d1758db03e27ba5dac6295ff2b30f3eaaa927d0748ab45ecd18c4991abfb,"create two pointers one that points to the current link while iteration over it and another to point at a link previous to the current link

and iterate through the linked list until the current pointer points to the last link which its pointer will point to null once the condition is met we will return what the previous pointer is pointing too.

time complexity will be linear O(n)",8.0,44
11839,11839,16061,06f90aca60b4b2db0e6d8bb78d0ed0da22ceb02b561b842eee51951b0e04be81e8817f795eb9597349f2e3c12b7befca0ed36322cff788052acb9b91388f1fdc,"to access the second last item in the list I would create 2 temp pointers called _curr _and _prev_. _curr _would point to the node that we are on and _prev _would point to the node before _curr_. I would then loop through the list with the condition _while(curr->next !=nullptr)_ OR while it is not equal to the tail pointer, so that it can loop through till the tail pointer, once _curr=nullptr_ which would happen at the last link in the list, my _prev _pointer would then point to the second last item in the list.

the time complexity would be O(n) because we would have to traverse to the end of the list",6.0,44
11840,11840,16062,562a79f866657142ac8bf9d260020a41dd948177d2bce6c88383e228d52056cf2d2544e838847e98137352689514e6b5fccb58b9b8779b353c6c283dfc7313ad,"Having a tail pointer in a singly linked list is not beneficial for an access function which is not providing access to the last element in the list or using the tail pointer to modify the list such _as in push_back(),back(),or a change(int i)[CHANGE VALUE AT I'TH LINK] and at() functions,for the at() _it would be beneficial if the size() is not  a linear function but we can return the size of the list in constant time and we would do something like:

_THING AT(INT I){_

_    IF(I==THIS->SIZE())_

_        RETURN (*TAILPOINTER).VALUE;_

_     ELSE{_

_        //SOME OTHER CODE_

_}_

_}_

Unlike in a doubly linked list whereby this could help us access the second last item in constant time by just _LINK* CURR = TAILPOINTER->PREV;_

To access the second last item we would consider making a traversal to the second last link in the list,the benefit of having the tail pointer is ultimately being able to avoid the hard to read _while(curr->next->next != nullPtr);_

_rat_her we would opt for us having a prev and current pointer and us comparing the current pointers value with the tailPointers value and if they are both equal to we then return the prev pointer like so:

_Link* getSecondLast(){_

_    Link* current = this->head,prev = nullPtr;_

_    while(curr != this->tailPointer){_

_        prev = current;_

_        current = current->next;_

_}_

_     return prev;_

}

Alternatively we could think of comparing the current-> next and the tailPointers->next which would be both equal to the nullPtr and wouldnt require us using the tailPointer in any way as we could just say WHILE(CURR-.NEXT!= NULLPTR){}..",8.0,44
11841,11841,16063,09a1699e91053a97e967035388a9bb6bf2333dc132838738d78edc417a8028213044038d23bdf9e5be7458e9014620b5d4a10df02214eb4aa340c740ce44d5c1,"Assuming the list has more than one element to obtain the second last list element, traverse list with curr pointer to node after equating it to head pointer. Traverse list via loop by equating curr to curr->next field of node, until curr->next = tailptr. This checks if the current node next field is a pointer to the tail node meaning it is the second last item.

Loop is terminated at this point and you can return the value field of the object curr points to using curr->value, or just return the pointer curr for the address of the node pointed to.",5.0,44
11842,11842,16064,1e61ac69c9ccec529a9d57595e183d7f2b1fa6a9903d4933718e237d1b12f704ba69dec35931222592238b7ab802821e4d5dd2c83c64cb9301a8bb0ced8b2cba,"Check if the current node is the the second last node of the linked list, if it is then the current node is the second last node. if the current node is not the second last node, we move onto the next node. we continue this until we find the second last node.

It takes O(n) time",5.0,44
11843,11843,16065,5cd0a202ef51535fb2cf79db8f13b432c752afb35952cb0416813c6c757163698e13f6f62bd6292909baa9745f2197e7ed5a1f16eebc10eb62867568861dbf00,"Assuming the list has more than 1 item. If we had a tail pointer we can store its reference in another pointer (call it tmp) that points to what the tail is pointing to. We can then let this tmp point to the previous link behind the tail and return its reference. In this way we access the second last item of the list. 

Because the List has a tail pointer, and we would want to access the second last item of the list, no matter how big the list is, it will take us the list size minus 2 to access the second last element. Hence it would take us constant time O(1) to access the second last item.",0.0,44
11844,11844,16066,c75c72f439ed0a1083505ca2fb274424bfa93184c45c67c47245732cd59fc54e342192b7a0a8538fb3676603ded389cab9a3431e9d476a9d9b140adb5ff30721,"Even though we have a tail pointer, this would only point to the last link in the linked list, and links in the linked list only have pointers to the next link in the list, so we wouldn't have a reference to the previous container (the second last item), in the linked list. For this reason we would still have to traverse the whole list in order to reach the second last item. This would have O(n) time complexity (linear).",6.0,44
11845,11845,16067,c75c72f439ed0a1083505ca2fb274424bfa93184c45c67c47245732cd59fc54e342192b7a0a8538fb3676603ded389cab9a3431e9d476a9d9b140adb5ff30721,"Even though we have a tail pointer, this would only point to the last link in the linked list, and links in the linked list only have pointers to the next link in the list, so we wouldn't have a reference to the previous container (the second last item), in the linked list. For this reason we would still have to traverse the whole list in order to reach the second last item. This would have O(n) time complexity (linear).",6.0,44
11846,11846,16068,c75c72f439ed0a1083505ca2fb274424bfa93184c45c67c47245732cd59fc54e342192b7a0a8538fb3676603ded389cab9a3431e9d476a9d9b140adb5ff30721,"Even though we have a tail pointer, this would only point to the last link in the linked list, and links in the linked list only have pointers to the next link in the list, so we wouldn't have a reference to the previous container (the second last item), in the linked list. For this reason we would still have to traverse the whole list in order to reach the second last item. This would have O(n) time complexity (linear).",6.0,44
11847,11847,16069,c75c72f439ed0a1083505ca2fb274424bfa93184c45c67c47245732cd59fc54e342192b7a0a8538fb3676603ded389cab9a3431e9d476a9d9b140adb5ff30721,"Even though we have a tail pointer, this would only point to the last link in the linked list, and links in the linked list only have pointers to the next link in the list, so we wouldn't have a reference to the previous container (the second last item), in the linked list. For this reason we would still have to traverse the whole list in order to reach the second last item. This would have O(n) time complexity (linear).",6.0,44
11848,11848,16070,c66e418bde3624775409174d439f8c7a104e4c741d28aa9a32d3dff6f27ee3fc70a6b61ca496d004e7124e5afeca9e6a74cf0455c76878d506978153185a8efb,"The tail is the last item in a list. In this case, tail->next, actually points to the previous item in the list and so if one had to traverse this list(assuming there is no head), you would start from the end and traverse to the beginning of the list. So, the tail pointer would point to the second last item of the list. Therefore, you would need to use the tail pointer and access what it points to 

(value = tail->next).  This would give you the value stored in the second last item of the list.

It would be done in constant time, O(1).",0.0,44
11849,11849,16072,f7abd04c97a647b1e757bccd7284173478fbf8f28e28e3102567ab244a63fd5c67a5e953a932ab1f774cb73ace52fda53cdbbded4668ee4660e933d867e532bd,"To do this l would declare a pointer that points to the last item just as the tail pointer. From there l would traverse the list using get_link function to reach the link before the last one and make the tail pointer point to that link before the last one. This will take 1 memory allocation ,,a traversal and one assignment and therefore the time complexity is linear time.",2.0,44
11850,11850,16073,9a6d2e6e6e0c1b575d6fd6f9cd31a3d7ef05b9fbb8f9b527d2f24c66326f4e25fb885d747e3511e370820c0e5c65531a52fb8637b76c7b43895037c2420cfc80,"Create a new pointer that points to the tail pointer and traverse backwards to the previous node/link and return the value of that node.

The time complexity would be Constant O(1). It will not depend on the size of the list no matter how big or small it is.",0.0,44
11851,11851,16074,5b79e321acf32f26a1c6cc9091fa349a8baa70385c6fb736e55b942fea1901b561d1f53857749ead207a2933e580c9dfc66c9af868e9b035d1dff322ef7cd5be,"I would traverse through the list  using a while loop and stop when the curr->next = tail
Link* curr = head

while(curr->next != tail){

curr = curr->next

}return curr

The time complexity will be linear O(n) since the no. of steps will depend on the no. of items we have.",6.0,44
11852,11852,16075,854bde56afcd2bd2c31fbe39384369ef7c0ac613a004a4b239a7a7d08872fa336ab049f8f45358abb5e93ca8dfc33e8954bf246487197e2265435ed3c204826b,"I would create a temporary pointer and point it to the head of the list. I would then use this pointer to traverse through the list so that when temp-> next == tail, return temp which would be the second last item in the list, e.g. while( temp->next != tail){  

                                                                                                    temp = temp->next;

                                                                                                    }

                                                                                      cout<<temp;

 The time complexity would be O(n) since I would have to traverse through the list to get to the second last item.",8.0,44
11853,11853,16076,662455ba865b7fa66132ae6520e999c9ea1b9fa1f85d0b16ee30bd84db7aa0bec3c7fd7269d6521a07e1ad16d091e298c84cb6c69ff3537fa78efdac09fa4677,"Since it is a singly linked list, despite having pointer to the last link in the list, you can not find the previous links address. Therefore to access the second last item one would have to iterate through the list up to the link that has a link.next = tail. The time complexity of the function would be linear.",7.0,44
11854,11854,16077,e7c9b4fd869eb791a63c71759d17fa7e8a93618d661588fa6ae371946756531c0923d86aafe2bfd7289d74b69cb5fe841e3839957a75e6446f2d8394b4178536,"Thing findSecondLast(){

    Link* curr = head;

    Link* secondLast;

    while(curr>next){
         if(curr->next->next) == nullptr{
              secondLast = curr;
         }
         secondLast=curr;
    }
    curr=curr->next;
}

TIME COMPLEXITY: O(N)",3.0,44
11855,11855,16078,936024d8e9328998a220b77c48098f57a0d619263f7c2ad0ac4157dfe9370e11abee7f579d65a28c46224757256e636c01fe798d4c5eb4d7e1574b7de8511fbf,You would create a doubly linked list with a tail pointer. We should have a next pointer and a previous pointer .This will allow us to traverse forward and backwards easily. We storing the head(first link) and the tail(last link) as well as the number of links in the list. Therefore we can access the second last item by last item -1. The time complexity is 0(1) which is constant.  ,0.0,44
11856,11856,16079,17a5fd9d02d6fba8d8046ace71c42e033c0f094c5a424e213efe17ca2b15dcda4339210b67d2e20cb931a5cb55e9b6fb5621dde12a8a5e6da612e051b176b44e,"You would access the second last item by traversing through the list using a while loop (while tmp != nullptr). In the while loop, you use an if function to see if the next node of tmp is the second last one by checking if the next of next of tmp is a nullprt (tmp -> next ->next == nullptr) until you find the second last one.

TIME COMPLEXITY = O(n)",8.0,44
11857,11857,16080,7a27fb1fa642a9bd3d76e8ce98be5e4779f4184eab8b901b0ee0d165d466de6122db493ca631d33ef289f724ffb838136d578f3b72df159667217c69ae154ed3,"Assuming the list has more than 2 items, you would need to traverse to the link where the one after the next link points to a null pointer. ie, ptr->next->next = nullptr. This link will be the second last item in the list. Due to the traversal, you would need O(n) time in this scenario. 

However, if there are only 2 items in the list, the second last item is technically just the first item. So a check for this scenario should be done and return the first item. This will take O(1) time. 

Where there is less than 2 item in the list, you wont have a second last item so a check is required here as well. So that a null can be returned. This will take O(1) time.",7.0,44
11858,11858,16081,912a17c5532a85cc610facff6c98d42b64fb259b767c809567c65cce318eb3dc8f21bcbe5e653de87fe40d2502ab66869bc553e63fc3a1d7697be613c3b49a69,"I would traverse the linked list and check if the if the current node's next-next pointer is the tail pointer, if it is false, then it needs to move to the next node and try again, until that agreement is fulfilled. This process should take O(n) time.

If I were to illustrate this process using code, I could do so by saying:

Link *current node = head;

while (current_node != tail){

if (current_node->next->next == tail){

return current_node->value;

}

current_node = current_node->next;

}",8.0,44
11859,11859,16082,d31899b98e7fb3e761998737c0078a84e48727b178f33ae85b1caf85762f7c95a36780c3f84b13e4c3f8980c15788bdfcc7bddbb75a6b63b7a164f238d74d926,"Traverse through the linked listed until the current pointer's next is equal to the nullptr, at the same time keep track of the previous pointer as prev. 

With each iteration of the loop make prev = curr and curr = curr-> next. (as seen below). To then find the second last element one can return prev. 

This would take a linear amount of time as we need to traverse through the list using a while loop. 

Alternately we could simply traverse using the condition of (curr->next->next) in our while loop and we would not need a prev variable, 

however this would not work in the case that the list had a single item in it.

LINK *PREV = NULLPTR;

    LINK *CURR = HEAD;

  WHILE (CURR->NEXT != NULLPTR){

        PREV = CURR;

        CURR = CURR->NEXT;

        }

    RETURN PREV;",8.0,44
11860,11860,16083,0a1930b4d16e62ac7ee353c6144c568d9ee6c791d0d3632d3ce78fd24bb2c65d328c4924d6cafd1daed9790efaefb16fe2a520125cf9396ef372146945ae0496,"struct Element* tmp = head;

while (tmp!= nullptr){

if(tmp->next->next=nullptr){

return tmp->data;

}

}

To access the second last element, traverse through the list using a pointer pointing to the head.  If the next pointer is before the null pointer, it is the second last element of the list.

Return that pointer.

Time Complexity: O(n)",4.0,44
11861,11861,16084,bef6837a7fdfe1da5fe1293f44c76b96d3b8dcc796faa186ced378d3238a30c359695c10ba31e008e6450186def6f4c6da86e1819e6310ac4629db0e4ae2f7c4,"link * curr = head;
   for( int i = 0; i < index ; ++i) {

  curr = get_link(i);

 curr  ➡️ value; 

}

The time complexity of the function would be O(n).",3.0,44
11862,11862,16085,5888307e6e5630e26d91393f9d95b55394aa59f773d80fc5cba42e8220ea74538fd7609c1185eaef557523bfd3715cc3b2307d7a31ddf68499df84fa7da160d9,"Link *ptr = head;

Link *prev = head;

while(ptr -> next  != nullptr){

prev = ptr;

ptr = ptr -> next }

return prev;

time complexity - O(n)",8.0,44
11863,11863,16086,20a63554bf7ab6e06ce970a9c763f370f49fc1a727f591ec7304c432565faf9d2b891194e01cc67ff029c1fe6de8363ececadce22ee4af544785f47985cda509,"Traverse through the list using a while loop

 Link * node = head;

while(head.next != tail pointer)[
node = node.next
}
 return node.value

Time complexity - O(n)",6.0,44
11864,11864,16087,df0d62df6145f98b9d8d85662b958119c20c6015becf9534b762b6d6c7c046d872ff37d4ccc77da23e1570c5a7712fc862bda45087171a56e4c5cfc3750e2ad2,"You have to travers through the list till you get to the second last list.

O(n)",4.0,44
11865,11865,16088,3824a0678a0ee80961c81764186a1496645536aadc7127ac81665ef8825202d12ca91cc1dddb49cb3545dd95e3ab23ddf164ccd399cf03acc33959144061677d,The last item can be accessed by creating a prev pointer which will be declared to be null on the head->prev on the first node and will be made to be the pointe of the second last item and this will be called by tail->prev and the time complexity will be 0(n),2.0,44
11866,11866,16089,414c0211baa0f7785fed3a2ae8d654438eeb57e32a72d726d41fb80a14e5bb82594bc148b341e170426f496146bb1f57723f178ed8b08e3a2a9402960a0201df,"Link* last=tail;

Link* first=head;

Time complexity: Linear time",2.0,44
11867,11867,16090,af813686acb18a064eece7968dc86f7e1ba2e2c4ebcbfb61de992275f213a5fe2248d15ae968c61ff6c270f401a739d21132339ee0a42afa471e88a17c352ab9,"You would use a Current and a Previous Link and traverse through the list until current->next=nullptr. While traversing through the list you would update previous to be the link before current, the time complexity would be linear O(n) because you would have to traverse through the whole list and the code would look like this:

    Link* current= head;

    Link* previous= nullptr;

    while (current->next!=nullptr){

        previous= current;

        current=current->next;

    }

    return  previous->value;",8.0,44
11868,11868,16091,56a9cf1853b1b03dca807886ec22074eec556b57734ef74dfe3d7a5ab906dc06e5ed46d46913780a3ebae603d6d67abd6ba7c9bc3ba254a5ffca3a3c25744144,"Traverse the link before the last item, set the prev pointer to point to the second last link.

This will be done in O(1) time.",1.0,44
11869,11869,16092,fe62a1f5e7fe2a4e7ab8c966f31166711ff57cc766445f2fc4370a7348f81dab059b866c1f91a4b1ff166d595fb9234d29f7f66b2297a565d84b506f3bd0f6e7,"First set up a current Link pointer and a previous link pointer (prev).

You can traverse thorugh the list until curr->next_next equals the tail. i.e while(curr->next->next!= tail) . in the while loop set current to current->next and prev = current.

Once the while loop has ended. current will be equal to tail and previous will be equal to the second last item's Link.

Then access the items value , use prev->value;

Since we are traversing through the whole listof n items , the time complexity will be O(n).",7.0,44
11870,11870,16093,9b13f2d70694a174cc296db2532a81cde5f414c86e87388e32c45d14a1b85a47b70cc54fdcb2f6455012d569323883da99f34aab409453d8e838e0ae2bf41aff,"Link *curr = head;

for(int c=o; c < i; ++c){

    curr = curr->next;

}

return curr;

time complexity will be O(1)

Class Link{

Link *next;

int value;

Link *prev;

}",0.0,44
11871,11871,16095,4fe3ddceb8532be5264d396e27eca9f3430928d2debfbdca391cfa468f769445f07ae40650717eb0131d20465c9068c4b8bf87a2c7932640884394a0094fc8e5,"struct node{
    int data;

    struct node *next;

}

int getSecondLast(struct node *head, int n){

    struct node *current = head;

    struct node *SecondLast = nullptr;

    int count = 0;

    int value = -1;

    while(current != nullptr){

        count++;

        current = current->next;

        if(count == n){

            SecondLast = head;

        }else if(count>n){

            SecondLast = SecondLast->next;

        }

    }

    if(count >= n){

        value = SecondLast->data;

    }

    return value;

}",5.0,44
11872,11872,16096,acc027b1281fb7611892bbd9cd22b170d39dac509f3cbd3c4ae2298ef8fcce3e213c9bdb095b30f4b14371abefeb025cbed1bfbb0b3e1f2baccc7d74d415003e,"struct Node {
    int data;
    struct Node* next;
};

int findSecondLastNode(struct Node* head)
{
    struct Node* temp = head;
  
  
if (temp == NULL || temp->next == NULL)
        return -1; while (temp != NULL) {

if (temp->next->next == NULL)
            return temp->data;

      temp = temp->next;
    }
}
void push(struct Node** head_ref, int new_data)
{
    Node* new_node = new Node;
    new_node->data = new_data;
    new_node->next = (*head_ref);
    (*head_ref) = new_node;
}
 ",0.0,44
11873,11873,16097,47f3a7bba3e31dce40c5cb73e1780ef17a7d27da797b9b8e1519bec1fa6b57a68e0e591111394becc40b5a2e1e2f5bfdb5b0b9727e966282c2516a6f687cab3e,"Traverse the list. If the list is less than two elements return an error, then check if the current is the second last in the list. If the current link is the second last link return the pointer pointing to this link otherwise traverse to the next link. ",5.0,44
11874,11874,16098,2238995f0ead9a3412ecc8b42340b20d5862bf47d5493b0c9fbe94b4e46ffb57c2cf52b4dd296cee7b6850d8a44e160d6bd1d96e80ab144e928044e44043acc6,"tail->prev

O(1)",0.0,44
11875,11875,16099,bc7ce8dcf81474ef89d407bc167ddbdc0ae686813582e07ef0e124f6d6fe081339ab3b2bb05c54a356b901c5c208933d91dbaf731894bf50cc25eab5e102a8e6,"Link *ptr=head;

Link *ptr2=nullptr;

While(ptr->next!=tail){

ptr2=ptr-next;

ptr=ptr->next;

}

return ptr2->value;

Time complexity=O(n)",3.0,44
11876,11876,16100,3d98aadbc95f1ceaf5723fac50fb4583048e99f3a608962c3b1c8cd33d79fc21685534ca4e509a1fb097360bbcf66d5d96593eff3b861f7814afdcae8fecdd1e,"Link *tmp = head;

while (tmp->next->next != nullptr){

        tmp = tmp->next;

}",5.0,44
11877,11877,16101,fcd3cd6f6ab23272e8ef67866982250cf0b69308ab1f155fea93b78f0f8230cc3a80d03659b858f52503462ba79795983adf53baae8dc1b2c6482664286cb263,"Link *curr = head;

while(curr->next->next != nullptr){

    curr = curr->next;

}

delete curr->next;

curr->next=nullptr;

The time complexity is O(n)

    ",7.0,44
11878,11878,16102,f568f900863758606ecd596c211921a4e2f0720e3778a3f2c91b74ff667248e8a2d4bcea0036dc07a6e043d08d7d7b64e5934aa3ba779587a955877ff84bfb17,"Link *tmp=head;

while(tmp->next->next!=nullptr){

tmp=tmp->next;

}

second last elemnt=tmp

you would traverse through the linked list untill you got to the second last elemnt, ie, untill the link->next->next does not equal to the null pointer.

O(n)",7.0,44
11879,11879,16103,18f6254c7b196766dbebfb4556ef6c2f9ff5e44918d8ea60921fbe90c8a42515b04ace17b80ecdd7f09efd69961a6da2d4a21f100e3ebd5acf67acba7ebaae55,"If the Singly Linked list has a tail, when wanting to access the second item, you do not need to traverse all the other nodes but just go straight to the last node, after that you can specify that you want to access an item in the position one less than the last one. As you do no need to traverse through other nodes, unlike a singly linked list without a tail pointer which takes linear-O(n) time, now it will take constant time-O(1).",0.0,44
11880,11880,16104,52f183a2edd50f67bf9165da2ed344e6b1dbef117bcc8a87e8fdd544cade3eccfad6434b2157d981bfdc96048e52a8b1696fb090b734b452d891d2f61d866105,We would traverse to the third last link.We would then update its next pointer to point to the next item which would be the second last item.This would take a linear amount of time.O(n).,5.0,44
11881,11881,16105,3b71cded09878fac739a748b2fcbc2d9e2bef1d7260004d93fa1cfe93d9b6830fe9dca43a0e8ef309e85cefb7f4580ca47263177668c6f4b88b993ec3fb19c7e,O(n!),0.0,44
11882,11882,16106,4c6239f4837a7e4857168ce1d90eccb0590dbff5755d1452f6eced3fa662d6b3d452d78b9021e9f1b0bb440c88d3e31a3396f8ac92fb89f14b2269d4512bdaa8,"Link* curr = head;

while(curr->next !=nullptr){

     curr = curr->next;

}

return *curr-1;",3.0,44
11883,11883,16107,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"Create a temporary pointer to traverse to the second last item from the head pointer.

Then the temporary pointer must be returned.",2.0,44
11884,11884,16108,20820f051ab9e7b5dde112869be67e2e49734267d017f30c8e3086343a31575407d74708ebc5d385e1b1a34dd7dd81fa4425af4e6cb2bbdba32928c419b4a8da,"- We create doubly linked list. It will have a head and a tail.

- We will create a next pointer and a previous pointer variable. (We can traverse or move forwards and backwards quicker and easier)

- We must store the head pointer which is the first link as well as the tail pointer which is the last link. 

- We also must store number of links (size) of the list.

- If we need to access the second last item in the list we will access the last item minus 1 and this will be easy to achieve since we have the last item stored.

-Time complexity is constant or O(1). ",0.0,44
11885,11885,16109,1645c663160108daa5ada428d3c9f6dd956d5580e851e511e34c81d79a9f5dccdbc9ce5cb4e79288fef46597606b100751038a21fcf2e865e1f3318a80532bd5,"Link *curr=head;

int counter =0;

while(curr=!nullptr){

   curr= curr->next;

   ++counter;

}

O(n)",3.0,44
11886,11886,16110,263fd6b7e81bd2b0bd84f67415866c3d75bf78011a0e0748b552d65d3fb35fc4bf5dca96f9ccb82225afdb2c9f73d9593526bb28fe17ab6d85ae420a8a33d70d,"I would have to start at the front/head of the list and use a traversal in order to get me to the tail pointer - 1. Because this process is dependent on a single loop repeated for every item in the list, it has a worst case time complexity of  O(n) (linear).",6.0,44
11887,11887,16111,2dd5e2f41652664c7010e9c75b107a0a619a9b54063e68bd2c6a9b76a1fcac07a9bceac7ca7bf3cdecc54ef1490301f90259c5d418e4b888c5d3f0477b59ef3c,"Create 2 pointers, both set to the head, and use a while loop to advance them so that one is always a step ahead of the other. This will give you one pointer set to the tail and the other set to the link before the tail. This is done in O(n) time",4.0,44
11888,11888,16112,52b1f6fd8e6c0289a8004d7d61b231157f72159bdb1098720813eb6a4750543a581c16358208b2fe293a6bc58612fe418d8dd4bccc56d715f7137f43db02b99f,"Link *tail = head;

while(tail != nullptr){

if( tail ->next->next == nullptr){

return tail->data;}

tail = tail->next;

}

O(n^2) time complexity.",4.0,44
11889,11889,16113,8f6fce38f378bd03b7e3015540844be6bf9823c5ceeeee423c75e7180e2218c7f9853b96b276e10dcc9cefdaf4b85b6d869df1573ced7bc1eae58f615449e857,"Link* curr=head;
while(curr->next->next!=nullptr){

curr=curr->next;

}

Thing value= curr->value;  //gives value in the second last link 

time complexity: O(n)",7.0,44
11890,11890,16114,27704af10f29b9fd01985b3a533f1213c119ce01a32f451e037e0491eede8c71f38ccb8abe4edd8c056927c76b6bf0c23fb2a88f8cca52e5000b6c906d6692ef,"WE would traverse the linked list while keeping track of the index. To do this, we create a temp pointer starting at head and using a while loop, we traverse the linked list till we find our index.

the time complexity would be O(n).",4.0,44
11891,11891,16115,5dcf09a63d08f8fcf484a27b8188aca8e05117584de8c4c8e580d2681056a972e8271fbb1e9e69a616d3a8d13ef9009ce7fbd4e4c680807f0aa62ce637934a9e,"Link* curr = head;

while(curr->next!=tail)

{ curr=curr->next;}

secondLast=curr->value;

This would take linear time O(n)",7.0,44
11892,11892,16116,01414e21ecb9a1334890023f94a0d282ee23097fe9f9524ae17a5a130cb936a59877f182817dee70cef409eabab63c6b47a25ed1ae4ef0dfef7f2566f253e2b1,"Using a tail pointer, the second last item of the list would be equivalent to the second item of the list when following the tail pointer. I would then use get link with an index of one or I would use the operator++ function of the LinkedListIterator to get to the next link in the chain. 

Link* s_last = get_list(1);

This has a time complexity of O(n) - Linear time complexity",2.0,44
11893,11893,16117,7c87322598f2ceacf4938051fa8e249fba61f740f1c131025859319c9334a0e7c5eed0d631406a69aaecd55c3154797379e9e557934a0c639e13848fc2a797db,"I would reverse the list by implementing a reverse function ,and once the list is reversed , the head pointer will point to the node that was the last node and the tail  pointer will  point to the  node that was originally the first.
Create a pointer to a link that will point to hea.

We can use a for loop to traverse to the second last  node which is now the second node of the reversed list.

After retrieving the value at that  node we then reverse the list back to its original form.

the reverse function will take constant time as it will be implemented outside the for loop.

the for loop will take linear time as we have to traverse to the second node

reversing again will take constant time therefore the entire function will have a time complexity of BigOh (n).",3.0,44
11894,11894,16118,ba67943d9c3f68c2a82bf70197366cb2cce1d21f6696fe648aaf7068ed18399b5899a40e2f0d4a0c53a04c7e84020c544f2b79e8fc23a17b4dca16bd22dbd15b,"Link *curr =head;

Link *prev = nullptr;

while( curr.next != nullptr){

prev = curr;

curr = curr.next;

}

return prev;

Time complexity is 0(n)

 ",7.0,44
11895,11895,16119,c318ecd5c05d3ffa65238b75e8aa9e67390cc6fb32c2fdbfaf84c4d21eee7f78cf713a8bc77a69838390c129742df9afc0ddd3cf48a8b7ef5ea2fb0f43dc4114,"I would call up the tail pointer and since this points to the last link in the linked list I would traverse one link over from the back and this would then have me accessing the second last link/item of the list. 

Since this would always just take one traversal from the tail, no matter the size of the linked list (greater than or equal to a size of 2), so the time complexity would be O(1) - linear time.

If the linked list has a size of zero or 1, this process should return an error as there would be no ""second last"" item. ",2.0,44
11896,11896,16120,ddf05f993d32eb46f0b5d18783c3f0bae7ba45bfb71b7a11c47b2697ab035bd02b089a647111ba9b72f32e9d1912bdd9dfcb6298cbd5226f8387827448c2cdef,O(n^2),0.0,44
11897,11897,16121,ab50392a96c4c3025a5963370825a15241a679c25a4771a2853db32d86a5e0a874ed37e6f390b06f6b3a0755f5bc0190ec94f83a3fd5bf730ba4d34a04efb6d1," *curr = head, *prev = NULL;
   while(curr->next != NULL)
      prev = curr;
      curr = curr->next;

return prev->data;

time complexity= O(n)",6.0,44
11898,11898,16122,ffb312171739bda8140d790d7e76d39d8cb251ebc0d6e983413e101fe068405632084409e60fc3615fbb0328c8c628ab617f395e064e10a0893ff352b3482def,Because the list is singly linked you cannot go from the tail pointer to the second last item. Therefor you need to traverse through the list to the the second last item. This would take n-1 operations and therefore has a run time complexity of O(n).,6.0,44
11899,11899,16123,a0053c94d18ea0e087a62013f5ac80c5b6b5b2b0c4aa9dd88e21096fafa1947351de1bc64c5f102a231a8bd4d8d7cf40acc72747f50d8fe1ae800f7aa85e0eed,"while(ptr->next!nullptr){

     ptr = ptr->next;

}

O(n),  linear time complexity",4.0,44
11900,11900,16124,db2da6294f4863255b8e851f3219cc1d358a9a52af31fcce04dfd21a77bd1b6105ebfb54ad3aa0cbea5dc9fb93c67b5af9e1ff40b17fbd626a20ad3636813679,I would create a temporal pointer that will point in the tail the iterate two times moving backwards and let the pointer to point at the item. this process will take constant time.,0.0,44
11901,11901,16125,ea2a1bfcbe729f7621c917f77c54d68d14594e336635f36baf52750af4fc628657adce12683b4083425f0f9b883a0f335d02fe57cab5815e5cb77320840dd672,We start at the back of the list and start by initializing the tail pointer to point at the last item in the list - afterwards you initialize a current to point at the pointer that is pointing at the last element that the tail is pointing to. Then you return the index of the element that the current pointer is pointing to. This is done in constant time 0(1) because with the tail pointer we'll always just need to do the same operations no matter how many elements are in the the linked list.,2.0,44
11902,11902,16126,7f5c90bc96b8c221313ac508a43f033a9cfd125b9a640028ec5de2c16d24018446de1823b9e0fbe3c2dc3484e86b2c9f0b03562cf165d778f49b41194d7ad86b,You use the end function to get the second last of the list by using using the get_link() functionn then you return it's value.,0.0,44
11903,11903,16127,97a01199b925330f29640cdb86e45eea363ff96eb767b66ea518348ab8ed24fd59b309226c6a592a7f7ea6b67fef81cbfd1daad02d4a32f29300da894c457dc7,"Link *prev = nullptr;

Link *curr = head;

while( curr->next != nullptr){

prev = curr;

curr = curr->next;

}

return prev->value;

O(n)

the time complexity is Linear",7.0,44
11904,11904,16128,d79246b4e37ca7cbd7cba0e73e77371bc01ee0686edc183593c8b72f08af7f56885ea93e866878670f104cfe50f22453d301d67ae7614531bda51a9f07fc7424,The tail would not help you do the operation any faster as it is a singular linked list so u can see the previous links in the list only the next one. You will have to iterate through the list while the link is not equal to tail and then display the last link from that loop as it will be the second last item. It would still take linear time as it has to iterate through the list n-1 times.,8.0,44
11905,11905,16129,67ade1890555ea7d6de913382858973bf82ef717e817e6295020978c59105278650d1bd8b5c2d42daf06ff2292f0b1f4096f4f20a6d3a8a92a4f522b583d867a,"I would declare a pointer called currentPointer and initialise it to be equal to the head Pointer. I would then update the position of currentPointer in a while loop for as long as currentPointer->next is not equal to the tail pointer. The position of currentPointer would be updated to currentPointer->next in each iteration of the while loop. When the while loop is terminated , the currentPointer will be pointing to the second last item, hence the objective will be achieved. This will be done in linear time O(n) due to the number of travels depending on the number of elements in the list.",6.0,44
11906,11906,16130,ca4ce15f201976aa63a06e9835ef2e7535f6e333ebe0b9e476d73f4ab1178f67e681ce79854159f2adbff73408c26875c5932413ad1732fdf68f9e1d442831d7,You would traverse through the list whilst checking the the pointer after the current pointer is not null. If it is you have reached the second last item. The complexity would be O(n) dependent on the number of items in the list = n.,5.0,44
11907,11907,16131,d5eef99882213e9e893ef6d31b163cddd65b11b328a038af368c63b9dea5c55582d674f73b7f44a7ffb0e808a2c14f224354666b5c8da68a3cf145583cdbcada,"   

To access the second last item in a singly linked list with a tail, you must first create two temporary pointers. One pointer is a null pointer and the other one called CURR points to the head of the list. Traverse using CURR until you reach the last item in the list. The pointer that is a null pointer can be changed so that it points behind CURR which will be the second last item in the list. The time complexity of the function is linear.

singly linked lists are unidirectional meaning they will traverse from the head to the tail pointer. ",2.0,44
11908,11908,16132,e5714a4c20e7bdae287b7c08ee230173a746342e508a1fdf6f9b0ca3985863c9a9c50fab8cf85194e61c4743030f16659c52ffd068494fd5d94fc6ea4ec382de,"In a singly linked list ,we know that the next of the last node point to the null,so we can find it by traversing.the time complexity will be O(n!)",0.0,44
11909,11909,16133,0210a9d3772d4f5814d5d585f47b6503d720f89ae8ca72b5fb7136f3da85dccbdba73ac11df998e73774b6321c99446733c7c479dc009a4e0dc92678413ef102,"int secnode{
Node* temp = head ;

Node* prev = nullptr;

while( temp->next != nullptr){

     prev = temp;

     temp  = temp->next;

  }

return prev-> data;

0(n) time.

     temp = temp -> next;

}",6.0,44
11910,11910,16134,0cd06500f6bc04ca04d6df402c164435dd4b1e3f62d49a5f81d45b91f4a6f4ac2ae8232fc2f485e2ef108625ecea2f61c466c82dcbccacd3d327b9b3b7efa90a,"The way in which I would access the second last item is by traversing through the entire list since the singly linked list is unidirectional. I would traverse until the current_link->next->next is equal to the nullptr. In this way the current link i would be at would be the second last one, and it would print it. But if the list is empty or contains less then 2 elements, it would return false. This function will be of time complexity O(n) since the function depends on how many links a list have and the fact that we always have to move through the list. ",8.0,44
11911,11911,16135,9723aae78697f512e67589fc396726b9c942a3d3f5596d681f9e90a55d7c7cee67b2655817396577b22474e4f116aa7866389d9d9a43a0c0e1dd45d6998cde32,"We would have to traverse through the singly linked list as the tail pointer will not help us in a singly linked list.
Create a temporary Link (node) called curr pointing to head and create another Link (node) called prev and set it to nullptr. Then create a while loop with the condition (curr->next != nullptr). If this condition holds, first update prev = curr and then update curr (curr = curr->next). Updating prev first will ensure that whatever curr was pointing to, prev will now point to it. The traversal will carry on until we reach the last link which curr will point to and therefore prev will point to the second last link (which curr was previously pointing to before it was updated).

The time complexity will be linear as you would have to traverse thorugh the the list n (amount of items) amount of times. ",6.0,44
11912,11912,16136,e81419dfc1d9569cd33a892060afd65b53683380b098be177940b37177a69388dbc26f4b88ae9117e614069eb6d29407e325e18a19fd38be90fa494f6adff772,"Since the list is a Singly Linked List (forward_list), we may only travel in a single direction (from the head pointer onto the link 1 and then accessing the next pointer on to link 2 and so on). So in the forward direction to access an item in the second last (n-1) list, we would have to create a pointer curr pointing to the head pointer. We would then have to traverse through the list until we reach the link before the tail pointer (second last) link, this would require O(n) linear time complexity. We could then retrieve the value of the item in the n-1 link which takes constant time O(1) as it is a single pointer dereference. Thus in total our time complexity is linear O(n). Having the tail pointer only helps with functions such as pop_back or push_back as we can now do that in constant time O(1) instead of O(n). However since the list is Singly Linked and thus has only next pointers (not prev) functions such as the ""at"" function would not benefit since we still have to traverse from the head till n-1. The time complexity thus remains at linear time O(n) for accessing the second last item.",8.0,44
11913,11913,16137,6accb08d7786944c71cd9b921787862856d4a3c42592fbffde311b7d0b92a8f983d0c4f430c2af6d29dc0b77bc121c3af33f1ea64f2b5de47c11c3122369896f,"I would have two pointers (head pointer and tail pointer). I would then set the head pointer to the first element in the list and the tail pointer from the nth position from last, to the nth position from first (for example we want the second last item in the list, thus the tail pointer would be set to the second item from the start). I would then traverse the linked list until the tail pointer reaches null (the end of the list). The head pointer would then be the nth item in the list (in this case the head pointer would thus point to the second last item in the list, as the tail pointer traversed through n items). The time complexity of the function would be of O(n) as it passes through n items in the list.",2.0,44
11914,11914,16138,336c0de60905df4ae163484013b5cc72929683b64ebae6f69a61ca7bbc767084419ba7cf9291246a9b63bc7e686a397f48c33976b41fb34999f9b50eee045aba,"I would traverse through the list and stopping at the second last item through a while loop ,like this:

Node* curr=head;

while(curr->next->next!=NULL){

         curr=curr->next;

}

this code will access the second last item of the list since the next link will be pointing to nothing, and the time complexity is O(n).",8.0,44
11915,11915,16139,833bd82b84984eac1561a2aa471c7fa8ce8fc83eb43410d162adbb99836f9c60ca90f110500d0a4cfae027c10757354954059b39ea510643c3c10d5e8f6e1bb9,"* I would have a temporary variable that will point to what the head is pointing to, and I would assign the tail pointer to nullptr, and have a while loop that will make my temporary variable stop at the second last item. I would make the tail pointer equal the what the temporary variable currently is and return the value of the temporary variable.

	* The time complexity is linear- O(n)",5.0,44
11916,11916,16140,feedd29892cd7ac7cbb3dcf2ebf122ea0910da8e729a40522cfec73f98427f11e38a2954619cb37c8da0cffc3dcb3d21b0fc9b9cb5630f1a8e01a0691d1d3af8,"int main()

(

    LinkedList myList;

     for(",0.0,44
11917,11917,16141,482f7dae015b4c467d12506c33e2fe66aeff1ddddb85f2c9bce0e0756918b84a46072cd434d5bf20b674533a59b9c793d9d747268246eec497aed1c0f31a1c3c,"I would transverse through the list using a while loop to the 2nd last item and return/access the 2nd last item

Link *tmp=head;

while(tmp->next->next!=tail){

          return tmp->next;

         }
OR

Link *tmp=head;

while(tmp->next->next!=tail){

          i= tmp->next;

         }
return(i)

This time complexity will be O(n)",4.0,44
11918,11918,16142,79e7d7f9dd31af42dafc3f30ed17b2ec3bfb7c371aeb90fda49a78ac5ff634413c5502ef51e48fca99485ebc6751e35a6357de07c8799c082943fd8aca0f76df,"The benefit of having a tail pointer is that we have information (memory address) of last link. So to access the second to last item we could use that information to get the pointer that pointing to it and show its value.

The time complexity would be constant.",0.0,44
11919,11919,16143,cb120576f9fc254cce2a2bdcc2fab8a2f95f1ad24a5398cde6a97bb68344852b25ff6ddb6448c5c344141e6c8f5ee1dd504e841ca984819c02a7811908c51bc8,"Link *Curr = tail;

cur = curr->prev;

return curr->value;

//time complexity is O(n) - linear time",1.0,44
11920,11920,16144,763a776e81302d0ca35787de395275bfa7dace1cb9ac6ce690e840ef2f280482559135e73ff9334c7ef80b3304e1f6061c108364e0e55bf5e56d4aafbce8e073,"The time complexity would be O(1) time

Link* curr = head;

while(curr != NULL){

      if(curr->next != NULL)

                return curr->next;

}

return curr->value;",0.0,44
11921,11921,16145,c1e9e5684a44aa14de0a7d7593ec9809b4c2858f861776d6d9a8b2df4bba9cc394db455eb7a58c49a19ed6c08dee2a5b9eba1e9f390b469640fea31d4ffda4c0,"There is no way of accessing the second last element in the Singly Linked List without traversing through the linked list, which implies a O(n) time complexity. 
This is because Singly Linked Lists only have a ""next"" pointer, and not one that points to the previous node (as in a Doubly-Linked List), hence there is no way of accessing it in constant time. Either way, to implement this we could write, using pointers of type/class Link:

Link *current = head;

while (current->next != tail){

        current = current->next;

}

return current;

The time complexity is linear - O(n).",7.0,44
11922,11922,16146,7f4b419d2ced93d50fb8649f87b2fa3a1ab4c6a1ecc8b63f150aeb372237c21eae97c5eba18c0880eb018ac5d3fb68e9a7180e8af2cbb1d90dc8d7f06f63f097,"to access the second last item, I would use two pointers, one will point to current node and another will point to the previous node of the current position. I will then move until the next of current is null, then I will return the previous node.

Time Complexity O(n)",7.0,44
11923,11923,16147,16751d82a0250cf90230a736276250ecd4342c2e9097f12ebacee397740771d03e925ee189c3aaacf702dbec6f3610c7e13e7ed44667c2823433286e585becf2,we would use the tail pointer to access the previous properter of the last node allowing us to acces the value of the second last item. this would happern in constant time.,0.0,44
11924,11924,16148,be31d5d430bb70d92105e501945893c26e6893599696162bc95d97dc68e8551bcabb0ec57e7e70881502e05fa1f8de1b8b173b3252cd099443fc870750db1827,"Link * curr = nullptr;

curr = tail -> prev;

This will access the previous link to the tail pointer and it will happen at a constant time O(1) regardless of the amount of links in the list.",0.0,44
11925,11925,16149,18821a50a643c1101d4d4b4a20eab092e9ef83d83d66cc8b476254122713205813222ecc2114e01a4fff80d19f68cc23c5bc386f899d5730224a2f35e7ae4a2c,"The tail pointer would be pointing at the last item, so to access the second to last item we'd need to simply refer to tail->prev with time complexity O(1), but because this list is singly linked, we don't have access to a ""prev"" member in the Linked List class this means that the tail pointer will be useless in this case.

So this means that in order to access the second to last item, we'd still have to traverse throughout the whole list till our desired item. This will make our time complexity to be linear O(n).",7.0,44
11926,11926,16150,f83dd55ad9e075a60c5134f9bf47ed3397e5224c478fcc48237d4341af57f9ae0b4893b2d9bfdacde4458f44d6dacdaedccfab297dd76d28c1d773deaaf399e4,"Start by traversing through the linked list so that we point to the last node which is the nullptr. Create a temporary node that, now the nullptr points to the head of the temporary node.Then the temporary pointer points to the prev second last node ,while the tail pointer is pointing one step behind the the current pointer pointing at the current position. and thus we will fetch the value pointed by the tail pointer.

Time Complexity Is Linear O(n).",2.0,44
11927,11927,16151,7db17fd2acfdd980933bf2f92abec54feac68e8b60f672ae1ba7781b8dd15de47315f37d74c147384e68a3a01e88e6539391471e6490908578bb1e2cdf85e7c7,"Link*tmp=head;

while(tmp->next->next!=nullptr)

{

tmp->next;

}

return tmp->next;

this tskes linear time 0(n).",8.0,44
11928,11928,16152,c7fddd77b6fed9bc15d19de2718acf9bd47e63c47fabc90953d259ee95b77d6203c59c32fab4eab8591fe4a7373a9aafae0952036c94bc9ebef7955717c99e00,"I would access the second last term by traversing through my linked list and take the element that is at index  (number of terms -2) and this would time complexity of O(n) 

using code

Link*cur=head;

counter=0;

while (cur.next!=nullptr){

cur=cur.next;

counter++;

;

  Sec_Last_Elemnt=data[counter-2];",6.0,44
11929,11929,16153,e8cc8f379686cf17ff7a79c51f234b372a7158c41925760d6a62468ac2bc253c196a10ef5af7f8e787abc174ba6435f331d902d6901bc07bc87271a8d067f35c,"I would reverse the Singly Linked List so that once we have the reversed list, the Tail will be the new head, and the original head will now be the tail, having a null pointer.  The second last element in the original list will now be the second element in the reversed list.  I would then, starting at the new head, traverse through the linked list to the second element.  The traversal will always be constant because no matter how many links there are, we always traverse to the second link.  However, the reverse function will have a linear time complexity, as the number of links to be reversed in the list depends on the size of the list (n).  Therefore the time complexity of the function would be O(n).",8.0,44
11930,11930,16154,8278e2d003c29d98e8cfc7117cefa90b7503054f5b50b162eaded6981387fa2f1b8b8f0ae2fa0d58942ac81f9cf7fda1cd474d106727d602bcd9f2d647883b50,"    void reverse()
     {
         
         Link* current = tail;
         Link *prev = NULL, *next = NULL;
 
         while (current != NULL) {
             next = current->next;
             current->next = prev;
             prev = current;
             current = next;
         }
         tail = prev;
     }

void print()
     {
         LInk * temp = tail;
        temp=temp->next->next;
 cout<<temp->value<<endl:
} 

Time complexity of reverse would be O(n) ",2.0,44
11931,11931,16155,379090fe3e1a52426e2efa659f8053df23496a4ea586e166878cbb0762b73fc0c775123cfc178af91eb03c2a90701a95a01965d904e259f9143a2034f3310380,"class Link{

    public:

    int value;

    Link *next;

     Link(int v): value(v), next(nullptr){}

}:

class LinkedList{

     public:

     Link *head;

     LinkedList(): head(nullptr){}

     ~LinkedList(){}

};

int main(){

LinkedList mylist:

Link *curr;

Link *prev;

curr = head;

prev-> = nullptr;

while(curr->next != nullptr){

     prev = curr;

     curr = curr->next;

}

return 0;

}

Time complexity would be O(n)",8.0,44
11932,11932,16156,d5a3f7d660aa30769e68a7c616a4942c8f05f0c2e034be1b4e61932df724917fd2a406f53a34e25ab412791ed6463a16ef1b087d401683c22430b89ba7a21be9,"Link *curr = head;

for(int i=0;i<size() -1;i++){
curr = curr -> next;

}

O(n)",4.0,44
11933,11933,16157,0425e17b97b62d847bfbb7a5f37fa98ed826dc582b46528b4a148c459379ead81390caacfd23b1628779d134c7092014f555b05833c612700ef174bd131b6587,"link* curr = head;

if (curr == nullptr || curr -> next == nullptr){

// throw an error

}

else{

     while (curr -> next -> next != nullptr){

          curr = curr -> next;

     }

     // access or do something to curr -> value

}

Time Complexity: O(n)",9.0,44
11934,11934,16158,67bc8fffe61d28188b3d7107d51be90441e6dd51c98f3db877749a2a97847646dc952b6812856f170fac011bfccdf49477179e4f3e8c4e51b5aea238df99b414,"Link *x = head;
while(x -> next != tail){
    x = x ->next;

     }

The time complexity is O(n)",7.0,44
11935,11935,16159,4d5583055b5cf0ef4bd7f80832ec9b8940eedb6261741378493c7c1e768d88d15f96d3b8d5850288f3731056d59b3dbe1878b8c16bbb307054b4401de38adc38,"I would read the address of the tail pointer to find the last item and would read the next value to find the address of the second last item to retrieve it. 

Link *curr=tail;

curr=curr->next;

curr->value;

It would take me constant time as no matter how many items in the List I always have a pointer telling me the address of the last item and the tail can take me to the second last value",0.0,44
11936,11936,16160,e1db971413a3e8370e48a08bd90e6c532854614ec97bf2846a8b6f64d7d2d64fceb404c5b40a925c2c496078dab9556b9aedc866e91bea3a7a6a8dc8cc19eb5b,"A singly linked list would only have pointers to the next item, therefore, to get the second last item in the list you would still need to traverse to access it since the last item does not have a pointer to the previous one. In the worst case, the list has more than two items, requiring a traversal through n items, the time complexity would be O(n), linear time. The best case time complexity would be if the list has only two items, then the time complexity would be constant, O(1).

To access the second last item, traverse through the list using a pointer, stop when pointer->next->next != nullptr, then access the item. ",9.0,44
11937,11937,16161,c4c2c137f4d09a740b1294afb17fe688d9891bca471136eebcbf46a7f61b0527136ab092a90608b5c573cd06db378a8bca203b8fa5cda62d61e93ce21bb7a858,"Link* tmp = tail;

for( int c = 0; c < i; ++1){

    tmp = tmp -> prev;

}

return tmp;

The time complexity will be linear - O(n)",1.0,44
11938,11938,16162,50ac02db01dc47f0f24bb2a0e8bc1bebe3aac1ecfe652f1c87b260f45da4def0a267392e043e67a0b0f3a39374188322db34615d5257a196fc0978d4d004e1ed,"if the head is pointing towards what the  tail pointer is, then there is no second last item,then the code should return an error

else:we should create another pointer (Curr)and initialise it to point to what head is pointing to,which is the first item. From there create a while loop.Inside our while loop the condition should be that (while curr->next!=nullptr) .If (curr-> is not null)then we must move to the next node.If (curr->next==nullptr) then  the the code should return what our pointer Curr is pointing to,which is the second last item.

The code should take a linear amount of time",4.0,44
11939,11939,16163,4427e3a6ae2786ed5636c638581416e62adf38c90aed72214004ce5b4fc79bb1e5696556f9677084defd90b33f5cf052534401db22ff6a075c7131169ee1bcf8,"We'd have to traverse to the second last item because the tail pointer points to the last item and we cannot move from the last item back to the second last, thus time complexity would be linear since it would depend on the number of items we have.",2.0,44
11940,11940,16164,72f8819c651aefda92260fa4f547f14f555e14f647747df897695708c9fa1a2f437da4d45f5b0c59c6c67b9f7f70e1068df3448aebfbb9759e5038bbc8c29ccf,"Link *curr = head ;

while(curr->next->next != nullptr){

    curr= curr->next;

}

curr = curr->next;

O(n*2)",4.0,44
11941,11941,16165,c0e222e387522491c144bc66b8d4aac6d8899881b15676a75bd42f6939be2d68b02062c035d5f028531cde71d4b0b2bb7581d5e165c7c3be11bd4e67e796913f,"Use the size function to get the number (n) of items in the list, then use the 'get' function to get to the last node (n).  The second last node is next of the tail pointer and use the 'at' function to get the item.

The time complexity is linear O(n) :

size() is O(n)

get() is O(n)

at() is O(n)

tail->next is O(1)

adding these gives a linear function.

LinkedList Mylist;

int n = size(myList);

*curr = get(n);

curr = curr->prev->next;

item = at(curr);",2.0,44
11942,11942,16166,6ce5c22e2014cf62c3f9857f1a5d029cd8403915d5de52ffef745d92a330418a129b81b3d1fc019ceb103f7414cb06b86a44ab05670ba63e692007c026c9822e,"Link *tmp = head;

  if (tmp->next->next = nullptr){

    head = head->next;

} esle{

while(tmp->next->next != tail){

    tmp = tmp->next; 

}

return tmp

}

The function would be 0(n) time complexity ",5.0,44
11943,11943,16167,202c8344f9f859aa64da3cc8ceffb88155f17aa53a21d20d5da4fef5e39546500eff34cbff57a9c00ff1871c748bb37a08181469555e6609e93120b6d7b83edc,"tail will have nullptr and its value...hence..
To access second last element...one would the at operation to get the second last item in the list 

time complexity is O(n)",2.0,44
11944,11944,16168,55ff8d4f9ee8af9848a55dc4a2a3322adb850c959c61827806d583f4f72e4caf8076da8ae41627b21a0edd1eccee2cd496b303fbcb256d41e8ba6c3b55c02e66,"The time complexity would be O(n).

You would have a pointer initially set to nullptr and another pointer pointing to the head.

You will then have a loop that will traverse to the end of linked list which will be terminated when the pointer that was initially pointing to the head becomes a nullptr. 

The pointer that was at first a nullptr wil store the value of the previous value as the loop traverses. 

Finnally you will have the second last item of list.",2.0,44
11945,11945,16169,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"I would use the get_link operation to traverse to the second last item in the list.
I would start at the front of the list and move from link to link until i get to the second last item.

It would take O(n) operations.",4.0,44
11946,11946,16170,4bd03f3c8f89617686a3536f1302b8ad51345512ea9473aae1ca497c4f25a59a5466e4df9b3e8a550246d3f93ec44b2398abe8c256bf5d3e51474d7b6863abb1,time complexity would be O(n|),2.0,44
11947,11947,16171,f1ba85bcb3cb35dd3a5763fa5946a3ff7df7d0bf7beb3182d0ecb801d8abdf353d4eeb7909c0cc4e94c0d221fea7a7c70e57bb1e1c70aaf71f4a7a0e8fe5269d,"If the tail pointer is known, one could access the second last element by returning the pointer that points to the node containing the tail pointer. This changes time complexity from O(n) time to constant O(1) time.",1.0,44
11948,11948,16172,400853532d18057c486e48e90c2e3817295b0b8da4abab44abf1f9dd692996bce343aa72b93713cdef71a68aff30879c7ec75ca8ea25a59fd4c48084879663a5,"Link* curr = tail;
for (int i = 0; i < 2; i++){

     curr = curr -> next;

}

 return curr;

This code will do O(n) operations.",1.0,44
11949,11949,16173,7034e661a6b51c59ff4e839b7430fa79082c9a14de4d5507d8b8f51bcf2e8507159f0b9ac4f2f0968d640ca40b95ebbbfcb9a489ff8f5bfe6ee49d4e9a458d5c,"Link* curr = head;
while (curr->next != tail){

curr = curr->next;

}

secondLastItem = curr;

(Traverse through the list until the current pointer's next pointer points to the tail pointer. The current pointer then points to the second last item in the list).

Time complexity: O(n); 

(The time complexity would be Linear).",8.0,44
11950,11950,16175,e1c10c192c9b6713ee5530dae2906c490884e9be67695456a693eb32bfedb4efb69953c8625279092ed97ffe2902abb90cc745c3952924b4e2ed73997890c89f,"I would loop through the list from the Head with a For Loop, going until LinkObject->next = Tail. The time complexity would be O(n).",6.0,44
11951,11951,16176,8a35389fd7c8ad2535687771b1bb68c8efb0b7de8dcab378f3a060f04342ee373ba7cc2c9fd072651f8268858486a9bd9dd5269dda1258346fc90ac33d038576,"We Will still have to traverse through the list with a ""curr"" LinkedList variable until the curr->next->next is the nullptr, as it is a singly Linked list(we can't traverse backwards). In this case the tail pointer won't help us. The time complexity will be the O(n) as it depends on how many items are in the list.",8.0,44
11952,11952,16177,0cbc810c065e1ea82d7b36219a5e375cbce8ff096ba3665c665a2eb1c6f0befa244bcbe226b2da5880d6b84bb7f0100310c96f80f96a3b3863c5c650f01ebc3d,"int main(){

Linked List my_list;

int n = size(my_list);

int i = n-1;

Link * get _link(int i);

return 0;",3.0,44
11953,11953,16178,0ddebbd83df885f86ba1c96720608778be815c854a9f153df224b96b22cf260eb651e6e1d04778d3c06f6de0d3c75049a5f3bb4b6575599d6f50e21a7074d16e,By creating a temporary (tmp) pointer and traverse through the list while  tmp->next->next != nullptr..... then return tmp.value;,4.0,44
11954,11954,16179,61263672c5c532106e7f21122dcaab559eafcffe3f9da40ef6a4194409e8f1be9b62145c70c7a6a62ca846b85c63f3fbde4504110d16d1088e8621a2430bcdec,"int searchforsecondlast(Link *head){

Link *current = head;

Link *previous = nullptr;

while(current->next != nullptr){

previous = current;

current = current->next;

}

return previous ->data;

}

The time complexity is O(n).",7.0,44
11955,11955,16180,d262858bac7cd6476e0cd48b8622c751312997fe7fae4adba9c98bf17ceadac187d9de2b401de3d1895e85edc24940f00a102bf214f436104f37cd1b8669240b,"Link* prev;

prev->next = tail;

O(1)",0.0,44
11956,11956,16181,dc1d80fcfca2cd7f4c0d66c0e3645622562d53654a85ac238b9c0b928dfd07eeca15aea65682a467ac6bd4135a13a6043d96321ee55136fa0664700d6e749201,"Check if the current node is the second last node of the of the linked list or not; that is, if(current_node->next-next==NULL) then the current node is the last node.

If the current node is the last node, print the node otherwise move to the next node.

Repeat the 2 steps until the second last node is reached.

The time complexity is O(n) ",7.0,44
11957,11957,16182,bacea88b3884d2acdf5b94b564c3ec6827ffca9c96b92221f37418e3f06607a9773dd54e02efe11a3f31dcc55f103233551301f8c7dbd6ce23f465133edd2ef3,"We need to start from the front, which is the head, and traverse to the second last item. The function to use is the get-link, which will get the ith position of the second last item. So basically, we will be traversing from the current ith starting from the head, and go to the next i. Then check before reaching the next link pointing to the null pointer, and return the value of the second last item. Since we will be traversing from the first link until towards the end, the time complexity is linear, because we will be going through every link until the second last item.",5.0,44
11958,11958,16183,fd0ace311926a44973b18eb55c0a2df285cc4ef58cf67836be1c2719041ca75111c81115da37e4e4879d8c00ffb63db68cb0de1c85a3fc373724acf7945dc463,"You create a temporary node that points to the tail, set the tail to NULL and then the node that points to NULL to be the tail then delete the NULL tail by deleting the temp  node, the return the new tail which would have been the second of last from the initial Linked List. The time complexity would be constant time. ",1.0,44
11959,11959,16184,5c96945f14d6fc788ed8c6c36dabf314debb1526e588422f61ac844f148e394c747509da6ebf3fac148319b89d19dab295d5360db7c4991b8db71ccf538d7808,"Link *curr = head;

while (curr->next->next != tail){

curr = curr->next;

}

O(n) for time complexity",5.0,44
11960,11960,16186,3dc26b747d97da3ab4afec05ff58fc24d9456624d1de4e773000cee11c5770c4305e55aba8a358eac1e51ad690a762f5e637a6ce6a5554139fe18ecd7662a5af,"By traversing from the head through the linkedlist to the  second last item.

The time complexity  would be linear time as it depends on the number of links the Linkedlist contains. O(n)",3.0,44
11961,11961,16188,a37e8cb6bec1612d5c3aa242e7b3e8cea873cb6f52435ece79359c13b8144256dc3d86709b38c13890622651a1bea3e2d4c9e9d39d9c4884e7ba93253dd09e29,"Link *tmp= head;

tmp=tmp->next;

O(1)",2.0,44
11962,11962,16189,6ba5306b04bb1c19ff5f5148036844fc07d1e828c1c4bdd9a403971c63a75670cfd9507d856d67663bf299025ddc744dc1aab73fcc8ad24aa24659b96dc9ae8e,"To access the second last item in the list, I would still traverse the list. If the list is empty or has only one item, I would throw an exception. Otherwise inside my while loop that iterates over the list, i would have a statement say if(current->next->next = NULL) then current is the second last item otherwise current = current->next, meaning move to the next item/node. The tail points to the last item, so we can't use this to access the previous item to the tail since  the list is a singly linked list. It takes O(n)-linear time to get the second last item of the list.",10.0,44
11963,11963,16190,ba47d803e26988b75d891eb0e76061b355587a9834711cd75248db6b2b1c6cccc9c5cadcd161a1c0dfe6bd2d1a8b1014e37dd57461b73e39268808ede1fe4392,we will have to traverse to the correct link in the chain.Starting from the front we point to the head.Then the pointer(e.g)(Curr) will point to the next node. Using a for-loop we can iterate with increament to the index we want until we get what we want and get the value we need). we ndifference steps so it take 0(n) time(linear amount of time),7.0,44
11964,11964,16191,4541bddfe14df82661aaba793d25bb038432ba934014876821269e81b4029af8b6064a54828f0509d14ee3f303c32ee014b7221977ad133bace3b01a694e694c,"The time complexity 
The time complexity would be 0(1) Code:",0.0,44
11965,11965,16192,a3989cc4476b1bbce9e79b34c3f0337ca13c9717a610fbe24ad51e9bdb052f2d445313904842463b1a859cd4d281ce72b5f85b0423f33b62cab82318e4116232,I will transverse to the link before the the last link using get_link function.  And then return the value stored in that link. The time complexity will O(n).,4.0,44
11966,11966,16193,b722c8fd9eec42aa602e4cbd2ceee62645727f2b19607bd1bed826053b9d70a2c8e8d845bbe5119d6c5e8f3413efde7438ae5ec2d12a60cf1215dd59daf4a367,One would access the tail pointer and find out what points to it and then access the value of that link. This would have a time complexity of O(1).,0.0,44
11967,11967,16194,eaeebfd434a43156f3712848577d3a5da6499b6e1784e16a24ab5777985e6e2eed30ffc0a110ed246a9badfba660cd9a812c4ed7d173d1a29f7e115ce4ad58b1,with a tail pointer we can use tail->prev to find the second last item and this counts as the constant time because we did not traverse through the list we just called it using the tail.,0.0,44
11968,11968,16195,4a10096efbe473298c3ffaa590c64747a3f122d6138157d16b669b6d6757b1ee312e247b5d7de57197c1100b67d525e21d2bdf5719b1e5397849be3138642057,"The only away to access the second-last item in the list is to traverse from the head pointer (assuming there is a head pointer) until the item before the tail pointer. This head a linear time complexity, O(n). 

i.e.

//making a pointer called curr that points to head

Link *curr = head;

while (curr->next != tail){

    //traversing until second-last item

    curr = curr->next;

}",7.0,44
11969,11969,16196,89502ac0aa9bcc7e1f53c6f2ab1184a643f5c96abf038408f562f5cb7340154d0c96d136d3c4ce774773aa13f3d95a0a98c70e80020a05dce05a8835fe30adf5,"int secondLastElement(Node *start) {
   Node *curr = start, *prev = NULL;
   while(curr->next != NULL){
      prev = curr;
      curr = curr->next;
   }
   return prev->data;
//time complexity (1)",6.0,44
11970,11970,16197,571f4b857c687d9d563078992ce0d593248d2c9f52df5afb071f8e300cfd009d7831df6cd94d1fdf3131324af503b103a8881171137c2ca59df7ead36faf3f74,"I would create a pointer and set that = to head.  I then run a while loop with the condition set to pointer->next != tail. In the loop you have the pointer = pointer->next.

After the loop has run pointer is a pointer to the link before the tail pointer. This should be done in O(n) time",7.0,44
11971,11971,16198,1b575ce85f9fe9d462e1de73f4e66ff04c921a768d297956a2d166b33e02a5691d14de4e07fdb716975b3003397dd6ecfd657024c0a233117dfee4b6480ebdcd,"-> I would access the second last item by traversing through the list until (curr->next->next = nullptr) as there is no prev pointer(not a double linked list therefore cannot use tail to traverse backwards).

-> The time complexity would be O(n) as it will take me a linear amount of time to traverse the list because of the (curr->next->next).",8.0,44
11972,11972,16199,798235659bb9174e71b3ff61763ec292691ece6655d9ff85d1fbb65ede38be3c46ca62a6d523bf01e0f519090370eeadd560efded9ef16231507d4492e919473,"1.Create a current link to traverse the linked list.

2.Make the current link point to head of linked list, so we can access the linked list.

3.Create for loop that will n-1 times so the current link can traverse.

4.When current link is at the second last value, return the current links value.

The time complexity will be linear.",5.0,44
11973,11973,16200,a4513e9eefe06c5d06cd544fbaa5db795547b8f01893c660dc4a8e31a77cbc61bded840bbf0b3fd52a94491adbe0a21a3d4396c46fe19d46198e8b7b21695be6,"First create a temp link to the head (Link*tmp = head)

Then setup a while loop with the condition of (tmp != tail) to traverse through the list

then use an if statement with the condition of (tmp->next->next == tail), this will make it so that we know if the second number ahead is the tail or not

if the condition is met, then just return (temp->data), else, set the tmp to (tmp->next)",3.0,44
11974,11974,16202,7c939bb7eae30ac9fde6bed7ba91e751cb79bad249785d6c36230c4d9e80b55aaaf08d983990b398d630a07852718c75269fe0b377bbd248cf1db616b416f57e,"Link *TMP=HEAD;

Link *CURR=NULLPTR;

while(TMP!=TAIL){

    CURR=TMP;

    TMP=TMP->next;

}

return CURR;

O(N)",2.0,44
11975,11975,16203,dec98074973763aa35f767e29ff1a337a2f96e27f7bb719852891850a70e146d6ceeda2c5cff7d622832dba02534fa96620c763e3c53dc17c1734a3ec63ba166,"since it's a singly linked list with a tail pointer, it means we would traverse through the list from the back instead of the front. Since the tail pointer contains the last link in the list, we would only have to traverse (ptr->next) once to get to the 2nd last item in the list. 

Because we only use this one operation, the time complexity would be constant ( O(1) ).",0.0,44
11976,11976,16204,0c11d203426fce7b3dc05c5b901a557cc9648e7fd3384bd9d8800631c383636176c5236339b82c8cac354a014c4e904c016c4f55b6e4ea8b971819143c0b5cb5,"Link * curr = tail;

curr = curr -> next;

return curr->value;

O(n)",2.0,44
11977,11977,16205,23b5a4e63c9fefece084783cc1411977943e7d8d3612a093af2540d5bb113a4845b418786034d0d238575bbb9fe95d816e937dc9fe084e3f124b6dcce8457f10,"Time complexity would be O(1) [constant time] since one won't need to go through the whole list but just to the second last link/item.

To access the last item of a list, one would use the get_link function and use the tail pointer as reference.

To use the tail pointer, one would need to know the size of the linked list. Then, go to the second last index number.",0.0,44
11978,11978,16206,6398cd3a19a3d471bc5a210dfd041039aa199f2840055e48507502bec88a8f8eb3f128de790430daa8207ba0fde7dea8a8fb8416bcb584e1bb9e76ef88b1e1f2,"if (temp->next->next == nullptr){

    return temp->data;

    temp = temp->next;

}

0(n)",3.0,44
11979,11979,16207,bec70f18652f9b1ec67ee94e23471083fc0530aad868499d925d500e71ccfd4f82652eb49a909778379c4583e97ce1464a3ae78de3b07114cb3a9e4c1179d625,"The time complexity would be O(n). In order to find the second last item in a singly linked list with a tail pointer, you would have to traverse the list until you reach the second last item in the list.",3.0,44
11980,11980,16208,c927373e71fe30f4255c61610bb88cd9a4bb26b4d4a5c6bc2711f05bbe84ffcf49fd97d920d1a706ea1e91d40784c2fadbc56f95b4fae450f318d7610a7daca1,"#include <iostream>
using namespace std;
 
// Link list node

struct Node {
    int data;
    struct Node* next;
};
 
// Function to find the second last
// node of the linked list

int findSecondLastNode(struct Node* head)
{
    struct Node* temp = head;
 
    // If the list is empty or contains less
    // than 2 nodes

    if (temp == NULL || temp->next == NULL)
        return -1;
 
    // Traverse the linked list

    while (temp != NULL) {
 
        // Check if the current node  is the
        // second last node or not

        if (temp->next->next == NULL)
            return temp->data;
 
        // If not then move to the next node

        temp = temp->next;
    }
}
 
// Function to push node at head

void push(struct Node** head_ref, int new_data)
{
    Node* new_node = new Node;
    new_node->data = new_data;
    new_node->next = (*head_ref);
    (*head_ref) = new_node;
}
 
// Driver code

int main()
{
    /* Start with the empty list */
    struct Node* head = NULL;
 
    /* Use push() function to construct
    the below list 8 -> 23 -> 11 -> 29 -> 12 */
    push(&head, 12);
    push(&head, 29);
    push(&head, 11);
    push(&head, 23);
    push(&head, 8);
 
    cout << findSecondLastNode(head);
 
    return 0;
}",7.0,44
11981,11981,16209,a41ff85d7c3f46c972cdda9b8d99297a4177ec80aa4a317631762cd6ae04cc877e3ccd31e4fd09e41eccdaa2cd1266d20e5947fd82dfa31e5b04a9f5e1bd8e0c,"First, after checking that this is possible (i.e. the list contains at least two items), declare a Link pointer called curr and set it to point at the first link in the list (i.e. curr = head;). Traverse through the list, stopping once the link curr points to is the tail pointer. That link is the second last link. Then return curr->value to access that second last item.

[if (head != nullptr && head->next != nullptr) {

    Link* curr = head;

    while (curr->next != tail) {

curr = curr->next;

    }

    return curr->value; ]

The time complexity is linear i.e. O(n)",6.0,44
11982,11982,16210,2f2bbc70f8136ca3b18457b652aa1d5317919459278da63d7273a5c4e29eded00275f14d0a5826a3efa0a4d6a86ce51a6129f3ba53f25a66bc7e4755b291485f,"You would create a temporary pointer (p1) that is equated to head and another temporary pointer (p2) that is equated to p1. We would add a a while loop and while p1->next != nullptr, then p2 = p1 and p1 = p1-> next. By the end of the while loop, p1 will be the last item in the list and p2 will be the second last value in the item list. We would then access and return the p2->value. The time complexity would be quadratic O(n^2).",5.0,44
11983,11983,16211,7b7f96fd3054bc9ce669e171530b421da5c4602ee50caf165895714d7c3b27b449d7dfd61e80faaf4431d24ebf5c471203cf58c62fa66a62c91b19647df9ee48,"I would traverse through the entire linked-list using the at operation and the getlink function .the time complexity would be linear.

at (int index)

  link*curr = getlink( index );

   return curr> value;",2.0,44
11984,11984,16212,8ccaa62cbbe76ea20aad42f0abeb4aea6b057f35352db9aef1c4c8bb791949070df63d7ca3789507be754a64de8d3383c759c83cb767d9e10e045b387bce8a09,"The idea is tp traverse the linked list  by:

creating a function that checks if the list is empty or contains less than 2 elements , if yes it will return false. otherwise check if the current node is the second last node of the linked list or not that is ( IF(CURRENT_NODE->NEXT-NEXT==NULL) then the current node is the second last node\item.

if the current node is the second last node , print the node otherwise move to the next node

then i will repeat the above two steps until the second last node is reached

int findsecoondlastNode (class Node*head)

{

if (tmp==NULL || tmp->next==NULL)

reurn -1;

while(tmp !=NULL){

if(tmp->next->next==NULL)

return tmp->data;

tmp = tmp->next;

}

}

the function will run in time complexity of  : O(n)",9.0,44
11985,11985,16213,d2c94c0dca7decb41292af9de73a32afa110cab818c0e296b000bfe9dd7b6bf221a0332e01f53ce869a1f4affd4abbea90b7e61d9504a5178a430b94bbde20af,"while (tail->next!=nullptr){

tail=tail->next;

} //push the tail pointer to the end if its not already there.

Link * curr=tail;

for (int i=0; i<2;i++){

curr=curr->prev;

} //curr will contain the second last item

Time complexity of O(n) if the tail pointer is not at the end and time complexity of O(1) if only accessing the second last item is necessary.",1.0,44
11986,11986,16214,9082e5ab0ae09b23b5e0275a763493886db0b7f721520ca423ce3577e6b6ec09537f5d0b22aac121f7604a542a413dd81640198a15212f5aa5403c721b42c11e,"To access the second last item of the list we use the arrow operator and say tail->prev so we can get to that second last item, the time complexity of the function will then be Constant time complexity because we did not traverse through the whole list but just called the tails previous item using the arrow operator.",1.0,44
11987,11987,16215,0a640b06ce1d454be947795a6308fcfcc73f66b49b60199788f434bf91f3e08719c4b7dee42514e49b76fea543dcbe6b2a18d9de0cfa87cc5f82c989cd2f76ff,"Thing &LinkedList:: secLast(){

Link* temp = head;

while(temp->!=tail){ 
temp = temp->next;}

return temp;

}

O(n) time complexity",3.0,44
11988,11988,16216,5ad20b3b420c21e1fc2861df4f4257210672d867b8a024855b258388d20148643f1a94c77f0aa2d4b47f8fba4b85741287207442ff519080915f15fdfd0e21b1,"Since the tail pointer points to the last link, there is no way of accessing the second last link through it as this is a singly linked list.

We will have to traverse to the second last element with a while loop to access the second last link.

(data type)* curr= head

while (curr->next->next != nullptr){

        curr= curr->next;

}

The time complexity is O(n) time (linear).",7.0,44
11989,11989,16217,e627fede4d8a070ca528e22154030076326cf75a860ce09e9231ab5eb164fd945cbc3f05b7190cc8d307288292134d5c83514ef1ec1b1c4974bcf393c3c20f68,"You would have to go from the head to n-1 as the list is singly and not doubly linked, making the time complexity O(n-1)",3.0,44
11990,11990,16218,6c0c4055e14104657e8b2f93690d540761c32c74b87c67cb6acc284b0968521966239252478c024e2c1fdc28ec4e72c01b4f28c3de78e04b7bbf604f3bad167d,"You would have to do a full traversal of the Linked list. Checking if the .next function is equal to tail pointer if so, then returning the function i.e. the second last item. The time complexity would be O(n-1) = O(n). Because it is singly linked you cannot move from the tail pointer, therefore requiring you to start from the head and move to the end.",7.0,44
11991,11991,16219,dba55105f290263eab690cc35467de21c1485b240568356b922de9e4385ff6cd7f9c33bdddf55cba48dae5962652c3708da244fefbb69455c6e660d7de9c7d15,"Create 2 pointers.(t1,12)

make t1 =head;

while(t1->next != nullptr){

t2 =t1;

t1 = t1->next;

}

delete t1;

when the code is done u can access t2 to get the 2nd last item in list.

and it is quadratic.",5.0,44
11992,11992,16220,a483d97f2f6f4b566a91dffee7b0dc51b69866d7a50c6e53308e166eaac8f5373cd9dfbf9a10c25bd5d41a415c716306b0d1e020a1acf8282aad769edfdcc9c4,"To find the second last item with a tail pointer we can use the arrow operator as follows tail->prev and this counts as the constant time complexity because we did not traverse through the whole list, we just called the tail and traversed once to the back to the previous item.",0.0,44
11993,11993,16221,ab943cfa0d926aa21911a9961743ce4779859ba20a4ac4e15e75033134ef20f2d090435e99a19a4b2beb23e354a8983d0355213a926be357504dc13138c83605,When there's a tail pointer we can make use of the arrow operator like as follows tail->prev to find  the second last item and this  will be constant time complexity because we did not traverse through the list we just called the tail and traversed once to the previous item.,0.0,44
11994,11994,16222,efa2c5b70f1ad8f0aebabd9a8317831d8e117c559aa0a29951f0659587ce28ce45a8ffe00e2d128d5b1b92e6f8033ccb1e7464d9f2f119aa95332037f62a3b76,"0(n)

Link* curr= head

for(int i = 0; i < n; ++i){
   Link *curr = myList.get_link(i);
   cout << curr->value << endl;
}",0.0,44
11995,11995,16223,3bd9fe37c1b0882728ca1d33a5ec95f5cc07ddfc68344ef642e52c5524e606feb184feaacb0fa6a93f01d38c076143e100f14e83fd9a44496f54705394ea6bd8,"1. if the list is empty or contains less than 2 elements return false

2. otherwise check if the current node is the second last node of the linked list which is (current_node->next-next==NULL)then the current node is the second last node

3.if the current node is the second to last node print the node otherwise move to the next node

4.repeat the above 2 steps until the second the node is reached

time complexity will be= O(n)",9.0,44
11996,11996,16224,6d04032d059678dcb346209e5f60e18a44d0c551ad3d7c0e551f1957033a386ffc9828dc7e1374b35e8828c43ed8d61ae22f6c2de063b8779cad31efc30f066d,we'd create 2 temporary pointers called (t1) and (t2). We then make t1 = head and after that we add a while loop (while(t1->next != nullptr)) then we would make t2 = t1. In the next line we would make t1 = t1 -> next and after the while loop we would then delete t1. t2  is now pointing at the second last item in the list which means we can now be able to access it. The time complexity would be quadratic.,6.0,44
11997,11997,16225,9b486d212bcbfc98bcb7006334a7bd057c017b3b5d6ddec828a1e7c71b279d57abf5933826cc5cd40f31ce09e30273c03c034afd55ad69a350c76adfabdffc7c,"Declare a new_pointer and Initialise a temporary_pointer that is set equal to the head of the Singly Linked List, and a previous_pointer equal to nullptr. 

I'd then crate a while loop with the condition of running until the temporary pointer equals nullptr. With the following contained in the loop:

new_pointer = temporary_pointer->next;

temporary_pointer->next = previous_pointer;

previous_pointer = temporary_pointer;

 temporary_pointer = new_pointer

and once I exit the while loop:

head = previous_pointer;

Time complexity:

O(1)",0.0,44
11998,11998,16226,1331f36c397a7f3ef0164ffcaa5260194b5155437532f6d6a3b90ce2b389bb384a64b370b55a6f3cf9d94a367da7f4975c8fca97863bc44aa2dda48a981d8882,"struct node

{

   int data;

  struct node*next;

};

//insert a new node in front of the list

void push(struct node*head, int node_data)

{

  /* 1. create and allocate node */   struct node* newnode = new node;

  /* 2. assign data to node */ newnode->data = node_data;

o(n)",2.0,44
11999,11999,16227,55ea1e4f47f56380767c8e74fc048f88ea3f77cbdba15f1928ce2c49d72fc6281a93cc53faad127cf63dd846a712edf93d7e45216338f7bc4ae6a26df95dd66e,"traverse from the tail pointer to the second last item (index 1) 

o(n) = o(2)",0.0,44
12000,12000,16228,07076ad9a7e3813bce19a739ebedaab894d1a330269763e0925227d8822b601591c19afe0ea5ecf81637c9b73f442db6cacafab2329d262fef0fb68d97bef78a," accessing the secound last element, I would initialize a link or node to point to what our head pointer is pointing to, let say name of link is equal  curr. Make a for loop that will stop when 

curr->next->next is equal to the nullptr. now this will traverse our linkedlist and stop at the secound last element, with an O(n) time complexity ",8.0,44
12001,12001,16230,c6919e466976b48c2f7b3823eb90c377fa8e67b3a290bcb3ab3a7c56083193c911bc05ef76e986e61a0a361e9ed5a7fec55840ba6afe1022bc97e18b5eabbeef,"Firstly check if the list is empty or contains less than two elements if so throw out of bond error.

Otherwise would traverse through the linked list to check if the current node is the second last node by checking the current nodes' next of next is equal to nullpointer. ie. test 

if (currentNode->next->next==NULL) if so then the current done is the second last node.

If the current node is the second last then return the node otherwise move to the next node.

I would repeat the above two statements until the second last node is reached.

The complexit is of oder O(n). as the traversal depends on the length of the list and will not stop untill the end.",8.0,44
12002,12002,16231,c879e65c8f9657768bbf6800906a28bff217c7ef9063d46acfccc25071a9fc3aef2ccd29821fdc92e96d2f98ca66aa74a3fa2a8f0df86509064e53b0fb9b54bc,"You would not be able to use the tail pointer to get to the second last item because it is a singly linked list and the last link will not have a previous pointer. You would need to implement a doubly linked list to access elements other than the last link if you wanted to traverse backwards in the list. This is a singly linked list and therefore a standard forward traversal to the second last link will need to be done. The code will look as below:

Link* curr = head;

while(curr->next->next != nullptr){

curr = curr->next;

}

return curr;

A traversal would take a linear amount of time based on the size of the linked list.  Therefore the time complexity would be linear O(n).",8.0,44
12003,12003,16232,a8dcc87a24b584021a1bb3ffd592a4ea66a1679acf3b2b41f26aef4e481760f4e64990e460e4e26ec12a8fef5d2354f5070843ac6e40f4a1e24bc122bfa91df9,"*Make a current Link that will equal to head of the linked list, this gives access to the linked list.

*Make a for loop that will loop n (n is the number of elements in the linked list) times.

*Make a while loop that will stop when curr->next is equal to nullptr (curr->next!=nullptr).

Inside the loop we will make curr=curr->next (as long as curr->next is not equal to nullptr)

*When curr->next is equal to a nullptr, then the function will return curr->value.

The time complexity is linear",8.0,44
12004,12004,16233,12066f8f6a7f4cd1c9586b77b6e85c69168c3e639d8a7cc579d0737f33e85026e0fc0bba1f43d9a6c097e420e073f5dd573d48b38e1cf440a6f948554edb9454,"_1.If the list(myList) is empty or has less than 2 elements than my function should return nothing(i.e return 0)._

_2. If not the above check that the current node is the second last node of the linked list or not(i.e  IF(MYLIST->NEXT->NEXT==NULL) ) then that is the second last item to be outputted. NOTE THAT MYLIST=HEAD;_

_3. If the above are not true, keep moving to the next node._

_code example:_

IF(MYLIST==NULL || MYLIST->NULL){

    RETURN 0;

}

WHILE(MYLIST !=NULLPTR){

    IF(MYLIST->NEXT->NEXT==NULL){

        RETURN MYLIST->VALUE;

    }

    

    MYLIST=MYLIST->NEXT;

    

}",8.0,44
12005,12005,16234,c0b5209a0b10c8dcfcb6cf4b7392c868a8a0f46868d7ead3603a66886d165a2ffbe1f975845aa3417da4caad2884f87961b388a20ee21c66a3e2d9cec38ed42f,"Create a new pointer ptr and make it equal the head of the linked list then

Using a while loop and comparing when the ptr’s* next next pointer would be null. Then assigning the current pointer value to a variable and therefor allowing you access to the second last item.

O(logN)",6.0,44
12006,12006,16235,2e87414379efcd8b6abefa082fd766ea6bbd6a7c49327da9b14527216de652d464a74ad3edb281cf63c53ec51b9a87c17ffe7ae230ea816e625650e59f9bd068,using a tail pointer a person can use the tail(->)  prev to find the second last item and this counts as the constant time[O(1)] as we did not traverse through the list a person just called it using the tail.,0.0,44
12007,12007,16237,4f0d170bb113012c8d343271d925a96ef0e199ecdca36f51a1fc99d7e0e8c67fb97155bfa738d3317830adb88f58c316437e0cf62b20c43f4e89ab893b6e7471,"Since you already have the tail pointer you can use that to find the second last item by using a while loop and traversal.

For example:

Link * current=head;

while( current->next->next !=nullptr){

current=current->next;

}

current would store the second last element

The time complexity would be O(n).",4.0,44
12008,12008,16238,95fcb6f4498706b42ae9b99b85ac88399a6d3275d00b87217fb05c5101d1dbf721727b60bf9e8e6b2dc1c2bdad3d13b66bf7f2d975e8a5f8863dd7d1ee3dcbef,"Link*curr=head;

while(curr->next->next!=nullptr){

curr->next=prev;

}

prev = second last item

complexity = O(n)",7.0,44
12009,12009,16239,1524a034e009646803d7074c495cb1bd3919f40bf0c99261b282adc7801990411f97759342d2d5b53fea8bfcd2292ae00d0444e55290b251e7ed8a081caf06dd,The program would need a temporary pointer and a value variable. The program would assign the temporary pointer to the head.The program would have to traverse the linked list using a while loop that's condition checks to see that the next pointer of temporary pointer does not point to the tail pointer. Within the loop the code will assign the temporary pointer to the next pointer in the linked list.  Once the while loop has been completed the temporary pointer will be pointing to the address of the second last address. The program would deference the temporary pointer and assign the result to the value variable. We would now have access to the second last item in the list. This program would take O(n) time (linear time).,8.0,44
12010,12010,16241,bd13f3a1f05cded43b306e7cf672db1fa9cf812229ead4318a993e62aa7ff42541e39b6868fb05069f972d798f5a5b109e0e615acf69b7c88b8e2bf435bfc374,"int main(){

    LinkedList myList;

    Link* curr = myList.head;

    while(curr->next->next != nullptr){

        curr= curr->next;

    }

    cout << curr->value << endl;

}

Time complexity = O(n)",8.0,44
12011,12011,16242,83c5e0cccc2c84d6aa6c84996703c9788a4c77ad197dc9cbe544f356daab1002c8cb4669771a7a17cb1f5a0ca37aa675d40cb959b05635bc4844ce29a466fa7e,"Link* curr = head;

Link* ahead = curr -> next;

while (ahead -> next != nullptr) {

      curr = ahead;

      ahead = ahead -> next;

}

return curr -> value;

//time complexity is O(n^2)",5.0,44
12012,12012,16243,8f8e96eb5a28d15c7802d177c96b97e53c9c9c2a37389d558dc50a5be6ad84289d3986f782da265340d7d86d9d174957d8d67890ddc79dd4587dd919a3bfb09b,"we would need to traverse to the item before the last item as the tail pointer does not have a pointer to the previous item

to do this we would create a temp pointer and point it to head and make use of a while loop

while the temp pointer's next pointer is not equal to tail, the temp pointer will be set to point to the next item i.e.

while(temp -> next != tail){

temp = temp -> next;

}

the loop will stop when temp reaches the second last time item and then all we would need to do is return the value of temp i.e.

return temp -> value;

O(n) time as it depends on how many items the list contains",8.0,44
12013,12013,16244,22140328599cc90e71d5de22898862c3b0e2dd7b2d6733a618551afede59cd91597d571fd42b02414ce2cee43da486638d6f616c5d08e161d9d14ea8e7479b0a,O(1),0.0,44
12014,12014,16245,b33d5ec88a2b0658fe1e9d5e59ea13311491654c12fd5b13cd9e270e44a1a125acca1c56bf136302c950a009d693b09accad74b98f9de4d82034269663959b89,I would use the tail pointer to access the previous pointer of the last node. In the previous pointer property i would access value. Thus accessing the second last item. This will all be done in constant time.,0.0,44
12015,12015,16246,c9533083b36a5867d42e175e5d9226d460bac0f67119822f32ea58c60b5c8ae66655217031dc5ae111931d8c34d1a88f17b852726bf446acb3dd87422ab66355,"Link*tmp=head;

while(tmp->next!=tail){

      tmp=tmp->next;

}

return tmp->value;

This will take Linear amount of time  [ O(n) ]",6.0,44
12016,12016,16247,cd3aa55745b79deafb0802ba9ebe30e68fbd1c089c006450727570d34769934d2b1c5a098a7d318146af21d8981711dce0bb006308d97edfcf9a088eb56e4532,"If the list has n items, I would first check that the list has at least two items as it would be impossible to get the second last item in an empty list or a list that has just one item. Then I would declare a pointer (*curr) that points to the head of the singly linked list. Next, I will traverse through the list using a while loop with the condition (curr ->next->next !=nullptr). This will traverse to the second last item in the list as each time the while loop runs, it checks whether the next of next pointer is pointing to the null pointer which indicates the end of the list. Within the body of the while loop I would update the current pointer (*curr) by pointing it to the next item in the list (curr->next). Once the loop has been executed, then (*curr) will be pointing to the second last item in the list and now we can return it's value (return curr-> value).  The time complexity of the function may be linear ,O(n), as we're essentially looping through the list until we get to the second last item (n-2) and continuously updating the current pointer (curr).",8.0,44
12017,12017,16249,3833aa3ef06cafdc78971652ad20444fe164affcf92c03de12570129a147987ae3263043850e741f6f77f4965176d32cb0f7b6200e6f1f08cf0158b373dc6fbe,"Because this is a singly linked list, there is no way to access the previous link to the last link without Traversing. Therefore we traverse through the list until the node which contains a next link pointer that points to the tail pointer. 

e.g 

link* curr= head; //this sets our link pointer to initially point to the head (the first link)

the function would include checks to prevent the traversal of an empty list or a list with one element.

if(head==Null){

return;   //if linked list is empty no 2nd last link exists so program will exit before traversing

}
if(head-next==Null){
return;   //if linked list has one link, no 2nd last link exists so program will exit before traversing

}

while(curr->next!=tail){

curr=curr->next; //this will set the pointer to the next link as long as it is not the second last link

} 

This will exit the loop once we have reached the second last element, leaving us with a pointer to the 2nd last link. The time complexity is linear time O(n)",10.0,44
12018,12018,16250,9b5371bf3d8a67220ea9112f458e092347973d5a590a2ada7f6d386201210567493e4842dd7263535c03e1b4ce797297171327f4cefdbdd79731ace1f4e756bb,"I would first have a curr pointer pointing to the head of the linkedlist and a prev pointer pointing to nullptr.

link *curr=head; and link *prev = nullptr;

Then a while loop where the curr is traversing through the linkedlist being tailed by the prev one step/one node behind until the curr reaches the nullptr which is the end of the linkedlist.

while(curr->next != nullptr) {

prev=curr;

curr = curr->next;

}

This way when the curr points to the last node which points to the nullptr the prev will be pointing to the second last item because the loop broke right after curr was pointing to null. and thus we have our second last item being equal to prev.

Time Complexity will be linear O(n).",5.0,44
12019,12019,16251,a2e71f759079413d4f87ec8f397142f2bf7f364e3ac1403027655c606e40a1106c0bace5c922e3aa206700cf3aa5120aeba8f93363e62c778029029dcc2335f1,"Link* secondLast(){

Link* curr = tail ->prev;

return curr;

}

Done in O(1) time",0.0,44
12020,12020,16252,f7763ea222dac1e375943618ea39c7850a59642b77b7731de5c2d200f944ea90e1861bca5e13b98b4e1c518e004e6a6d55592f5ac74fe6b5f4bf1fc2d7073996,"int findsecondlastitem( struct Link* head)
{

    struct Link* tmp = head;

    if (tmp = nullptr || tmp -> next = nullptr)

    return -1;

    while (tmp != nullptr) 

    {

        if(tmp->next->next == nullptr)

            return tmp->data;

            tmp = tpm -> next;

    }

}",0.0,44
12021,12021,16253,7ed1c803cb6942b25a462119e14146d3dfdc8b2d8405742d6e37974d2693c34f2838afb58a1bcf41b9fcd8829c1dff4d4b192c929c721bc46e1615dcea231b30,"Link*temp=tail;

temp = temp ->prev;

return temp-> value;",0.0,44
12022,12022,16254,1ae15e0f8c76ae99b51e83372a1074e20d0c372f497d2600b23a4ed137e5d58ad3914d0e0fce9e4d1885de19b788d1beec93c22c6cc3c2146c9349afe08e62f9,The tail pointer points to the last link of the linked list. To access the second last item I would swap the head and tail pointer so that the last item turns into the first item and the second last item becomes the second item of the linked list and then I would traverse until I obtained the second item. This would take O(n) complexity to complete.,4.0,44
12023,12023,16255,501a07a5ea6f4893b82a87c50efa2e6849e0292029937de9a64287e786810e4498fb2e84312270ed729b5eb12c98287b4c4eec9a42ad9e2a27abbebab12b5852,I would use the AT operator to access the second last item. To access the value stored at the second last item we would need to use its index value. We'd use the get_link function to traverse to the according link and furthermore find the value stored there. The implementation of the get_link function would require a time complexity of O(n) and therefore in this case the time complexity for finding the second last element would be linear too ( O(n)) ,5.0,44
12024,12024,16256,d02795a14cf200c3a4e42da8fa77ef31727a409d797dd41af60f44aca9829ba9ae25ee3cf59e3f4d5058d031c70d2bc7493c09427e32e68aa4eb4dcf5128f375,"I know that the next of the next of the second last item points to the nullpointer. so I would a current object and then create while loop that has a conditions to execute if the next of the next of the current object is not equal to the nullpointer. and the create the function inside the loop be current object is assigned to be the next of the current object. and then after the loop is finished i would return the current object

the time complexity is O(n)",7.0,44
12025,12025,16257,33903c4df6729a45e2485f57a528848aea77fb0ac81607f602f6f53f80eb513d5b18fef57c086d43fef4cdb3f78bbc1f8da0bcaa1e67afb26268e9484bbb4ded,"Since the tail pointer in a singly linked list cannot move backwards the only way to reach the second last item in the list is through the process of traversal. For a linked list since traversal takes place the time complexity will be O(n). A pointer called current is implemented and the head pointer is assigned to it. In order to perform the traversal, a for loop is used and the current pointer points to the value of each node with each execution of the for loop. This process continues until the current pointer points towards the second last value of the linked list. In order to extract the item from the linked list the current pointer is dereferenced. The complexity is still O(n).",7.0,44
12026,12026,16258,ac47e3ceebccb755b1987f028345ba571e2bbf0bc4ebc355e11ab520e9f3ffd71073789246ed0c633ccffb81e8b77e299c90427fa5f8a55f41455cee47d290e1,"-we need to get the index of the last item in the list but after getting the index of the last item we know that the index of the second last item in the linked list is (n - 1). so we need to create a temporary pointer which points from the tail to the second last. we will now try to delete the pointer which points to the tail then after doing so we will update the nullptr to point to the last second item. Then by so doing we can be able to access the second last item because now we will be having the second last item as the last item.

-this will take 0(n^2) time complexity ",1.0,44
12027,12027,16259,ed5a8c0425e8a7a0d2d402e42e3298539ec0ceb1b43ca8fa3f4b83dce862ed24fe276be92f07cf85365c96c7391564d1c0da45fd6e6ba4bd80ecb01a39467209,"Link *tmp = head;

while (tmp->next->next != nullptr){

     tmp = tmp -> next;

}

return tmp;

time complexity is O(n).",7.0,44
12028,12028,16260,49da1899a556de47c2ec5c0aee3103579dd1b8665560fbd2cb26362bd85bf2a291f8280bc21e1f838e024dcd8764915c6b880be08a2f6c8f404d85517511406c,Traversal. O(n).,2.0,44
12029,12029,16261,e0c83344227ee0e9cbe053565e48a2fdd45505359ef079abf58dae6d4b8251e874c464186ed9d597d1e6bd62c45d87ea5c0897cd6938b6926936cb2def62d356,"Link *curr = head;

if (curr == nullptr || curr->next == nullptr)

return -1;

while (curr != nullptr) {

 if (curr->next->next == nullptr)

  return curr->value;

curr = curr->next;

}

}

Time Complexity : 0(n)",10.0,44
12030,12030,16262,0bce68d12d4bb423184167950cec8450c2529233502545e57429beb9cfc6f093c786ba9febad285f8197b7bbc233a3b506a933f196c9852e05b5416cd8c68c8e,"Link *tmp=head;

if(tmp->next->next==nullptr){

tmp=tmp->value;

}

else{

while(tmp->next->next!=tail){

tmp=tmp->value;

}",2.0,44
12031,12031,16263,9ef08903fc9bcdb48895ecc5b1fae5cd197bde173b9729429afd0455acdabd651995bcf58c93f0a9f803a86fd3d68cb2f4b604260158eb5fae2f92dc6b1309cc,"* If the list is empty or contains less than 2 elements, return false.
	* Otherwise check if the current node is the second last node of the linked list or not. That is, IF (CURRENT_NODE->NEXT-NEXT == NULL ) then the current node is the second last node.
	* If the current node is the second last node, print the node otherwise move to the next node.
	* Repeat the above two steps until the second last node is reached.",6.0,44
12032,12032,16264,bb69eebb6b9661fb2659b9201956c2d150fd7601de8f2339f22c3c3c7289abd28101e1b6206a923a6b9fd81f7d0d617c8b5485dd0958ad06769fcf98922a4e97,"With the help of the tail pointer and the arrow operator I would call the second last item by saying tail->prev, this would be of constant time complexity since we did not traverse through the whole list but traversed/moved once to get to the second last item.",0.0,44
12033,12033,16265,a959a4bd23a818684dfb2a6c94ac89925575f3b11f0de3ed6d4df640b02681f2171e62de10059d8c04c758f13335e59b8e75b311b1045da8f168f89c32919f7f,"Traverse the linked list and check if each current node is the second last node of the list. If the current node->next node == null, then the current node will be the second last one. Otherwise keep moving on to the next node and repeat the check until the second last node it reached. If the list is empty of contains less than the 2 needed elements, return a value and end. The time complexity of this function will be O(n).",6.0,44
12034,12034,16266,a50f1f05303eb676c08e683fb412c46779741d1e408ab7173f3f3a12df3f04196b4fd7b7add1fd647d8efd191c43d6971e5cae7611afd814fbea2a7330f3ce46,"Thing *access(){

Link*tmp = head;

while(tmp.next!=tail){

tmp = tmp.next;

}

return tmp;

}

The Time complexity of the  function is O(n);",5.0,44
12035,12035,16267,1db17093b11c1476f03e1842d3fd75c18d4034c323e18d85de2325fa751f6201dc73b8705d987e46f915cfc55474341bdc436a256b6ba4b925f54ea754c444c7,"curr = get_link(size()-2);

curr->value;

O(n)",2.0,44
12036,12036,16268,3535a43df3300af7e5c3e95a4369804ca852c0470f1fe060d2a246291726064d9eeb362ff2318c56c2b2c1abd2d650cb0578f3dab1f0c9bef113f35bec7220b3,"{

Link *tmp = head

while (tmp->net->next != tail){

tmp = tmp->next;}

delete tmp->next;

tmp->next  = tail;

}

Time Complexity : O(n)",6.0,44
12037,12037,16269,252668df997d55b86d753e14db9bb82d9a9ab0f27d714f3256c72a03986a906ffccf1958bf221d3ab998a7770edda41ec2de25393f1d9a62f105684cf09211ed,"you wouldcreater a new temporary pointer that would be equal to the head. the check whether the temp is a nullptr or is the next on after temp is a null pointer. you would then proceed to do a while loop where temp is not equal to nullptr. then apply an if statement which would check if temp->next->next == nullptr this will check if the current node is the second last node. if not temp will now point to next

time complexity = O(n)",8.0,44
12038,12038,16270,d098e277cb3df3b25c9e42904322dbd46a16b60a20b139d8066f16584a8bb599eddc05cac924f310971f38fb613ad7daea71749bb268694cb7e0d2fdf74a35a0,"Link *tmp = tail;

tmp = tmp -> prev;

return tmp -> value;

time complexity is O(n)",2.0,44
12039,12039,16271,ca7ca134b5efdd7b26013cdee3bcba7329b07570412673ca953a2b1fc000b358026f967889f2b4b641fef26d116ce971213d8a9f77c08db97c244ae7f54e090e,"I would traverse through the list till I reached the tail pointer (nullptr) . 
I would be doing this while keeping track of the previous pointers I would have passed.

Once I reached the nullptr I would simply access the previous pointer which I have kept track of

The complexity would be O(n)",4.0,44
12040,12040,16273,3d924476d27d7afee3c446be78c3bfa807a26922031bb4eac61f97a7c6f17eb08bf7666e6b4cc961e48bd773db3725b57e5ee0d093b4129e2c89bae53ea3a074,I would access the second last item using the end() function which uses an iterator to past the last item and it has a time complexity of O(1) which is constant.,0.0,44
12041,12041,16274,b8ff274cc91e39334247b9673eeb1e1ed2acdbcefc990de9bf2b4226b88349ab6bc97343b39be8aded8a6ab21d1bf5dc3045e9f7596480cb1279270e81abbd58,time complexity = 0(1),0.0,44
12042,12042,16275,5f92eb6a07aed01e019162660614241903fd30335dc49cd736d18a97a0b8e4d8d8eaa7a31ce7cb8ad65e895e5a8906b98d2e7635d42d019af72333c76c35da1a,"Check if the list is empty or not, or contains less than two items. If either of the cases are true, return false for there will be no second last item. If that is not the case, we can traverse the list from the tail pointer using the get_link function and get the value of the item that comes before the last item of the list. Since I will not be traversing through the whole list to find the second last item, the time complexity will be linear.",3.0,44
12043,12043,16276,675e836215b62d793972ecb9d5ace2eaf438e0e5d0d26f496ddc3442ba479da55ac029b8a4555f73c538c50ecac4b04edc042861ca9b743e991c19c46392aa72,"Link *tmp=tail;

tmp = tmp -> prev;

return tmp -> value;

time complexity is O(n)",2.0,44
12044,12044,16277,bf9f7563cc9f901b96502125e7d25475a0aeee128b8258ce038a51e3af3c4093e4ee3d48f8e688baf55d2e74c7a660d473b521169612f2e6991be2accf5a47f1,"make a temp pointer (P1) equated to head and make another pointer (P2) that is equated to P1.then we can add a while loop and while P1 -> next ! =nullptr, then P2=P1 and P1=P1-> next. By the end of the while, P1 will be the last item in the list and P2 will be the second last value in the item list. Then we would access and return the P2 -> value, thus the time complexity would  be quadratic i.e O(n^2) ",5.0,44
12045,12045,16278,a7fd82a5660b8b1764aaf3905cfa33ae20bea31c698c90051afd8871bc86a6b25112ca62d2256ae4d96fc9b6c6488d5d0378685fcf8bb4b9bc5b8b918494fd4f,make the tail pointer point to the second last link and use second link   -> value to get the value of the second last link. This is linear.,2.0,44
12046,12046,16279,2c32439612d29606cd7276c7d7327878252b82b353a0e5c5a38f508a89318428edb5d433b571f4ed85a8cddd2dbf4c9c5eb5b82d38c65addb4bffc9179a95b21,"Firstly, if the linked list contains less than 2 items, the time complexity would be O(1) as nothing is being accessed, thus there will be constant time of 0 to access no link. If there are two or more elements, we would write the statement: if(link->next->next == NULL){}. This would ensure that the next item would be the last as the following element would not contain a value. The time complexity of this would be O(n) as we have to traverse through the whole list due to there being no tail pointer. This means that the traversal will take a linear amount of time that depends on the size of the linked list.",5.0,44
12047,12047,16280,20d849b0f14d796b315efcd61e863b25c7b0891949c9f1f08039226267e2ec02fc126e19dc6bac1596ae1c91066636280bb491c789bcd5f5ca3de77e3170945e,"Singly Linked Lists can only traverse forward since they have pointers pointing to the next node and none pointing to the previous node. To access the second last item I would have create a _CURRENT_ pointer pointing the first node(which is what the head points to), then traverse through the list until the _CURRENT_ pointer points to a node which points to the same node that the tail pointer is pointing to. If the list has _n _items, it will take n-1 operation to access the second last item and hence the time complexity will be linear O(n).",8.0,44
12048,12048,16281,4428555ef8072ef23d17db65e798fc29286c3f011a1099d994917d7424cc31d5f0d195105018e3c14dd5ec04f91fc4ea0c088a5e61680d4692faa4d313c225c0,"Since this is a singly is not a doubly the list has only one direction, with is from the start to the finish. Then in order to access the second last item we must traverse from the head pointer to the second last item, using a while loop with a condition that says "" curr->next->next != nullptr ""

This will take linear time. ",6.0,44
12049,12049,16282,f2a1d44943cafd29447c9cc6d850c73ca115efbe45cc60a50c497d9c39593f6c44e4c2d4facba5ee2393c40106c70b0307d8a427a20ee6b2ecb0031a02f6d25c,"Stepping through, or traversing all the entries of a linked list from beginning to end following the chain of references is a useful operation. Moreover, this process may be enhanced to search for and locate specific nodes which would take O(n) time complexity",3.0,44
12050,12050,16283,df7c40110480895f223a4ad7a154ce6d14071ffef29c798823d9a68e307bd1447fc569c4b8f3e4353216405210fd26445fb7aeea3ad07da82c16c8e5aa5ac0cd,"Link * prv = nullptr;
Link * curr = head;
while(curr->next!=nullptr){
    prv=curr;
    curr = curr->next;
}
cout<<prv->value<<endl;

time complexity= O(n)",7.0,44
12051,12051,16284,b96308b5b954fc4c2086f6faec027fc8299af60a164d99cbdc75a0802d3bb5ac5823699b9e2e5c78a86bbf73886ed3408a16b29a0f7ee6dc90b05a8f2f91fcd5,"Link *temp= tail;

Link *curr=nullptr;

while(temp->next==nullptr){

curr= get_link(2);

return curr->value;

}

The time complexity of the function would be O(n).",2.0,44
12052,12052,16285,dcb36512b447a313662d0f410494b8558ba9ebb01567bc86a95298f6904541d3214ff36bc5d7b6282877fc7d17b5d1d22bd45efc068f60d6574cc4f66e60986b,"struct Node* temp = head;
if (temp->next->next == NULL)

return temp->data;

temp = temp->next;

O(n) ",6.0,44
12053,12053,16286,910daf6bb90bfaca5b8329327dbb6876d9a383514e01fe819f79abb1a27019ac7b7555a07d09a61e93831fa5c489e19d607608ea54797f25aad8bd641ed60e55,"We would have to traverse the linked list using two pointers, one pointing to the current node and another pointing to the previous node of the current position. We will have to move through the list until the next pointer pointing to the current position is null then return the previous node. This will take O(n) or Linear time.",5.0,44
12054,12054,16287,0fd0096c1497543ca0003b9e3ba007221cbda2328585a2f2260277e1c7038bb2ae7ad23e03908936421523651b3b5785ece380b977ac663ea4a02a050d012617,"1.     link*prev  = nullptr;

        link*curr = head;

        while(curr-> next -> != nullptr;){

                 prev = curr;

                curr = curr -> next;

     }

      cout << curr->value <<endl;

      dele curr;

     prev->next = nullptr;

2. the time complexity its linear complexity",8.0,44
12055,12055,16290,c2c29b17660ccaffde93650bbaabbeca722766be9c7f4c24079c9b3711df082352b0623847e9af19ff96cf4f2d45d0bd1cd360dd8fa3d9a37f5041dcc804b8b1,"Since the tail pointer only points to the last item in the list there would be no way to be able to access the second last item. I would have to start from the head of the linked list and traverse through it.For the second last item the temporary pointer should point to a pointer which is a nullptr(temp->next->next=nullptr). We would be able to access our second last item this way.

The Link list will traverse from the beginning until the second last item. It would do this over a single for loop. The number of times  in will run is (n-1)times. Therefore its time complexity is O(N). ",8.0,44
12056,12056,16292,a58cc7a946eda613e1ba5b3286e27532a7ed6202aac74240dace327e45260834a089fa12052292c507fb1aec6f37cb1855be0992f9b6be6541ab2eebe4c77364,"you must traverse through the list and set a while loop to stop at the second last item, while(P->next->next!=nullptr){
P=P->next;

}

in this way the loop will stop at the second last item.

the time complexity will be O(n) because we traverse through the list.",6.0,44
12057,12057,16293,e394539baa7fd0006de5096759d1db9943b0b453927105fc99e564a56547ecb01587d2f0348be0224bd521c0377577b713f00c14b60183a6d229e89193dcb643,"Thing &LinkedList::at(int i)

{if(i<0){

      throw std::out_of_range(""i out of bounds"");

    }

    Link*current=head;

    for(int j=0;j<i;j++){

        current=current->next;

        if(current==nullptr){

          throw std::out_of_range(""i out of bounds"");

        }

    }

    return current +1->value;

}

time complexity= O(n)",4.0,44
12058,12058,16294,7784c26ab2d9766ae819dd1da89317a98dc39ebd7976e740ed6ab84978a76aaebcecee3ccbfd4bc08a3df68e244abf9916ece7c5f547ed6b7e35d519a43c7259,"Link* curr = get_link(i-1);

return curr->value;

the time complexity will be O(n)",5.0,44
12059,12059,16295,b1b3e86f0d270a61f8fd878f224a3849ed613dcb005f40bfd930beec1496e89a0e58f28b9b719a548b167e0db0c44afd5aae82094d2f118c0287dc3bf2b65cac,"Use the get_link() function and traverse thought the current link using the tail pointer ,such that curr=curr->tail ;
The head pointer must always be pointing to the first item in the linked list, while the tail works backwards.

use a for loop to traverse backwards

so that linear amount O(n)-of time is used for traversal and O(1)- constant amount of time is used for accessing the second element from the back .hence the total time complexity is linear.",1.0,44
12060,12060,16296,8f4f0cec01fab6a6a49376ed0eca817677b16456497e4474dea2db6c84f10bbab5215841562427aec9d1d1cb57d57272e23d92898bef51a2205b3db761cea98d,"Link* ptr = head;

while (ptr -> next -> next != tail){

ptr = ptr -> next;
}
return ptr -> value;

O(n) - Linear time",5.0,44
12061,12061,16297,2b92088102e0af9a5553cb90ac0d16cccf7d22e656abd8591794202e3ad9e3740967e9bc58b6fe2de9b9f1fca59eea10df4f48ad04955724c20b00283b3e3844,"int main(){

link *tmp = head;

if (tmp==nullptr || tmp->nullptr){

return ",0.0,44
12062,12062,16298,3b012b96c98d84ed8e9f88d92fde8d672f449955feec04f1b94283d72586d2586b31cd4b32cb1464ddc219af63c953c4b0015e421667a55126d1bf7700e02016,"Time complexity - O(1)

Link *curr=tail;

Link*prev= prev

while (curr==nullptr){

curr= tmp;

}",0.0,44
12063,12063,16299,ef46ab4c4baea61ce39205f3f8b9ba2f08ab48270b777e4f042aafc6410a82e9cddc1dd033e57ccba5e191584e8763e9b5c270df38cd4daee3f921d844f6b7a8,"* If the list is empty or contains less than 2 elements, return false.
	* Otherwise check if the current node is the second last node of the linked list or not. That is, IF (CURRENT_NODE->NEXT-NEXT == NULL ) then the current node is the second last node.
	* If the current node is the second last node, print the node otherwise move to the next node.
	* Repeat the above two steps until the second last node is reached.",7.0,44
12064,12064,16300,b9d82cd7c247fea1955a43aaaf5bb439ce7f4f53d3df9728ceb44f0e1b947c368ff1574400183b4d31d82813774edfdb38a1fdb56e3256ef8ab3e682f8c08da1,"Create a current pointer. While the current pointer does not point to the next pointer that points to tail pointer, current pointer points to the next pointer. This traverses the pointer through the list. It stops at the second last item and then current pointer can be returned. 
The time complexity would be linear time. O(n).  ",5.0,44
12065,12065,16301,a1c2b05bc77a92969182ba646d8a653eca3913d57c538fdf187c677d2b0c51d076b45d82612615ca734696b4dfc388e9684934287cf1a84a26d20f8be5134c6a,"Link*curr=head;

while(curr->next->next!=nullptr){

return curr;

}",3.0,44
12066,12066,16302,92791654d3cd52922c5b338b34156b28fe55a4ccee1e7fc5905b97888cf317c2fcae873ea940af535130a211df4483d7fb93e8718b1976f9cc9aa146daf834aa,"Link *curr = head;

for (int i=0; i != Null;++i){

curr = curr->next;

}

return curr->value;

O(n)",2.0,44
12067,12067,16303,2f8068722efcb5acef0b043ef7eeece2ba76bc57f445239c4ee08b7c2bb5238f231cca575128f6a330204e13d52f6c557830c59595c0c60a57b982bbb0aba187,"int main()

{

LinkedList mylist;

mylist=tail.next;

Thing n=mylist.value;

return 0;

}

O(1)-Constant time",0.0,44
12068,12068,16304,407769fbf475dbb4360f6394c41bf1fe1b09a93e6d82ce4845a84070494a0f47c40c801c2682df7cfd3bd3657df86e3329652953a2e09d84c89aab85cdc47d86,I would create  a temporary link/node to point to the tail. I would then trace the pointer of the value in the tail pointer. Moving backwards twice. The time complexity would be linear.,2.0,44
12069,12069,16305,e4de8560a7833ea7e41506cbf2b98858d3fa4c3e63a3de4e7dc8bd29355e0d9ed6e046298ea3e0b168144f8ec8172fffceca442b1283186ffc527c0ffb6fd2b3,"void printsecondlast(Node* (n)){
    while(n!=NULL){
        n=n->next;
        if(n->next==NULL){
            cout<<n->data<<"" "";
        }
    }
}",0.0,44
12070,12070,16306,b47077d26f125d33895ab4e74aaf28fe8f7c178510281c8f57b7442d02759e1b65f084667fd29bc28b1ee7c5ef5636b4eeff800b31bae656e7ddc319a0b75064,"I would create a function that returns a value. The function would create a pointer to the tail of the list. Then make that pointer point to previous. I would then make the pointer point to the value which is on the previous node. Then the function must return the value of the node.

The time complexity of this function would be linear O(1)",0.0,44
12071,12071,16307,8c6eaf7f60009bf511475c1e1f0a55bd524f57db7075d81ac6324fa20c67170610813fd28d5d1a71cf68fd79649c07e7ddbcbaee618c9d5cb0d649f541152433,"Create a class called link

create pointer which points to head 

Link* crnt=head

while(crnt ->next -> next! = nullptr)

{

return crnt

}",5.0,44
12072,12072,16308,6411a31397edca98a86156eda9fe940cd25214f5793edb40ff98bea1168dd2f02767f84a7d8f08cc5cbcf1da236fabf58172c048483fca623b7f16592128e03a,"Since a singly linked list is a forward list, we'll have to traverse to the head pointer going forward through the nodes. But we'll need to stop traversing on the second last item .We'll implement a while loop similar to this:

Link *curr = head; 

While(curr->next->next!= nullptr){

return curr;

}

this while loop makes sure we stop at the second last since it makes the nullptr comparison a step prior to the full

traversal of the list , so it stops and returns the second last item.

The item complexity for this is linear/O(n). ",4.0,44
12073,12073,16309,c6130d795cb6021c7594812b73d6b159744ce452f7f194d2a8acfd0f6313f2562bada8d95c7d6c5736c9d1d528be9655da041882fe8c7474badb6562243ddc74,"Since a Singly linked list is a forward list, we'll have to traverse from the head pointer going forward through the nodes. But we'll need to stop traversing on the second last item. we'll implement a while loop similar to this:

Link *curr = head;

While (curr->next ->next != nullptr){

return curr;

}

this while loop makes sure we stop at the second last since it makes the nullptr comparison a step prior to the full traversal of the list, so it stops and returns the second last item.

The time complexity for this is linear/O(n). As we'll have to traverse through the list forward and how quickly we access the second last item will depend on the number of items in the list.",8.0,44
12074,12074,16310,91d41b2f32ab492a059463744b0e5f6cd6e21e57c981adbf25309713090c378a42bc574b38c9745bce66a49918299962c618772aa540a5c09c38c4d73e58815f,"Link* curr=head;

while (curr->next->next!=nullptr){

return curr;

}",3.0,44
12075,12075,16311,3bf5a6c902e4bbf41f8d7229fb34d303a6721b98a13f667dc5f2cbb64cc24ce8b6caffed089bfaa8a9035860dae36438bbdda86f5a082d98f0cf239492dc448b,"Link* current = head;
while (current->next->next! = nullptr) {

return current;

}",3.0,44
12076,12076,16312,03af6c40b97133a1240dcc22b0dd356e3929ea04c9cf63c336ed0f2605d19efb0d0a0e5a6c60e766990694456ae922f3a477316845f8028bca7fb236d74cb185,"Link* newhead = head;

if(newhead == NULL) || newhead.next == NULL)

{

}

while(newhead != NULL)

{

    if(newhead.next.next == NULL)

    {

        return newhead;

    }

    newhead = newhead.next;

}",3.0,44
12077,12077,16313,d7dfb51332e1c950aa433a238f3273834b82e31a54a773c512e9c88094b5b27c10ba7527d092402ee28c450551c97d4efc1d9a6fab4f18a9a6df9f32cd052165,"link curr= tail;
while(curr!=nullptr){

         cout<<curr->value<<endl;

         curr= curr->next

}",0.0,44
12078,12078,16314,a6a1956dca8537b87c581329dd539be0e1754c767a458496056c957b37b7d5cf8e38e7b6a815b9c917caee9a53108cd46c4caa581c67b0f0565e27d0605c7826,"class list {

   public:

      int data;

      list *next;

};

void prepend(list** start, int new_data) {

   list* new_list = new list;

   new_list->data = new_data;

   new_list->next = NULL;

   if ((*start) != NULL){

      new_list->next = (*start);

      *start = new_list;

   }

   (*start) = new_list;

}

int secondLastitem(list *start) {

   list *curr = start, *prev = NULL;

   while(curr->next != NULL){

      prev = curr;

      curr = curr->next;

   }

   return prev->data;

}

   cout << ""Second last item  is: "" << secondLastitem(start);

 

Time Complexity=O(n)",0.0,44
12079,12079,16315,0dd6ddfbe50025d9a72df696362b0bdfb49434124c6d6642bcd0c15ba9544de38a86488e790b653cf1d9ab0bbd206e27a92d4ffa059eb91de07bea325c7f7613,"LINK *CUR=HEAD; _//CURRENT LINK IS HEAD//_

WHILE(CUR->NEXT!=NULL){ _//WHILE THE NEXT LINK ISN'T A NULL POINTER//_

 CURR=CURR->NEXT}_//CURRENT LINK BECOMES THE NEXT LINK IF IT IS NOT A NULL POINTER//_

RETURN CURR; _//CURRENT LINK, WHICH IS THE SECOND LAST ITEM WILL RETURN//_

Time complexity is O(n)",2.0,44
12080,12080,16316,6e573d9284194cc7291f560a714a872dd47b4e061283e85a73d0f329ec03550a03a1a3f166b0239189f5a0ff40814ee55278425a8a226193ee0b842b340ab615,"link *curr get_link(2);

return curr->value;

the operation would be a linaer amount of work O(n)",2.0,44
12081,12081,16317,e7c7348f23786b9e18a28e68e5d9ba68b1b693a74a0d58100a7db9e2aeee706b92e8dc4a38b20cb50289290e86666a9bfd49334f05b1673c8db1a8b26f9c9689,"Link*curr =head;

while(curr->next->next!=nullptr){

return curr;

}",3.0,44
12082,12082,16318,611e62668a69a44120f4c094b741411c87184ef32e42939a38515edfc5b988a4050fb89730be7833c2365cfa3031ef1f4593e6c36d340bca6106a175c159094f,even  though the tail points to the last item . I cant use it to get second last item since there are no prev pointers . so i will traverse the list from the head using while(curr->next->next != nullptr) this will stop me on the second last item then I can get its value  by curr->value  . this is O(n). linear time .,8.0,44
12083,12083,16319,72bbc5b06aa933675f586b02eb7091979ed0d9cd4489dbf74c1a3cab5f7664fc97395b4d5ff80f04c6b7fc94837ad7229b3d6417b2c8d007ae33e9006fc697c6,"use at() and size() subtracted by a number to get the second to last element.

	* If the list is empty or contains less than 2 elements, return false.
	* Otherwise check if the current node is the second last node of the linked list or not. That is, IF (CURRENT_NODE->NEXT-NEXT == NULL ) then the current node is the second last node.

Will we use constant time O(1)",6.0,44
12084,12084,16321,db0698cd03866d48da0c9cab1c327e767c6fb2c70ab318867db7094af47e41c16fc1528b63425d8d7a1a4e5cc071eef840fd0e4c5113866d0139015edb52f238,"We want to traverse the link by: 

a) returning false if the list contains less than 2 elements 

b) check if the current element is the second last element of the list. 

c) if b is true, print the element. if false, move on to the next element. 

d) repeat b) and c) until the second last element is reached. 

Time complexity: O(n)",6.0,44
12085,12085,16322,d769cb4350a2d0976becfe481525dc9d02dc1f9046972fa6c8520ab04b3261083dea6c123c8b92335bf36b4da15677a73288dad33238ed67179e8e986d0ce171,"link *curr = head;

while(curr != n-1){

head=curr.next

}",2.0,44
12086,12086,16323,8127d4098ce90e5354b83277c230528a4f346dff2268e6e565e170f557f4828895b86ce9e4d45680788cfb7696e91c4b7e7c80cf0ef0611dfea212b6f772071c,"head=temp;

tail=temp;

Link*temp=get_link(i-1);

return temp-> value;

its time big O(n)",2.0,44
12087,12087,16324,d39f1221c1c1fa8d17ca77420f1bba8cbd56fd8e4b2efb35a70c05cd360218b8d98dd79e4c1abc4c057030cb040ef7358efbb5cda6b9051c1e5bddbf68b768c0,"Link* curr = head;

while (curr->next != tail){
curr = curr->next;
}

curr->value;

O(n)",8.0,44
12088,12088,16325,b9398cac04fafed43567a061ce43d1f6d47a11dc43ed26ca3b7c803119e60ccce5216c5b0d8f2fe86de25d577c66b8be90d26d4412d9f88f080c8ddc823e6bcb,"link *curr=head;

link *prev=nullptr;

while(curr->next!=nullptr){

prev=curr;

curr=curr->next;

}

prev->next= NULL;

return curr->",3.0,44
12089,12089,16326,3c19a4ca3efa7d86230abf2250f098b931301930e60c23aba57d34a20945975cd4cccaccd719a3026ae41c4cbdfeb48a8b4d80928036af9a93a5f7cdfaaab709,"Link* tail=nullptr

Link* tmp

tmp->next=tail

tmp->value",0.0,44
12090,12090,16327,bbda30f1bc14304c6e790f22a459366d7df21db83cacfaab7fa97f23e08f9ea6d540b989b2f855a6b10224ce128ef7de8ce703f345305fd513061e429569c02a,I would traverse through the list using a while loop which stops while a temporary link's next pointer is equal to the tail pointer since the tail pointer points to the last link in the list. Therefore the loop would stop at the second last link and the temporary link would be equal to the second last link. This would have a linear time complexity.,6.0,44
12091,12091,16328,144fe98b924f74a4cb0e0020ec3ddfeccf820bfabdc366ff5bf990f2f806b30158897deffdf43eaec7d0e8b090cab1bb52a2dedd43e24a988f1cada5b7d709f1,"link *lllll = head ;

while (lllll != nullptr ){

   lllll = lllll -> next ;

}

2ndlast = nullptr -1 ;

cout << 2ndlast << endl;

TIME complexity

= 𝑂(n)

  ",3.0,44
12092,12092,16329,97b7f5ff46c1c824381cef505f20511747560e70b8b1e616642dc4fcce22c546867f43d01ab15335e8a2a57b9d3fba9ae8276c6347ded2ad2c8d88ebec13760a,"The second last item would be accessed by using the push_back function, and the run time would be linear.",0.0,44
12093,12093,16330,1d906c438dbb2a0adc2a7e04ed6b3c53c2ee28b5c43a5e83e583d5199a13a7bb6abb74579e2679fb4b6602b8efe2849ab290c6db2b1f573c02a4880312c09f25,We need to traverse to the index before the last one. This would take use linear time complexity,4.0,44
12094,12094,16331,639a68158c22ced38b469e5ff5439c6df90887f4ac511792920966a4b66fbbb0736453130f1e07f675685ab76215a4ca74f33ab5a9bf6fded51b150fcaa550e3,"Link *curr = tail;

curr=curr->prev;

return curr;

O(1)",0.0,44
12095,12095,16332,4a108b6388ab518862a0eddc19b8d86fd9549abfafdc544be7cbe5e9a91a20102b9726ddaa529a19a86fc38fa4700a0fdd752705615738f3f81b854fa84c557b,"int SecondLastTerm(struct Term* head)

{

   struct Term* temp = head

   if (temp == NULL || temp->next == NULL)

       return -1;

   while (temp != NULL) {

             if ( temp->next->next == NULL)

                 return temp->data;

            temp = temp->next;

   }

}

void push(struct Term** head_ref, int new_data)

{

   Term* new_term = new Term;

   new_term->data = new_data;

   new_term->next = (head*_ref);

   (head*_ref) = new_term;

}

int main()

{

  struct Term* head = NULL;

// PUSH ELEMENTS USING REFERENCE FROM LAST TO FIRST

  cout<<SecondLastTerm(head);

  return 0;

}

linear time case complexity",0.0,44
12096,12096,16333,d3544671dadb1e9fba295ae64f13440360bebd241846a32c589e6e4b9b7d2ae364664e1cb7d58f76720073e469e960448cb066f79ef57f1cede9b6551e65fec1,"I would traverse the linked list by doing the following:
If list is empty or contains less than 2 elements, return false 

Else, check if current node is the second last node or not

If current node -> next-next == NULL then current node is second last node, then print current node.

If not, repeat the above until second last node is reached.

Time complexity = O(n)",8.0,44
12097,12097,16334,eca946aebda9a9b4177d6f115af990d8e97aceaf5b9e945366e5e65b189b91181b165b8de20a658f63f6ad071cac081dfb0b61ed3ea41bd5546e198d3476c47b,"for(Link* curr = myList.head;
curr -> next != nullptr;

curr = curr -> next){

cout<<curr ->next ->next<<endl;

}

O(n)",3.0,44
12098,12098,16336,5bdb3585d2c72fd4097fa2022a52fea83bfe7b5d526e2baace26020f022448d80f8893352a325536d9cbe87e49f67b2d5812ff380f1d884c4d18fe00dec1b577,"Traverse through the list to the node with a null pointer, obtain the address in the tail pointer,  this would result to a linear amount of work, hence O(n). Traverse through the linked list again and search for a node with a pointer containing the same address as the tail pointer,  this would also result to a linear amount of work, hence O(n). Then conclude that particular node is the second last and access the item it stores, total work done would be quadratic, hence O(n2).",2.0,44
12099,12099,16337,b44584ccd8b5f428825956ad2bd876dd80c6494335aff0205a382354e687bb945dfab58c9f5cd5ee6d0fb386b28c2c5331192bb900a0c9c779312ec0ec3d111c,"i would make s new link call curr and make it equal to the head of the list, i would then use a while loop that would end when the curr->next->next is equal to null. this will terminate the loop when the curr point is equal to the second last element of the list giving me access to the second last element of the list, the time complexity of this would be O(n).

Link *curr = head;

while(curr->next->next != Null){

curr = curr-> next;

}",2.0,44
12100,12100,16338,1f4524a2fd59c574019f8ad8b33abc021be58689cba39707f11cd1078f398cec3601bbf4921f36f7a2e064229f97028bc2295ede798351e5c21a364219f36f07,"#include<iostream>
using namespace std;
class Node {
   public:
      int data;
      Node *next;
};
void prepend(Node** start, int new_data) {
   Node* new_node = new Node;
   new_node->data = new_data;
   new_node->next = NULL;
   if ((*start) != NULL){
      new_node->next = (*start);
      *start = new_node;
   }
   (*start) = new_node;
}
int secondLastElement(Node *start) {
   Node *curr = start, *prev = NULL;
   while(curr->next != NULL){
      prev = curr;
      curr = curr->next;
   }
   return prev->data;
}

int main() {
   Node* start = NULL;
   prepend(&start, 1);
   prepend(&start, 2);
   cout << secondLastElement(start);
}",0.0,44
12101,12101,16339,888a700ecff48b8e58609f74298e3e913836c7525e3508cee74dcd45d73e3b5cb35996869dd34b3342eba886899eba46a61c603fc724f15dfcf45804ca8c7ece,"Get the size of the linked list which is n. To get the second last element we would to get to the index of the second last element which would be the size - 2 because the last element is n-1.To get the value at index i, we need to traverse to the correct link in the chain and then return the value stored inside it. Since i=n-1, as the second last item is n-2, we would traverse to n-2. To do this we call the get_link(). You would need to traverses from the beginning of the list from the head node. Then find the pointer to the second node. From the second node, you find the pointer to the third until the index in question is reached.  This function with the index of the second last element. We then have to return the value stored at the index of the second last element with which n-2. The call to get_link()  is linear and then there is another 1 dereference operation. This results in a linear function plus a constant, which is still a linear function. So the complexity is still linear in the worst case.",4.0,44
12102,12102,16342,3065fd9b5327500ccd01f2dbaaeb4517f874d19bdf3e90a9e58fc3902fdfcf795607548f33b16d677a8bfdbfbec8dfd27757ca207e98b81490a4df15aab3c3f5,"Link *curr = head;

for(int c = 0; c < i; ++c){
   curr = curr->next;
}

return curr;

Complexity is O(n)",3.0,44
12103,12103,16343,02cb07161473723283d91a3c998f4ade4cb197abe855244e901ae8f3133fa745a87cf9dec28bee7621c8d3b8308477fc042faa7e0319e0ad9256c728f396d7bf,travers through the linked list and check if the current link is the second last link by simply check if the next pointer of the current link is pointing to a link with a next pointer pointing to a null pointer. ,4.0,44
12104,12104,16344,c33667ae11b7bded2337c08d116fa497bbbd12dbb6b1affa7fb94c650c68ba165865aab5e81895db475a23ff725c4bc69da22573104a9522dcaf9138fd9b447c,"The time complexity is O(n). To get the second last item in the list you will have to traverse the linked list by first checking the number of items in the list , followed by checking if current node is on the second last item and if not by then we move the current node to the next item. And continue this process until we are at the second last item in the linked list.",9.0,44
12105,12105,16345,4f0d3d105739426de624e80e4172c91f975854864036ed28cb0cc55661f472e21aded52d1f5f536d0d4dd33f28d74050fc9f2666a2c90499bf0336317ba4c7e6,"Name head current.
Start iterating from the head using a while loop that implies that while current->next->next is not equal to NULL, current must equal current->next.

Time complexity of the function is O(n). ",7.0,44
12106,12106,16346,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,"First intialise two pointers to a link one pointing to the current Link so we will intialise this pointer to the head of the list, the next pointer should be set to the nullptr. Then we will use a while loop to traverse to the last link in the list, leaving the first pointer(curr) now pointing to the last link in the list, the condition to the while loop would be curr->tail != nullptr, in the while loop we would update the other pointer to point to the previous link by curr = prev. Once the while loop has traversed to the last link then prev will be pointing to the second last link and we just need to make the tall pointer of this link to point to the nullptr. This will be done in O(n) time .",4.0,44
12107,12107,16349,ba17ced0b845a961a4ba2b9f572020680e40bd19c35ccad68ac84e48d9cb5d04fd0000feb318fb1b5fed6a59256f91eb5d0cc5f4be4d4f154e8d52a24ea8af8a,"I would access the second last item in the list by traversing the linked list in the following way:

	* If the list is empty or contains less than 2 elements, return false.
	* Otherwise, check if the current item is the second last item of the linked list or not. That is, if(current_item->next-next == NULL) then the current item is the second last item.
	* If the current item is the second last item, print the item otherwise, move to the next item.
	* Repeat the above two steps until the second last item is reached.
	* Time complexity : O(n)  ",8.0,44
12108,12108,16350,f11178d26d71b36980a2e031712b410b8887af4a2b6c48901c6a568377c95cf608d8bdb211ef99a8ec80760d046f982bcd08b27ff9c8f8cd3f71083f65b80c48,"If the list is empty or contains 1 item, return  false.

Check If the current pointer is the second last pointer of the linked list. For example if (curr->next=nullptr) then the current item is the second last.

If the current item is the second last, print the item otherwise move to the next one.

Do the steps above again until the second last item is reached.

The time complexity is O(n)",5.0,44
12109,12109,16351,1848cd7f48fa46779deb7b0a0eb59a877c6d421045e3cfd89b389428863439dfcd907f1dfee5210fe7c99e6e24483c87f1eba9c0df60ab0e72ef97072d4bd765,"That will be like,  if(current_node->next-next == null) then the current node is the second last node. 
therefore if the current node is the second last node,use print function to print the node otherwise move to the next node.

time complexity of this function will be 0(n) since we traverse to the entire list.",7.0,44
12110,12110,16353,fd3ac26e8f1d74669c591d17cfba292d301a38f59035e0e015254638e09238378ffbb05277661aa625df195230a27bb79b8964e830815de826a62bf695fefa00,"LINK *CURR = TAIL;
CURR=CURR->PREV

TIME COMPLEXITY -> Constant time",0.0,44
12111,12111,16354,64e451748c8e64219c1dcf31828cb7ded38a1447346285c9e9b6559aebe71fd6c492c0cffcdb5c0c6a652b339b2aa51ca0d8310a628f12a661261dc55ced044f,time complexity is 0(1),0.0,44
12112,12112,16356,fa9e03d0ca767f086bcd9ef36b2098757508e1e31055329ce57a6c2012e0fc52ea26b7511314fd601a7a535cdf128ba0717226b541ddae15232dd77b79a7f243,"Link*before =get_link(i - 1);

curr =curr->next;

if(curr->next = nullptr){

    curr->next = bofore;

}",0.0,44
12113,12113,16357,2f3e315687119ead6a818da568e78a6a6a1fca8ffa33209c3dff24c186275e23df6af032db0ab8c3cc902f57fda3972c9cc02a021860b531f2f8a447436717fc,"iterator :an object that allows us to traverse a program or a code. the iterator provides 2 functions namely:

dereference and the increment object. the dereference object usually returns reference to the current object and the increment advances the iterator to the next object in the container.

to access the second last function we will use the end function which should return the item before the last item. then the iterator we will get is the increment one. it advances the pointer from object _i _to_ i _ + 1.

then we write the function as follows:

ie let list be king 

LinkedkingIterator linked list :: end(){

return linkedkingiterator();

}

the time complexity of the function is O(1)",1.0,44
12114,12114,16358,eec934572d7644ba0121c8b2feb2c582e9f3f4f5b58187b8858bc2ee24ad1c13bedfb2cdb5029267bc11b865502439fbacde60c9046792350b575350ddc17ef6,"We traverse through the linked list and at the end the prev pointer points to the second last item and the curr pointer points to the 

link*curr = head;

link*prev = nullptr;

while (curr -> next != nullptr){

    prev = curr;

    curr = curr -> next; 

}

return prev -> item;

while (curr -> next != nullptr){

    prev = curr;

    curr = curr -> next;

}

tail = prev;

Time complexity : 0(n)",8.0,44
12115,12115,16359,9ab5ee6dcd1eeee42b584dd13d10dfb771aeae24b070596bf8e33f41840796cff5a58f61a4f76bd5d61ec8edd7ee76fc7e403b38a2b713cfce865554906c5149,"Link *ptr = tail;

ptr =ptr->prev

Constant time",0.0,44
12116,12116,16360,525cefc66631b9eb601410acc1c632cc3a6d9976bb8f3ac653d46807a4053f29a6c3c85a0e8a38a43486b45bae46acd949e27f910bf00828afed11257c7034f3,We need to traverse to the correct link and return the value in side it. and the time complexity would be linear.,5.0,44
12117,12117,16361,e14e9d17ff105f338133a504a8588dd3a4f00fc621c5f17144797195169ba4c75e604521ca51834df3c6d93ca9b2fc4c8ad180844dc2bfb9532b3a1ade38118d,"Get a prev pointer which point to the item previous the tail pointer

Linear time complexity:O(n)",3.0,44
12118,12118,16362,dd8364e8ed91c439ef01f1b1c5d50548af1ed1f45d9fe938f00f04ffde7150da61acbb591a7654fb4c9958209c9c12e4108f4761b34d706a0ab07033cf3359c4,"Link*curr=head;

While curr.next!=null{

Curr=curr->next;

If curr.next=null{

}

}

N^2",2.0,44
12119,12119,16363,0acf933aafd8ccfefdb0a07c9cd769ff21b003c332b8b90f6edffc1573664ade1e2d7b54669b2cee7b03b35091d029450c66d87d0c0afdf5016d3799c57a4fc9,"Traverse through the list

Check if it is the 2nd last node (curr->next->next == nullptr)

if true, print.

Time complexity: O(n)",6.0,44
12120,12120,16364,3d3c1be79bbed7b365d3aace59dfe14a7a1385e7072a675c0aa539c52e6b6368cbd7b12fc937010386846b4d8cccf764dc628c232956154c4f1395918f004d16,"Link *curr = head;

for (int c = 0; c< i - 2; i++){

     curr  = curr -> next;

}

return curr;",3.0,44
12121,12121,16365,b4c6456081dd2873697bb9c5121dc221c2e6cfd2e914f59b56d45a20d004a7bfc27cdee673babd3b806585202e69664f595e673038093dbdd5ed6fd4f728110d,"Link* curr =  get_link(i);

return curr -> value;

complexity time = O(n)",2.0,44
12122,12122,16366,dc654a3d0a49a8045440d0a47a162366cb8c5b30f1fbfe16fd058e7bee5d840a459b70ea1468db1f0ce164b7af14bedf02e15cd2f876678ba6f0d0d5502b4093,you can use tail->prev .and complexity will be O(n),2.0,44
12123,12123,16367,87b26af5215183ea5d646e967e1e3374a7a4afb5a13a2967680ff8a29d219e9ac775560a42891913325361c21b3cb2f9b5121d0317fb7c951cff2c01aed37b66,"Traverse the linked list. Check if the list is empty, if so return false. Check if the node is the second last node or not and repeat until the second last node is found. Time complexity is O(n).",7.0,44
12124,12124,16368,47a96f7fd37a4283bd96fcb03ba26cf7cdfd591682a3ab89197e64c489356cb4cf67ddd2623e0d973228f2c5400031304b672d076d17a1440971f1f289cb22d7,"Go to the tail pointer, then go one backwards. 

Time complexity of O(1)",0.0,44
12125,12125,16369,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"If we keep a reference to the tail node , then it would be easy to insert an element at the tail of the list.

Algorithm addLast(String newData):

v.setNext(null)

if (head == null){

head = v;

}

else{

tail.setNext(v);

}

tail = v;

siz3e = size + 1;

Time complexity: O(n)",1.0,44
12126,12126,16371,7ee2a07ed8605f9b7e2a082751cb95a96baac16cb0bf39fd77ca963963f89dc899500eaec8aaa9621d868e97b67ab53ef71efa8d993d9a386011c08cc84fffc4,"Link* tmp = head;

while (tmp->next != tail){

tmp=tmp->next;

}

tmp->value;

O(n)",7.0,44
12127,12127,16372,51fb076cb9d7d8b92862424eea499f35f08c6facc1b5c6e1e497403f1f9dbee1fb9ddd9c6593abdecd04415987773f5ad077b2de0c9a6e482bf6dc3e7350e3dd,O(1),0.0,44
12128,12128,16373,bf4b5731c3c3bd0f2b59e631e277805959da8b9efedbe010df49f525b49b713ed8678bb3e54ddfd542bb302e79e236dfb9ec30ec253f0f80d3cd72c6a5094fbc,"struct Link{

Link *next;

int value;

Link(int v) : value(v), next(nullptr){

};

}

struct LinkedList{

Link* head;

LinkedList() : head(nullptr){

}

~LinkedList(){

}
}

Link* tail(Link* head, int value){

Link *last = new Link;

last -> value = value;

last -> next =NULL;

if(head == NULL){

head = last;
}
else{

Link *temp = new Link;

temp = head;

while(temp->next != NULL){

temp = -> next;

}

temp->next=last;
}
return head;
}",0.0,44
16305,16305,20550,f1847bb5d29f39224664df29173ee4eea8241f8aa777b795f86bafdb3b6165e8679750df7902af2beb1387f258e9970c22324224cff020b701254fc8b35d988f,"Because vectors do not have a push_front function, code would need to be written that would copy the values of the vector. Then a new vector would need to be created with the new element in the 1st position and the copied values following after it. the previous vector would then be deleted. Thin would take O(n) time. A similar procedure would be needed to pop from the front, with the exception being that the 1st value would not be copied over and no new elements would be added. the top() function would return a reference to the 0th element, which takes constant time and the size() function would take constant time as well.",6.0,57
16306,16306,20551,8f3267fb35d28eb10e3fc9fcbb0f22bf91f2506cc5526c9b2d0ca2807bf6f55a3324c012d8567781f2f103a5869506dd55924327b0937c914d8880e993d33ca9,"if the topt of stack is at front of vector then I would implement the stack as follows:

* Push function : this will not be affected by position of top I will use Push_back() function to add items in Array

*Pop this will not be affected by position of Top I will used void pop() also

*T& top() to get the value at the top this will change because our vector  top position is different, then here I will get the size of vector first then return data[n_items -1]",2.0,57
16307,16307,20552,3d98aadbc95f1ceaf5723fac50fb4583048e99f3a608962c3b1c8cd33d79fc21685534ca4e509a1fb097360bbcf66d5d96593eff3b861f7814afdcae8fecdd1e,"We could first create a class for our stack and within the class we create functions that allow us to perform operations to our stack. However when we want to either push or pop an item to the top of the stack, or peek the top item in the stack, we will do this to the front item in our vector. So we will use pop_front() and push_front() functions, and the front() function in order to perform the relevant operations. ",0.0,57
16308,16308,20553,912a17c5532a85cc610facff6c98d42b64fb259b767c809567c65cce318eb3dc8f21bcbe5e653de87fe40d2502ab66869bc553e63fc3a1d7697be613c3b49a69,"In this instance of the stack, the push() function would add an element to the front of the vector. 

To implement the push() function, you would need to insert the new element into a new vector and then copy the rest of the elements from the old vector into the new vector. The complexity of the push() function would therefore take O(n) time, since you would be making n copies.

In this instance of the stack, the pop() function would remove the first element from the front of the vector. 

Implementing this pop() function would involve, copying all the elements besides the first one in the current vector and pasting them into a new vector. The complexity of the pop() function would take O(n) time as well. If we go into specifics, this process would take O(n-1) time since you would require n-1 copies to be made.",4.0,57
16309,16309,20554,cd3aa55745b79deafb0802ba9ebe30e68fbd1c089c006450727570d34769934d2b1c5a098a7d318146af21d8981711dce0bb006308d97edfcf9a088eb56e4532,"For the push function I would push_front the parameter and its run time complexity would be O(n). To pop an item I would pop_front and the run time complexity would be O(n) because the last item is at the bottom of the stack. For peek I would return the reference to the item that is at the front of the vector, in this complexity is O(n). And for size, I woud return the size of the vector, which is constant O(1).",3.0,57
16310,16310,20555,af813686acb18a064eece7968dc86f7e1ba2e2c4ebcbfb61de992275f213a5fe2248d15ae968c61ff6c270f401a739d21132339ee0a42afa471e88a17c352ab9,"Using the front of a vector to add to the top of the stack would simply mean that you would use pushfront(add items at the front of the vector) to add items and popfront(remove items from the top of the vector) to delete items, the time complexity would be O(1) for best case and O(n) for worst case. To peek the stack you would return the front value of the array and to get the size you would return the size of the vector, both of these function would be O(1).",2.0,57
16311,16311,20556,d31899b98e7fb3e761998737c0078a84e48727b178f33ae85b1caf85762f7c95a36780c3f84b13e4c3f8980c15788bdfcc7bddbb75a6b63b7a164f238d74d926,"The implementation would be very similar to the implementation of the back corresponding to the top.

To add items to the top of the stack we vector.push_front() function which would take O(1) time (unless we run out of space and need to make a new buffer in O(n) time).

To remove items from the stack we would make use of the vector.pop_front() function which would take O(1) time unless we reallocate a smaller buffer (O(n) time).

To peek we would use the vector. front() in O(1) time.

To get the size we would use the vector. size() in O(1) time.",2.0,57
16312,16312,20557,4427e3a6ae2786ed5636c638581416e62adf38c90aed72214004ce5b4fc79bb1e5696556f9677084defd90b33f5cf052534401db22ff6a075c7131169ee1bcf8,"For implementing both the pop_front and push_front functions we would need to move the items from the second one, one place to the left for pop_front and one place to the right from the first item for push_front in order to have space at the front. Or we would have to copy all the items to a new memory buffer for both functions.

Since in all cases we have to go through all the items in the list, the complexity of both functions will be linear O(n).",4.0,57
16313,16313,20558,72f8819c651aefda92260fa4f547f14f555e14f647747df897695708c9fa1a2f437da4d45f5b0c59c6c67b9f7f70e1068df3448aebfbb9759e5038bbc8c29ccf,"* for Push front , if there's space we have to copy every item by moving them  one place to the right then add the new item on the index[0]. It will use O(n) complexity.
	* for   Pop front , we will need to move every item from index[1] one place to the left. Which will also use O(n).",4.0,57
16314,16314,20559,74594d76e743115e9e80c4119a5039c4fec5aed2b1eb9af70c89d53a42b69ad2163ffd8ce8a40f97632e4be0cb18aad097e1d70fac3137214bb4656688c9555b,"The push_front function would work by moving each element of the vector's buffer one index to the right, which creates an empty cell at the first index that the new element can be added to.
This would have a linear time complexity (O(n)) in every case. Note: Even though the case of reallocating the vector's buffer is also in linear time, these copying functions occur after each other making this specific case have a complexity of O_[reallocation](n) + O_[moving over one index](n). This specific case therefore does have a greater time complexity, but it is an increase that is affected by the individual computers performance due to only an increase in operations not cells, making it possible to leave this case's time complexity as linear.

The pop_front function would work by moving over each element of the vector's buffer one index to the left in effect erasing the first element of the buffer. This would have a linear time complexity in every case(O(n)). Note: see above why the reallocation of the vector's buffer does not affect the time complexity.

The peek function would return the first index of the vector's buffer, and it would have a constant time complexity(O(1)) due to the pointer arithmetic possible with vectors as a result of their buffer's contiguous memory.

The size function would return the size of the vector. The vector would store its own size making it's size function constant time and therefore the stacks size function would have a constant time complexity.",6.0,57
16315,16315,20560,c318ecd5c05d3ffa65238b75e8aa9e67390cc6fb32c2fdbfaf84c4d21eee7f78cf713a8bc77a69838390c129742df9afc0ddd3cf48a8b7ef5ea2fb0f43dc4114,"With the front of the vector the top of the stack, every time when pushing an item we would need to increase the existing items indexes by 1 to create space for the new item. This would take a linear amount of time to do.

When popping an item we would need to decrease the indexes of the items in the vector by 1 to essentially remove the first item from the vector. This would take a linear amount of time.

Both these functions would be relatively inefficient. ",4.0,57
16316,16316,20561,06f90aca60b4b2db0e6d8bb78d0ed0da22ceb02b561b842eee51951b0e04be81e8817f795eb9597349f2e3c12b7befca0ed36322cff788052acb9b91388f1fdc,"in order to use the front of the vector as the top, you need to use the front functions shown below

push_front - will have time complexity of O(1) as best case if there is space in vector OR O(n) as worst case if more space needs to be allocated

pop_front - will have time complexity of O(n) as when the first item is removed all the other items will have to be shifted 

.front for top/peek - O(1) as will always return first value

size - O(1) as it does not matter what is the front as will still have to count all items in vector",4.0,57
16317,16317,20562,88e4f79f72acbc7dd458837989d41695a9b36b9c96cdb3ba66c7b90921d69150d478abfb1ed6fc7e89594f6b4ccd5c2a5625a644a888136358b59b68dc7b8205,"we can use push_back() to add a new element to the stack- O(1) constant time

use the pop_back operation to remove the top most element of the stack- O(n)  linear time",2.0,57
16318,16318,20563,df0d62df6145f98b9d8d85662b958119c20c6015becf9534b762b6d6c7c046d872ff37d4ccc77da23e1570c5a7712fc862bda45087171a56e4c5cfc3750e2ad2,"* push() - To do the push function you will have to copy every item (n off) in the vector once to move it up by one place to make space for the new item that is entering the stack - O(n)
	* pop() - To do this you will have to delete the first item in the vector and move every other item (n off) in the list one position back, by copy - O(n)
	* top() or peek() - This will be a lookup of one item by vector arithmatic - O(1)
	* size() - Number of items in the stack can be looked up by the vector size function as the vector function keep a counter to the items stored. - O(1)",2.0,57
16319,16319,20564,8f8e96eb5a28d15c7802d177c96b97e53c9c9c2a37389d558dc50a5be6ad84289d3986f782da265340d7d86d9d174957d8d67890ddc79dd4587dd919a3bfb09b,"when adding to the top of the stack a value would have to be added at the front of the vector.

each item currently in the vector would have to be moved one position back (from position 0 to 1 for example) for the item to then be added at the front

O(n) time

when the item is removed from the top of the stack a value would have to be removed from the front of the stack

each item in the vector (except for the first item) would have to be moved one position forward (from 1 to 0)

O(n) time

to return a reference to the item currently on top of the stack we would return the value currently at the front of the vector, and to return the number of items on the stack we would get the number of items in the vector

front() and size() is part of the STL and will take O(1) time",6.0,57
16320,16320,20565,20a63554bf7ab6e06ce970a9c763f370f49fc1a727f591ec7304c432565faf9d2b891194e01cc67ff029c1fe6de8363ececadce22ee4af544785f47985cda509,"I would use push_front() to implement my push functions and pop_front() to implement my pop function. For the push function in the best case there is already space so it's O(1) and in the worst case, there's no space and we have to create a new vector and copy n items so it is O(n). It is the same for the pop functions, we don't waste space O(1), if we are wasting space then O(n). Both functions are a bit complex, with if functions. 

For the size function I will use the vector.size(function) and that is always O(1) and for peek() I'll use the operator[], return data[n] n - corresponding to the position of the front value - it will always be O(1).",4.0,57
16321,16321,20566,f7bbac457e26e926aa83f65c706f322284bcae4a69df367438ec5060865432bf63d2eef51ed308d86119a8e1745e619fe74662cd103d43378e65328b7630ff57,"Instead of using the ""pop_back"" functions, you would use the ""pop_front"" etc functions. This would add data to the front of the vector rather than to the back of the vector. The time complexity of both the ""pop_front"" as well as of the ""pop_back"" are both O(n) as when adding data, everything would need to be shifted one to the right and perhaps copied over if there is not enough data allocated and when removing data all data would need to be shifted one to the left. The only time that the time complexity for both will be O(1) is when there is no data in the vector. ""peak"" will always be O(1) complexity as the top of the stack is the first data point of the vector. ""size"" will be O(1) complexity as the data is contigious.",6.0,57
16322,16322,20567,3227954877ff6b3d6e5d415eabaacb6ee56a5809874f349fcc72cbd6b74b9924802065f3198d52fa435eef46404fa2ce0465698400217a4b7b18ef03d8cc91ec,"PUSH

We will have to make n copies and copy each element one index over in order to add an element to the front of the vector and effectively the top of the stack. If there is no space left in the vector, a reallocation will be required, again with n copies to be made. So we always perform n copies and thus the complexity is linear, O(n).

POP

Each element will have to be copied over to the index before it in order to remove the item at the top of the stack which is the at the front of the vector. This would require n - 1 copies and then we would use the vector pop_back to remove the last element so that only n - 1 elements remain. As such we perform ~n operations and the complexity of the function is thus O(n).

PEEK

We are able to access the top of the stack which is the front of the vector in constant time using vector front() function. Thus time complexity is O(1).

SIZE/EMPTY

The size can be accessed in constant time since the vector keeps track of the number of items and we can determine if the stack is empty if the size is 0. Thus both cases take constant, i.e O(1) time.",6.0,57
16323,16323,20568,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,"Create a vector. Set the first element of the vector equal to the element at the bottom of the stack then expand the size of the vector, move the existing elements one position forward and insert the element at the top of the stack in the 0th position.

The space complexity of the function would be linear because you would need to create new memory and copy across the old vector elements and then move them into the expanded vector memory.",0.0,57
16324,16324,20569,9b13f2d70694a174cc296db2532a81cde5f414c86e87388e32c45d14a1b85a47b70cc54fdcb2f6455012d569323883da99f34aab409453d8e838e0ae2bf41aff,"we need to push which add items to the top, pop which is removing an item , peek which reference whatever is on top and we would also want the size. we would need to store our data. pushing  and popping will take O(1) in the best case and O(n) in the worst case then peek and size will take O(1) always. push adds an items in the stack.pop removes an item from the stack.peek returns top element of stack ",2.0,57
16325,16325,20570,c75c72f439ed0a1083505ca2fb274424bfa93184c45c67c47245732cd59fc54e342192b7a0a8538fb3676603ded389cab9a3431e9d476a9d9b140adb5ff30721,Since with a vector there exist no push front and pop front methods we would have to implement these ourselves. In each case it would be O(n) time since we have to traverse over the vector in each scenario so that we can move each element backwards and forwards depending on whether we used push or pop respectively. For peek we would use the front() method from vectors.,4.0,57
16326,16326,20571,bef6837a7fdfe1da5fe1293f44c76b96d3b8dcc796faa186ced378d3238a30c359695c10ba31e008e6450186def6f4c6da86e1819e6310ac4629db0e4ae2f7c4,The stack will first get stored in the vector. The elements which are stored in the stack will be pushed. They will have a time complexity of O(1) when being pushed and when being popped they would have a time complexity of O(n). ,1.0,57
16327,16327,20572,7a27fb1fa642a9bd3d76e8ce98be5e4779f4184eab8b901b0ee0d165d466de6122db493ca631d33ef289f724ffb838136d578f3b72df159667217c69ae154ed3,"Since there is no push_front or pop_front function in a standard vector in C++, an implementation of the stack would be a pretty bad implementation if the front of the vector = top of the stack. 

A stack requires a last in first out system.

So for a PUSH function, since there is no push front in a vector class, we need to reallocate everything into a new vector with an extra space in the beginning for the new element to be pushed to the top of the stack. This reallocation will take O(n) time because you have to copy each element across into the new space. 

For a POP function, it is required for us to pop the first element of the vector. There is no pop front function so we need to again reallocate the vector into a new space after popping the first element. It is always going to take O(n) time due to realllocation. 

The SIZE function would take O(1) becuase the function exists in a vector and will just return a value

The PEEK function will also take O(1) time by using the front function in the vector class. It will take O(1) time because of pointer arithmetic. ",6.0,57
16328,16328,20573,f7abd04c97a647b1e757bccd7284173478fbf8f28e28e3102567ab244a63fd5c67a5e953a932ab1f774cb73ace52fda53cdbbded4668ee4660e933d867e532bd,"To implement a stack in this way the vector would require that whenever any item is added l use a push_front function and to remove an item l use a pop_front function. This would mean adding or removing would happen at the front the vector. To add a new item would mean that the existing items would need to be moved a step to the right which translates to moving n items to the right ,,thus in any case the shifting would have to happen n times resulting in a linear complexity 0(n) for push_front. To remove an item would cause a ""hole"" in the front of the vector and therefore existing items( n - 1items) would end up having to be shifted one step to the left ,, therefore n-1 shifts will happen everytime resulting in a linear complexity O(n).
To implement size would require keeping count of everytime an item is added or removed and therefore only returning the counter number or n_items and thereby giving constant time complexity O(1). 

To peek would mean returning the first item in the vector and this will always take the same amount of time thus giving constant time complexity O(1)",6.0,57
16329,16329,20574,2639eb56a1989682f1b8fb8c5a3437ea6a5d663be094f02f4aaae47dc57a1af7165cfaae33d61d670e26c96083744d494e42187a468df938459fc0c70030a175,If the front of the vector is the top it is based on contiguous memory. If we want to remove something in the front of the vector we would simply just pop off the top of the stack which is the first index and this would take constant time in the best case and linear time in the worst case. If we want to push an item but since it we started at the top we would simply just add it to the top of the stack.,1.0,57
16330,16330,20575,725a0125b367c6f17c35c11b2109d01e495cc98a9983ee64edff98f1e31691682af784e585cb9ffd4450baefac075cf1659b1b9f4409ec665f5bbef7fd4002df,"When you push to the front of the vector you would need to see if there are other elements in the vector if there are you would need to copy the vector somewhere else in memory add the new element to the font of the list and then copy the other elements from the other vector to the new vector and then you would need to free the old memory, this would take 0(n) time. You would need to do the same to pop from the front of the vector, you would need to pop the element from the front and then copy over the other element to a new buffer and then free the old memory which will take o(n) time. The peek function would take 0(1) time as the element at the top of the stack is at the front of the vector and size would also be 0(1).",6.0,57
16331,16331,20576,b62aa4d567faf4c8c2d7b435cab87c30c9d1e6af89f8a0e3d7867630ef600446840f333742c814bc8a0c9d2f0ab23474abdecc13d41d7312f08a47b7fc5bb67c,"With the top of the vector being the top of the stack:

we could push to the front of the vector in O(n) complexity, by moving all the data over 1 space and adding the data in the new space created

we can pop from the back of the stack in O(1) complexity using pop_back. as the end of the vector has a known location.

to peek at the front of the vector we would return the data at the top of the stack and it would be O(1) complexity.

to find the size we would have to iterate through and add to a counter in O(n) complexity, then return the counter",6.0,57
16332,16332,20577,833bd82b84984eac1561a2aa471c7fa8ce8fc83eb43410d162adbb99836f9c60ca90f110500d0a4cfae027c10757354954059b39ea510643c3c10d5e8f6e1bb9,"I would use the pop_back function to the vector and what is popped at the back of the vector should now be added first to the stack. then we will now have a stack where the front of the vector is at the top of the stack.

	* pop_back will take O(n)
	* push_back will take O(n)
	* size will take O(n)
	* peek will take O(n)",2.0,57
16333,16333,20578,d5eef99882213e9e893ef6d31b163cddd65b11b328a038af368c63b9dea5c55582d674f73b7f44a7ffb0e808a2c14f224354666b5c8da68a3cf145583cdbcada,"First, you will not be able to use the vector that c++ provides since it does not have a push front function and pop front function.
 Using a vector that you have implemented that has a push front and pop front functions. To add a variable to the stack, call the push front function. To remove a variable in the stack, call the pop front function. To look at the top of the stack, use the front function and to get the size of the stack use the size function.

The complexity of adding and removing a variable at the stack is quadratic time. The complexity to peek and get the size of the stack is constant time.",2.0,57
16334,16334,20579,aba8ccda4763601c960552191c4b4ea7d3e94521d25f84c03f905aac0bf9578acabd1a7e87e98918c1a32dbc6bc0f00b14222dbc9e37a19a4efb13f1c52924d7,"Pushing items onto the stack,there is no best case. The worst case is O(n) time, here we have run out of pre-allocated space, therefore we have to copy all items in a newly allocated vector and  copy each item one to the right to create space at the front then add to the front.  We want to remove the item at the front. We can't push_front/pop_front, vector does not give us that. So it will take us O(n^2) to implement it.
Peek() will still take constant time, and the size() will also take constant time.",4.0,57
16335,16335,20580,8f6fce38f378bd03b7e3015540844be6bf9823c5ceeeee423c75e7180e2218c7f9853b96b276e10dcc9cefdaf4b85b6d869df1573ced7bc1eae58f615449e857,"Use a normal vector except instead of using the push back and pop back functions, you would use a push front and pop front function respectively. The complexity of the push front function is linear. The complexity of the pop front function is linear as well (since you will be copying each member and shifting them one spot left). ",4.0,57
16336,16336,20581,0acf933aafd8ccfefdb0a07c9cd769ff21b003c332b8b90f6edffc1573664ade1e2d7b54669b2cee7b03b35091d029450c66d87d0c0afdf5016d3799c57a4fc9,"use the push function to add values into the stack

continue to use a while loop to make sure that the stack isn't full",0.0,57
16337,16337,20582,3833aa3ef06cafdc78971652ad20444fe164affcf92c03de12570129a147987ae3263043850e741f6f77f4965176d32cb0f7b6200e6f1f08cf0158b373dc6fbe,"A vector class would have to be created that has 2 extra functions as compared to the STL vector. The vector would need to include a pop_front and push_front  function. the push_front would copy each item in  a cell into the next adjacent cell and then add the new value into the first position. this results in a linear/ O(n) time complexity as the number of shifts or copies made is n. The pop_front would shift all the cells after the first memory cell back by one. this results in n-1 shifts/copies which makes the function time complexity O(n), linear time.",4.0,57
16338,16338,20583,18f6254c7b196766dbebfb4556ef6c2f9ff5e44918d8ea60921fbe90c8a42515b04ace17b80ecdd7f09efd69961a6da2d4a21f100e3ebd5acf67acba7ebaae55,"If the front corresponds to the top, then when pushing an item we would not use push back but we will have to push at the front, this can be implemented by copying each item one block to the right if there is still space available in the vector in order to open space at the front, then you can insert the new element in the front(index 0). if there is no space available we have to reallocate and copy all the elements across and do the same thing. In both cases it takes a linear O(n) time.

for the top element, you can use the front() function to access the top item. this takes constant O(1) amount of time.

for removing the item on top, you have to copy each item one block to the left and the first one will be removed, this takes linear amount of time.

The size function will take constant amount of time.",6.0,57
16339,16339,20584,12066f8f6a7f4cd1c9586b77b6e85c69168c3e639d8a7cc579d0737f33e85026e0fc0bba1f43d9a6c097e420e073f5dd573d48b38e1cf440a6f948554edb9454,"I would create a vector with all its elements then use the reverse function to have the front of the vector as the top of the stack, after doing that then I will perform any functions on the reversed elements of the vector. Or use .front().",0.0,57
16340,16340,20585,c2a635a9bcf4ad40fa50102eeb50a8298caf1f43a284d43931e8d6ff78372592382df0d5a087e759cf9a231e99eb6b2b3a8890e03edb12bf9295b2611174eebb,"If we implement a vector with the front of the vector being the start corresponds to the top of the stack means that we need to reverse the back and front of the vector. Therefore we need to start from the back and move backwards which means we should create a push_front function (this function will add items to the end of the array, and due to the fact that vectors have contiguous memory we are able to perform pointer arithmetic. This does not affect the time complexity as memory allocation is still the leading problem when implementing a stack using vectors as the underlying data storage therefore time complexity for the push_front function and pop function is still constant in the best case and linear in the worst. The peek function will just return the item in the front so complexity is still the same (constant) and for size function, vectors already keep track of number of items in the vector so time complexity is still constant.",6.0,57
16341,16341,20586,666d09a4d8260961dbb488b896e8680fe46f9012a9bfa6adbe518edfaed179e00538132a0e660a988cc51e3f8b8695b7b78d6679f0a1e7d0f26361ce20a96384,"push:

We would create a push_front(v) function to add to the top of the stack ( O(n) Linear time ).

pop:

We would create a pop_front() function to remove from the top of the stack ( O(n) Linear time).

peek:

We could use the front() function to return a reference to the item on top of the stack ( O(1) Constant time).

size:

We could use the size() function to get the number of items on the stack ( O(1) Constant time)",4.0,57
16342,16342,20587,8988e05f865164f4560af96560c21e55905eac0bb5f61f3d6e278f9698c3b2aef4e2c138e098da5e867aaa523133fd657970eaa9429e994d798d7fd717f54fcc,"If were to use the member functions of the vector in this particular implementation, then pushing and popping to the front of the vector would always call for reallocation of its items, and hence always take linear or O(n) time.
Instead, we might attempt a sort of 'reverse reallocation open space', where instead of storing the first item at the first index of the vector, we store the first item at the midpoint index of the vector. If we combine this with an initialised variable that stores the index of the first item, then we could use simple arithmetic with this variable such that we wouldn't always have to reallocate when pushing to/popping from the front i.e. pushing to the front would mean changing the value of vector[first - 1] and decrementing 'first' by 1, and popping from the front would mean simply incrementing 'first'.

When we eventually push an item to the first index [0], then we would have to reallocate, and so the best case for pushing this way would be O(1) and the worst case would be O(n).

On the other hand, when we pop enough items that our vector is for the large part 'empty', we would reallocate our items to a smaller memory space. Popping therefore has a best case of O(1) and worst case of O(n).",4.0,57
16343,16343,20588,afeeaae30229bbf9032ee9948e95a3a98860a874d1b1d0d67ee088b120bc22e9fb34f7eeb7b1df4260a0f1a548b9e0b11d627eaa2a17433f88a21e97dee9550e,"If we were pushing to the front we would first have to add to the back of our original vector and then traverse through the vector make every element equal to the one that comes before it and make the first element equal to the one we initially added and the would be O(n). when popping we would have to traverse through the function and make every element equal to the one the follows it and popback the last element and that would be O(n). With peek we just return the first element, that would always be O(1), and for size we just return the size, that be O(1).",2.0,57
16344,16344,20589,a0052d1186f3fa53f67763ddf5dc1148fc540657d42f0891ff3ac99ce8c9f5c8c2cc81fa44f5583e909b3bdda1a0f1e6a21067a67ce2ede8b9d60f7eef57955f,"My implementation would be pretty similar to the way I would implement a stack with the back of the vector being the top.

My size function would be the same, simply relying on the vector storing the number of elements thus O(1).

My pop and push would both be O(n) as they both require all the elements to be shifted up. Push shifts all the element up a place and adds at the front. Pop shifts them all back a place after removing from the font. 

Peak would be very simple, just return the first element thus O(1)",4.0,57
16345,16345,20590,e7c9b4fd869eb791a63c71759d17fa7e8a93618d661588fa6ae371946756531c0923d86aafe2bfd7289d74b69cb5fe841e3839957a75e6446f2d8394b4178536,"I would initialise the vector then implement the relevant functions in the following way:

PUSH: I would implement a PUSH_FRONT function for this since the front is the top of the stack and we can only add to the front of the vector. The function would essentially shift the items in the vector 1 block forward then add then place the item in the argument in the first position.

COMPLEXITY: O(1) - Constant time.

POP: I would implement a POP_FRONT (DATA.POP_FRONT()) function for this since we can only ever remove from the top of the stack. This would essentially delete the first item and shift the remaining items 1 block backwards.

COMPLEXITY: O(n) - Constant time.

TOP: I would use the FRONT (DATA.FRONT()) function for this, since the front is essentially the front.

COMPLEXITY: O(1) - Constant time.

SIZE: I would use the size function for this to return the size of the vector.

COMPLEXITY: O(1) - Linear time.",3.0,57
16346,16346,20591,74ac16aad9cffebc9a82a3d84552ea746b2a726fb003881a5a45ccd11c8a938caed3d1a49b6f0f3b5bc663c85f99ca3ae1d10cb0f79247d51859bb82beada81b,"Fiset the push_back function will take O(n) time since there's no push_front function in vectors...We have to loop in reverse in order to add that item.

To implement the pop_front function will  take constant time O(1).",1.0,57
16347,16347,20592,5d0d60194fd1b05c809499adb963afbac0ab800c552d7666ea7779f6183d17839f234e9ecee3ed11e567d9e2e5d5f869bc08bd2cc74894f9ca624282e8055b10,"Using a vector as the underlying data storage, we would use the functions pop_front() and push_front() as we are dealing with the front of the vector as the top of the stack. Meaning that we should only be able to access the first element in the vector. Thus push_front() and pop_front().

We would use the pop_front() function of a vector for the pop() function of the stack, and the push_front() of the vector as the push() function of the stack.

For the top() or peek() function, the return would be the front() function of the vector, or data.front()

The function, push(), would be constant, O(1), in terms of time complexity.

pop(0 would be linear, O(n), in terms of time complexity

The size() function of a stack would be constant O(1) in terms of time complexity

The top() function of a stack, which uses the front() function of a vector, takes constant, O(1), time.",4.0,57
16348,16348,20593,a4513e9eefe06c5d06cd544fbaa5db795547b8f01893c660dc4a8e31a77cbc61bded840bbf0b3fd52a94491adbe0a21a3d4396c46fe19d46198e8b7b21695be6,"Since the front on the vector is the top of the stack, we would be dealing with push_front and pop_front to add and remove from the top of the stack which would be both O(1), and the top function would be our data.front() which would be O(1), and the size function would just return data.size() in O(1) time",2.0,57
16349,16349,20594,4c6239f4837a7e4857168ce1d90eccb0590dbff5755d1452f6eced3fa662d6b3d452d78b9021e9f1b0bb440c88d3e31a3396f8ac92fb89f14b2269d4512bdaa8,We would be pushing and popping at the front of the memory buffer. The 2 functions would always take constant time as we would have to move all the items either to the left when we popping and to the right when we pushing.,2.0,57
16350,16350,20595,50ac02db01dc47f0f24bb2a0e8bc1bebe3aac1ecfe652f1c87b260f45da4def0a267392e043e67a0b0f3a39374188322db34615d5257a196fc0978d4d004e1ed,"The pop and pushing functions will always taking  a linear amount of time because whenever we use a stack as a vector as the underlying data structure we  will be required to move items one space to the right or to the left ,depending on whether we are pushing or popping",4.0,57
16351,16351,20596,ab914ab560d18c5aef3e43bda3ed23f3106afabfcaabd71fb45ebbdc423746252b1d705ea396aa70f877858829d5c8d335f73b945106c9ea584789a7d7f0ea77,"If we use vector as our underlying data structure for our Stack and we treat the front of the vector as the top of our stack then we will have to push and pop from the front of the vector. Popping from the from of the vector would require us to move everything one position over to the left and then delete the last item. Thus it would be O(n) complexity as we move over n items. We also have the special case where the vector is to empty and we have to reallocate with a smaller size, the time complexity still remains as O(n). Pushing to the front would require that we move everything one position to the right and then insert the value at the front. This would also be O(n) time complexity as we move over n items. We also have the special case where we have to reallocate with double the size because the vector is too full, but the complexity is still O(n).Our top( ) function would take constant time as we are just accessing the item in the front of the vector. Our size ( ) function would have O(n) time complexity as we have to loop through n items and add to the count to determine the size of our stack. ",5.0,57
16352,16352,20597,c1e9e5684a44aa14de0a7d7593ec9809b4c2858f861776d6d9a8b2df4bba9cc394db455eb7a58c49a19ed6c08dee2a5b9eba1e9f390b469640fea31d4ffda4c0,"Using the front of the vector as the implementation of a stack complicates things because the pop and push functions would always take O(n) time. This is because to push or pop at the front of the vector, one would need to reallocate all the items that follow the item at the front of the container one place forward, then only add the new item or remove it. This is also the reason why ""push_front"" and ""pop_back"" are not included in the std::vector class; pop_back and push_back are just better since they take constant time - O(1), and O(n) in the worst case. 

The size() and peek() functions can be easily implemented in O(1) using std::vector::size and std::vector::front. You would need to create your own push_front and pop_front functions as described above as there none in the STL under the vector class.",6.0,57
16353,16353,20598,6398cd3a19a3d471bc5a210dfd041039aa199f2840055e48507502bec88a8f8eb3f128de790430daa8207ba0fde7dea8a8fb8416bcb584e1bb9e76ef88b1e1f2,"1. Push_front() will be used to push an item to the top of the stack. this will be O(1) time complexity.

2. pop_front() will be used to pop an item from the top of the stack.this will be O(1) time complexity.

3. vectorname.back will be used to get a reference to the last item on the stack. this will be O(1) time complexity.

4. vectorname.size will be used to get the number of elements on the stack. this will take O(1) time complexity.",1.0,57
16354,16354,20599,9723aae78697f512e67589fc396726b9c942a3d3f5596d681f9e90a55d7c7cee67b2655817396577b22474e4f116aa7866389d9d9a43a0c0e1dd45d6998cde32,"PUSH FUNCTION

We would have to create a push front function which adds an element to the front of the vector. This function would always take linear time because each item currently in the vector would have to copy/shift each element one to the right therefore allowing the first index to be occupied by the new element.

POP FUNCTION

We have to create a pop front function which would remove the element at the front of the vector because it indicates the top of the stack. This function would also always take linear time O(n) because we would have to copy/shift over each element one to the left after removing the first element. 

PEEK FUNCTION

Ths would take constant time using front function which uses pointer arithmetic to get the first element.

SIZE FUNCTION

This would take constant time using the size function as the vector keeps track of the number of elements.",6.0,57
16355,16355,20600,c7d75d976a010a38db71e259afee15ce7c42ba18fa8ef2214021124356299e2bc696f235d69042a2e7d6021b611ee4096167f90988dc7b1e755fca98c40f31fd,"To implement the push function for the stack, i would create a push front function which would add an item in the front of the vector by copying all the elements in the vector one space towards the back of the vector and change the value of the first element in the vector. In the best case, there would be enough space in the vector to add an item and the time complexity would be O(n). In the worst case, i would have to reallocate space and by creating a new vector and copy all the elements to the new vector. The time complexity of the worst case would be O(n).

To implement the pop function, i would create a pop front front function which would remove an element from the vector by copying all the elements in the vector one space back. In the best case where we are not wasting too much space from our vector and therefore don't need to reallocate space, the time complexity would be O(n). The worst case would have a time complexity of O(n) as we have to reallocate less space for the vector.

I would implement the peek function by returning the vector's front() function which will return the item stored in the front of the vector. The time complexity in big-oh notation would O(1).

I would implement the size function by returning the vector's size() function which has time complexity in big-oh notation as O(n).",5.0,57
16356,16356,20601,263fd6b7e81bd2b0bd84f67415866c3d75bf78011a0e0748b552d65d3fb35fc4bf5dca96f9ccb82225afdb2c9f73d9593526bb28fe17ab6d85ae420a8a33d70d,"We would have to implement our code very similarly to a regular vector, however, we will need to write some code that allows us to remember which entry is the 'top' entry and update it as we make changes to the stack. In this case the first entry is the top of our stack and we will need to make use of the push_front and pop_front functions in order to add and delete entries which will find some new memory if there is not enough space or too much space in order to copy over the entries and delete the old list from the old memory. Meaning there is a best case of O(1) and a worse case of O(n) for both the push and pop functions. For the peek and size functions it will always be O(1) because we always know where the top of the stack is.",2.0,57
16357,16357,20602,5b79e321acf32f26a1c6cc9091fa349a8baa70385c6fb736e55b942fea1901b561d1f53857749ead207a2933e580c9dfc66c9af868e9b035d1dff322ef7cd5be,"Push : For the push function i would have to implement push front function by copy all the elements in the vector and moving every single element in the vector one element back .The time Complexity will be O(n).

Pop: For the pop function i would have to implement a pop front function by using the erase function of a vector  , i would pass in the begin function of a vector as the parameter of the erase function  . The time Complexity will be O(n) since the erase function of a vector takes O(n) time.

peek: for the peek function i would use the  begin function . The time complexity will be 0(1) since the begin function uses O(1) time.

size: for the size function i would return  using  the size function of a vector . The time complexity will be O(1) since the size function of a vector takes O(1) time",6.0,57
16358,16358,20603,7f4b419d2ced93d50fb8649f87b2fa3a1ab4c6a1ecc8b63f150aeb372237c21eae97c5eba18c0880eb018ac5d3fb68e9a7180e8af2cbb1d90dc8d7f06f63f097,"for push: I would shift each element 1 position to the right then I would push the new element to the first free index. I would double the size if there isn't enough space. It would be O(n).

for pop: I would access the element and index 0 and remove it, then I would shift each of the remaining element 1 position to the left. This would be O(n).

for peek: I would access the element at index 0 and find its address then return it as a reference. It would be O(1).

for size: I would introduce a counter variable and loop through each element and when it reaches an element it would add 1 to the counter. This would be O(n).",6.0,57
16359,16359,20604,0a1930b4d16e62ac7ee353c6144c568d9ee6c791d0d3632d3ce78fd24bb2c65d328c4924d6cafd1daed9790efaefb16fe2a520125cf9396ef372146945ae0496,"If the front of the vector corresponds to the top of the stack, when pushing, a push_front function should be implemented. The time complexity is constant (O(1)) in the best case scenario and linear (O(n)) in the worst case scenario.

When popping, a pop_front function should be implemented in order to remove from the top of the stack. Time complexity is constant O(1), but can be linear O(n) in the worst case scenario.

To implement the peek function, data at the front of the vector should be returned using data.front. Time complexity is constant O(1)

To implement the size function, the amount of data within the vector is returned using data.size(). Time complexity is constant O(1)",4.0,57
16360,16360,20605,fe62a1f5e7fe2a4e7ab8c966f31166711ff57cc766445f2fc4370a7348f81dab059b866c1f91a4b1ff166d595fb9234d29f7f66b2297a565d84b506f3bd0f6e7,"Vectors use contiguous memory. So once we implement and initialise our stack variable , we will know that each item in our stack is tored next to eachother in memeory.

Having the top of the stack in the front of the vector we implement the pop , push and peek functions as follows:

	* Push : adding a value to the top of the stack will mean our first item in the vector , the data stored in position 0 , will be where our value gets pushed / added to. If there are already items in the stack , they will be moved down a position in the vector. Since the standard vector class doesnt havea push front function we would have to use a for loop of size = size of the vecor and move everythign down and then store the new value at position 0. since we have to move everythign down , it is of time complexity O(n)
	* Pop: Removing the top value of the stack will be deleting the data at position 0 of the vector. Since there no pop front function in the c++ std libraries for vectors we would need to implemnt it ourselves. Start by deleting the data in postion 0. Then , loop for size = size of vector -1 and start at i = 0. set data at i to be equal to data at i+1. Vectors are dynamic but it would be safer to reset the size to n-1 using the resize function. Since we loop through all the values , it will be O(n).
	* Peek: for peek , all you need to return is the data at postion 0. so it will O(1) complexity.",6.0,57
16361,16361,20606,66ba5975b098f5fa2bae0b86dceb6b280b99b8f4c6fff5dafe0a067b8a9153b49a39abe1525261732c63d25886c01c121ff46cf2ab2721a603f04674ea202257,"Because the front of the vector corresponds to the top of the stack we do not need to create a top variable and increment it every time we add an item to the vector. Instead we can assign the Top variable to be equal to the front of the vector, ie to 0 and leave it at that. 

PUSH: USING PUSH BACK

	* Adds a value to the top of the stack and would take constant time, O(1), but the worst case scenario is if there is not enough space and we need to reallocate, this would then take O(n) time. 

POP: USING POP FRONT

	* Because the top of the vector is the top of the stack, removing the item at the front of the vector would require that every other remaining element in the vector is shifted one place to the left, therefore this will always take O(n) time. 

PEEK

	* Always requires a constant amount of work - O(1). 

SIZE - USING SIZE FUNCTION

	* Similar to peek, this always requires the same amount of work - O(1). ",4.0,57
16362,16362,20607,5888307e6e5630e26d91393f9d95b55394aa59f773d80fc5cba42e8220ea74538fd7609c1185eaef557523bfd3715cc3b2307d7a31ddf68499df84fa7da160d9,"I would write ""top"" to always return the first element in the vector only whenever it is called.
this will take constant time because it will not have to traverse the whole vector to return the first element.

Total time will be O(1)",1.0,57
16363,16363,20608,854bde56afcd2bd2c31fbe39384369ef7c0ac613a004a4b239a7a7d08872fa336ab049f8f45358abb5e93ca8dfc33e8954bf246487197e2265435ed3c204826b,I would implement it in such a way that the push function of the stack pushes that certain item to the front of the vector. I would also implement the pop function of the stack to remove the front element of the vector. The top/peek function of the stack would then return the front item in the vector. The push function would take O(n) time since the vector would need to shift every element to the right before inserting the new element at index 0. The pop function would also take O(n) time since every element would be shifted to the left after popping. The top function would take O(1) time since vectors support indexing and the size function would also take O(1) time.,6.0,57
16364,16364,20609,482f7dae015b4c467d12506c33e2fe66aeff1ddddb85f2c9bce0e0756918b84a46072cd434d5bf20b674533a59b9c793d9d747268246eec497aed1c0f31a1c3c,"I would first initialize a stack, then use the front as the top of the stack. I would have a counter or use the size() function to show how much is in the vector to know how much we need to push up the vector to add a number to the front. 

The pop() function will have an O(n) function as we would remove the item from the stack and move the items in the vector down. 

The push() function will have an O(n) as we need to move the items in the vector down and then add an element to the front of the vector. 

The top() function will be O(n) as it gets the first item which is at the top of the stack and the first item in the vector. 

Size() function will be the number of items in the stack and vector will be O(n) as we will have to transverse through the vector to get the amount of items ",4.0,57
16365,16365,20610,17a5fd9d02d6fba8d8046ace71c42e033c0f094c5a424e213efe17ca2b15dcda4339210b67d2e20cb931a5cb55e9b6fb5621dde12a8a5e6da612e051b176b44e,"Push all the items in the vector one step backwards and then add to the front. 

Time complexity - O(n)",2.0,57
16366,16366,20611,8ccaa62cbbe76ea20aad42f0abeb4aea6b057f35352db9aef1c4c8bb791949070df63d7ca3789507be754a64de8d3383c759c83cb767d9e10e045b387bce8a09,"vectors have push back and pop back functions\methods , so i will use the front the vector as the top of the stack . The i will have to peek at the front to get the value before i pop it, stack is stored in a vector then we will have to push the elements which will be stored in the stack .

push front = O(1)

push back = O(1)

pop back =O(1)

size = O(1)",1.0,57
16367,16367,20612,336c0de60905df4ae163484013b5cc72929683b64ebae6f69a61ca7bbc767084419ba7cf9291246a9b63bc7e686a397f48c33976b41fb34999f9b50eee045aba,"Every time I push data into the vector I move the previous item one block forward using pointer arithmetic and for loop , therefore therefore the most recent item will be the front of the vector and this will take constant amount of time to shift items and linear amount to push them so, overall it will take linear amount of time.",0.0,57
16368,16368,20613,be6529d2c60e9c3e44398e6d6378522b796199a001be8bd7e7bf876610ef85fd8204961bc4cabc5a2506d1dd5b074658c765a8f7b3311d9493c6efa1d870167b,I would create a vector and then every time I want to use the push function I would shift all the items in the vector one unit to the left by using a for loop which will make the push function have the complexity of 0(n). Then when using the pop function when I want to remove the something from the top of the stack I would remove the thing in the front of the vector and then shift the items one unit to the right so that the first space in the vector is not empty and that will be done by iterating so making the pop function also 0(n). Then for the size function I would just keep a variable named size and keep increasing it when push function is used and decrease it as pop function is used so this will have the complexity of 0(1).,3.0,57
16369,16369,20614,2c32439612d29606cd7276c7d7327878252b82b353a0e5c5a38f508a89318428edb5d433b571f4ed85a8cddd2dbf4c9c5eb5b82d38c65addb4bffc9179a95b21,"A vector could make use of two different stacks and reverse the stack each time an element needs to be added. After this, the stack will have to be moved back. Thus, the complexity of the push and pop back functions would be linear, O(n) as each frame on the stack will need to be removed before implementing the function. This would mean that the time is dependent on the size of the stack. O(n) would also be the best case scenario, the worst case would be quadratic, O(n2). The size function would also be linear, O(n) as it needs to count how many items are on the stack. Thus, it is dependent on how many items there are.",0.0,57
16370,16370,20615,db2da6294f4863255b8e851f3219cc1d358a9a52af31fcce04dfd21a77bd1b6105ebfb54ad3aa0cbea5dc9fb93c67b5af9e1ff40b17fbd626a20ad3636813679,I would swap the push front function and the push back function,0.0,57
16371,16371,20616,9a6d2e6e6e0c1b575d6fd6f9cd31a3d7ef05b9fbb8f9b527d2f24c66326f4e25fb885d747e3511e370820c0e5c65531a52fb8637b76c7b43895037c2420cfc80,"For the push function I would insert the item at the front of the vector

time complexity O(n)

For the pop function I would remove the item from the front of the vector

time complexity O(n)

For the peek function I would return the reference of of top item

time complexity O(1)

For size function I would traverse the entire vector

time complexity O(n).",3.0,57
16372,16372,20617,cb120576f9fc254cce2a2bdcc2fab8a2f95f1ad24a5398cde6a97bb68344852b25ff6ddb6448c5c344141e6c8f5ee1dd504e841ca984819c02a7811908c51bc8,"Instead of using the push_front and pop_front functions of the vector we will be using the push_back pop_back functions which will always require O(1) constant time in the best case and O(n) linear time in the worst instance.

To get the size we will use the vectors ""size"" function and to peek at the top we will use the ""front"" function, both of these will always require O(1) linear time.",4.0,57
16373,16373,20618,5dcf09a63d08f8fcf484a27b8188aca8e05117584de8c4c8e580d2681056a972e8271fbb1e9e69a616d3a8d13ef9009ce7fbd4e4c680807f0aa62ce637934a9e,"Push functions:

We start at the last element and set the value of next position to the current value. Then we would work our way down the memory block to the first position.

The best case would take a O(n) time and the worst case would take a O(n^2) time.  

Top function:

We would access the first element of the vector i.e data[0].This function would take a O(1).(the std front function)

Pop Function:

We would start at the first element and go through a loop to size of the vector , setting the current data[i] = data[i+1] . Then we would set the last element to a null value. ",1.0,57
16374,16374,20619,efe8bbe0531a8edbaeccdc4f50ad7d19da4ae088aef554a1013cb2ff8b78ba31a24fa0e8f957d84b8c738910275c42c68da1550413f3ef77aa9c38fb88257b54,"To implement stack which uses a vector is the underlying data storage, we could create a class called 'Stack' and then implement the following functions as follows:

	* push - to implement a push function we can make use of a function called push_front() (which we would have to make since it is not already present in the c++ standard library).  This function would copy every item over to the right (for example position n would be assigned the value at position n -1... position 2 would be assigned the value that position 1, position 1 would be assigned the value at position 0) and thereafter set the value at position 0 to the value of our new item. Following this logic we have successfully pushed the new item to the top of the stack. At best, this would take O(n) time since we have to copy n - 1 items, however at worst this will take O(n^2) time since we might have to reallocate to a larger block of memory before copying to the right, and hence have to perform an additional  n copies.
	* pop - to implement a 'pop' function, we could make use of a pop_front() function which we also have to make ourselves. This function good copy every item over to the left (for example, position 0 would be assigned the value at position 1... position n - 1 would be assigned the value at position n) and then pop the end of the vector using pop_back(). At best, this function would take O(n) time. However, since we may have to reallocate to a smaller block of memory after calling pop_back, this function would take O(n^2) in the worst case.
	* top/peek - to implement 'top', we simply need to return the location of the value at the front of the vector (top of the stack). This can be done using the .front() function, which would take O(1) time.
	* size - to get the size of the stack we can simply use the .size() function, which would take O(1) time.",6.0,57
16375,16375,20620,f568f900863758606ecd596c211921a4e2f0720e3778a3f2c91b74ff667248e8a2d4bcea0036dc07a6e043d08d7d7b64e5934aa3ba779587a955877ff84bfb17,"I would use the c++ standard library for the the size and ppeek funtion. i would use the ""front"" vector function to impliment the peek function. The time complexity of these would be O(1). 

For the push and pop functuions i woukd have to code tem myself a C++ vector standard library doesnt have pop_front or push_front. i would code these using the ""insert"" and ""front"" functions, and you woukd then need to shift all the elements either one up or one doeen depending on if you are poping or pushing. The time complexicty would then be O(n). ",6.0,57
16376,16376,20621,0bce68d12d4bb423184167950cec8450c2529233502545e57429beb9cfc6f093c786ba9febad285f8197b7bbc233a3b506a933f196c9852e05b5416cd8c68c8e,"push front move every item  over by 1 this take O(n)

pop front removing the item at the front O(n)

peek looking at the item on top O(n)

size O(1)",4.0,57
16377,16377,20622,ea2a1bfcbe729f7621c917f77c54d68d14594e336635f36baf52750af4fc628657adce12683b4083425f0f9b883a0f335d02fe57cab5815e5cb77320840dd672,This would have 0(1) complexity since you would need to appoint a value to the front of the stack which can easily be accessed in 0(1) time. you would need initialize a variable that represents the stack and indicates the contents  of the stack. As you push more elements you are incrementing that variable and you would make that specific area in the vector equal to the element you would like to append.,0.0,57
16378,16378,20623,b722c8fd9eec42aa602e4cbd2ceee62645727f2b19607bd1bed826053b9d70a2c8e8d845bbe5119d6c5e8f3413efde7438ae5ec2d12a60cf1215dd59daf4a367,"One would need to create a class that takes in data of type thing and also that has a variable that is a vector of type thing.

Then one would would ensure pushing will only have the data being pushed to the front of the vector. Also ensuring one could only pop from front of vector.

When accessing the top of the stack one would access the front of the vector.

Overall the code would be very similar to when the top of a stack corresponds to the back of a vector, except that one can only access or add to or remove from the front of the vector.",0.0,57
16379,16379,20624,d7dfb51332e1c950aa433a238f3273834b82e31a54a773c512e9c88094b5b27c10ba7527d092402ee28c450551c97d4efc1d9a6fab4f18a9a6df9f32cd052165,"call a class stack and make it public, then call the push, pop, size and peek function inside the class and the complexity will be constant. popping, peek and size time complexity will be constant. ",2.0,57
16380,16380,20625,16f09d60ea55f541a3437e3e2ab8e9c69f838f50f98dec712996c73779cd9f654e7fa72007ae7a3b8d9cb813c8fad8d686dc40ba57c222e292c85b1a88fc8b53,"In order to implement a stack which uses a vector as underlying storage and the front of the vector is the top of the stack, one needs to remember where the top of the stack is at all times. So if we had 4 blocks of memory and it is empty then the top of the stack (front of the vector) is at -1 (Top=-1). In order to add data at the top: 
Top=-1;

data[top+1]=S1;

          top++;

this will ass S1 to the first block of memory. Continue adding items to the top in the above manner, until we run out of space when  n_items = n_allocated. Now, reallocate and copy everything across and free old memory. This is the same as implementing a vector. So implement a class stack and make it public.

To push- data.push_front      time complexity is O(n)

To pop- data.pop_front         time complexity is O(n)

To peek- return data.front()   time complexity is O(n)

size_t- return data.size()        time complexity is O(n)

then make private : 

       vector<thing>data;

                                                  ",2.0,57
16381,16381,20626,20820f051ab9e7b5dde112869be67e2e49734267d017f30c8e3086343a31575407d74708ebc5d385e1b1a34dd7dd81fa4425af4e6cb2bbdba32928c419b4a8da,"- if the top is the front of vector, when inserting we will have to push all other elements back

-removing would result in just taking off the top of the stack and will have time complexity of O(1)

- the time complexity is O(n) for pushing front",2.0,57
16382,16382,20627,936024d8e9328998a220b77c48098f57a0d619263f7c2ad0ac4157dfe9370e11abee7f579d65a28c46224757256e636c01fe798d4c5eb4d7e1574b7de8511fbf,"We will push the items back in the stored stack. We remove from the top of the stack as the top is the front of the stack and the time complexity would be O(1) ,popping.

We add the item to the stack. Time complexity is O(1) ,pushing.",0.0,57
16383,16383,20628,18821a50a643c1101d4d4b4a20eab092e9ef83d83d66cc8b476254122713205813222ecc2114e01a4fff80d19f68cc23c5bc386f899d5730224a2f35e7ae4a2c,"size() will be the same as the size() function of the vector class with time complexity O(n)

peek() will  make use of the front() function of the vector class with time complexity O(1)

for push() we'll need to move each element 1 cell back and make the first cell equal to what we wanna add, the time complexity will usually be O(n) and O(1) in best case.

for pop() we'll need to move each element 1 cell forward starting from making element 0 equal to element 1, the time complexity will usually be O(n) and O(1) in best case.",6.0,57
16384,16384,20629,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"I would use Push back and Pop back methods and the time complexity would be 0(n).

I would return a reference to the bottom of the item and the time complexity would be O(1)",2.0,57
16385,16385,20630,3dc26b747d97da3ab4afec05ff58fc24d9456624d1de4e773000cee11c5770c4305e55aba8a358eac1e51ad690a762f5e637a6ce6a5554139fe18ecd7662a5af,"For push_back I would
Move items of the vector forward once, then make the first item equal to the item I want to push back, it would take linear time O(n) 

For pop_back 

I would make the first item to be equal to the next item and then delete the last item. 

It would take linear time O(n) ",2.0,57
16386,16386,20631,c33667ae11b7bded2337c08d116fa497bbbd12dbb6b1affa7fb94c650c68ba165865aab5e81895db475a23ff725c4bc69da22573104a9522dcaf9138fd9b447c,Time complexity will be 0(1),0.0,57
16387,16387,20632,17af69de9b004cebc772407eb454a4695fd215d61e6315c9d12ef0dd3a08b8a8642b4cc8dfc787e7755ff0571045a1730ffe50dbf1069009256ea87e870d4fed,"When using the front of the vetor corresponds to the top of the stack, the 0th item will correspond to the peek of the stack getting this reference will be in constant time. When popping an item from the stack you would need to remove the first item of the vector this will be in constant time most times and linear time worst case. The push function would be implemented using insert to add an item to the front of the vector, the best case would be constant time but linear time in the event the vector needs resizing.",3.0,57
16388,16388,20633,c4c2c137f4d09a740b1294afb17fe688d9891bca471136eebcbf46a7f61b0527136ab092a90608b5c573cd06db378a8bca203b8fa5cda62d61e93ce21bb7a858,I can dynamically allocate a memory to the heap memory and use the push_front and pop_front functions to insert value into the vector and this would take constant time - O(1),0.0,57
16389,16389,20634,01414e21ecb9a1334890023f94a0d282ee23097fe9f9524ae17a5a130cb936a59877f182817dee70cef409eabab63c6b47a25ed1ae4ef0dfef7f2566f253e2b1,"A stack should be able to push and pop and these functions both take place at the top of the stack 

Push: the top of the stack is the front of the vector. This means that every time we push a new item to the front of the stack, all the other items must move a place to the right  i.e their place would increase by 1 n the vector and this will take O(n) time as every item has to move 

pop: If one pops an item off the front of the vector, every item in the vector must move one space left i.e the pace of each item must be decremented by 1 so that there is a new ""top"". This will take O(n) time as each item is shifted ",4.0,57
16390,16390,20635,a0053c94d18ea0e087a62013f5ac80c5b6b5b2b0c4aa9dd88e21096fafa1947351de1bc64c5f102a231a8bd4d8d7cf40acc72747f50d8fe1ae800f7aa85e0eed,"We first need to implement a class for our stack with a tail pointer Then we make and call all our functions public we can define our functions such as pop, push, peek, and size. We then make functions where the user outside cannot change our functions and where we store out vectors on the heap, where we will would not worry about it. 

push and pop functions will be linear in worst cases and best in constant. The peak function will be constant and the size function too.",4.0,57
16391,16391,20636,1d469feec8dabc8efe190b91bf2431897a77efbd16b2d85bdc6124d89beaeb95e4c3d1758db03e27ba5dac6295ff2b30f3eaaa927d0748ab45ecd18c4991abfb,"Create a class push_front of the vector by using pushing the thing at the back (push_back) of the vector that I want to add to the stack and copy each element in the vector to the next index which will make index 0 be empty and add the thing to in the first index and use it in the stack class. The complexity of push_front and push_back will be linear will the linear 

 ",3.0,57
16392,16392,20637,5ad20b3b420c21e1fc2861df4f4257210672d867b8a024855b258388d20148643f1a94c77f0aa2d4b47f8fba4b85741287207442ff519080915f15fdfd0e21b1,"To add to the top of the stack (which is the front of the vector) we would have to use the push_front function. This would take a constant amount of time  (O(1) time). 

To remove a value from the top of the stack, we would have to pop from the front of the vector using the pop_front function. This would also take a constant amount of time (O(1) time).

for the top()/peek() function which returns a reference to the top item, we would have to return a reference to the first item in the vector, which can be done through indexing or pointer arithmetic. this will take constant time (O(1) time).

for the size function, we will have to return n_items, which keeps track of the size of the vector.",1.0,57
16393,16393,20638,0fd0096c1497543ca0003b9e3ba007221cbda2328585a2f2260277e1c7038bb2ae7ad23e03908936421523651b3b5785ece380b977ac663ea4a02a050d012617,"A  stack follows the LIFO last in first out principle so to implement push you to push to the top of your stack and pop at the top of your stack also.

you use the push operation to push, push (int x);

you use the pop operation to pop, pop ( )

to return the size of the queue you use the operation size( ), it will return the number of elements in the stack

the top operation returns the top elements  present in the stack top ( )

the time complexity is O(1)  for all the  four operations   pop ,push ,peek and size 

in the worst cases its linear O(N)",2.0,57
16394,16394,20639,e81419dfc1d9569cd33a892060afd65b53683380b098be177940b37177a69388dbc26f4b88ae9117e614069eb6d29407e325e18a19fd38be90fa494f6adff772,"To implement the stack which has the vector as the underlying data storage with the front of the vector as the top we would have to implement some new functions in which the normal STL vector does not support such as push_front and pop_front. The push_front function would have to increase number of items in the vector, (reallocate if necessary), shift all elements to the right by one and then insert in the very first position our new value thus our push function in our stack would be implemented easily if we adjusted our vector container. The pop_front would work the same just in reverse, this would remove the first element of the vector, (reallocate if necessary), then it would shift all elements one to the left thus our stack pop would be implemented easily if we just adjusted our vector container. The size of the stack would be implemented as normal as the vector keeps track of the amount of items in it and so that would require constant time O(1). Peeking would also take O(1) as we could just return the value stored in the first position using .front(), etc. Push would take linear time O(n) due to all the copies in push_front of the vector, and pop would have to take O(n) due to also all the copies in the pop_front of the vector..",6.0,57
16395,16395,20640,a0a0e3863f2cfe81dc13120d1d5fb28060efbca078cff0afc0ca4a53755acf909a3b28053a432d02251e8d53776e3aedf7eeff75f48fc36029b0d4fb7d46aa25,"Vectors in C++ do not support push_front or pop_front. Thus I would first reverse the items in the vector so that the back of the vector would correspond to the top of the stack.

In order to implement push, you need to add an item to the back of the reversed vector, so I would use the push_back function. This function adds an item to the back of the vector using pointer arithmetic. If the vector is full we need to copy all of the items into a bigger vector. In the best case this function takes O(1) time and worst case it take O(n) time.

For the pop function we need to remove an item from the back of the reversed vector. To achieve this I would use the pop_back function which removes the last item. This would take O(1) time in the best case and O(n) time in the worst case as we would need to copy everything into a smaller vector.

To implement peek, we can use pointer arithmetic to access the last item in the vector. We would use the back function. This always takes O(1) time.

Finally I would use the size function of vectors to implement size. This function always takes O(1) time because vectors need to keep track of the number of elements they contain.",6.0,57
16396,16396,20641,640080dea627eeb31a3d305d032f6df57a0ee21da5dcbd20ff6bbe259d5ca01d650ffa6e7bab08f963664be0fe5ab3d7fb527ab7ad27b3354df44960876962d7,"to add to the top of the stack we would push_front at the vector ,complexity is always linear O(n).

to remove at the top of the stack, we would pop_front at the vector. complexity is always linear O(n).",4.0,57
16397,16397,20642,92791654d3cd52922c5b338b34156b28fe55a4ccee1e7fc5905b97888cf317c2fcae873ea940af535130a211df4483d7fb93e8718b1976f9cc9aa146daf834aa,"complexity is 0(1)

just as how you use push_back function for the vector to add values at the back you would use a similar push function to add values on top of the stack. Therefore the thing stored latest in the stack is what is at the back of the vector.",0.0,57
16398,16398,20643,55ff8d4f9ee8af9848a55dc4a2a3322adb850c959c61827806d583f4f72e4caf8076da8ae41627b21a0edd1eccee2cd496b303fbcb256d41e8ba6c3b55c02e66,"push - O(n) We always need to traverse through the vector until we reach the front in order to insert at the front of the vector.

pop- O(n) We need to traverse the vector until we reach the last item then erase it from the stack.

peek- O(1) the item will always be at the top of the stack. We need to access the address by simply calling the item at the top of the stack

size- O(n) traverse through the vector till you reach the last item while keeping count then return the count.",3.0,57
16399,16399,20644,67bc8fffe61d28188b3d7107d51be90441e6dd51c98f3db877749a2a97847646dc952b6812856f170fac011bfccdf49477179e4f3e8c4e51b5aea238df99b414,"Push function: use the push_front function which will push the object to the front when called .The time complexity will be O(n) since all the other elements need to be shifted one position to the right

Pop function: use the pop_front function which pop the value at the front when called.The time complexity will be O(n)  since the other values will have shift one position to the left.

size: use size() function which will return the size of the vector .The time complexity will be O(1)

peek: use the front function which return the value of the element at the front of the stack.The time complexity will be O(1)",6.0,57
16400,16400,20645,d2c94c0dca7decb41292af9de73a32afa110cab818c0e296b000bfe9dd7b6bf221a0332e01f53ce869a1f4affd4abbea90b7e61d9504a5178a430b94bbde20af,"To add to the top of the stack, you use push_front(t) with time complexity O(n).

To remove from the top of the stack, you use pop_front(t) with time complexty O(n).

To get the size of the stack, you use size() with time complexity O(1)

To get a reference of the item at the top of the stack, you use front() with time complexity O(1).",4.0,57
16401,16401,20646,936c1ec869d8f0942d3b84b8b6c320188374f7b930016464dda43168d457286fd222e445f17b63344d55d3ca25f550407692016dc54317e807a5e1c9658269bd,"ALLOCATE ENOUGH MEMORY.

VOID PUSH

VOID POP.

BOTH 0(1) IN BEST CASE

0(N) IN WORST CASE",0.0,57
16402,16402,20647,7c939bb7eae30ac9fde6bed7ba91e751cb79bad249785d6c36230c4d9e80b55aaaf08d983990b398d630a07852718c75269fe0b377bbd248cf1db616b416f57e,"With the front of the vector as the top of the stack;
to implement a PUSH function that means I will have to copy each element to the right (assuming it starts from the left as the front) starting with the right most element in the vector and then setting the value of the element at index 0 to my new element that is being pushed. In some cases if there is no space I would have to reallocate and then copy elements across to the new buffer and then copy them again to the right and lastly setting the value at index 0 to be the new element being pushed. and with each push I increment my counter(NUM+1)

O(N) in worst cases O(N^2)

For the POP function I would simply copy each element to the left starting with the element at index 1. and then decrement the counter(NUM-1)

O(N)

For the PEEK/TOP function I would simply return the element/reference to the element at index 0.

O(1) CONSTANT TIME

For the SIZE function I would simply return the counter, (NUM)

O(1)",4.0,57
16403,16403,20648,4ee5c3f6edd0831bd10d63a696f6638df5b754a34f97686d41e648c7e383b2fbf2f7080c3b7f108b718723955a3e61137ab00a8d8d64c8fb5453ee8eef444085,"as stacks use LIFO principle, the front of the vector will correspond to the top of the stack and an element will be removed from the front of the vector.

for creating the stack we will include the <stack> header file in our code. then use std:stack to define it.",2.0,57
16404,16404,20649,562a79f866657142ac8bf9d260020a41dd948177d2bce6c88383e228d52056cf2d2544e838847e98137352689514e6b5fccb58b9b8779b353c6c283dfc7313ad,"The implementation would require a protected data member which in this case will be a vector. The functions included specifically pop() and push() will take O(n) because their implementantions and also due to the way a vector is constructed and its points are placed contiguosly that means that each and every time we pop() we have to make a new data buffer in memory and copy the next n-1 items after the first so that we 'POP' at the top of the stack . The same thing happens where we have to push, we are going to make a new data buffer which is capable of holding n+1 elements where n is the size of the previous vector and not the allocated blocks of memory, then we would have to copy first the new item into the front of the vector then copy the remaining items into the new vector which would always be some linear function hence the time complexity would be O(n).",6.0,57
16405,16405,20650,6a787853e1f57b2d3b0d74f5ae62b179adb7413dd588b37a8f7082bdd65e471590c4f39498c937e59e73bcf33962fea95df098117d05b73852f11db547a99d9b,"-When using vector as a data storage the vector stores a pointer to some data that is on the heap.

-the vector would also store the items stored in the stack and the amount of space that is being used.

-pushing =O(n)

-popping=O(n)

-size =O(1)

-peek=O(1)",2.0,57
16406,16406,20651,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,"Using a vector has benefits of using it's built in functions so for adding items to the stack I would use the push_front(t) function which has  O(n) time complexity

for removing items I would the pop_front() function because we would be removing from the front of the vector which is the top of the stack. The time complexity of is O(n) because we would need to copy all items to the left index after popping

To get the size of the stack i would use function size() which will take constant time. O(1) is the time complexity

for the peek I would use the data.front() function to give me the first item with time complexity O(1)",6.0,57
16407,16407,20652,6ce5c22e2014cf62c3f9857f1a5d029cd8403915d5de52ffef745d92a330418a129b81b3d1fc019ceb103f7414cb06b86a44ab05670ba63e692007c026c9822e,"To implement a stack using a vector where the front of the vector corresponds to the top of the stack would require 
moving every element/item in the vector one element back, therefore, needing multiple copies of the same vector in 

order to add to the front or remove from the front. Time complexity - O(n)",4.0,57
16408,16408,20653,5f92eb6a07aed01e019162660614241903fd30335dc49cd736d18a97a0b8e4d8d8eaa7a31ce7cb8ad65e895e5a8906b98d2e7635d42d019af72333c76c35da1a,"Given a vector,  we can use the pop_back() function. Initialize the stack, as we pop from the vector, store and use the popped items into the stack. In this manner, the front of the vector will correspond to the top of the stack.",0.0,57
16409,16409,20654,a09890d1b445c23fabb578b3483b14013fc02062f1b3aa1b4c6df4bdeb9b3b91a9c90e4c472aa2da65ecaa5b831c0625b91b1940398021966ddfe90195c5216f,"First declare the vector itself, pushing each object into the vector would require a linear time as we would have to traverse through the vector until the front of the vector. Popping in the vector will require a linear time as well because one must traverse through thee vector in order to be able to remove an object. this implies we will be using the FIFO principle of stacks.",2.0,57
16410,16410,20655,414c0211baa0f7785fed3a2ae8d654438eeb57e32a72d726d41fb80a14e5bb82594bc148b341e170426f496146bb1f57723f178ed8b08e3a2a9402960a0201df,"First initialize a stack using a vector as the container / data structure. Use vector::begin, which will have linear complexity, to get the first element in the vector, everytime you add another element to the back of the stack/vector, using push(value), which has constant complexity. Then change the top() function(constant complexity) to reference the same value returned by begin().",0.0,57
16411,16411,20656,22140328599cc90e71d5de22898862c3b0e2dd7b2d6733a618551afede59cd91597d571fd42b02414ce2cee43da486638d6f616c5d08e161d9d14ea8e7479b0a,"-push:constant time best case, linear time worst case

-pop: constant time best cae, linear time worst case

-peek:always constant time

-size_t:always constant time ",4.0,57
16412,16412,20657,bdfce9df7f76cf1d9d59e67b4abc8ea7efe61159b5740bcaa398a756f14d620d749204982411a64d206b741761332b21655b6d1819a4957a944006bdab28b4e1,"Pushing an item to the front would require shifting every item in the vector backward and assigning the new item as the first position. The complexity of this is O(n).

Poping the front would require shifting every item in the vector backwards then deallocating the back of the vector. This is of O(n) complexity.

Peeking at the top of the stack requires only calling the front of the vector. This is of O(1) complexity.",5.0,57
16413,16413,20658,2238995f0ead9a3412ecc8b42340b20d5862bf47d5493b0c9fbe94b4e46ffb57c2cf52b4dd296cee7b6850d8a44e160d6bd1d96e80ab144e928044e44043acc6,the time complexity of push and pop will be O(1),0.0,57
16414,16414,20659,d262858bac7cd6476e0cd48b8622c751312997fe7fae4adba9c98bf17ceadac187d9de2b401de3d1895e85edc24940f00a102bf214f436104f37cd1b8669240b,"With push(), I would still use the push_back() because the memory is contiguous and if I were to use push_front(), I would have n copies. Which means push_back() would be better because in the best case the complexity is constant meaning O(1). 
With pop(). I would still use pop_back() similar to the point of push(). Where the memory is contiguous, pop_front() would have n copies whereas pop_back() in its best case is constant meaning O(1).

With size(). I would use "".size()"" because no matter if the front of the vector is at the top of the stack or the back of the vector is at the top of the stack the complexity would still be O(1). 

With peek(), I would still use "".back()"" because no matter if the front of the vector is at the top of the stack or the back of the vector is at the top of the stack, the complexity would still be O(1).  ",2.0,57
16415,16415,20660,07076ad9a7e3813bce19a739ebedaab894d1a330269763e0925227d8822b601591c19afe0ea5ecf81637c9b73f442db6cacafab2329d262fef0fb68d97bef78a,"the stack uses a LIFO method, we will always add our items at the front of the vector and the time complexity will always be O(1) constant time, we will also pop at constant time ",0.0,57
16416,16416,20661,6accb08d7786944c71cd9b921787862856d4a3c42592fbffde311b7d0b92a8f983d0c4f430c2af6d29dc0b77bc121c3af33f1ea64f2b5de47c11c3122369896f,"I would create a class that contains the stack. I would then create the push and pop functions of type void that would be able to push and pop values into/from the stack. A top function would be created that would reference the top of the stack and the size function that would reference the size of the stack

The time complexity of push and pop would be O(1) in the best case and O(n) in the worst case.

The time complexity of top and size would be of O(1",4.0,57
16417,16417,20662,a2e71f759079413d4f87ec8f397142f2bf7f364e3ac1403027655c606e40a1106c0bace5c922e3aa206700cf3aa5120aeba8f93363e62c778029029dcc2335f1,"To remove from the front of the vector one would have to move all the stored stacks up by n-1 places to delete what is considered the front of the stack in this situation. However, the situation is to know first if storage is not being wasted in the vector needs to be considered. This space is checking that half of the vector storage is not being wasted. If it is being wasted then a new vector needs to be made and all the items be moved into the new storage. By the items being needed to move into the new vector this situation will take O(n) time. 

To add from the front of the vector one would have to first check if there is place to move all stacks stored in the vector n+1 movement down. If there is not enough space, then the need to allocate double the space, move all the items into a new vector and then add to the front of the vector of the new stack would take place. Thus by moving all the items stored requires n amount of loops to move each item therefore taking O(n) time. ",4.0,57
16418,16418,20663,dc654a3d0a49a8045440d0a47a162366cb8c5b30f1fbfe16fd058e7bee5d840a459b70ea1468db1f0ce164b7af14bedf02e15cd2f876678ba6f0d0d5502b4093,It runs on  at constant time O(1),0.0,57
16419,16419,20664,c66e418bde3624775409174d439f8c7a104e4c741d28aa9a32d3dff6f27ee3fc70a6b61ca496d004e7124e5afeca9e6a74cf0455c76878d506978153185a8efb,"Since the top of the stack will be the front of the vector, there will be  push_front, pop_front, peek and size functions. Due to pointer arithmetic, the peek function will have O(1) complexity, the push_front and pop_front will have a best time complexity of O(1) and a worst time complexity of O(n) and the size function will be completed in O(1) time complexity.",4.0,57
16420,16420,20665,4a10096efbe473298c3ffaa590c64747a3f122d6138157d16b669b6d6757b1ee312e247b5d7de57197c1100b67d525e21d2bdf5719b1e5397849be3138642057,"In order to push to the front, the program will have to copy the current vector into a new one and reallocate the values to one that it has already inserted the value to, then delete the old vector, with the time complexity O(n).

To pop_front, the program needs to reallocate the values (from the second value onwards) to another (new) vector, the delete the old vector. Time Complexity: O(n).

To get the size, it would just return the size (using size()), with the time complexity O(1).

To peek at the top of the stack, it would just use standard back(), with time complexity O(n).",5.0,57
16421,16421,20666,0a640b06ce1d454be947795a6308fcfcc73f66b49b60199788f434bf91f3e08719c4b7dee42514e49b76fea543dcbe6b2a18d9de0cfa87cc5f82c989cd2f76ff,"size function- use the size() function of the vector, return the size of the vector O(1)

peek function- use the front() function of the vector, return a reference to the front of the vector O(1)

pop function- shift all the elements in the vector starting from the second, to the left, then decrease the number of items in the vector by 1 O(n)

push function- copy all the items in the vector, create a new vector with an extra space, paste all the items from the previous vector into the new vector starting from the second position, then add the new item on the first position O(n)",6.0,57
16422,16422,20667,c6919e466976b48c2f7b3823eb90c377fa8e67b3a290bcb3ab3a7c56083193c911bc05ef76e986e61a0a361e9ed5a7fec55840ba6afe1022bc97e18b5eabbeef,"I would implement the same code as if the top was the back, but would use push front to add on top of the stack and I would use pop front to remove from the stack.  I would use front to peek at the stack. The rest of the code would not change.",0.0,57
16423,16423,20668,3065fd9b5327500ccd01f2dbaaeb4517f874d19bdf3e90a9e58fc3902fdfcf795607548f33b16d677a8bfdbfbec8dfd27757ca207e98b81490a4df15aab3c3f5,"When s front of the vector corresponds to the top of the stack, it means whenever we do operations such as push and pop . We do it from from the front instead of the back and the complexity for push front, pop front and peek front would be O(1), the size would be O(n).",1.0,57
16424,16424,20669,b33d5ec88a2b0658fe1e9d5e59ea13311491654c12fd5b13cd9e270e44a1a125acca1c56bf136302c950a009d693b09accad74b98f9de4d82034269663959b89,"I would allocate enough memory beforehand. The top of the stack is at the front of the vector, meaning that the vector is empty. If I have not allocated enough memory I would have to reallocate and copy everything across. The first item added to the stack will be at the front of the vector, at position 0. The second item would be at position 1

The time complexity of each function would be constant time.",1.0,57
16425,16425,20670,0425e17b97b62d847bfbb7a5f37fa98ed826dc582b46528b4a148c459379ead81390caacfd23b1628779d134c7092014f555b05833c612700ef174bd131b6587,"In order to push to the stack, you would need to move every element in the vector one index higher, and possibly resize the vector if there is not enough space reserved. Then you could assign to the first element.

If you wanted to pop off the stack you would need to move every element in the vector to one index lower (copying over the first element), and also possibly resize.

This is a terrible way to implement a vector as your underlying container, and both of these functions would always take O(n) time.

Accessing the top item would still be O(1), though, since pointer addition is constant time, regardless of the index.",5.0,57
16426,16426,20671,d79246b4e37ca7cbd7cba0e73e77371bc01ee0686edc183593c8b72f08af7f56885ea93e866878670f104cfe50f22453d301d67ae7614531bda51a9f07fc7424,A vector does not have a push_front so you cant add to the stack that way. If you write code to do a push_front it will take O(n) time as it will need to copy all the values in the vector one space back then insert into the front. And then to pop from the stack you will have to write code to pop_front the vector and this will also take O(n) time as you will have to copy every value in the vector one place earlier then delete the duplicate value at the end. It would be an ineffective implementation of the stack as the stack can usualy do these features in linear time. Peeking will take O(1) time as you will just use the front function.,5.0,57
16427,16427,20672,a18d348d984f5bd8aca6ebc4fccb86f8d160a802b4c7ee70a595f3b8caf6c18513e302bc5cfcbf90d284bd7a320b1536220dd429aa4a21d61efb3ef1771458a4,"If the top of the stack is the front of the vector then we are adding and removing values from the front of the vector.

To get the size, we would just use the vector's size() function, which is O(1).

For peek we could just use the vector's .front() function to return a reference to the first value in the vector (the value at the top of the stack)

To pop, we could shift all values (besides the first) one space towards the front, which would cause the second value to overwrite the first and all other values to move one space over to the front. The cost would be O(n).

To push, we would have to shift all values over one space to towards the back and then place the value we are adding to the front of the vector. The shift would be O(n) and the placement would be O(1). So the cost of the entire push function is O(n).",6.0,57
16428,16428,20673,202c8344f9f859aa64da3cc8ceffb88155f17aa53a21d20d5da4fef5e39546500eff34cbff57a9c00ff1871c748bb37a08181469555e6609e93120b6d7b83edc,"1,have a vector then reference the first item of the vector to the stack and that would take O(1) amount of time or space (complexity)..since memory in a vector is contiguous....the pointer to the following item will point to the top of the stack then by dereferencing the pointer , the item will be on top.",0.0,57
16429,16429,20674,ba67943d9c3f68c2a82bf70197366cb2cce1d21f6696fe648aaf7068ed18399b5899a40e2f0d4a0c53a04c7e84020c544f2b79e8fc23a17b4dca16bd22dbd15b,"peek-O(1)

push-O(1)

pop-O(1)

size-O(1)

for creating a stack we must include <stack> 

Create a stack to store your  items, use push() function to insert into the stack, pop to remove from the top of stack , use peek to get item at front and size to know how many items in stack",2.0,57
16430,16430,20675,bc7ce8dcf81474ef89d407bc167ddbdc0ae686813582e07ef0e124f6d6fe081339ab3b2bb05c54a356b901c5c208933d91dbaf731894bf50cc25eab5e102a8e6,"First allocate memory that can contain an n number of items.Then to add to the stack we have to add to the front of the vector which is the top of the stack hence the push front function can be used.This will take a constant amount of time in best case but for worst case it will take a linear amount of time

Then in order to remove an item from the stack,you have to remove from the vector and the pop back function can be used,this will take a constant amount of time in best case but in worst case it will take a linear amount of time.

Then implement the top function to return the item at the top but using data.front,this will takeThis will always do a constant amount of work.

Then implement the size function which simple returns the size of the vector and this is already built in.This will always do a constant amount of work.",4.0,57
16431,16431,20676,571f4b857c687d9d563078992ce0d593248d2c9f52df5afb071f8e300cfd009d7831df6cd94d1fdf3131324af503b103a8881171137c2ca59df7ead36faf3f74,"Push: you will first push to the back of the vector with value of the last item in the vector. Then you will add the contents of each cell to the cell above starting from the back and going to the front. Then in the first cell of the vector you will add the item you wanted to push to the vector. O(n)

Pop: starting from the 2nd item in the vector, you will move the item into cell before the current cell. So if you start at the 2nd cell, you will put its contents into the first cell, then the 3rd cells contents into 2nd cell.. until you reach the end. Then you will pop the back of the vector. O(n)

Peek: just return the 1st item in the vector. O(1)

Size: create a variable called count. Use a loop to iterate through the vector until you reach the last item in the vector and each time you iterate you add 1 to the count. You then return count O(n)",5.0,57
16432,16432,20677,b9d82cd7c247fea1955a43aaaf5bb439ce7f4f53d3df9728ceb44f0e1b947c368ff1574400183b4d31d82813774edfdb38a1fdb56e3256ef8ab3e682f8c08da1,"To implement from the front, I would create a function for .push_front(item) and .pop_front() since there aren't built in functions for that in the vector. The time complexity for the two would be O(n^2), quadratic time.

(This would take too much time and it would be wiser to use the back of the vector as the top of the stack, since the time complexity is O(n) for the worst case.)

To implement the peek I would take the .front() function which would take O(1), linear time complexity.

To implement the size I would use the .size() function which returns the n_item in the vector, this would also take O(1), linear time complexity.",0.0,57
16433,16433,20678,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,"If the front of the vector is taken as the top of the stack then the member functions of the stack would be first the push function would use the push_back function for vectors, but in O(n), the pop function would use the pop_back for vectors in O(1) time and the size function is just the normal size function for vectors but in O(n) time, lastly the peek function would just be the front function for vectors and done in O(1) time.",2.0,57
16434,16434,20679,a3989cc4476b1bbce9e79b34c3f0337ca13c9717a610fbe24ad51e9bdb052f2d445313904842463b1a859cd4d281ce72b5f85b0423f33b62cab82318e4116232,"I would first create class called Stack, then make my class public. Then I would would create a void function for push, but then body of my function will use push_front function and time complexity of this function would be constant. Then create a void function for pop, body of my function would use pop_front function and its time complexity would be constant. Then create another void function for peek, its body will use front function instead of back and its time complexity would be constant. Then create a function for sized, time complexity of this function would be constant.",2.0,57
16435,16435,20680,f83dd55ad9e075a60c5134f9bf47ed3397e5224c478fcc48237d4341af57f9ae0b4893b2d9bfdacde4458f44d6dacdaedccfab297dd76d28c1d773deaaf399e4,"push_back pushes an element to the stack

back() returns the last item and rrearrange 

The time complexity is 0(n)",0.0,57
16436,16436,20681,611e62668a69a44120f4c094b741411c87184ef32e42939a38515edfc5b988a4050fb89730be7833c2365cfa3031ef1f4593e6c36d340bca6106a175c159094f,"when the front of the vector is the top the :

To push i will use the vector push_front function which  is O(n)

to pop i will use the pop_front() function which is also O(n)

the size fuction will also be O(n) from using the vector size() function

to peak i would just use the front() function to return the top item which is O(1)",5.0,57
16437,16437,20682,662455ba865b7fa66132ae6520e999c9ea1b9fa1f85d0b16ee30bd84db7aa0bec3c7fd7269d6521a07e1ad16d091e298c84cb6c69ff3537fa78efdac09fa4677,"This could be implemented using a push front and pop front function which will either add an element to the front of the vector by copying the entire vector , moving it over by one index and then placing the new element at index zero or popping the first element by copying the entire vector after index 0. In both cases, a linear amount of work is required as we have to iterate over an entire vector of elements.",4.0,57
16438,16438,20683,8a35389fd7c8ad2535687771b1bb68c8efb0b7de8dcab378f3a060f04342ee373ba7cc2c9fd072651f8268858486a9bd9dd5269dda1258346fc90ac33d038576,"Adding to the stack we would have to move every element up to the next space and then add it to the front of the vector. If there is not enough space a copy will have to be made, all items will have to be copied, moved over by one spot and then the new entry can be made. Removing/Popping a person will remove the first entry then move all elements up one space. Adding and popping will take O(1) as a best-case scenario, otherwise, it will take O(n). Top will be constant time, and size will be O(n)",5.0,57
16439,16439,20684,1524a034e009646803d7074c495cb1bd3919f40bf0c99261b282adc7801990411f97759342d2d5b53fea8bfcd2292ae00d0444e55290b251e7ed8a081caf06dd,"We would require: A push function, pop function, size function and peek function for the stack. I would implement the push function by pushing the front of the vector by copying all elements one position forward and pushing the new element at the front. Therefore this function would always take linear time O(n) as each element has to be copied one position forward. 

I would implement the pop function by deleting the first element of the vector and copying all elements in the vector one position to the front of the vector. Therefore this function would always take linear tine O(n) as the function would have to copy each element in the vector one position towards the front.

I would implement the size function would take Constant time as the vector data structure keeps track of the vectors size at all times and can be called using "".size"". Therefore the function would take Constant time O(1) as the function only calls the size function.

I would implement the peek function by using built in vector function "".front"" which will return a reference to the top element of the vector. Therefore this function will take Constant time O(1)",6.0,57
16440,16440,20685,fcd3cd6f6ab23272e8ef67866982250cf0b69308ab1f155fea93b78f0f8230cc3a80d03659b858f52503462ba79795983adf53baae8dc1b2c6482664286cb263,"push front the items with time complexity O(1) 

pop front the items with linear time and peek the items with return data_front with constant time 

size will have a linear time  and its implementation will be return data_back",0.0,57
16441,16441,20686,c927373e71fe30f4255c61610bb88cd9a4bb26b4d4a5c6bc2711f05bbe84ffcf49fd97d920d1a706ea1e91d40784c2fadbc56f95b4fae450f318d7610a7daca1,"I would first find what the first element at the front of the vector is by using the std::vector::front function. Then, I would use the push_back function to add this value from the front() function to the top of the stack. The complexity of the front() function is 0(1). The push_back function complexity is 0(1). ",0.0,57
16442,16442,20687,1e61ac69c9ccec529a9d57595e183d7f2b1fa6a9903d4933718e237d1b12f704ba69dec35931222592238b7ab802821e4d5dd2c83c64cb9301a8bb0ced8b2cba,If you wanted to add a something to the vector you use the push_back() function which will add the item to the end of the vector. time complexity O(1). If you wanted to remove something from the vector you would use pop_back() as it will delete the last item of the vector. The time complexity is O(1). To get a reference to the top of the list you would use the back() function as it gives a reference to the last item in a vector which will be the top of the stack in this case. The time complexity is O(1). To get the size we just use the size() function and the time complexity is O(1);,2.0,57
16443,16443,20688,7db17fd2acfdd980933bf2f92abec54feac68e8b60f672ae1ba7781b8dd15de47315f37d74c147384e68a3a01e88e6539391471e6490908578bb1e2cdf85e7c7,"to add to the top of the stack i would use push_front which will take linear  time 0(n).To remove from the top of the stack i would use erase(),this will take linear time.to get the reference to the top of the stack i would return myVector[0] which takes constant time 0(1).Finally to return the size i would return myVector,size(),this takes constant time.",4.0,57
16444,16444,20689,2f2bbc70f8136ca3b18457b652aa1d5317919459278da63d7273a5c4e29eded00275f14d0a5826a3efa0a4d6a86ce51a6129f3ba53f25a66bc7e4755b291485f,"we would intialise a vector, and then push we push the first element back into the vector and stack, which would be linear. We would then create a second vector with double the size of the first vector, where we copy the values from the first vector to the second vector, we then add the first element to the stack, and this would all be linear.",1.0,57
16445,16445,20690,d34efe98a2513ac08acc6faef18dfc38310a4938c3e2400c3ec9b606c14e0455c45534357347e63004ac9d2c3c1e1d7805afa99ff5f4d271c3dc0f7c2153d7d4,"* I would create a class called Stack

	* My class would have the following methods

	* the method to push

	* this method will accept a 1 parameter
	* the function type is of type void
	* to push we shift all the numbers to the left and add the number to the index [0]

	* the method to pop

	* with no parameter
	* the type of the function is of void

	* the method to return size

	* with no parameter
	* the function type is of size_t

	* the method to get the value that is on the top of the stack

	* with no parameter
	* the function type is of type of what is going to be stored in the vector
	* our function referenced

	* the complexity of my methods will be

	* for pushing - O(1) and O(n) in the worst case
	* for popping - O(1) and O(n) in the worst case
	* for the size - O(1)
	* for peeking - O(1)",5.0,57
16446,16446,20691,bacea88b3884d2acdf5b94b564c3ec6827ffca9c96b92221f37418e3f06607a9773dd54e02efe11a3f31dcc55f103233551301f8c7dbd6ce23f465133edd2ef3,"I would implement the functions, pop, push, peek as well as size to the vector. I would push front by adding items to the front of the vector, as well as pop or remove items from the front of the vector as required. to peek the value at the top of the stack, I will return the value of the first item in the vector. Also the size, I will return the size of the vector to actually get the number of items in the stack. all these functions will take the constant amount of time O(1) since the memory is contiguous and adding/removing to the front will require pointer arithmetic of the first item.",2.0,57
16447,16447,20692,7c87322598f2ceacf4938051fa8e249fba61f740f1c131025859319c9334a0e7c5eed0d631406a69aaecd55c3154797379e9e557934a0c639e13848fc2a797db,"To implement a stack using a vector I would.need implement the functions that are used by a stack which are the push , pop ,peek and size 

To implement the push I would use the built in vector function push back to add to the top of the stack this will take constant time

To peek I would use the back function to return the reference to what us at the top of the stack takes constant time. 

To pop at the top I would implement using the pop back function in the vector which will take constant time to pop 

AND finally utilise the size function which counts as we add and remove from the top of the stack and takes constant time",2.0,57
16448,16448,20693,6c0c4055e14104657e8b2f93690d540761c32c74b87c67cb6acc284b0968521966239252478c024e2c1fdc28ec4e72c01b4f28c3de78e04b7bbf604f3bad167d,we would allow this by using push_front and pop_front. As these two functions allows you to add and remove only from the front of the vector which keeps that stack intact. Time complexity would normally be O(1) if the vector has space/or has to much depending on the function being used. In these cases when memory adjustments have to be made to the vectors time complexity would be O(n),0.0,57
16449,16449,20694,c9533083b36a5867d42e175e5d9226d460bac0f67119822f32ea58c60b5c8ae66655217031dc5ae111931d8c34d1a88f17b852726bf446acb3dd87422ab66355,"to add to the top of the stack use push_front(),this takes linear time. To pop use pop_front().This as well should take linear time.

to get the peek at the top just simply return data.front().This takes constant time. Lastly to get the size of the stack just return the size of the stack by returning  data.size().This should take constant time.   ",4.0,57
16450,16450,20695,763a776e81302d0ca35787de395275bfa7dace1cb9ac6ce690e840ef2f280482559135e73ff9334c7ef80b3304e1f6061c108364e0e55bf5e56d4aafbce8e073,"we would first need to push an item(add an item) and then we would need to get the last item in the vector and then pop it(remove it), we can then check to see if it is empty by using the empty function to see if there are still items that are still in the vector. ",0.0,57
16451,16451,20696,b96308b5b954fc4c2086f6faec027fc8299af60a164d99cbdc75a0802d3bb5ac5823699b9e2e5c78a86bbf73886ed3408a16b29a0f7ee6dc90b05a8f2f91fcd5,We would use pop fr,0.0,57
16452,16452,20697,4d5583055b5cf0ef4bd7f80832ec9b8940eedb6261741378493c7c1e768d88d15f96d3b8d5850288f3731056d59b3dbe1878b8c16bbb307054b4401de38adc38,"Push:

I would have to reallocate memory to a new block and insert the item in the front of the block of memory then I would copy the rest of the items into the rest of the block then I would free the old block of memory. This would take O(n) amount of time as it depends on the amount of items needed to be copied.

Pop:

I would allocate new memory and store all the items starting from the second till the last into the new block then I would free the rest of the memory. This would take O(n) as it depends on the amount of items needed to be copied.

Peek:

I would just call the item at the front using the vector function. This would take O(1) time.

Size:

I would use the size() function to return the number of items in the stack. This would take O(1) time.",6.0,57
16453,16453,20698,52b1f6fd8e6c0289a8004d7d61b231157f72159bdb1098720813eb6a4750543a581c16358208b2fe293a6bc58612fe418d8dd4bccc56d715f7137f43db02b99f,"We must have a variable that tells us where the top of the stack lies, which would like outside the vector.

variable ""top"" = -1; and to add a thing to the top of the stack, we would have data.[top + 1] = thing; followed by an increment of the top variable.",0.0,57
16454,16454,20699,6d04032d059678dcb346209e5f60e18a44d0c551ad3d7c0e551f1957033a386ffc9828dc7e1374b35e8828c43ed8d61ae22f6c2de063b8779cad31efc30f066d,"Initialise a vector and push function. Push the first element into the vector and stack(linear(O(n)). Make another vector that is double the size of the first one then copy the values from the first vector to the new vector, now add the first element to the stack(linear(O(n)).",1.0,57
16455,16455,20700,e7c7348f23786b9e18a28e68e5d9ba68b1b693a74a0d58100a7db9e2aeee706b92e8dc4a38b20cb50289290e86666a9bfd49334f05b1673c8db1a8b26f9c9689,"If you are implementing a stack using a vector, we must create a class that has 4  which are, functions push,pop,top and size and these functions must be public so that they are accessible to the user. Then we must create a vector which is private inside the stack that will be managed by the computer not the user.

The complexity of each function is constant i.e O(1)",0.0,57
16456,16456,20701,bec70f18652f9b1ec67ee94e23471083fc0530aad868499d925d500e71ccfd4f82652eb49a909778379c4583e97ce1464a3ae78de3b07114cb3a9e4c1179d625,The push function adds something on top of the stack and therefore will add it to the front of the vector. The time complexity would be O(1). The pop function will delete an item from the top of the stack and the front of the vector. The time complexity will be O(1) as this is the best case.,0.0,57
16457,16457,20702,c879e65c8f9657768bbf6800906a28bff217c7ef9063d46acfccc25071a9fc3aef2ccd29821fdc92e96d2f98ca66aa74a3fa2a8f0df86509064e53b0fb9b54bc,"To implement a stack which uses a vector and uses the front of the vector as the top of the stack you would use the following functions:

Push: You would use the vector's push_front function: This would be O(n) because you would need to copy every item in the vector again to make space at the front of the vector.

Pop: You would use the vector's pop_front function. It would be O(n) because you would need to copy every item in the vector to shift it 1 forward after the front item is deleted.

Peek: You would use the vector's front function. It would be O(1) because you would only need to look at the first item in the vector which is always constant.

Size: You would use the vector's size function. It would be O(1) because you would simply count the number of items in the vector.",6.0,57
16458,16458,20703,fd0ace311926a44973b18eb55c0a2df285cc4ef58cf67836be1c2719041ca75111c81115da37e4e4879d8c00ffb63db68cb0de1c85a3fc373724acf7945dc463,"Would implement the stack with 4 functions, the push function for push_back , pop function for pop_back , top function to get the item at the the front and the size function to get the number of items in the vector. These would all use constant time except for the size function which will use linear time.",1.0,57
16459,16459,20704,ffb312171739bda8140d790d7e76d39d8cb251ebc0d6e983413e101fe068405632084409e60fc3615fbb0328c8c628ab617f395e064e10a0893ff352b3482def,"Using the front of the vector as the top means when you push onto the stack you would have to create a new vector with the first element being what's added onto the stack, which is O(n) runtime complexity. This is the only difference between having the top at the back and at the front. the other stack functions, peek, size and empty all have simply vector implimentations which are all O(1) runtime complexity",3.0,57
16460,16460,20705,e0c83344227ee0e9cbe053565e48a2fdd45505359ef079abf58dae6d4b8251e874c464186ed9d597d1e6bd62c45d87ea5c0897cd6938b6926936cb2def62d356,"In stacks the data is implemented on a list-in first-out basis which means the data that is inserted last will the first to be removed. However, the front of the vector is the last item which will be removed, so in order to implement this vector we will need to insert all the data and then reverse the contains of the stack in order for the front of the vector to point to the top of the stack. The time complexity will be constant and in Big-Oh notation will be 0(1).",0.0,57
16461,16461,20706,ed5a8c0425e8a7a0d2d402e42e3298539ec0ceb1b43ca8fa3f4b83dce862ed24fe276be92f07cf85365c96c7391564d1c0da45fd6e6ba4bd80ecb01a39467209,"For the push function:

we would have to reallocate n items to move to positions n+1 and then add the data to the front of the vector using the push_back function

best case: our vector will be empty and this would take O(1) 

worst case: there are n items in the vector and reallocation has to take place this will result in n operations to move items to positions n+1 and n operations for memory reallocation which gives us a time complexity of O(n^2)

For the pop function:

we would implement an iterator that keep a reference to the front of the stack. when this function is called the iterator increments and references the next item and this operation will have a time complexity of O(1)

for the peak function:

we would use vector.front() to see what is at the top

time complexity will be O(1)

for the size function:

we would have to use the size function.

time complexity O(1)

 ",3.0,57
16462,16462,20707,9082e5ab0ae09b23b5e0275a763493886db0b7f721520ca423ce3577e6b6ec09537f5d0b22aac121f7604a542a413dd81640198a15212f5aa5403c721b42c11e,for push I would make a function that pushes an item to position 0 of the vector and for pop I would make a function that pops an item at position zero again for size its still the same I would make a function that returns the vector size using size().,0.0,57
16463,16463,20708,3535a43df3300af7e5c3e95a4369804ca852c0470f1fe060d2a246291726064d9eeb362ff2318c56c2b2c1abd2d650cb0578f3dab1f0c9bef113f35bec7220b3,"We push the item located in the top of the stack to our vector.
push_back takes O(n) time",0.0,57
16464,16464,20709,acc027b1281fb7611892bbd9cd22b170d39dac509f3cbd3c4ae2298ef8fcce3e213c9bdb095b30f4b14371abefeb025cbed1bfbb0b3e1f2baccc7d74d415003e,"time complexity

push_front  : best case O(1)   worst case O(n)

pop_front : best case O(1)  worst case O(n)

peek : O(1)

size : O(1)",4.0,57
16465,16465,20710,df7c40110480895f223a4ad7a154ce6d14071ffef29c798823d9a68e307bd1447fc569c4b8f3e4353216405210fd26445fb7aeea3ad07da82c16c8e5aa5ac0cd,We allocate our vector into memory. Add the first element at the front of the vector . When we add the next element we use the push_front function which basically shifts the element at the front one position backwards. The time complexity would be constant time each in the best case when there is enough space to copy and paste each item one position backwards then insert the current item to the top of the stack. Time complexity would be linear time in the worst if there is not enough space at the back of the vector and we have to to allocate the vector new memory and copy every element into newly allocated space with twice as much memory as the previous one t and then move each item one position  backwards then we insert the new element at the front of the vector.,1.0,57
16466,16466,20711,27704af10f29b9fd01985b3a533f1213c119ce01a32f451e037e0491eede8c71f38ccb8abe4edd8c056927c76b6bf0c23fb2a88f8cca52e5000b6c906d6692ef,"I will set the top of the stack to be equal to -1 since there is nothing in the stack, and I will update it each time I add or remove an item. To push an item to the stack I will call the push_front function. To pop an item from the stack I will call the pop_front function. To return the number of items in the stack I will call the size function. Lastly, to return a reference to the item that is at the top of the stack I will call the front function.

Pushing an item to the stack will usually take O(1) time, but in the worst case it will take O(n) time.

Popping an item to the stack will usually take O(1) time, but in the worst case it will take O(n) time.",2.0,57
16467,16467,20712,bd13f3a1f05cded43b306e7cf672db1fa9cf812229ead4318a993e62aa7ff42541e39b6868fb05069f972d798f5a5b109e0e615acf69b7c88b8e2bf435bfc374,first we allocate our vector into memory. We then add elements add the elements using pushfront function moving the front elements one position backward. You can use std::vector size() or std::vector::empty() to check if there are elements in the vector.,4.0,57
16468,16468,20713,e128973184d15ac7a750b822c9d3b3fe1c0b4d5c9ec9968806c119de2807128c5380243007b2944cf3a301c3270578e76aaa068c636326951a9eea7851758fdf,"when implementing push_back function we put it in the public class the we push_back the data that we want to add on the stack

best time complexity of push_back is O(1) and worst time complexity of it is O(n)

when implementing the pop_back function we put it in the public class then we pop_back the data we want to remove from the stack 

best time complexity of pop_back  is O(1) and worst time case is O(n)

when implementing peek we first put this function in a public class then after we return the data 

time complexity of the peek is O(1)

when implementing a size function we will first put it in a public class then we return the data size 

time complexity of the size is O(1)",4.0,57
16469,16469,20714,400853532d18057c486e48e90c2e3817295b0b8da4abab44abf1f9dd692996bce343aa72b93713cdef71a68aff30879c7ec75ca8ea25a59fd4c48084879663a5,"To do this, we can use 4 functions - the push, pop, &top and size functions. The push function will add a value at the front of the vector which is the top of the stack. The pop function deletes something that is at the front of the vector, top of the stack. The &top function returns a reference to the top item whereas a size function will return the number of items in the stack or vector. The complexity of each in a vector as the underlying data storage is O(1) but the worst case is O(n) in the pop and push functions.",4.0,57
16470,16470,20715,f11178d26d71b36980a2e031712b410b8887af4a2b6c48901c6a568377c95cf608d8bdb211ef99a8ec80760d046f982bcd08b27ff9c8f8cd3f71083f65b80c48,"first check if the stack is empty, If not add the top element .Repeat this step until the stack is empty. print the final value of the variable.",0.0,57
16471,16471,20716,c0e222e387522491c144bc66b8d4aac6d8899881b15676a75bd42f6939be2d68b02062c035d5f028531cde71d4b0b2bb7581d5e165c7c3be11bd4e67e796913f,"Create a class called stack and initialize a vector. The push function would be push_front to vector and the pop function would be pop_front to vector.

The complexity of the push function will be linear O(n) because each item in the vector has to be copied to a new one so that the new item is inserted in front.

the complexity of the pop function will also be linear O(n) because it will copy n-1 times.",4.0,57
16472,16472,20717,8f4f0cec01fab6a6a49376ed0eca817677b16456497e4474dea2db6c84f10bbab5215841562427aec9d1d1cb57d57272e23d92898bef51a2205b3db761cea98d,"I would initialize a stack with the underlying container being a vector.
I would then create a void push function that reallocates the vector on the heap, the new buffer will be double the size of the initial buffer if the vector is already full. The new item is then pushed before copying each item across and deleting the previous vector from the heap. This will be O(n) - Linear time.

I would then create a void pop function that copies each item in the vector one to space behind its current space. This will also be O(n) - Linear time.

I would then create a peek function that returns the address of the first item in the vector. This will be O(1) - Constant time as the first item will be the vector [0}.

I would then create  a size function that returns the size of the vector. This will be O(1) - Constant time.",6.0,57
16473,16473,20718,bb69eebb6b9661fb2659b9201956c2d150fd7601de8f2339f22c3c3c7289abd28101e1b6206a923a6b9fd81f7d0d617c8b5485dd0958ad06769fcf98922a4e97,"declare Myvector then declare the datatype that I want to implement then use the pushback function so that each time I input a value,it gets added to the vector as I input taking constant O(1) amount of time.",0.0,57
16474,16474,20719,d098e277cb3df3b25c9e42904322dbd46a16b60a20b139d8066f16584a8bb599eddc05cac924f310971f38fb613ad7daea71749bb268694cb7e0d2fdf74a35a0,"if we decided to use the front of the vector as the top of the stack, then we would pop from the front of the vector and push to the front of the vector. since if we pop front, we would need to shift every element one place to the left after deleting an element at index 0, then the time complexity would be O(n). For pushing to the front of the vector we would need to shift every element 1 place to the right and then insert an element at index 0, then the time complexity of this would always  be O(n).",4.0,57
16475,16475,20720,798235659bb9174e71b3ff61763ec292691ece6655d9ff85d1fbb65ede38be3c46ca62a6d523bf01e0f519090370eeadd560efded9ef16231507d4492e919473,"To push would have to find out if the is enough space allocated to vector to push , if not we would create a new vector with twice to space allocated or if the is enough space no new vector creation is needed. The each element in vector is moved forward one position , then the the element to be added to top of stack is added at index 0. Time complexity is O(1) at best case but is O(n) at worse

To pop we would reassign each element to be at the position before it and that would remove the element at index 0. The time complexity is always O(n).

To peek would return element a front of vector at index 0. Time complexity is O(1).

To get size, the standard library vector size function can be used. The time complexity is O(n).",5.0,57
16476,16476,20721,95fcb6f4498706b42ae9b99b85ac88399a6d3275d00b87217fb05c5101d1dbf721727b60bf9e8e6b2dc1c2bdad3d13b66bf7f2d975e8a5f8863dd7d1ee3dcbef,we would use the push front and pop front functions in order to remove items from the front of the vector which is the top of the stack. this will result in the need to shift items up and down to add and remove from the stack. the amount of items needed to move depends on how many are in the vector thus a linear complexity (O(n)) will be used.,4.0,57
16477,16477,20722,ec66e4473040e8ee3556fe295a682aef55293bdc440d5beebc8fb799f1964c0abc0afc761e0c9e5b3dec6cb5d26467ba51d5e312925807725d0b86097bb74bce,"Adding to the top of the stack would require copying everything stored in the vector one element to the right to make space for the new value, which would take O(N). Peeking would entail getting the value of the first index of the vector which would always take O(1) time. Popping would require copying all elements except the first one element to the left, which would take O(N). Getting the size of the vector you could just use the built in size function which uses pointer arithmetic and takes O(1)",6.0,57
16478,16478,20723,55ea1e4f47f56380767c8e74fc048f88ea3f77cbdba15f1928ce2c49d72fc6281a93cc53faad127cf63dd846a712edf93d7e45216338f7bc4ae6a26df95dd66e,"use the functions:

TO ADD A VALUE TO THE TOP OF THE STACK:

push_front()

best case O(1) constant complexity

worst case O(n) linear complexity

REMOVE AN ITEM FROM THE TOP:

data.pop_front()

best case O(1) constant complexity

worst case O(n) linear complexity

SEE THE NUMBER OF ITEMS:
data.size()

O(1) constant complexity

READ TO TOP ITEM OF STACK:
data.front()

O(1) constant complexity",6.0,57
16479,16479,20724,cf2a591555132b8efff123c8f7ccc21271d730e9428d05bb18c0b7a135f2079a4699131b2b59fa5959e47af328e627e627f0109196051d6ed6e0b9c23d9d5978,"we would use the push function; pop function; peek function. then on the push function we would be adding elements at the front of the vector, on the pop function we would be removing the elements at the front of the vector, peek function would be for returning the value of the top element. using the operations push front, pop front.

the complexity would be O(1) but in the worst case would be O(n) when popping and pushing elements",2.0,57
16480,16480,20725,7ed1c803cb6942b25a462119e14146d3dfdc8b2d8405742d6e37974d2693c34f2838afb58a1bcf41b9fcd8829c1dff4d4b192c929c721bc46e1615dcea231b30,"A stack adds and removes from the same side. IF we decided to use the front of the vector as top of the stack, we would then pop from the front of the vector and push to the front of it. If we pop front we would need to shit each and every element one place to the left after deleting an element at index 0. Then the time complexity would be O(n). For pushing to the front of the vector we would need to shift every element one place to the right and insert an element at index 0. The time complexity would always be O(n)",4.0,57
16481,16481,20726,680d91225cab44dd05e534f9e43db41735c5c1d374cc902f5585fb054238f603a599d4ef9dab5fa3942be1f948538952ecb942a66b8672d9ac04303366506ece,"You could implement a stack which uses a vector as the underlying data storage, but the front of the vector corresponds to the top of stack by actually concepualising the terms not the terms in the underlying statement.",0.0,57
16482,16482,20727,828a54706b7956f06065af9a928b49958122a77b54a5e0593021ac1ee5bfac90e0bf9488291ceaad9b7538bfadd4796253d8359db184b0bd7f7e1ed456e8f30c,"A stack has push, pop, isEmpty and size as it's main operations. To implement push in a vector that has the front as the top of the stack we would use push_front. push_front takes O(n) since we would need to shift all the elements one step further. To implement pop we need pop_front which takes O(n) since we need to shift elements a step behind to maintain order. To implement isEmpty we just need to check if the size of a vector is zero which takes O(1) time and the same for the last operation size.",6.0,57
16483,16483,20728,252668df997d55b86d753e14db9bb82d9a9ab0f27d714f3256c72a03986a906ffccf1958bf221d3ab998a7770edda41ec2de25393f1d9a62f105684cf09211ed,in order to implenet the stack as a bector we would need pus to insert data and pop to delete data. the push function will add an element to the top of the stack and pop will delete from the top of the stack. we would then print the top eleement of the stack and pop that element then print again etc. until the stack is empty . the time complexity of each functon would be O(1),0.0,57
16484,16484,20729,525cefc66631b9eb601410acc1c632cc3a6d9976bb8f3ac653d46807a4053f29a6c3c85a0e8a38a43486b45bae46acd949e27f910bf00828afed11257c7034f3,I would create a vector store all my I terms the use the std:: reverse function. Then use another reversed vector as the underlying data storage. This would take O(n) linear time.,0.0,57
16485,16485,20730,ac47e3ceebccb755b1987f028345ba571e2bbf0bc4ebc355e11ab520e9f3ffd71073789246ed0c633ccffb81e8b77e299c90427fa5f8a55f41455cee47d290e1,"For the push function I would make a void function that takes in an item of desired type and pushes it to position zero of the vector using our once implemented push_front() function, for the pop function it would have to do a pop_front() of the item at position zero, for peek I would make a function that returns an item at vector position zero, for size I would make an integer function that returns the vector size using size() as we already know. All in all the push and pop functions would take linear time complexity, and the size and peek would take constant time complexity.",4.0,57
16486,16486,20731,49da1899a556de47c2ec5c0aee3103579dd1b8665560fbd2cb26362bd85bf2a291f8280bc21e1f838e024dcd8764915c6b880be08a2f6c8f404d85517511406c,"complexity would always be o(n). every element added to the top of the stack has to be put as the first element in a new vector, and then every subsequent element is a copy of the original vector",2.0,57
16487,16487,20732,86a22e8a0f9641e87ca4e2ad806de08b394e73d2c41a296c66bdf8a43027f536887494504dc5545f0596ae97131302d63974f19424417f466775542fb23789e0,"In a vector as we add an item we push to the back. Once an item is added to the vector it will also be added on the stack. When we pop out an item at the back of the vector ,on the stack the top item on the stack will be removed.",0.0,57
16488,16488,20733,be31d5d430bb70d92105e501945893c26e6893599696162bc95d97dc68e8551bcabb0ec57e7e70881502e05fa1f8de1b8b173b3252cd099443fc870750db1827,"Pop- This would remove the first item in the stack, this will be done by using the pop_front function and would usually be constant O(1) unless there is a reallocation where the complexity would change to linear O(n).

Push - This would add an item to the first block of memory in the stack using the push_front function and this would take a constant O(1) amount of time unless there is a reallocation of memory where the complexity would change to linear O(n).

peek - This function would return a reference to the first item in the stack and will be don using the front function. The time complexity is constant O(1).

size - this function does not change as the value of the number of elements in memeory is stored in the vector. the function will return the value number of elements in memory and it will be don by using the size_t function. The time complexity is constant O(1).",4.0,57
16489,16489,20734,675e836215b62d793972ecb9d5ace2eaf438e0e5d0d26f496ddc3442ba479da55ac029b8a4555f73c538c50ecac4b04edc042861ca9b743e991c19c46392aa72,"If we use the front of the vector as the top of the stack , we would pop from the front of the vector and push to the front of the vector. For pushing to the front we would use the push_front () which uses time complexity of O(n) as we shit every element to 1 place to the right and insert an element at index 0. For popping we would use pop_front() which uses time complexity of O(n) as we shif every element to the one place to the let after deleting an element at index 0. then also using data.size () ot get the numbers items at O(n) and data.back () with time complexity of O(1).",6.0,57
16490,16490,20735,bf9f7563cc9f901b96502125e7d25475a0aeee128b8258ce038a51e3af3c4093e4ee3d48f8e688baf55d2e74c7a660d473b521169612f2e6991be2accf5a47f1,"make a void function that takes an item of any type and places it in the first position which would be zero of the vector using the implemented push_front()function
for the pop function, we can use the pop_front function to place it at position zero
for peek, make a function that would return an item the item at position zero

for size make an int function that would return the vectors size 

time complexity for both pop and push functions are linear 
time complexity for size and peek functions are constant",4.0,57
16491,16491,20736,33903c4df6729a45e2485f57a528848aea77fb0ac81607f602f6f53f80eb513d5b18fef57c086d43fef4cdb3f78bbc1f8da0bcaa1e67afb26268e9484bbb4ded,"Since a vector doesn't have a push_front and pop_front function a for loop is required to traverse backwards from the end of the vector to the beginning. This means that the complexity of the push and pop front functions will be O(n) and so push and pop will have the same complexity.
With these two functions implemented, a stack where the front of the vector is the top is implemented. The peek and size functions will still remain O(1) since the front and size functions do not require traversals ",6.0,57
16492,16492,20737,6ba5306b04bb1c19ff5f5148036844fc07d1e828c1c4bdd9a403971c63a75670cfd9507d856d67663bf299025ddc744dc1aab73fcc8ad24aa24659b96dc9ae8e,"Here, we will have four main functions as we have seen before. The first being a push_front function, which when we want to add at the top of the stack it will add to the front of the vector. The function will simply moving each item one place to the right then add at the very front of the vector.This will take a linear amount of work.
The pop_front function, will remove an item at the top of the stack meaning at the front of our vector, taking a linear amount of time, as each item in the vector will move to the left by a position of 1.

Getting the item that is currently at the top of the stack, that is the first item in our vector will always take constant time as the vector handles this for us in the background. We will use the member fucntion "".front()"" to get this item.

The size function will also take a constant time, the "".size()"" member function of a vector simply returns this value to us.",5.0,57
16493,16493,20738,3b71cded09878fac739a748b2fcbc2d9e2bef1d7260004d93fa1cfe93d9b6830fe9dca43a0e8ef309e85cefb7f4580ca47263177668c6f4b88b993ec3fb19c7e,"I can create std::vector as my dynamic array ,then use the functions, push-back, return function and pop_back function",0.0,57
16494,16494,20739,72bbc5b06aa933675f586b02eb7091979ed0d9cd4489dbf74c1a3cab5f7664fc97395b4d5ff80f04c6b7fc94837ad7229b3d6417b2c8d007ae33e9006fc697c6,add items at end of array that would make push be O(1) in time complexity except when array is full,0.0,57
16495,16495,20740,3bf5a6c902e4bbf41f8d7229fb34d303a6721b98a13f667dc5f2cbb64cc24ce8b6caffed089bfaa8a9035860dae36438bbdda86f5a082d98f0cf239492dc448b,"Since I know that the front and the top corresponds, I would create a new stock and I would transfer each item from the top of the old stock to the new stock until the old stock becomes empty and I would reverse the vector. This would mean that the bottom of the new stock corresponds with the front of the reverse vector. The functions used are push back, pop back, peek and size. Push back and pop back both share the same time complexity of O(1) for best case and O(n) for worst case. Size and peek also share the time complexity of O(1).",5.0,57
16496,16496,20741,d5a3f7d660aa30769e68a7c616a4942c8f05f0c2e034be1b4e61932df724917fd2a406f53a34e25ab412791ed6463a16ef1b087d401683c22430b89ba7a21be9,"You would use push_front() which will have a time complexity of O(1) as you are just adding to the front of the vector. If its the worst case then time complexity is O(n) as you have to resize the vector.

you would use pop_front() which will have time complexity of O(1) as you are removing from the front of the vector.

size() will stay the same and be O(1) complexity.

peep() will also be O(1) and you would use .front() to get the first element in the vector.",2.0,57
16497,16497,20742,67ade1890555ea7d6de913382858973bf82ef717e817e6295020978c59105278650d1bd8b5c2d42daf06ff2292f0b1f4096f4f20a6d3a8a92a4f522b583d867a,"As stated, the front of the vector corresponds to the top of the stack. Hence, items pushed to the stack will have to be added to the front of the vector and items popped will be removed from the front of the vector.

Push:

Since there is no existing function to add an element to the front of a vector, this operation will have to be done manually. To add an element to the front of the vector, all elements of the vector have to be shifted one place to the right and the size of the vector will become size+1. This operation will always take O(n) time.

Pop:

Again, carrying out this operation is not possible through built in methods. Instead, each element, starting from the second will have to be copied into the slot to its left and the size of the vector will have to be changed to size-1. This operation will take O(n) time.

Peek:

The first element of the vector (and top hence stack) can be accessed using the front() that exists for vectors. This will take O(1) time due to pointer arithmetic.

Size:

The size of a vector is always known and can be accessed using the size() function which operates in O(1) time hence the whole operation will take O(1) time.",6.0,57
16498,16498,20743,888a700ecff48b8e58609f74298e3e913836c7525e3508cee74dcd45d73e3b5cb35996869dd34b3342eba886899eba46a61c603fc724f15dfcf45804ca8c7ece,"To push in the stack, you would move each element in the vector so that each items it ith+1 index and then insert the first item of the stack at the beginning of the vector. Doing this has a linear complexity, so O(n). The complexity of the other functions is constant. ",4.0,57
16499,16499,20744,910daf6bb90bfaca5b8329327dbb6876d9a383514e01fe819f79abb1a27019ac7b7555a07d09a61e93831fa5c489e19d607608ea54797f25aad8bd641ed60e55,"We would need to create a class called stack and in that class, we would have 4 void functions i.e the push function, the pop function, the peek function, and the size function. The peek and size functions should return values and they should both have a constant time complexity. The push and pop functions will not have a return statement and will have a best and worst case time complexity. The best case will be constant time and the worst case will be linear time.",4.0,57
16500,16500,20745,a8dcc87a24b584021a1bb3ffd592a4ea66a1679acf3b2b41f26aef4e481760f4e64990e460e4e26ec12a8fef5d2354f5070843ac6e40f4a1e24bc122bfa91df9,"For push, firstly the size must be checked, if the is no space a new vector is made with twice the space is created and all elements are copied to the new vector and if the is space no new vector is created. After space checking is complete, all elements are moved to a position that is one place in front of their current position, then the element to be pushed front is assigned to front of vector or index 0.The time complexity is always O(n)

For pop, all elements are reassigned to the position that is one place before their current position. That would mean the first element in vector is removed.The time complexity is always O(n)

For peek the first element at index 0 is returned. The time complexity is always O(1)

For size the standard library function for vector (.size) can be used. The time complexity is always O(n).",5.0,57
16501,16501,20746,a58cc7a946eda613e1ba5b3286e27532a7ed6202aac74240dace327e45260834a089fa12052292c507fb1aec6f37cb1855be0992f9b6be6541ab2eebe4c77364,"there must be a pop front function, where you pop the item at the top of the front of the stack which in this case is also the back/the top time complexity is O(1), you must push front, that is add to the front of the stack which in this case is also the top O(1) time complexity, last in first out, the item at the top of the stack is the last item in. you must peek at the front because it is also the top of the stack therefore must return reference of the item at front of the stack O(1) time complexity, for the size you must pop front until there's nothing left on the stack O(1) time complexity",2.0,57
16502,16502,20747,e083cbbf008c42438bc396229643f759537dd38e9f70943e360360b6f27f45207e60ac5070353bd70bc7b26433e973228b25ccf89b152c434341d5c266f31945,"If we have a stack which is implemented by a vector and the front of the vector corresponds to the top of the stack. When we are adding or removing an item from a stack, it is the item on the top. Thus when you add something; you would push front on the vector. The complexity of push front can be constant time(O(1)) when the vector is not yet full. Worst case scenario can be when the vector is full, we have to create a new larger memory for the vector and copy all the data in the old vector to the new one which will take linear(O(n)) time.

Removing also have the best case and the worst case just like the push front. Removing is pop front in the vector.

Peek is always constant time and we use the front function.

Getting the size of the stack is the same as getting the size of the vector. The function size always has the complexity of constant time.  ",2.0,57
16503,16503,20748,a483d97f2f6f4b566a91dffee7b0dc51b69866d7a50c6e53308e166eaac8f5373cd9dfbf9a10c25bd5d41a415c716306b0d1e020a1acf8282aad769edfdcc9c4,"for push I would make a void function that that takes in an object and pushes it to posdition zero of the vector using push_front() approach, and similarly for pop it wil have to do pop_front() steps to chop off the object at position zero of the vector. Both these two functions would then take linear time complexity. the size would just return an integer value specifying the size of the vector using size() inbuilt function, this would be constant time complexity. the peek function will just have to do one operation which fetches the item at vector index zero, this would be constant time complexity. ",4.0,57
16504,16504,20749,c6130d795cb6021c7594812b73d6b159744ce452f7f194d2a8acfd0f6313f2562bada8d95c7d6c5736c9d1d528be9655da041882fe8c7474badb6562243ddc74,"For the push function, I'd use the push_front() function and the time complexity will always be O(n) 

For size function, I'd use the std::vector built-in size() function and the time complexity will always be O(1) as the vector class itself keeps track of the size of the vector.

For peek, I'd use the [] operator built in the std::vector to access the item at index 0 and the time complexity will be always O(1) since it's just the [] operator which is just one pointer arithmetic.

For pop, I'd use create a pop_front function that removes erases the item at index 0, and then moves the remaining items one index to the front. The time complexity will always be O(n) as we always have to move the items and sometimes have to copy them wen resizing the vector.",5.0,57
16505,16505,20750,52f183a2edd50f67bf9165da2ed344e6b1dbef117bcc8a87e8fdd544cade3eccfad6434b2157d981bfdc96048e52a8b1696fb090b734b452d891d2f61d866105,use the push_back( ) function which takes O(n) time .CREATE FUNTION AND USE Use pop_back () FUNCTION WHIUCH TAKES O(N) TIME.USE ,0.0,57
16506,16506,20751,9b5371bf3d8a67220ea9112f458e092347973d5a590a2ada7f6d386201210567493e4842dd7263535c03e1b4ce797297171327f4cefdbdd79731ace1f4e756bb,"We first create a class for the stack.

we make the functions we want to implement public then we start with the functions.

the function Push which uses the vector push_front and  O(n) time

the function Pop will use the vector Pop_front and also takes O(1) constant time and O(n) for worst case

the peek functions which will use the vector front function which takes O(1) constant time.

lastly its the size function and it does'nt change also with the complexity is O(1).",3.0,57
16507,16507,20752,b9398cac04fafed43567a061ce43d1f6d47a11dc43ed26ca3b7c803119e60ccce5216c5b0d8f2fe86de25d577c66b8be90d26d4412d9f88f080c8ddc823e6bcb,"In this problem I'll have to use the push function which is the push_front function found in the built in function since the front of the vector is the top of the stack and  push_front function will take O(n) linear time.

Then I will have to use the pop_front function from the std:: built in function to pop values from the stack which in turn will take linear time complexity O(n)

the peek funtion will the one which will be made to take or check a value from index zero and only taking constant time O(1) complexity

size funtion i will implement it using pointer arithmetic taking constant time",4.0,57
16508,16508,20753,d39f1221c1c1fa8d17ca77420f1bba8cbd56fd8e4b2efb35a70c05cd360218b8d98dd79e4c1abc4c057030cb040ef7358efbb5cda6b9051c1e5bddbf68b768c0,"I was going to start by creating a vector class and create functions called pop_front and push_front which pops and pushes items at the front of the vector since c++ does not have that function by default.

The complexity is - O(n)",2.0,57
16509,16509,20754,61263672c5c532106e7f21122dcaab559eafcffe3f9da40ef6a4194409e8f1be9b62145c70c7a6a62ca846b85c63f3fbde4504110d16d1088e8621a2430bcdec,"I would use push_back() to add elements from vector on to the stack, time complexity would be O(1). The create another stack, then I would use pop_back() with time complexity of O(1) to remove elements from the first stack and use push_back() with time complexity of O(1) to add to the second stack, one at a time.

The second stack with now have the front of the vector at the top of it stack.",0.0,57
16510,16510,20755,23b5a4e63c9fefece084783cc1411977943e7d8d3612a093af2540d5bb113a4845b418786034d0d238575bbb9fe95d816e937dc9fe084e3f124b6dcce8457f10,"On could switch the vector around so that all elements that were at the front are now at the back so that they correspond to the top of stack. Vectors cannot push, pop or peek at the front but only at the back which is why we have to do it this way.",0.0,57
16511,16511,20756,1db17093b11c1476f03e1842d3fd75c18d4034c323e18d85de2325fa751f6201dc73b8705d987e46f915cfc55474341bdc436a256b6ba4b925f54ea754c444c7,vector<Things>,0.0,57
16512,16512,20757,eaeebfd434a43156f3712848577d3a5da6499b6e1784e16a24ab5777985e6e2eed30ffc0a110ed246a9badfba660cd9a812c4ed7d173d1a29f7e115ce4ad58b1,"push function should take in an object and push it to vector position zero and pop should pop the object at position zero using pop_front() and these two would take linear time complexity, for peek the function should return the item at vector index zero and size should just return the size of the vector, peek would take constant time and so would the size function.",4.0,57
16513,16513,20758,ef46ab4c4baea61ce39205f3f8b9ba2f08ab48270b777e4f042aafc6410a82e9cddc1dd033e57ccba5e191584e8763e9b5c270df38cd4daee3f921d844f6b7a8,By using pop.back() and push_back() so that the vector is filled in well.,0.0,57
16514,16514,20759,75a3383738a198a57b5bf911227bc1acefa5387a63447f6ac8def117cc9ca26c926b9a06fe676ff769e333554195eaa647257e22733d67710ae7508ceb7f3115,v,0.0,57
16515,16515,20760,a50f1f05303eb676c08e683fb412c46779741d1e408ab7173f3f3a12df3f04196b4fd7b7add1fd647d8efd191c43d6971e5cae7611afd814fbea2a7330f3ce46,"push function

if the vector is empty then that means push in front will be O(1) and if not that means one has to move all values before pushing in front to next consecutive position in the vector, that means the time complexity for that is linear.

pop function

Similarly like the push function one will have to move values to back to their previous positions thus it will also take linear time to do that given that the vector has more than one item, if not popping is constant time O(n) 

peek function

using pointer arithmetic peeking in front will be constant time O(1)

size function

one will have to keep on adding when an item is removed or added to the data structure thus it will be linearly constant time O(n)",3.0,57
16516,16516,20761,91d41b2f32ab492a059463744b0e5f6cd6e21e57c981adbf25309713090c378a42bc574b38c9745bce66a49918299962c618772aa540a5c09c38c4d73e58815f,"in the size function i would choose to use the std::built-in size() where the time complexity will be constant.

for popping,i would use the pop_front function which i will create and its function will be to erase the item at the index=0,and it will move some of the remaining items one index to the front

for the push_function , i would use the pop_front function with a linear time complexity.

for peek,usng the [] operator built int the std::vectorto get access to the index 0 where the time complexity will be constant",5.0,57
16517,16517,20762,2f8068722efcb5acef0b043ef7eeece2ba76bc57f445239c4ee08b7c2bb5238f231cca575128f6a330204e13d52f6c557830c59595c0c60a57b982bbb0aba187,We would declare a vector and every time we want to add to the stack I would use the push_front function which will always take linear time(O(n)) because we will always have to copy all the elements in the vector every time we add an element. If the vector is empty it would take constant time(O(1)).To get peek we would use front function which is O(1).,2.0,57
16518,16518,20763,47a96f7fd37a4283bd96fcb03ba26cf7cdfd591682a3ab89197e64c489356cb4cf67ddd2623e0d973228f2c5400031304b672d076d17a1440971f1f289cb22d7,"this could be implemented if 2 stacks are used. on the first stack values are added as they come, but then they are transferred to the next stack and are now in reverse order. The oldest entries will be at the top of the stack. This can be done once the vector has been filled up. If more values are needed, then the original vectors have to be copied into a vector of larger capacity and then the process of transferring data from the vector to the first stack, then to the second stack will occur. Because of this, time complexity would be as follows: push_back = O(n); pop_back = O(n); peek = O(1)",0.0,57
16519,16519,20764,b8ff274cc91e39334247b9673eeb1e1ed2acdbcefc990de9bf2b4226b88349ab6bc97343b39be8aded8a6ab21d1bf5dc3045e9f7596480cb1279270e81abbd58,"Push:

Time Complexity = O(n) as a function push_front in a vector would take linear time O(n) if it existed.

Pop:

Time Complexity = O(n) as a function pop_front in a vector would take linear time O(n) if it existed.

Top:

Time Complexity = O(1) as pointer arithmetic always takes constant time.

Size:

Time Complexity = O(1) as we are returning a value which the vector keeps track of.",4.0,57
16520,16520,20765,dba55105f290263eab690cc35467de21c1485b240568356b922de9e4385ff6cd7f9c33bdddf55cba48dae5962652c3708da244fefbb69455c6e660d7de9c7d15,Intiatialise the stack and the vector. this would be done in a class. then you would use the pushfront function.If their is enough memory it just push to the front. if it does'nt its o(n) speed because u have to create a second vector with double the size so u can pushfront the new item to the front of the vector. You would use the pushback function in the stack. this function works on linear time. since it runs through each value.,0.0,57
16521,16521,20766,ab943cfa0d926aa21911a9961743ce4779859ba20a4ac4e15e75033134ef20f2d090435e99a19a4b2beb23e354a8983d0355213a926be357504dc13138c83605,"For the push function I will create a void function that accepts an item of the desired type and pushes it to the position zero of the vector using our once implemented push_front function, For the pop function i will have to do the pop_front() of the item at position zero, for peek I will create a  function that returns an item at vector position zero,  for the size I will make an integer function that returns the vector size using size() as we alredy learned. All in all the push and pop functions will take linear time complexity and size and peek would take constant time complexity ",4.0,57
16522,16522,20767,a1c2b05bc77a92969182ba646d8a653eca3913d57c538fdf187c677d2b0c51d076b45d82612615ca734696b4dfc388e9684934287cf1a84a26d20f8be5134c6a,"in the push function i would use the push_front() function which has a linear time complexity.

in the size function(),iwould use the std::vector built in size() function and the time complexity will be a constant.

for pop, i will createte the pop_front function that erases the item found in index=0.",1.0,57
16523,16523,20768,a41ff85d7c3f46c972cdda9b8d99297a4177ec80aa4a317631762cd6ae04cc877e3ccd31e4fd09e41eccdaa2cd1266d20e5947fd82dfa31e5b04a9f5e1bd8e0c,Time complexity is O(n) for pushing and popping because time taken to do so at the front of the vector depends on size of n. It increases linearly as n increases.,4.0,57
16524,16524,20769,7ee2a07ed8605f9b7e2a082751cb95a96baac16cb0bf39fd77ca963963f89dc899500eaec8aaa9621d868e97b67ab53ef71efa8d993d9a386011c08cc84fffc4,c++ does not have functions which pop and push at the front of the vector so I am going to start by creating a class vectors and create functions which pop and push at the front of the vector.   ,0.0,57
16525,16525,20770,6411a31397edca98a86156eda9fe940cd25214f5793edb40ff98bea1168dd2f02767f84a7d8f08cc5cbcf1da236fabf58172c048483fca623b7f16592128e03a,"we would use push_front() function for the push functionand time complexity will always be O(n) 

We would use the std::vector built in size()function for size function and the time complexity will always be O(1)

We would use a pop_front function for pop",2.0,57
16526,16526,20771,8278e2d003c29d98e8cfc7117cefa90b7503054f5b50b162eaded6981387fa2f1b8b8f0ae2fa0d58942ac81f9cf7fda1cd474d106727d602bcd9f2d647883b50,"create a vector 

and insert items into the vector using push back

the run time for push back is O(1)

use rotation to the right so that the last pushed element is at the front  of the vector and the first element is at the back of the vector 

run time is O(n)

to remove the first item use pop back

run time would be  O(1)",0.0,57
16527,16527,20772,a959a4bd23a818684dfb2a6c94ac89925575f3b11f0de3ed6d4df640b02681f2171e62de10059d8c04c758f13335e59b8e75b311b1045da8f168f89c32919f7f,"By popping, pushing and peeking to the front of the stack, instead of the back. The time complexity would be O(n) for all functions.",0.0,57
16528,16528,20773,8c6eaf7f60009bf511475c1e1f0a55bd524f57db7075d81ac6324fa20c67170610813fd28d5d1a71cf68fd79649c07e7ddbcbaee618c9d5cb0d649f541152433,"* Create a new stack.
	* Empty the old stack by transferring each item starting from the top of the old stack to the the new stack.
	* Reverse the vector. ",0.0,57
16529,16529,20774,639a68158c22ced38b469e5ff5439c6df90887f4ac511792920966a4b66fbbb0736453130f1e07f675685ab76215a4ca74f33ab5a9bf6fded51b150fcaa550e3,"The push back function would require traversal to add an item to the back and would thus be linear (O(n)) time.

The pop function would require traversal to the bottom of the stack and would also be linear (O(n)) time.

The peek function would return the front of the vector and have a constant (O(1)) time.

The size function would return the size of the vector and have a constant (O(1)) time. ",4.0,57
16530,16530,20775,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,Create a new constructor for the stack implementation do that the reference gets independent copy of stack.The stack does not underflow unless there exists an integer k such that the first k pop operations occur before the first k push operations.,0.0,57
16531,16531,20776,c2c29b17660ccaffde93650bbaabbeca722766be9c7f4c24079c9b3711df082352b0623847e9af19ff96cf4f2d45d0bd1cd360dd8fa3d9a37f5041dcc804b8b1,"I would use pop_front to remover elements at the front of the vector. This operation will always take a constant time . Thus it has a complexity of O(1).

I would also use pop_front to add elements from the front of the vector. This will also take a constant time O(1)..",0.0,57
16532,16532,20777,6e573d9284194cc7291f560a714a872dd47b4e061283e85a73d0f329ec03550a03a1a3f166b0239189f5a0ff40814ee55278425a8a226193ee0b842b340ab615,"To ensure that the implementation is the best case(i.e constant)

i would implement the four operations of stacks on the vector which are push(),pop(),peek() as well as size()

This implementation will allow me to treat the front of the vector as the top of the stack according to operations  operations i implemented.",0.0,57
16533,16533,20778,c7fddd77b6fed9bc15d19de2718acf9bd47e63c47fabc90953d259ee95b77d6203c59c32fab4eab8591fe4a7373a9aafae0952036c94bc9ebef7955717c99e00,"To add a new item on the stack I would push front, because the front of the vector correspond to top of  stack in this case on the stack we always adding at the top.and the time complexity for push,pop,size and top will have O(1) at best and O(n) at worst.",2.0,57
16534,16534,20779,e4de8560a7833ea7e41506cbf2b98858d3fa4c3e63a3de4e7dc8bd29355e0d9ed6e046298ea3e0b168144f8ec8172fffceca442b1283186ffc527c0ffb6fd2b3,"You would include the stack and the vector and you can create a stack by using the line of code (stack< int, vector<int> >my_stack;)

The complexity would be  exponential",0.0,57
16535,16535,20780,75fb392795f510a47294b64115e91ce7d1c8b8f1a838562042230066b246ab6f5bab879c5a1a2a2cdc7ea648749734fcc5c1729a757ed2c29cd8f8187b92206d,the time complexx,0.0,57
16536,16536,20781,4f0d170bb113012c8d343271d925a96ef0e199ecdca36f51a1fc99d7e0e8c67fb97155bfa738d3317830adb88f58c316437e0cf62b20c43f4e89ab893b6e7471,"I would implement the stack using functions: push, pop and size and peek. 

These functions will be done under public:

push function: I would call the push_front() function whilst implementing the push function and that function will take in a parameter. Time complexity Best Case: O(1) Worst Case O(n)

pop function : I would call the push_front() function whilst implementing the pop function. Time complexity Best Case: O(1) Worst Case: O(n).

peek function id call the front() function to find the value on top of the stack whilst implementing the peek function. This will be O(1) time complexity.

size function i would call the size() function whilst implementing the size function. This will be O(1) complexity.

under private:

declare the vector",5.0,57
16537,16537,20782,e8cc8f379686cf17ff7a79c51f234b372a7158c41925760d6a62468ac2bc253c196a10ef5af7f8e787abc174ba6435f331d902d6901bc07bc87271a8d067f35c,"Push_front will add an item to the top of the stack.  In the best case the time complexity will be O(1), however in the worst case, if the vector does not have enough space, the time complexity would be O(n).

Pop_front will remove an item from the top of the stack.  In the best case the time complexity will be O(1), however in the worst case O(n).

Peek returns the item at the top of the stack, so we will use the function data.front to return the item at the front of the vector.  The time complexity will always be O(1).

Size returns the size of the vector and will use the size function. The time complexity will always be O(1).",6.0,57
16538,16538,20783,87b26af5215183ea5d646e967e1e3374a7a4afb5a13a2967680ff8a29d219e9ac775560a42891913325361c21b3cb2f9b5121d0317fb7c951cff2c01aed37b66,"Initialize the stack and Vector. Use a for loop to loop through the vector and add items to the stack (last element of the vector to the first) using the push operator. The time complexity for the for-loop would be O(N), for push operator it would be O(1).",0.0,57
16539,16539,20784,3824a0678a0ee80961c81764186a1496645536aadc7127ac81665ef8825202d12ca91cc1dddb49cb3545dd95e3ab23ddf164ccd399cf03acc33959144061677d,"push - if there is a space in my vector, I would mobe all items to the next position in the vector and then add the front one by putting it at position 0 of the vector, if there is no space I would increase it by allocating the vector to a vector +1 bigger to the original size
size - The complexity of the push would be 0(n) because I have to move the original values n times then add a new value",2.0,57
16540,16540,20785,09a1699e91053a97e967035388a9bb6bf2333dc132838738d78edc417a8028213044038d23bdf9e5be7458e9014620b5d4a10df02214eb4aa340c740ce44d5c1,"Stack has a public data field as, the underlying data structure, which is a vector of whichever type such as a vector of things or int. Functions will be created for it, being the push, pop, size, peek. Push is a void function that pushes back to the vector. Push has the parameter for a reference to the relevant variable being passed in, to pass in the address of the actual value. It will use the argument to push in a thing into the vector of things using the vector's push function-O(n). Pop is a void function with no parameters that will remove an item from the top of the stack and use the pop front function of the vector-O(n). Size is a function with a size_t return type, with no parameters. It will use the vectors size function to return it's current size-O(1). Peek is a function which will return a reference to the top of the stack, which is the front of the vector in this case, thus it will use the vector's front method to return a reference to the front-O(1).",2.0,57
16541,16541,20786,8127d4098ce90e5354b83277c230528a4f346dff2268e6e565e170f557f4828895b86ce9e4d45680788cfb7696e91c4b7e7c80cf0ef0611dfea212b6f772071c,"I will declare a class called stack.

and i will put the functions in the public so that they can be easily accessed.

the declaration of vector will be put in private.

both pop(remove an item at the back) and push would have a better constant time and worst linear time and

both peek and size will only have constant time complexity.",4.0,57
16542,16542,20787,02cb07161473723283d91a3c998f4ade4cb197abe855244e901ae8f3133fa745a87cf9dec28bee7621c8d3b8308477fc042faa7e0319e0ad9256c728f396d7bf,"declare and define function that adds item from the top of the stack...O(1) BCS; O(n) WCS

declare and define function that  adds items to the bottom of the stack... O(n)

declare and define a function that removes an item from the top of the stack...O(1) BCS; O(n) WCS

declare and define a function that removes an item from the bottom of the stack...O(n)

declare an define a function that returns a reference to the top item...O(1)

declare and define a function that returns a reference to the bottom item...O(n)",0.0,57
16543,16543,20788,78249ef9b62941992169ea6ab9335b72fe3732b0d62324e87cfd98782c3176ff3a0f6d77d1563959cb064ffef03d777dd5132e65d5820daed930a9e3247d9f38,"For the push function make a void function that takes in an item of any type and pushes it to position zero of the vector using push_front() function. For pop function it must do a pop_front() of the item at position zero,for peek make a function that returns an item at position zero ,for size make an integer function that returns the vector size using size().Push and pop functions take linear time complexity and size and the peek will take constant time complexity ",4.0,57
16544,16544,20789,16751d82a0250cf90230a736276250ecd4342c2e9097f12ebacee397740771d03e925ee189c3aaacf702dbec6f3610c7e13e7ed44667c2823433286e585becf2,the is empty function will check if the size is zero or not. the top function will use the index of the last item and try output the the item on top. the push function will use the push_back function and add the new item to the top of the stack.. pop will return false if the stack is empty otherwise it will use the pop_back function to remove the last item.,0.0,57
16545,16545,20790,20d849b0f14d796b315efcd61e863b25c7b0891949c9f1f08039226267e2ec02fc126e19dc6bac1596ae1c91066636280bb491c789bcd5f5ca3de77e3170945e,"Pushing to the stack would take linear time O(n) since the items in the vector have to be shifted one position to the front and I would use the push_front function.

For poping from the stack I would use the pop_front function which will take constant time O(1). 

Peeking would also take constant time as I would be simply returning a reference to the first value.",3.0,57
16546,16546,20791,ba17ced0b845a961a4ba2b9f572020680e40bd19c35ccad68ac84e48d9cb5d04fd0000feb318fb1b5fed6a59256f91eb5d0cc5f4be4d4f154e8d52a24ea8af8a,"A vector has push_back and pop_back functions, so I would use the end of the vector as the top of the stack. This means that I will have to peek at the end to get the value before I pop it. push_back will have a time complexity of O(1)  and pop_back will have a time complexity of O(N).",1.0,57
16547,16547,20792,3b012b96c98d84ed8e9f88d92fde8d672f449955feec04f1b94283d72586d2586b31cd4b32cb1464ddc219af63c953c4b0015e421667a55126d1bf7700e02016,Time of each function would be O(n) time,0.0,57
16548,16548,20793,2b92088102e0af9a5553cb90ac0d16cccf7d22e656abd8591794202e3ad9e3740967e9bc58b6fe2de9b9f1fca59eea10df4f48ad04955724c20b00283b3e3844,"* firstly i  would initiate my stack as a class 
	* even though classes are automatically public I would re-specify public
	* i will then create a void pushback function and pushback data 
	* next i will create  a void pop function and pop_back  whatever I call the function for ()
	* i would the create a Thing &top function and with this function i will return data.back()
	* i will then create my last function which is my size function and with my size function i will return the size of my data vector.
	* lastly i will specify that which should be private and kept to the user which will be vector <Thing>data.

	* the time complexity for these functions will be linear ",1.0,57
16549,16549,20794,9ab5ee6dcd1eeee42b584dd13d10dfb771aeae24b070596bf8e33f41840796cff5a58f61a4f76bd5d61ec8edd7ee76fc7e403b38a2b713cfce865554906c5149,"THE IMPLEMENTATION

	* I would use the PUSH_FRONT FUNCTION to add an item on top of the stack and with CONSTANT O(1) TIME COMPLEXITY.

	* I would also use the POP_FRONT FUNCTION to remove the the item from the top of the stack with them LINEAR TIME COMPLEXITY.",1.0,57
16550,16550,20795,fd3ac26e8f1d74669c591d17cfba292d301a38f59035e0e015254638e09238378ffbb05277661aa625df195230a27bb79b8964e830815de826a62bf695fefa00,"I would use the following functions to implement the stack.

	* PUSH

-I would use the PUSH.FRONT() function to add an item to the top of the stack.

-Time: CONSTANT O(1)

	* POP

-I would use the POP.FRONT() function to remove an item from the top of the stack

-Time: LINEAR O(N)

	* PEEK

-I would use DATA.FRONT() to get the item on top of the stack.

-Time: CONSTANT O(1)

	* SIZE

-I would use the DATA.SIZE() function to get the size of the stack.

-Time: LINEAR O(N)",2.0,57
16551,16551,20796,97a01199b925330f29640cdb86e45eea363ff96eb767b66ea518348ab8ed24fd59b309226c6a592a7f7ea6b67fef81cbfd1daad02d4a32f29300da894c457dc7,"adding new data to our vector will be at the front no longer at the back so when we add we have to push at the front.

finding the peek/top (the last data added) will change from being at the back to the front , finding at we will have to check the last data added at the front.

when we look for size, we just count the number of data in the vector and that our size.

removing data from the vector we will have to remove it from the back because we can't do it at the front, that's new added data so pop at the back.

time complexity for size is always linear.

time complexity for push front as we add our new data from the front is constant.

time complexity for pop front is constant along with peek/top. ",1.0,57
16552,16552,20797,fa9e03d0ca767f086bcd9ef36b2098757508e1e31055329ce57a6c2012e0fc52ea26b7511314fd601a7a535cdf128ba0717226b541ddae15232dd77b79a7f243,complexity for both functions is O(n).,0.0,57
16553,16553,20798,2f3e315687119ead6a818da568e78a6a6a1fca8ffa33209c3dff24c186275e23df6af032db0ab8c3cc902f57fda3972c9cc02a021860b531f2f8a447436717fc,"the void push of ay value will add value to the top of the stack, the time complexity of it is 0(1) at constant(best time)

and 0(n) at linear 

the void pop of any value will remove the item at the top of the stack, the time complexity of it is 0(1) at constant time and 0(n) at linear 

 the object peek will return a reference to the top item

the size object size will return the number of items in the stack",0.0,57
16554,16554,20799,dd8364e8ed91c439ef01f1b1c5d50548af1ed1f45d9fe938f00f04ffde7150da61acbb591a7654fb4c9958209c9c12e4108f4761b34d706a0ab07033cf3359c4,"Initialising the stack would be done the same way as initialising a vector.

We could also create a class called stack:

In which the push function would correspond to .push_front()

Which would have constant time complexity in the best case and linear time complexity in the worst case

Pop function to the .pop_front()

Which would have constant time complexity in the best case and linear time complexity in the worst case

Top function to return (vectorname).front()

Which would only have constant time complexity

Size function to .size()

Which would only have linear time complexity",1.0,57
16555,16555,20800,e5714a4c20e7bdae287b7c08ee230173a746342e508a1fdf6f9b0ca3985863c9a9c50fab8cf85194e61c4743030f16659c52ffd068494fd5d94fc6ea4ec382de,"using vectors  we could implement a stack either by pushing,popping or get the top of a standard vector ,which is basically an implementation of a stack with vectors,so the time complexity for each would be O(n)",2.0,57
16556,16556,20801,e8ac13437ca4eb4696e3ef433ae3842afba862c0118c6894733767a015023753193111e7d4c262c3227484acd644f4e441faf59e7cd3f61df893fbe34d31e198,"To add items For the best case scenario is when there is still enough space left from the vector, I would copy all the items 1 block forward and have one space left at the back to allocate the next item. In this case it will have a linear time complexity._  _

To add items For the worst case scenario is when there is no space left from the vector, I would copy every item into a new vector with  twice the space, and then repeat the steps (Like in the best case scenario). Also in this case we will have a linear time complexity.   ",2.0,57
16557,16557,20802,7034e661a6b51c59ff4e839b7430fa79082c9a14de4d5507d8b8f51bcf2e8507159f0b9ac4f2f0968d640ca40b95ebbbfcb9a489ff8f5bfe6ee49d4e9a458d5c,"I would use a push_front function when there is a new item that needs to be added to the stack. The complexity of this code would be constant since to push a new object into the front of the vector doesn't require any loops, only two variables.

For the peek function I would use the front() vector function which has the time complexity that is always constant because of vector arithmetic.

The pop function would use the pop_front vector function. This function would usually be constant but could be linear if we have to resize the vector.

The size function would use the size() vector function which always has the time complexity that is linear.",1.0,57
16558,16558,20803,615a61127c6c0ce82fff3b905af9891145f1a8b7de3c813ff28357e83206738e51030e5e11f925cb1ff08e1e1848b449cb4a5ebd866eaf249477de58f163ccf4,"If you had to have a linear vector with the front of the stack at the front of the vector,

you would have to implement a push_front function to insert values to the front of the stack
and a pop_front function to remove the elements at the back of the stack

The time complexity of this would be O(n) for push_front as all the elements already inserted would have to be shifted to the right

and

the time complexity of pop_front would be O(n) as all the previous elements would need to be shifted to the left to fill in the space left.

peek would be O(1)

size would be O(1)",6.0,57
16559,16559,20804,6faeacee0c2269025dd90b7721d39fd6ea59274d1116063ca6e894050048f55cfc48de8438d931d22afb7e2c6e6e2971358b83dd0ec2d867cc557d7b6b500315,"Push: you would need to create push_front that moves all elements over to the right by one and adds the new element to the front, which takes O(n)
Pop: you would need to create pop_front() that moves all elements over to the left by one, taking O(n)
Size: would take O(1) as it returns the number of elements
Peek: You would need to create front() which would return the front of the vector taking O(1)",6.0,57
16560,16560,20805,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"The peek function would be implemented by return the first element of the vector. The complexity of peek function will be constant time O(1).

The size function would be implemented by returning the size of the vector using the vector size function. The complexity of size function will be constant time O(1).

The pop function would be implemented by moving all element by a single place to the left. The complexity of pop function will be linear time O(n).

The push function would be implemented by pushing back the new element and reversing all the elements. The complexity of the push function will be linear time O(n).",6.0,57
16561,16561,20806,0210a9d3772d4f5814d5d585f47b6503d720f89ae8ca72b5fb7136f3da85dccbdba73ac11df998e73774b6321c99446733c7c479dc009a4e0dc92678413ef102,i would implement the push_front and pop_front function which will add and remove in the front of the vector .I would also implement the peekThe complexity would be O(1).,0.0,57
16562,16562,20807,9140ffa3b52741e2ae246773dfeed94b1141ba7c3dc70e8cb17fb6410cd6b017d81c18ceaa0264d9c4b8354cae095d12f4a720da352b65b62d37bdd0fc9fdc69,"For the peek function I would return a reference to the first item of the vector. This would always be O(1)

For the size function I would return the size of the vector.. This would always be O(1)

For the pop function I would move every item one place to the left, so that the first item is replaced by the second item. This would always be O(n)

For the push function I would move every item one place to the right so that the first item would now be the second, then I would add to the vacant space which is where the first item was. This would always be O(n)",6.0,57
16563,16563,20808,9b486d212bcbfc98bcb7006334a7bd057c017b3b5d6ddec828a1e7c71b279d57abf5933826cc5cd40f31ce09e30273c03c034afd55ad69a350c76adfabdffc7c,"Since the top of the stack corresponds to the front of the vector a ""push_front()"" and ""pop_front()"" type of functionality will need to be implemented, however since this does not exist within the library for vectors (as it is inefficient) it will need to be coded in.

For every instance of adding an item to the top of the stack, an item will need to be pushed to the front of the vector. Meaning that the vector will need to be duplicated and an item added to the front of the every time a push() is required. For this reason there will always be a linear time complexity of O(n).

Similarly, removing an item from the stack will require the entire vector to be copied, excluding the first item of the vector, always resulting in a linear time complexity of O(n).

However, to find the top of the stack the front() function native to the vector library only needs to be called and has a time complexity of O(1). This is also the case for the size of the stack as the size() function can just be returned which will have a time complexity of O(1) as well, as just the number of items in the vector will be returned.",6.0,57
16564,16564,20809,0ddebbd83df885f86ba1c96720608778be815c854a9f153df224b96b22cf260eb651e6e1d04778d3c06f6de0d3c75049a5f3bb4b6575599d6f50e21a7074d16e,"For the push() function I'll use the vector push_front function which will take 0(1)

For pop() I'II use the vector front() function to get the location of the 1st element and set it to null then move every element one space back which will take O(n)

For peek() I'II use the vector front() function taking O(1) and vector size function for size() taking O(n)",3.0,57
16565,16565,20810,db0698cd03866d48da0c9cab1c327e767c6fb2c70ab318867db7094af47e41c16fc1528b63425d8d7a1a4e5cc071eef840fd0e4c5113866d0139015edb52f238,Void the push function. Then increment the top position. Then insert the element on incremented position. This will be a linear O(n) time complexity ,0.0,57
16566,16566,20811,efa2c5b70f1ad8f0aebabd9a8317831d8e117c559aa0a29951f0659587ce28ce45a8ffe00e2d128d5b1b92e6f8033ccb1e7464d9f2f119aa95332037f62a3b76,"Using the front of the vector as the top of the stack is essential the opposite of using the back of the vector as the top of the stack

If top corresponds to the front of the vector.

push() and pop() is 0(n) due to the elements needing to be shifted across

back() 0(1) due to pointer arithmetic 

size() 0(1) n_items as it is stored in the vector",6.0,57
16567,16567,20812,1b575ce85f9fe9d462e1de73f4e66ff04c921a768d297956a2d166b33e02a5691d14de4e07fdb716975b3003397dd6ecfd657024c0a233117dfee4b6480ebdcd,"push -> There is no pushfront in std::vector and so I will have to do linear work of n - 1

    complexity -> O(n)

pop -> There is no popback either so I will have to again do a linear amount of work to implement it

    complexity -> O(n)

top/peek -> I can easily use vector's front function to access the front/top of the vector/stack

    complexity -> O(1)

size -> I can use the in-built size function of the vector to get access of the size

    complexity -> O(1)

empty -> I can again use size to see if there are elements or no elements(0 elements)

    complexity -> O(1)",4.0,57
16568,16568,20813,c2e3a17d6cc0156e335ca9215e55053ddbc80682871f8957ca1d1b73d39dbe24e0950e6728cd273bbd1fbaac4e9fc1f8fc1eeb009c8b2565447f198e841deab0,"In order to add I would have to implement a push front which will copy each item one step backwards then add a new item at the front of the list.
For the pop I would simply use pop_front. 

In order to get to get the peak I would then have to have to collect the item at the first position in the vector",2.0,57
16569,16569,20814,e1db971413a3e8370e48a08bd90e6c532854614ec97bf2846a8b6f64d7d2d64fceb404c5b40a925c2c496078dab9556b9aedc866e91bea3a7a6a8dc8cc19eb5b,"A vector is a dynamically allocated data structure on the heap, therefore, the item at the front needs to be known in order to access the rest of the vector. In order to implement a stack which uses a vector with the front of the vector corresponding to the top of the stack, any push_front or pop_front functions would require reallocation, since the stack is a Last In First Out structure, where items are added and removed from the top of the stack. Therefore, adding to the front of the vector would require reallocation to another vector, and the copying of each item across one position, in order to add the new item at the front, this would take linear time due to the reallocation and copying of n items, therefore O(n) time. To remove items from the front, this would also take linear O(n) time due to the reallocation and copying of items one space over. The top() or peek() function would be constant O(1) time as this would require accessing the first item in the vector. Additionally, vectors keep track of the number of items, therefore the size() function would also be constant O(1) time. ",6.0,57
16570,16570,20815,ca7ca134b5efdd7b26013cdee3bcba7329b07570412673ca953a2b1fc000b358026f967889f2b4b641fef26d116ce971213d8a9f77c08db97c244ae7f54e090e,"Instead of pushing back when adding elements to the stack I will instead push front 0(1) : TIME COMPLEXITY to add the elements.
But I will pop back 0(1) : TIME COMPLEXITY to remove elements from the stack.

To count the number of elements on the stack I will call the size function 0(N) : TIME COMPLEXITY

To peek onto the stack I will call the front function as the front corresponds to the top of the stack 0(1) : TIME COMPLEXITY",1.0,57
16571,16571,20816,83c5e0cccc2c84d6aa6c84996703c9788a4c77ad197dc9cbe544f356daab1002c8cb4669771a7a17cb1f5a0ca37aa675d40cb959b05635bc4844ce29a466fa7e,"To implement  stack using a vector, type stack<Thing, vector<Thing>> s1; where Thing is the type of the items the stack is storing. Create a stack class and for the member function push(), use the push_front() function of the vector. For the pop() member function of the stack, vector does not have pop_front() as a member function so then a new vector must be created, then starting from the second value of the original vector, the values must be pushed to the new vector. push() will have O(1) complexity but pop() will have O(n) complexity. size() will have O(n) complexity, and will simply be implemented using the vector member function size().",2.0,57
16572,16572,20817,5c96945f14d6fc788ed8c6c36dabf314debb1526e588422f61ac844f148e394c747509da6ebf3fac148319b89d19dab295d5360db7c4991b8db71ccf538d7808,"To implement this, you would have to create a vector as normal but when using the operations you would have to implement your own functions that will delete the first item in the vector when it is called because the vector data structure does not have a push/pop front function.  These self-created functions for what would be pop_front and push_front would take linear time( O(n)) because they would have to find a way to copy each current object 'one space to the right' when adding a new object into the vector as well as copy each item 'one space to the left' to remove the item in the front of the vector.",4.0,57
16573,16573,20818,eec934572d7644ba0121c8b2feb2c582e9f3f4f5b58187b8858bc2ee24ad1c13bedfb2cdb5029267bc11b865502439fbacde60c9046792350b575350ddc17ef6,"To add an item to the back of the stack one would use the push_back() funtion. Time complexity: 0(1) in the best case as we just have to add an item to the back of the vector. 0(n) in the worst case as we would have to copy the items to a new larger vector so that the new item can be added to the already full vector.

To remove an item from the back of the stack one would use the pop_back() function. Time complexity: 0(1) in the best case as we would just have to remove an item from the back of the vector. 0(n) is the worst case as we would have to copy the items to a new smaller vector so that there are not many empty spaces in the old array after removing the last item.

For the peek function, we would use the front() function as the item at the top is at the front of the vector. Time complexity: 0(1).

For the size, we sould use the size() function. 0(10",2.0,57
16574,16574,20819,2e87414379efcd8b6abefa082fd766ea6bbd6a7c49327da9b14527216de652d464a74ad3edb281cf63c53ec51b9a87c17ffe7ae230ea816e625650e59f9bd068,"One would need to reallocate to a new vector with (n+1) space then copy all n items from the original vector and erase the original vector then allocate [1] with the first element from the original vector then allocate[0] with the value needed.

Since we have to copy each element from the previous vector and shift them one unit back in a new vector,this will result in this function being on linear complexity O(n).",2.0,57
16575,16575,20820,267e2a74684712f40153e983cf911454f693aaba7aeefb5a018f4e1b42bb05582faee8c5c865be8869988dea6e1c2f220a507c49209244aad2cd13359f2247d7,Luckily each function will be constant. ,2.0,57
16576,16576,20821,b1b3e86f0d270a61f8fd878f224a3849ed613dcb005f40bfd930beec1496e89a0e58f28b9b719a548b167e0db0c44afd5aae82094d2f118c0287dc3bf2b65cac,"for adding an item to the stack ,use the push_front() function which we will be O(1) ,and add it to the front of the vector.

for popping the last item off the stack , use the pop_front() which will also be O(1)

for finding the size / number of ittems ,we traverse through the vector O(n) and count each item O(1) .weuse the .size() function.

for peek function ,use the .front () finction ,which will make use of .at(i) ,O(n).",0.0,57
16577,16577,20822,89502ac0aa9bcc7e1f53c6f2ab1184a643f5c96abf038408f562f5cb7340154d0c96d136d3c4ce774773aa13f3d95a0a98c70e80020a05dce05a8835fe30adf5,This cannot be achieved with vectors as the stack only care about the last item which is the top item on the stack,0.0,57
16578,16578,20823,ef56d487f412ffdca7b3412858b2ccd1fa21fc365016661f00994f5e06683c6e545b948b70c4775a9a839e6049995e36f03b1f06a7374933a80a9013b6052c37,you can use push front and pop back in order to remove or add from the stack.and then the functions size and peek in order to get the size ans element needed of the stack.and then the functions size and peek in order to get the size and first element needed of the stack,0.0,57
16579,16579,20824,4428555ef8072ef23d17db65e798fc29286c3f011a1099d994917d7424cc31d5f0d195105018e3c14dd5ec04f91fc4ea0c088a5e61680d4692faa4d313c225c0,"For pushing in the stack, I would create a temporary vector to store the items by using push back and will store the items from bottom to top. Then use a for loop which will run for the size of the temporary vector ( for ( int i; i < tmp.size; i++)), which will push back on the underlying data storage vector and will make the items to be stored as top to bottom from the front to the end.
The time complexity will be linear O(n).

For pop in the stack, I do  what I did for the push but vice versa, where the items of the vector will be moved to a temporary vector using a for loop, then push back.

The time complexity will be linear O(n) .",4.0,57
16580,16580,20825,03af6c40b97133a1240dcc22b0dd356e3929ea04c9cf63c336ed0f2605d19efb0d0a0e5a6c60e766990694456ae922f3a477316845f8028bca7fb236d74cb185,"Use pop_back() to remove the last item which will function the same as the pop() and this will take O(1) time. Reverse() the items in the vector then use push_back to insert an item on the top, which will take O(n) time. Use vec.size() to see if the vector is empty or not, which will take O(1) time. Equivalent to peek() we can use vec{vec.size() - 1), which will take O(1) time. And for the size of the vector we can use vec.size(), and it will take O(1) time.",2.0,57
16581,16581,20826,f2a1d44943cafd29447c9cc6d850c73ca115efbe45cc60a50c497d9c39593f6c44e4c2d4facba5ee2393c40106c70b0307d8a427a20ee6b2ecb0031a02f6d25c,"To implement a stack all you need is push_back() which is going to add elements at the top of your stack and pop_back to remove them together with a few more functions provided by std::vector. If you wanted to make the top of the stack the front this could be done by making every new stack point the previous stack and move the head to point to the new stack every time its added. This would affect our complexity by generally making our code take longer to execute using 0(n) complexity for both pop and push_back because stacks remove the most recent layer, and if the most recent layer of the stack frame isn't the back, the compiler would have to traverse through the stack to get to the back.",2.0,57
16582,16582,20827,dc1d80fcfca2cd7f4c0d66c0e3645622562d53654a85ac238b9c0b928dfd07eeca15aea65682a467ac6bd4135a13a6043d96321ee55136fa0664700d6e749201,.,0.0,57
16583,16583,20828,e627fede4d8a070ca528e22154030076326cf75a860ce09e9231ab5eb164fd945cbc3f05b7190cc8d307288292134d5c83514ef1ec1b1c4974bcf393c3c20f68,"To implement the push_front function, one would use the insert function from the vector inserting at std::vector.begin(). As all elements would need to move one back when this is done the time complexity will be linear O(n)
pop_front will be done in the exact same way but by using std::vector.erase() at vector.begin(). This will also shift all the elements making the time complexity linear as well O(n)

peek can be implemented simply using std::vector.begin() time complexity of O(1)

lastly size is a built-in function of std::vector which has a time complexity of O(1) ",6.0,57
16584,16584,20829,0cd06500f6bc04ca04d6df402c164435dd4b1e3f62d49a5f81d45b91f4a6f4ac2ae8232fc2f485e2ef108625ecea2f61c466c82dcbccacd3d327b9b3b7efa90a,"Since i would be using contigous memory i would first allocate sufficient memory first. Then i  would implent the push,pop, size , and peek functions using the vector which supports there. Push will have its time complexity being linear since we have to move things one to the right and with poping we would have to  move things to the left so it will also be linear. Peek will be Constant and size will be linear.",5.0,57
16585,16585,20830,65a6873c33aadcc2f385dcf41fe7257442b3db3e7c6b66b6512e8c943bfc186cd6a55217da7df9053eb7519b0f2cce5a776966d54e638536f0ae9c05ec98e97b,i would create a function that reverses the order in which sacks are stacked,0.0,57
16586,16586,20831,0ad70082487aef48dd8912618a0445b23be9d26b96b52da22e5f3af4c7b4d4d69fafa295a66b77bf05bcac5efb5907b62a38ffd4c57f8b0ef91795d6e3e55fac,I would fist need to declare a new class. Then I would implement the function void push() in order to enable users to add values to the stack with its time complexity as 0(1). Then implement the function void pop() to enable users to remove items from the stack with time complexity as 0(1). I would also implement the function Thing & top() to enable users to be able to look/ peak into the stack also with time complexity of 0(1). I would also implement the function size_t size() to bring about the possibility of getting the size of the stack. ,0.0,57
16587,16587,20832,e394539baa7fd0006de5096759d1db9943b0b453927105fc99e564a56547ecb01587d2f0348be0224bd521c0377577b713f00c14b60183a6d229e89193dcb643,head pointer would point the first item in the vector O(1),0.0,57
16588,16588,20833,bf4b5731c3c3bd0f2b59e631e277805959da8b9efedbe010df49f525b49b713ed8678bb3e54ddfd542bb302e79e236dfb9ec30ec253f0f80d3cd72c6a5094fbc,"I would enter the values in the vector in reverse, so that the the last element is the first and vice versa. The complexity for the push function O(n), pop function O(n), top function O(1), size function O(1)",4.0,57
16589,16589,20834,f1847bb5d29f39224664df29173ee4eea8241f8aa777b795f86bafdb3b6165e8679750df7902af2beb1387f258e9970c22324224cff020b701254fc8b35d988f,"The push_back function for vectors could be used to push to the top if the stack(O(1) time).

To pop at the front, one would need to delete the 0th element and move over each individual element by one, taking O(n) time.

The peek function would just reference the 0th item in the vector, which takes O(1) time for vectors.

The size() function for vectors could be used to implement the size() function for the stack (O(1) time).",11.0,58
16590,16590,20835,8f3267fb35d28eb10e3fc9fcbb0f22bf91f2506cc5526c9b2d0ca2807bf6f55a3324c012d8567781f2f103a5869506dd55924327b0937c914d8880e993d33ca9,"For Push() function we can use push_back(Thing t) function in vector that we have defined already in previous lab of Myvector, the time for this it will be O(1) [ constant ] if we have enough space that's when n_allocated>n_items worse case will be when we have n_allocated = n_items and we are trying to push at the back the O(n)[Linear] operation will happen

* Pop at front, we can use void pop_front() function that we already defined to pop at front, Best case will be when n_items< (n_allocated/4) then O(1) operation will happen. Worse case is when n_items> n_allocated/4 then O(n) operations will take place which is Linear

* to peek at front will always be constant time O(1) and we can use function void front() from vector STL",11.0,58
16591,16591,20836,912a17c5532a85cc610facff6c98d42b64fb259b767c809567c65cce318eb3dc8f21bcbe5e653de87fe40d2502ab66869bc553e63fc3a1d7697be613c3b49a69,"The queue is using the vector<Thing> for our data storage and so the implementation of push(), peek(), pop() and size() functions would be as follows:

The push() function would call the push_back() function on the vector and this would take O(1) time.

The peek() function would call the .front() function on the vector and this would take O(1) time.

If we're told to pop at the front, the pop() function would involve copying all the elements besides the first element from the old vector and pasting them into a new vector, this process would take O(n) time

The size() function would call the .size() function on the vector and this process would take O(1) time.",14.0,58
16592,16592,20837,cd3aa55745b79deafb0802ba9ebe30e68fbd1c089c006450727570d34769934d2b1c5a098a7d318146af21d8981711dce0bb006308d97edfcf9a088eb56e4532,For push I would add the parameter to the back of the vector and complexity would be O(n).,0.0,58
16593,16593,20838,af813686acb18a064eece7968dc86f7e1ba2e2c4ebcbfb61de992275f213a5fe2248d15ae968c61ff6c270f401a739d21132339ee0a42afa471e88a17c352ab9,"Since a queue is adding items at the back and removing items at the front, for the push function you would add the item at the back of the vector(best case O(1), worst case O(n)) using pushback and for the pop function you would remove items from the front of the vector(best case O(1), worst case O(n)) using popfront. Peek would be O(1) because of pointer arithmatic and would return the first item in the vector. The size function would be O(1) and would return the size of the vector.",13.0,58
16594,16594,20839,d31899b98e7fb3e761998737c0078a84e48727b178f33ae85b1caf85762f7c95a36780c3f84b13e4c3f8980c15788bdfcc7bddbb75a6b63b7a164f238d74d926,"Similar to a stack we would primarily make use of the functions in the vector class. 

In order to push to the queue, we would make use of the vector's push_back function, which would usually take O(1) if we had space in the buffer, if we run out of space in our buffer it would take O(n) time to reallocate. The case for popping would be the same in complexity if we decide to make our buffer smaller if it reaches a certain amount of items (we would use vectors pop_front function).

The peek would use the vectors.front() function and would be in O(1) time and the size function would use the vector.size() function and would also be in O(1) time.",11.0,58
16595,16595,20840,4427e3a6ae2786ed5636c638581416e62adf38c90aed72214004ce5b4fc79bb1e5696556f9677084defd90b33f5cf052534401db22ff6a075c7131169ee1bcf8,"FOR THE POP FUNCTION.

Since we would be removing at the front we would need to move every item from the second one one over to the left and if after we need to move to a new buffer both cases would have linear complexity.

FOR THE PUSH FUNCTION.

When pushing at the back, if there is space available, the time complexity would be constant but if we have to move to a new buffer because of lack of space, coping everything would make the code to have linear time complexity.

FOR THE PEEK FUNCTION.

since peek looks at the last added item, pointer arithmetic would make accessing the item have time complexity of O(1).

FOR THE SIZE FUNCTION.

Since we keeping track of the number of items we have  size function will have constant time complexity.",11.0,58
16596,16596,20841,72f8819c651aefda92260fa4f547f14f555e14f647747df897695708c9fa1a2f437da4d45f5b0c59c6c67b9f7f70e1068df3448aebfbb9759e5038bbc8c29ccf,"* for Peek , since we would have to go to the end of the list to get the last item , we can use pointer arithmetic to do so.  Which  would provide us with a constant time complexity .
	* for Pop front we will have to move every item from index[1] one place to the left. The time complexity will be O(1).
	* for Push back , if there's space , we would just add the item at the back with O(1) time  complexity but if there's no space , we would have to create a new buffer , copy every item then add the new item at the back . The time complexity would be O(n).
	* For Size , since we are keeping track of the number of items we have , getting the number would take constant time.",10.0,58
16597,16597,20842,74594d76e743115e9e80c4119a5039c4fec5aed2b1eb9af70c89d53a42b69ad2163ffd8ce8a40f97632e4be0cb18aad097e1d70fac3137214bb4656688c9555b,"The push function of a queue data structure would be executed by using the vectors push_back function which means that the time complexity would be O(n) in the worst case and O(1) in the best case.

The pop function would use the vector's pop_back function resulting in a time complexity of O(n) in the worst case and O(1) in the best case.

The peek function would just return the first index of the vector with a time complexity of O(1) because of pointer arithmetic.

The size function would just return the size value of the vector which is accessed  in O(1) making the queues size function O(1).",8.0,58
16598,16598,20843,c318ecd5c05d3ffa65238b75e8aa9e67390cc6fb32c2fdbfaf84c4d21eee7f78cf713a8bc77a69838390c129742df9afc0ddd3cf48a8b7ef5ea2fb0f43dc4114,"The push function would add an item to the back of the vector. This would take a constant amount of time in the best case and a linear amount of time in the worst case ( when reallocation of space is needed).

The pop function would move each item already in the vector down 1 index to essentially remove the first item in the vector. This would take a linear amount of time.

The peek function would return the address of the first item of the vector and would take a constant amount of time.

The size function would return the number of items in the vector, by calling the standard vector.size( ) function and this would take a constant amount of time.",11.0,58
16599,16599,20844,06f90aca60b4b2db0e6d8bb78d0ed0da22ceb02b561b842eee51951b0e04be81e8817f795eb9597349f2e3c12b7befca0ed36322cff788052acb9b91388f1fdc,"push - push will add an item to the BACK on the container which will increase the size by one, the time complexity will also be constant O(1) in the best case. in the worst case, it will be O(n) as there might not be space in the vector so all the items will need to be copied to a new space

size - it will be constant, O(1), as all the items in the queue will need to be counted. this will never change

pop - pop will remove the FIRST item in the container it will therefore be O(n) time complexity as after the first item is removed and all the other items will have to shift to the left but it will have O(1) time if the last item has to be removed as no shifting will need to be done

peek - will always return the 1st item so will have a time complexity of O(1) which is constant",7.0,58
16600,16600,20845,df0d62df6145f98b9d8d85662b958119c20c6015becf9534b762b6d6c7c046d872ff37d4ccc77da23e1570c5a7712fc862bda45087171a56e4c5cfc3750e2ad2,"* push to the back- To push to the back of a vector will take O(1), A Vector keep count of the items and with pointer arithmatic it will find the back and place the item in constant time. O(1)

	* pop at the front- That will take O(n) and after deleting the item in the front it need to copy every item (n off) in the vector one place backwards - O(n)
	* peek at the front - That will take constant time O(1) as by pointer arithmatic it will find the item in the front in constant time",6.0,58
16601,16601,20846,7784c26ab2d9766ae819dd1da89317a98dc39ebd7976e740ed6ab84978a76aaebcecee3ccbfd4bc08a3df68e244abf9916ece7c5f547ed6b7e35d519a43c7259,"to push what I would do is to create a function push that accepts any data type and uses the vector push_back function that is in the STL for vectors, this would be used to add items to the top of the stack. In the best case, the time complexity would be O(1) constant time and worst-case O(n) linear

to pop, I would create a function that uses the pop_back function that is in the vector STL and this would remove the last added item, the best case would be O(1) and the worst case would be O(n)

for peek, create a function that uses the back() which is in the vector STL that fetches the last item at the back of the item and this function will always have a time complexity of O(1)

to size create a function that uses the size function in the vector STL that checks the size of the vector. it also has a time complexity of O(1)",6.0,58
16602,16602,20847,8f8e96eb5a28d15c7802d177c96b97e53c9c9c2a37389d558dc50a5be6ad84289d3986f782da265340d7d86d9d174957d8d67890ddc79dd4587dd919a3bfb09b,"push: to add an item to the queue we add to the back of the vector

push_back is part of the STL and will take O(1) in the best case, but O(n) in the worst case

pop: to remove an item from the queue we would need to remove from the front of the vector

each item in the vector (excluding the first item) would need to be moved one position forward (from position 1 to 0 for example)

O(n) time

peek: we would need to return the value of the item currently at the front of the vector

front() is part of the STL and will take O(1) time

size: we would need to return the size of the vector

size() is part of the STL and will take O(1) time",13.0,58
16603,16603,20848,20a63554bf7ab6e06ce970a9c763f370f49fc1a727f591ec7304c432565faf9d2b891194e01cc67ff029c1fe6de8363ececadce22ee4af544785f47985cda509,"For push function you can use push_back functions - best case: O(1) - already space and worst case: 0(n) - create new vector and copy n items.

For pop function - you can use operator[], pop data[0], because the front is always data[0], best case: O(1) (not wastingspace) and worst case: O(n)  (wasting too much space)

For peek.pop function - you can use operator []. It will always take a constant time - O(1)

For size function - you can use size() - it will always take a constant time. ",10.0,58
16604,16604,20849,f7bbac457e26e926aa83f65c706f322284bcae4a69df367438ec5060865432bf63d2eef51ed308d86119a8e1745e619fe74662cd103d43378e65328b7630ff57,"""push"" would be implemented by traversing to the next available memory space and adding data to it. The best case time complexity is O(1) as you would simply do pointer arithmetic. The worst case complexity is O(n) as if there isn't enough space then you would have to copy over n items to the increased vector. 

""pop"" would be implemented by going to the first item in the vetor and removing it. The time complexity is O(n) as n items would have to be shifted to the left, else O(1) if there are no other data points in the list. 

""peak"" would be implemented by returning a reference to the first item in the que and the time complexity is O(1) as it would be at the front of the vector 

""size"" would be implemented by counting the number of data points filled and will be of O(1) complexity as the data is contigious. ",11.0,58
16605,16605,20850,3227954877ff6b3d6e5d415eabaacb6ee56a5809874f349fcc72cbd6b74b9924802065f3198d52fa435eef46404fa2ce0465698400217a4b7b18ef03d8cc91ec,"Consider the front of the vector to be the front of the queue and the back to be the back.

PUSH

Add the element to the back of the vector using push_back and effectively to the back of the queue. The complexity of this function is O(1) amortised, since in the best case there is sufficient space at the back of the vector which would take O(1), and in the worst case we would have to reallocate, which would be O(n) since n copies would have to be made.

POP

Remove the element from the the front of the vector. This would always take O(n) time since we must make n-1 copies to move all the elements one index forward and pop_back() to maintain n-1 elements.

PEEK

Return the element that is at the front of the queue. This takes constant time O(1) since we always have access to the front of our vector using the vector front() function.

SIZE

The stl::vector keeps track of the size of the vector and thus we can get the size of the queue in constant, i.e O(1) time.",14.0,58
16606,16606,20851,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,"To push, you would simply add an element to the back of the vector. This will take constant time.

To pop, you can delete the 0th element of the vector, move all of the vector elements over by one position and then change the size of the vector. This will take linear time

To peek, you can access the 0th index of the vector. This will take constant time

To determine the size, you would use the length function. This will take constant time.",11.0,58
16607,16607,20852,9b13f2d70694a174cc296db2532a81cde5f414c86e87388e32c45d14a1b85a47b70cc54fdcb2f6455012d569323883da99f34aab409453d8e838e0ae2bf41aff,"when implementing the best case in push and pop  the time complexity will be O(1) in the best case  and worst case will be O(n). and it will be O(1) in the peek and size always.

we would create a class stack which is public which has a void push function which add  items to the stack  and it will be data.push_back(t);

void pop,which removes always operate at the back of the vector and it will be data.pop_back();

the peek returns what is at the back of the vector and will be return as return data.back();

 the size will be return data.size();",5.0,58
16608,16608,20853,c75c72f439ed0a1083505ca2fb274424bfa93184c45c67c47245732cd59fc54e342192b7a0a8538fb3676603ded389cab9a3431e9d476a9d9b140adb5ff30721,"For this queue data type we would implement push() with the push back function of vector, which will be O(1) in the best case and O(n) in the worst case. Pop would be implemented with a pop front function which does not come with the vector class, so we would have to implement it ourselves, possible through using the erase method from vector and then using that to delete the first item this would be O(n) since we would have to traverse the whole list in each scenario. With peek we would use the front() method to access the item at the front of the queue and this would be O(1).",8.0,58
16609,16609,20854,bef6837a7fdfe1da5fe1293f44c76b96d3b8dcc796faa186ced378d3238a30c359695c10ba31e008e6450186def6f4c6da86e1819e6310ac4629db0e4ae2f7c4,"Using namespace std, a vector<Thing> should be declared. From there on you just type in the push, pop, peek and size and the time complexity of these functions will be O(n).",0.0,58
16610,16610,20855,7a27fb1fa642a9bd3d76e8ce98be5e4779f4184eab8b901b0ee0d165d466de6122db493ca631d33ef289f724ffb838136d578f3b72df159667217c69ae154ed3,"For a queue to be implemented with a vector as the underlying storage, we are required to push at the back and pop at the front. Since a queue has a first in first out structure. 

A standard vector class does not have a pop front function. Hence it is not a good implementation.

To implement a PUSH function, we can use the push function that is already in the vector class. This will take O(1) time in the best case and in the worst case, when there is no space and reallocation is necessary, we will need to spend O(n) time on the push function due to reallocation. 

To implement POP, since there is no pop_front function in a vector class, we will need to reallocate each time that we want to remove an element from the front.. This reallocation will always take O(n) amount of time and this is a bad implementation.

PEEK will take O(1) time as there is a front function in a vector. 

SIZE will take O(1) because of pointer arithmetic and the existing size function in a vector. ",13.0,58
16611,16611,20856,f7abd04c97a647b1e757bccd7284173478fbf8f28e28e3102567ab244a63fd5c67a5e953a932ab1f774cb73ace52fda53cdbbded4668ee4660e933d867e532bd,"I would implement push_back in a normal vector method by simply adding an item at the back if there is space available which will take constant time since its a best case,,,,or if there is no space l would reallocate a new bigger block of double the size of the previous one, copy all the n items and insert/push the item thus its a worst case and yield a linear O(n) time complexity.

To implement a pop_front would mean the first item is removed and in the best case when there is only one item in the vector this would take a constant amount of time O(1). In the worst case however the first item in the vector would be removed and a ""hole"" in the first block of the vector would be created and to address this all the last existing (n-1) items in the vector would have to be shifted to the left ,,thus the time complexity of copying n-1 items to the left would yield a linear amount of time.

To implement a size function would require keeping track of every addition and removal of an item which the vector does as an ADT. Thus we would only return n items thereby doing the same amount of work everytime resulting in constant time O(1) complexity.

To implement the peek function would mean returning a reference to the first item in the vector and thus it shall always take the same amount of time independent of the size of the input thus yielding constant time O(1) complexity. ",11.0,58
16612,16612,20857,2639eb56a1989682f1b8fb8c5a3437ea6a5d663be094f02f4aaae47dc57a1af7165cfaae33d61d670e26c96083744d494e42187a468df938459fc0c70030a175,Push would take constant time but if we run out of space it would take linear amount of time. Pop would take linear amount of time since we have to copy each time over to fill in the space that we initially removed. Front would take constant time since we just want the value at the beginning of the vector. Size would take constant time. ,4.0,58
16613,16613,20858,725a0125b367c6f17c35c11b2109d01e495cc98a9983ee64edff98f1e31691682af784e585cb9ffd4450baefac075cf1659b1b9f4409ec665f5bbef7fd4002df,We would push to the back of the vector which would be 0(1) in the best case and 0(n) in the worst case as you would need to reallocate the memory. We would then pop from the front of the list which would be 0(1) in the best case and 0(n) in the worst case. Peek would be 0(1) as its always going to be your first element and size would be 0(1).,4.0,58
16614,16614,20859,b62aa4d567faf4c8c2d7b435cab87c30c9d1e6af89f8a0e3d7867630ef600446840f333742c814bc8a0c9d2f0ab23474abdecc13d41d7312f08a47b7fc5bb67c,"Seeing as though its a vector

push: we could use vector.push_back to add an item to the end of the list in O(1) complexity, O(n) worst-case for memory reallocation

pop: pop would be O(1) (worst case O(n) for resizing the memory allocation) time as we pop the last stack off of the stack frame. We can do this by creating pop_front in vector.pop_front

peek: peek would be O(1) complexity. you can return the data stored at the first node (top of stack). 

size: size would be O(n) complexity. We would have to traverse the queue and adding to a counter when a new node is reached.",3.0,58
16615,16615,20860,833bd82b84984eac1561a2aa471c7fa8ce8fc83eb43410d162adbb99836f9c60ca90f110500d0a4cfae027c10757354954059b39ea510643c3c10d5e8f6e1bb9,"I would do a push_front by myself and add to the queue the thing im removing from the vector.

	* push back O(1) worst case O(n)
	* popback O(n)
	* size O(1)
	* peek O(1)",6.0,58
16616,16616,20861,d5eef99882213e9e893ef6d31b163cddd65b11b328a038af368c63b9dea5c55582d674f73b7f44a7ffb0e808a2c14f224354666b5c8da68a3cf145583cdbcada,"To push an item in a queue we can use the push back function that comes with a C++ vector and the time complexity would be a constant time in the best case and linear time in the worst case.

To peek in a queue we can use the begin or front function that comes standard with vectors and the time complexity would be constant time no matter the size of the queue.

to check the size of the queue we can use the vector size function and its time complexity is constant due to pointer arithmetic and contiguous memory",10.0,58
16617,16617,20862,aba8ccda4763601c960552191c4b4ea7d3e94521d25f84c03f905aac0bf9578acabd1a7e87e98918c1a32dbc6bc0f00b14222dbc9e37a19a4efb13f1c52924d7,"When we are pushing an item, the best case is O(1), this means there is space in the and the worst case is O(n), now here we have run out of space, so we need to reallocate, copy all the items and then add the neww item.

Pop also works in a similar manner, when removing an item, the best case is O(1), but if our number of items is less than (number of items allocatedfor/4), then this become our worst case and it will take us O(n) time.

peek() and size() will take O(1) time.",4.0,58
16618,16618,20863,8f6fce38f378bd03b7e3015540844be6bf9823c5ceeeee423c75e7180e2218c7f9853b96b276e10dcc9cefdaf4b85b6d869df1573ced7bc1eae58f615449e857,"Push: just use standard push_back() function. O(1) best case, O(n) Worst case  

Pop: implement a pop_front() function. O(n) every time

Peek: just use the in-built vector[0] function to get first item since that is the item next in the Queue. O(1) every time 

Size: just use the inbuilt vector.size() function which takes O(1) time. ",14.0,58
16619,16619,20864,0acf933aafd8ccfefdb0a07c9cd769ff21b003c332b8b90f6edffc1573664ade1e2d7b54669b2cee7b03b35091d029450c66d87d0c0afdf5016d3799c57a4fc9,"push - allows users to add a value to the top of the stack - O(1)

pop -allows users to remove item from top of the stack - O(1)

peek - allows users to return a reference to top item - O(1)

size - allows users to return the number of items in the stack - O(1)",2.0,58
16620,16620,20865,3833aa3ef06cafdc78971652ad20444fe164affcf92c03de12570129a147987ae3263043850e741f6f77f4965176d32cb0f7b6200e6f1f08cf0158b373dc6fbe,"The push function would add a value to the memory space next to the last item in the vector. it would use the vector method .push_back(), to add a value to the back of the queue. the time complexity would be O(1) (best case) due to pointer arithmetic allowing access to a specified contiguous memory space of the vector. and O(n) if the space allocated in the vector is full. this is because all of the values need to be copied into a new vector with more space allocated.

The pop_front function would need to be implemented into the vector class as it is not found in the STL vector. This function copies  each item into the previous memory cell of the queue(underlying vector). This results in n-1 copies done and gives a time complexity of O(n). 

The peek function would use the vector method .front() which returns the value stored at the front of the vector, being the underlying data structure. due to pointer arithmetic found in vectors(arrays), the time complexity would be O(1).

For the size function, The vector class keeps track of the size of the vector. we can use the vector method .size() which will return the size of the queue in O(1) constant time as each addition and removal from the queue is tracked and affects the size value stored.",13.0,58
16621,16621,20866,18f6254c7b196766dbebfb4556ef6c2f9ff5e44918d8ea60921fbe90c8a42515b04ace17b80ecdd7f09efd69961a6da2d4a21f100e3ebd5acf67acba7ebaae55,"for push, we would implement it by using push_back function and this takes takes constant time O(1) if the vector still has enough space.

for pop, we have to copy each item one block to the left so that the item at the front is removed, this takes linear amount of time.

for peek, we would use the front() function which takes constant time.

for size, it will take constant time as we do not need to traverse and count items in a vector",8.0,58
16622,16622,20867,12066f8f6a7f4cd1c9586b77b6e85c69168c3e639d8a7cc579d0737f33e85026e0fc0bba1f43d9a6c097e420e073f5dd573d48b38e1cf440a6f948554edb9454,"1. In order to push an element to a queue we can use the vector.push_back  function of a vector. This will take O(1) but O(n) in the worst case when the vector is full and we have to create a new bigger vector and do n copies. Unless we use deque which makes time complexity O(1).

2. To pop an element at the back use vector.pop_back() function which deletes the last/top item only. This will take O(1) or O(n) in the worst case . Unless we use deque which make the time complexity O(1).

3. To peek an element we use the .peek function to check if there elements first, if there are then it then enqueue, if there aren't any the dequeue. This takes O(1) time.

4. To get the size we use the .size function and the time complexity is always O(n).",4.0,58
16623,16623,20868,c2a635a9bcf4ad40fa50102eeb50a8298caf1f43a284d43931e8d6ff78372592382df0d5a087e759cf9a231e99eb6b2b3a8890e03edb12bf9295b2611174eebb,"For the push and pop function, there is already one implemented in the vector class, therefore we can just call that function from vector class, however with a vector, space allocation is a problem and this is inclusive for both trying to save memory (when too much is allocated) and when memory is needed, because of this the time it takes to reallocate memory for the vector causes the time complexity to be linear and when there is no need for reallocation then the complexity is constant. For the peek function, we just need to return the last item in the vector, which is on the top of the stack, therefore this function is not dependent on the amount of items within the vector and thus the time complexity for it is constant. For the size function, we just need to return the number of items in the stack and vectors being the underlying data structure already keeps track of the number of items in the vector itself and  there is no need for memory reallocation so time complexity is constant.",8.0,58
16624,16624,20869,666d09a4d8260961dbb488b896e8680fe46f9012a9bfa6adbe518edfaed179e00538132a0e660a988cc51e3f8b8695b7b78d6679f0a1e7d0f26361ce20a96384,"Queue

push:

We would use a push_back(v) function to add items to the back of the queue ( O(1) time in the best case and O(n) time in the worst case where we reallocated).

pop:

We create a pop_front() function to remove the first item in the queue ( O(n) time ).

peek:

 We would use data[0] to get the first item of the queue ( O(1) time ).

size:

We would simply use the size() function to get the number of items in the queue ( O(1) time )",13.0,58
16625,16625,20870,8988e05f865164f4560af96560c21e55905eac0bb5f61f3d6e278f9698c3b2aef4e2c138e098da5e867aaa523133fd657970eaa9429e994d798d7fd717f54fcc,"To push to our queue that has a vector as its underlying container, we would make use of the member function ""push_back()"" of the vector in the implementation, and because this works based on contiguous memory, the time complexity would be constant - O(1) time.

To pop from the vector, we could reallocate all items following the first item, but this would take O(n) or linear time every time it is called. Instead, we could initialise a variable that stores the index of the first item in the queue, so that its implementation would mean simply incrementing the index variable by 1. This would take O(1) or constant time, but in cases where the pop function is called many times we may have a large space of memory taken up by ""empty"" items. This means reallocation would have to be performed at certain thresholds of empty cells, so the worst case time complexity would be O(n).

To peek or access the first item would take O(1) or constant time as we have a index variable that stores the index of the first variable, and since we are working memory that is contiguous, access time is always constant.

To retrieve size, or the number of items in the queue, we could initialise another counter variable and increment its value every time we call our push function, and decrement its value every time we call our pop function. This way would allow for O(1) or constant time.",11.0,58
16626,16626,20871,afeeaae30229bbf9032ee9948e95a3a98860a874d1b1d0d67ee088b120bc22e9fb34f7eeb7b1df4260a0f1a548b9e0b11d627eaa2a17433f88a21e97dee9550e,"If we were pushing to the top we would use the pushback() function of the vector data structure, and for pop we use the popback() function and for peek we would use back() function and for size we use the size() function. pushback is O(1) in best case and O(n) in worst case, pop is O(1) in best case and O(n) in worst case, size is always O(1) and so is peek.",10.0,58
16627,16627,20872,a0052d1186f3fa53f67763ddf5dc1148fc540657d42f0891ff3ac99ce8c9f5c8c2cc81fa44f5583e909b3bdda1a0f1e6a21067a67ce2ede8b9d60f7eef57955f,"Push: With a vector, we have the number of elements stored. Thus using pointer arithmetic, I would implement a push by simply adding the item into contagious memory at the next available spot. Normally it would take O(1) however if the contiguous memory is full, we would need to copy all the elements into a bigger vector which would take O(n).

Pop: Using a vector I would pop the front element off. Thus every pop function would take O(n) as it needs to remove the first element and shift all remaining elements one down (Sort of how a queue of people would move).

Peek: this would always be O(1) as it simply returns the first element in the vector

size: This would be O(1) as the vector actually stores the number of elements stored. Thus one simply needs to return it. ",13.0,58
16628,16628,20873,e7c9b4fd869eb791a63c71759d17fa7e8a93618d661588fa6ae371946756531c0923d86aafe2bfd7289d74b69cb5fe841e3839957a75e6446f2d8394b4178536,"I would initialise the vector and implement the functions as follows:

Push: I would use the vector push_back function for this as we can only ever add to the back of the vector.

Complexity: O(1) in general but O(n) worst case.

Pop: I would implement a pop_front function for this as we can only ever remove items from the front of the vector.

Complexity: O(n)

Peek: I would use the vector front function for this.

Complexity: O(1)

Size: I would use the vector size function for this.

Complexity: O(1)",11.0,58
16629,16629,20874,74ac16aad9cffebc9a82a3d84552ea746b2a726fb003881a5a45ccd11c8a938caed3d1a49b6f0f3b5bc663c85f99ca3ae1d10cb0f79247d51859bb82beada81b,"To push push to the back of our queue we us push_back(Thing t)...This will take O(1) time and worst case will be O(n) time. 

In a queue we pop from the front, so we use the pop_front operation. This takes O(n) time.

The peek is the top of a queue, so we implement the data.top() to retune the item at the top.This takes O(1) time.

To get size of a queue we first traverse through to the last item in the queue to get the total number of items in the data.This will take O(n) time.",8.0,58
16630,16630,20875,5d0d60194fd1b05c809499adb963afbac0ab800c552d7666ea7779f6183d17839f234e9ecee3ed11e567d9e2e5d5f869bc08bd2cc74894f9ca624282e8055b10,"The push() function would use the push_back() function of a vector. This function is constant, O(1), in the best case, and linear, O(n), in the worst case, in terms of time complexity

The pop() function would use the pop_front() of a vector. This function is linear, O(2), in terms of time complexity.

peek() would use the front() function of a vector. This function is constant, O(1), in terms of time complexity

size() would use the size() function of a vector. This function is constant, O(1), in terms of time complexity",13.0,58
16631,16631,20876,a4513e9eefe06c5d06cd544fbaa5db795547b8f01893c660dc4a8e31a77cbc61bded840bbf0b3fd52a94491adbe0a21a3d4396c46fe19d46198e8b7b21695be6,"we would use push_back which is best case O(1) time, and worst case O(n) time

we would use pop_front which is case O(n)

we would use data.front() for peek, which is O(1)

we would use data.size() for size, which is O(1) because it is a vector which keeps track of the number of items",14.0,58
16632,16632,20877,4c6239f4837a7e4857168ce1d90eccb0590dbff5755d1452f6eced3fa662d6b3d452d78b9021e9f1b0bb440c88d3e31a3396f8ac92fb89f14b2269d4512bdaa8,"For push. We would use the push_back function, which would take us constant time using pointer arithmetic provided that we still have space in our memory buffer. If we do not then we would be required to copy all the items to a new memory buffer which would take time complexity O(n).

For pop. We would use the pop_front function which will always take linear time complexity because we would have to move the items from the second item one space to the left.

For peek. Referencing the first item in the memory buffer would always take us constant time as we have a pointer to it.

For size. Since we keeping track of the number of items we have. Accesing the number will always take constant time.",14.0,58
16633,16633,20878,50ac02db01dc47f0f24bb2a0e8bc1bebe3aac1ecfe652f1c87b260f45da4def0a267392e043e67a0b0f3a39374188322db34615d5257a196fc0978d4d004e1ed,"Push: Queue is a last in last out data structure, therefore for the push function  we will be required to use pointer arithmetic to add  the new item  if the is space .However in the worst case, the function will take a linear amount of time of time and for the best case the time complexity will be constant.

Peek: Peek function will return the reference to the first item and the time complexity of O(1).

Pop: The pop  function will always take linear amount of time because  we to move every item one space to the left.

Size: By keeping track of the number of items stored, the size function will always access the number of items in constant time.",13.0,58
16634,16634,20879,ab914ab560d18c5aef3e43bda3ed23f3106afabfcaabd71fb45ebbdc423746252b1d705ea396aa70f877858829d5c8d335f73b945106c9ea584789a7d7f0ea77,"We will always have to pop and push from opposite ends of the vector since it is a queue. Pushing or popping from the front of the vector will always be linear time complexity O(n) due to moving everything one over. Pushing or popping from the from the back of the vector will always be a constant time complexity O(1) due to pointer arithmetic, unless we have too little or too much space in the vector, then we have to reallocate with O(n) time complexity. Whether we choose the back of the vector or the front of the vector as our front of the queue, the back and front functions will always take constant time O(1). Lastly the size( ) function will always take O(n) time complexity because we have to loop through n items and add to our count.
We will have a trade off always whether we choose the front orr the back to be the front of the qu",10.0,58
16635,16635,20880,c1e9e5684a44aa14de0a7d7593ec9809b4c2858f861776d6d9a8b2df4bba9cc394db455eb7a58c49a19ed6c08dee2a5b9eba1e9f390b469640fea31d4ffda4c0,"We can use the std::vector member functions to implement our push, peek and size functions. We would use std::vector::push_back, std::vector::front, std::vector::size respectively. The push_back function takes O(n) in the worst case, but the best case, front and size all take O(1) time.

To implement pop we would need to create our own function as there is none in the STL vector class that allows you to pop at the front. We would need to create a function that reallocates the memory to fit all the items following the first one, shifted one place forward, and we must not forget to deallocate the original memory. Since in the function we'd need a for loop that iterates through the entire vector (n times or the size of the vector), the complexity of our pop function would be O(n).

In conclusion:

push takes O(1)

pop takes O(n)

peek takes O(1)

size takes O(1)",13.0,58
16636,16636,20881,6398cd3a19a3d471bc5a210dfd041039aa199f2840055e48507502bec88a8f8eb3f128de790430daa8207ba0fde7dea8a8fb8416bcb584e1bb9e76ef88b1e1f2,"1. To push an item , we would use the push_back() function ,which would insert an item at the back of the vector/ top of the stack. this would be O(1) complexity in the best case and O(n) complexity in the worst case.
2. To pop an item , we would use the pop_front function , which will pop the first item in the vector.
this will be O(1) complexity.
3. we would use the vectorname.back function to peek. this will return a reference to the last item in the list.this will be O(1) complexity.
4. the vectorname.size function will be used to return the number of elements. this takes O(1) time complexity.",8.0,58
16637,16637,20882,9723aae78697f512e67589fc396726b9c942a3d3f5596d681f9e90a55d7c7cee67b2655817396577b22474e4f116aa7866389d9d9a43a0c0e1dd45d6998cde32,"The front of the vector will be the front of the queue and the back of the vector will be the back of the queue.

PUSH FUNCTION

Using the push back function of the vector class we can add the value to the back. This would take constant time O(1) due to pointer arithmetic (contiguous memory layout) but will take linear time O(n) if the vector is full because this will require reallocation of a bigger capacity vector and making n copies.

POP FUNCTION

We would have to create our own pop front function which will always take linear time O(n) to complete because we would remove the first element but then we would have to shift each element 1 to the left, essentially making n - 1 copies.

PEEK FUNCTION

We can use the front fucntion of the vector class and this will always take constant time O(1) because we can easily access an element using pointer arithmetic due to contiguous memory layout.

SIZE FUNCTION

We can use the size function of the vector class and this will always take constant time O(1) as well as the number of items are tracked in the vector class",13.0,58
16638,16638,20883,c7d75d976a010a38db71e259afee15ce7c42ba18fa8ef2214021124356299e2bc696f235d69042a2e7d6021b611ee4096167f90988dc7b1e755fca98c40f31fd,"To push an item to the back or add an item at the back of the queue, i would use the pushback function of the vector. In the best case where there is still enough space in the vector, the time complexity of the function would be O(1). In the worst case where the vector is full and it than has to resize itself with twice the size it was before, the time complexity would be O(n) as all the items would have to be copied to a new vector.

To pop an item from the front of the queue, i would implement a pop front function which would copy every item in the vector one place towards the front of the vector. I would do this by copying the items in the vector to a new vector starting the iteration from the old vector at iterator i+1 and equating it to iterator i from the new vector where i = 0. In the best case, the time complexity would be O(n). In the case where there is no item in the vector, the function will throw an error as no item can be removed from the vector.

I would implement the peek function by using the vector's back() function which returns the item stored at the back of the vector. The time complexity of this function will be O(n). 

I would implement the size function by using the vector's size() function and return it. The time complexity of the size function will be O(n).",8.0,58
16639,16639,20884,263fd6b7e81bd2b0bd84f67415866c3d75bf78011a0e0748b552d65d3fb35fc4bf5dca96f9ccb82225afdb2c9f73d9593526bb28fe17ab6d85ae420a8a33d70d,We would add new elements to the back of the queue. If there is not enough we space we will need to allocate more memory and copy n items across. This means the push function has a best case of O(1) and a worst case of O(n). The pop function is implemented by moving every element over by one in order to delete the first element. This means it always has a time complexity of O(n). The peek function just need to access the front element making the time complexity O(1). The size function will be O(n) as we need to traverse the whole queue in order to count how many items are in it.,11.0,58
16640,16640,20885,5b79e321acf32f26a1c6cc9091fa349a8baa70385c6fb736e55b942fea1901b561d1f53857749ead207a2933e580c9dfc66c9af868e9b035d1dff322ef7cd5be,"We take the back of the vector as the top of the stack
Push : To implement push function i  would use the push back function of the vector to push to the top of the stack .Time complexity will be O(1) if space is available , It will be O(n) if space needs to be reallocated.

Pop: To implement pop function i would use the pop back function of the vector to pop the item at the top of the stack. Time Complexity will be O(1) in best case, It will be O(n) in worst case when we the number of items is less than 1/4 th of the allocated space.

Peek: To implement the peek function i would return  using the back( ) function to the return a reference to the item at the top of the stack. The time complexity will be O(1) since the back function of the vector has a time complexity of O(1)

Size : To implement the size function i would return using the size function of the vector.Time Complexity will be O(1) since the size function of the vector has O(1) time complexity.",13.0,58
16641,16641,20886,7f4b419d2ced93d50fb8649f87b2fa3a1ab4c6a1ecc8b63f150aeb372237c21eae97c5eba18c0880eb018ac5d3fb68e9a7180e8af2cbb1d90dc8d7f06f63f097,"for push: I would find the size of the vector and go to the (vector size-1) index and push the item, if there is enough space. it would be O(1).

If there isn't enough space I would resize the vector by finding the initial size and doubling it, then copy the elements to the new allocated space, delete the old one. it would be O(n).

for pop: I would find the size of the vector and go to the (vector size-1) index and pop the element in that index. It would be O(1).

for peek: I would go to the last item and find it address and return it which will be its reference. It would be O(1).

for size: I would introduce a counting variable and loop through every element in the vector, every time I get to an element add one to the counter until I reach the end. This would O(n).",2.0,58
16642,16642,20887,0a1930b4d16e62ac7ee353c6144c568d9ee6c791d0d3632d3ce78fd24bb2c65d328c4924d6cafd1daed9790efaefb16fe2a520125cf9396ef372146945ae0496,"If the front of the vector corresponds to the front of the queue, the push function can be implemented like that of the stack, where an item is added to the back of the queue. The time complexity is O(1), but will be O(n) in the worst case scenario.

For a pop function, a linear amount of work is done as each item needs to be copied over in order to remove the item in the front. n-1 items are being copied over. Time complexity is O(n).

In order to find the peek, return the data at the back of the queue. The time complexity is constant i. e O(1).

Size returns n items stored inside the vector and thus the time is constant, that is time complexity is O(1)",13.0,58
16643,16643,20888,fe62a1f5e7fe2a4e7ab8c966f31166711ff57cc766445f2fc4370a7348f81dab059b866c1f91a4b1ff166d595fb9234d29f7f66b2297a565d84b506f3bd0f6e7,"I am assuming you mean implementing a queue and its functions.

	* Push back : Since we are using a vector Thing, we can use the push_back function from the std vector library. This will allow us to add a value to the back of the queue. It time complexity is O(1).
	* Pop front: The standard vector library does not have a pop front function , so we implement it ourselves. We delete the Thing at postion 0. then we loop for i = 0 to the size of the vecor -1 (using the vector .size function). then we take data at i and make it eqaul to data at i+1. this will take O(n) time complexity since we loop through the whole vector. to be safe , after this function , resize the vecor to size n-1;
	* Peek: to peek at the top pf the queue , we return data at postion 0. Since this value will always be at the front of the vector , it will take O(1) TIME Complexity.",10.0,58
16644,16644,20889,66ba5975b098f5fa2bae0b86dceb6b280b99b8f4c6fff5dafe0a067b8a9153b49a39abe1525261732c63d25886c01c121ff46cf2ab2721a603f04674ea202257,"Push - using push back

	* Because push adds the element to the back of the queue, under the best case it will take O(1) time, however, if there is not enough space and a reallocation is required, then it will take O(n) time as the worst case scenario

Pop - using pop front

	* The pop function removes the item at the front of the queue and will therefore require that all the remaining elements in the queue are shifted one space to the left. This means that pop will always take O(n) time

Peek:

	* Peek simply returns a reference to the item and the front of the queue and as a result will take O(1) time to complete. 

size - using size

	* This will require a constant amount of work as it is a vector and we can use the size function. ",14.0,58
16645,16645,20890,5888307e6e5630e26d91393f9d95b55394aa59f773d80fc5cba42e8220ea74538fd7609c1185eaef557523bfd3715cc3b2307d7a31ddf68499df84fa7da160d9,"push - I would make the push function to always add after the first element in the queue - This will take O(1) in the best case and O(n) in  the worst case

pop - I would make the pop function to always delete the element at the front  at index 0 - this will take O(1)

peek - i would also make this function to only return the first element at index 0 and dereference it to get its value - this will take O(1)

size - from the first element i would make the size function to add 1 after each element and then return the number of items when it reaches the last element. O(n)",4.0,58
16646,16646,20891,854bde56afcd2bd2c31fbe39384369ef7c0ac613a004a4b239a7a7d08872fa336ab049f8f45358abb5e93ca8dfc33e8954bf246487197e2265435ed3c204826b,"I would implement the push function is such a way that it pushes an item to the back of the vector, the pop function would remove the element at the front of the vector. The peek function would return the element at the front of the vector and the size function would return the number of elements stored in the vector. The time complexity of the push function will usually be O(1) but in the worst case will be O(n). The pop function will always take O(n) time and the peek function will take O(1) time. The size function will also take O(1) time.",8.0,58
16647,16647,20892,482f7dae015b4c467d12506c33e2fe66aeff1ddddb85f2c9bce0e0756918b84a46072cd434d5bf20b674533a59b9c793d9d747268246eec497aed1c0f31a1c3c,"push: We would have to transverse to the end of the vector and then add an element to it/end. Time Complexity is O(n) as we have to move down the vector.

pop: We would remove the first item in the vector however we would have to move the rest of the items up by using a loop. Time Complexity is O(n) as we have to copy/move the vector up

peek: We would have to reference the top item. Time Complexity is O(1) as the top is the front of the vector in queues

size: We would have to get the number of the items in the queue, Time Complexity O(1)",11.0,58
16648,16648,20893,17a5fd9d02d6fba8d8046ace71c42e033c0f094c5a424e213efe17ca2b15dcda4339210b67d2e20cb931a5cb55e9b6fb5621dde12a8a5e6da612e051b176b44e,"PUSH 

Add each item to the back of the vector. Best case - constant of time, O(1). Worst case - linear amount of time, O(n).

POP

Copy all items 1 forward. Constant time, O(n).

PEEK

Dereference the pointer pointing to the first item in the vector. Constant time, O(1)

SIZE

Return the number of items stored in the vector. Constant time, O(1)",11.0,58
16649,16649,20894,8ccaa62cbbe76ea20aad42f0abeb4aea6b057f35352db9aef1c4c8bb791949070df63d7ca3789507be754a64de8d3383c759c83cb767d9e10e045b387bce8a09,"I  would implement a push function by adding a value to the the back of the vector , time = O(1)

i would implement a pop function by removing the item at the front of the vector , time= O(1)

i would implement a peek function by returning a reference to the front item of the vector , time = O(1)

same applies to the time function",6.0,58
16650,16650,20895,336c0de60905df4ae163484013b5cc72929683b64ebae6f69a61ca7bbc767084419ba7cf9291246a9b63bc7e686a397f48c33976b41fb34999f9b50eee045aba,"-I would call  the push_back function provided by the stl :: stack which takes constant time to push and in worst cases it takes linear amount of time.
-I would call the pop_back function provided by the stl:: stack  which takes constant time to pop and in worst cases it takes linear amount of time.

-I would call the back function provided by the stl :: stack which returns reference to the top data in the stack in constant amount of time.

_I would call the size function provided by the stl:: stack which returns size of the data in constant amount of time.",7.0,58
16651,16651,20896,be6529d2c60e9c3e44398e6d6378522b796199a001be8bd7e7bf876610ef85fd8204961bc4cabc5a2506d1dd5b074658c765a8f7b3311d9493c6efa1d870167b,When implementing the functions i would keep track of the top of the vector so the whenever something is added (pushed) I add one to the top or removed (pop) from the top i would decrease the top by one. When push function is implemented i would use vector[top+1] which will be the used to add the new pushed item so the complexity would be 0(1). When implementing the pop function i would decrease the top by 1 and then remove the item next to the top which would be vector[top+1] will be removed and it will have the complexity of 0(1). The size function would be implemented by having a variable that will keep the track of the size as it will be intialized to 0 and as push function is used one would be add to it and if the pop function is used then the variable would be decreased by one and then the variable would be used when the size function would be called so that would have the complexity of 0(1). The pee function would just print out the top variable that we have been using all this while to do the other functions where used top for vector algebra so the complexity would be 0(1),6.0,58
16652,16652,20897,2c32439612d29606cd7276c7d7327878252b82b353a0e5c5a38f508a89318428edb5d433b571f4ed85a8cddd2dbf4c9c5eb5b82d38c65addb4bffc9179a95b21,"A push function could be used as it is normally in stacks.It would just be added on the top of stack or queue in this case. This would take content amount of time, O(1).

A pop function would require the reversal of the whole queue and then the pop front function could be used. After this, the whole queue would need to be reversed again. This would take a linear, O(n) amount of time as the reversal would depend on how many items are in the queue and the pop front function would take constant time, O(1).

The peek function would take a constant amount of time, O(1) as it requires a reference to the top of the stack, or the back of the queue each time.

Lastly, the size function would take a linear amount of time, O(n) as it requires a traversal through the whole queue as each element needs to be counted. Thus, it would be dependent on how many items there are.",9.0,58
16653,16653,20898,db2da6294f4863255b8e851f3219cc1d358a9a52af31fcce04dfd21a77bd1b6105ebfb54ad3aa0cbea5dc9fb93c67b5af9e1ff40b17fbd626a20ad3636813679,"for the push back function we will use push_back and the time complexity will be linear.

for the pop front function we will have to replace the n with n-1.

for the size function we will have to return the size using the data.size

for the peek we will just return data.back()",7.0,58
16654,16654,20899,c0b5209a0b10c8dcfcb6cf4b7392c868a8a0f46868d7ead3603a66886d165a2ffbe1f975845aa3417da4caad2884f87961b388a20ee21c66a3e2d9cec38ed42f,"to implement the push function with a vector underlying storage, you would have to use the push_back vector function which will add a new vector to the array at the end. O(1)

the pop function would use the pop_back funtion which would remove the last element entered into the array.O(1)

the peek function would use the front function as it returns a reference to the top value in the stack allowing you to view it.O(1)

the size function would use .size which returns the integer value of the amount of elements in the stack.O(1)",6.0,58
16655,16655,20900,9a6d2e6e6e0c1b575d6fd6f9cd31a3d7ef05b9fbb8f9b527d2f24c66326f4e25fb885d747e3511e370820c0e5c65531a52fb8637b76c7b43895037c2420cfc80,"For push function I would add the element at the front of the vector.

time complexity would be O(1).

For pop function I would remove from the front the vector

time complexity would be O(1).

For the size function I would have to traverse from front to back of the vector

time complexity would be O(n)

For the peek function I would return a reference to the item at the front of the queue

time complexity would be O(1)",5.0,58
16656,16656,20901,cb120576f9fc254cce2a2bdcc2fab8a2f95f1ad24a5398cde6a97bb68344852b25ff6ddb6448c5c344141e6c8f5ee1dd504e841ca984819c02a7811908c51bc8,"Pushing to the back we would just use the ""push_back"" function of the vector which will mostly be O(1) constant time and be O(n) time which is linear time in the worst case scenario.

Popping at the front will utilise the ""pop_front"" function of the vector which will mostly be O(1) which is linear time but in the worst case it would be O(n) which is linear time.

Peeking at the top will utilise the ""back"" function of the vector which will always be O(1) constant time.

Getting the size will require will constant time O(1) using the vector's ""size"" function.",13.0,58
16657,16657,20902,5dcf09a63d08f8fcf484a27b8188aca8e05117584de8c4c8e580d2681056a972e8271fbb1e9e69a616d3a8d13ef9009ce7fbd4e4c680807f0aa62ce637934a9e,"push 

we would use the push back function form the standard library. This would take O(1) for the best case and O(n) for the worst case 

Peek

We would use the std front function. This would take O(1) time .

pop

we would start at the first element and go through a for loop to the size of the vector. We would set the current element to equal the value of the next element. After the loop we would set the last element to a null value. This would take O(n) best case and O(n^2) in the worst case  ",6.0,58
16658,16658,20903,efe8bbe0531a8edbaeccdc4f50ad7d19da4ae088aef554a1013cb2ff8b78ba31a24fa0e8f957d84b8c738910275c42c68da1550413f3ef77aa9c38fb88257b54,"To implement a push function, we could make us of the push_back() function present in the underlying vector data type. This function would access the memory location at one position past the last item using pointer arithmetic and then, provided there is still space, insert the new item at the end of the queue. However, if there is no space available, we need to perform a reallocation to a larger block of memory by copying all our already-present items over before adding the new item. Thus, 'push' would take O(1) time for the best case and O(n) time for the worst case.

To implement 'pop', we could make use of a custom pop_front() function. This function would copy every item over to the left (e.g the value at position 0 is assigned the value at position 1; then the value at position 1 is assigned the value at position 2... the value at position n - 1 is assigned the value at position n) and thereafter pop the last item in the queue using pop_back(). Following this logic we have effectively removed (popped) the item at the front. At best, 'pop' will take O(n) time because we have to copy over n - 1 items, however at worst 'pop' will take O(n^2) time since we may have to reallocate to a smaller block of memory once the vector is less than a quarter full after calling pop_back().

To implement 'peek', we would simply return the value at the front of the queue using the .front() function. This would take O(1) time since we can easily find the location of the front item using pointer arithmetic.

Finally, to implement 'size', we can make use of the already present .size() function which would return the number of items in the queue. This would take O(1) time.",14.0,58
16659,16659,20904,f568f900863758606ecd596c211921a4e2f0720e3778a3f2c91b74ff667248e8a2d4bcea0036dc07a6e043d08d7d7b64e5934aa3ba779587a955877ff84bfb17,"For these functions you would use the c++ standard libary and use the standard Vector functions.

push:  

You would use the Vector ""push_back"" function. With the time complexicty  being O(1) or at worst O(n).

Peek/pop at front:

for these functions you will need to code them yourself as they are not member funtions of C++ vectors. You will need to use the ""front"" fiunction and delete the front item and then shiftt all thw elemnts in the list down one. therefore the time complexcity is O(n)

Pop back: for pop back you can use the C++ vector standard libary function of ""pop_back"" The time complexity would be O(1). 

Size:

For Size you can use the c++ Vector standard libary member funtion of ""size"" and the time complexicty is O(1).",10.0,58
16660,16660,20905,0bce68d12d4bb423184167950cec8450c2529233502545e57429beb9cfc6f093c786ba9febad285f8197b7bbc233a3b506a933f196c9852e05b5416cd8c68c8e,"push function you just add to the back at the vector .In the best case the vector has space and this will take a constant amount of time O(1) and if the vector is full we need to reallocate memory and this will time a linear amount of time O(n). 

pop_front function copy every single over by 1 and this will take a linear amount of time O(n)

peek function look at the item in front O(n)

size this would take O(1)",13.0,58
16661,16661,20906,ea2a1bfcbe729f7621c917f77c54d68d14594e336635f36baf52750af4fc628657adce12683b4083425f0f9b883a0f335d02fe57cab5815e5cb77320840dd672,"To push we would make use of the push_back() function if the front of vector is the top of the function - This would be in 0(1) time since the amount of time it will take will be the same no matter the size of the queue and 0(n) in the worst case if there's no space.

To pop we could implement the pop_back which would also be easy since the back of the queue is instantly accessible therefore this would be 0(1) in the best case and 0(n) in the worst case.

To peek we would need to traverse the queue until the end - this is 0(n) since it would depend on how large the queue is

To size() we would need to travese the queue with a counter to find how many items are in the queue therefore it's done in linear time 0(n)",6.0,58
16662,16662,20907,b722c8fd9eec42aa602e4cbd2ceee62645727f2b19607bd1bed826053b9d70a2c8e8d845bbe5119d6c5e8f3413efde7438ae5ec2d12a60cf1215dd59daf4a367,"For push: If back of vector is top of stack, then would add the new data to back of vector. In the best case this will take O(1) and worst case would be O(n).

For pop: If back of vector is top of stack, then would remove data from back of vector. In best case this will take O(1) and worst case would be O(n).

For peek/top: If back of vector is top of stack, then one would access data at back of loop. This would be O(1), as one just need to access number of items minus 1.

For size: One needs to access number of items in vector, therefore it will have a Big-Oh notation of O(1).",11.0,58
16663,16663,20908,d7dfb51332e1c950aa433a238f3273834b82e31a54a773c512e9c88094b5b27c10ba7527d092402ee28c450551c97d4efc1d9a6fab4f18a9a6df9f32cd052165,"call a stack class that's public and a vector class that's private and call the push, pop , peek and size function.

push-O(1)

pop-O(1)

peek-O(1)

size-O(1)",2.0,58
16664,16664,20909,16f09d60ea55f541a3437e3e2ab8e9c69f838f50f98dec712996c73779cd9f654e7fa72007ae7a3b8d9cb813c8fad8d686dc40ba57c222e292c85b1a88fc8b53,"pop is contant time O(1) in best case and O(n)  in worst case

push is O(n) - moving everything over by 1

size is O(n) 

Front is O(n) ",3.0,58
16665,16665,20910,20820f051ab9e7b5dde112869be67e2e49734267d017f30c8e3086343a31575407d74708ebc5d385e1b1a34dd7dd81fa4425af4e6cb2bbdba32928c419b4a8da,"-Time complexity is O(1) for all functions

- we will push items to the top of stack which is the back of vector. time complexity is O(1)

- we will remove or pop from back of vector or top of stack . time complexity is O(1)

- we will peek by traversing through vector with time complexity of O(n)

- we will check size by traversing as well with time complexity of O(n)",0.0,58
16666,16666,20911,936024d8e9328998a220b77c48098f57a0d619263f7c2ad0ac4157dfe9370e11abee7f579d65a28c46224757256e636c01fe798d4c5eb4d7e1574b7de8511fbf,"A queue is FIFO

-The pop functions removes the front element or the item at the top. Time complexity is O(1)

-The push function inserts an item at the back of the queue or at the bottom. Time complexity is O(1)

- The peek returns the item at the front and peeks by traversing through a vector. Time complexity is O(n)

- The size will be checked through traversing. Time complexity is O(n)",2.0,58
16667,16667,20912,18821a50a643c1101d4d4b4a20eab092e9ef83d83d66cc8b476254122713205813222ecc2114e01a4fff80d19f68cc23c5bc386f899d5730224a2f35e7ae4a2c,"push will use the push_back function of the vector and it's time complexity will usually be O(1) but will be O(n) in the worst case

pop will require us to move every element to the front by 1 cell starting by making the first element be equal to the second thereby overwriting it and the 2nd equal to the 3rd and so on. It's time complexity will O(n).

peek will simply be implemented by using the front() function of the vector class and will be of time complexity O(1).

size will simply use the size() function of the vector class and will be of time complexity O(n). ",12.0,58
16668,16668,20913,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"I would implement:

Push by adding to the back of the vector and the time complexity would be O(1)

Pop by removing from the front of the vector and the time complexity would be O(n)

Peek by returning a reference to the front item and the time complexity would be O(1)

Size by returning the number of items in the vector and the time complexity would be O(1)",7.0,58
16669,16669,20914,3dc26b747d97da3ab4afec05ff58fc24d9456624d1de4e773000cee11c5770c4305e55aba8a358eac1e51ad690a762f5e637a6ce6a5554139fe18ecd7662a5af,"Push: we would insert a new number at the back of the vector. Best case,will take constant time O(1)Worst case, will take linear time O(n) 

Pop : we have to make the first item to be equal to the next item, then delete the last item it will take linear time O(n) 

Peek: Return the value of the last item it will take constant time 

Size : Return n_items and it will take constant time O(1)",7.0,58
16670,16670,20915,c33667ae11b7bded2337c08d116fa497bbbd12dbb6b1affa7fb94c650c68ba165865aab5e81895db475a23ff725c4bc69da22573104a9522dcaf9138fd9b447c,"Pop, size, peek and push operations will all be 0(1)  time complexity. ",2.0,58
16671,16671,20916,17af69de9b004cebc772407eb454a4695fd215d61e6315c9d12ef0dd3a08b8a8642b4cc8dfc787e7755ff0571045a1730ffe50dbf1069009256ea87e870d4fed,Push can be implemented using push_back which will have in the best case happen in constant time and worst case in linear time when the vector needs resizing. Removing an item from the back can be implemented by removing the first item in the vector which in the best case will happen in constant time and worst case is linear when the vector needs resizing. Peek can be done by referencing the 0th item in the vector which will always be constant time. Size will always be constant time and can be done using the size function.,14.0,58
16672,16672,20917,c4c2c137f4d09a740b1294afb17fe688d9891bca471136eebcbf46a7f61b0527136ab092a90608b5c573cd06db378a8bca203b8fa5cda62d61e93ce21bb7a858,"I would assign a head pointer to the front item and a tail pointer to the last item
When I push, I'd use the push_back function which will use the tail pointer to go to the end of the list and insert an item, and this process will take constant time.

When I pop I'd use the head pointer to point at the first item and the use the pop_front function and this would take constant time

When I peek I'd use the tail pointer to the return the value stored in the node where the tail pointer is pointing and this would take constant time

When getting the size I'd traverse all the way through to the last item with a counter and this will take a linear amount of time",3.0,58
16673,16673,20918,01414e21ecb9a1334890023f94a0d282ee23097fe9f9524ae17a5a130cb936a59877f182817dee70cef409eabab63c6b47a25ed1ae4ef0dfef7f2566f253e2b1,"push: Because vectors are a fixed size ( very similar to arrays), the best case scenario is that the vector still has space for another thing to be added to it. We would then just add this new thing to the back of the vector (Time complexity: O(1)) 

Pop: Removing the first item at the front of the queue would also result in a time complexity of O(1) because the in a queue, we remove items in the order they arrive and since we are removing the first item, it will always take a constant time regardless of how many elements are in the queue 

Peek: Because the peek function is implemented at the front of the queue and a vector allows for random access, the time complexity of O(1) because you can access any value in the vector independently of the others

Size: The queue has a counter that automatically keeps track of the number of elements within it so getting the size is as easy as just calling the function so it returns this value, Time complexity O(1) ",7.0,58
16674,16674,20919,a0053c94d18ea0e087a62013f5ac80c5b6b5b2b0c4aa9dd88e21096fafa1947351de1bc64c5f102a231a8bd4d8d7cf40acc72747f50d8fe1ae800f7aa85e0eed,Push and pop will be constant in best case and linear in worst case .,2.0,58
16675,16675,20920,1d469feec8dabc8efe190b91bf2431897a77efbd16b2d85bdc6124d89beaeb95e4c3d1758db03e27ba5dac6295ff2b30f3eaaa927d0748ab45ecd18c4991abfb,"Push - use push_back of a vector complexity is O(1)

Pop - use a for loop to loop over the vector and each time it loops it takes the thing it's at and copy's it in the previous index and when it is done, use pop to remove last element, complexity is O(n)

Peek - get element at index 0, complexity is O(1)

Size - use function size of the vector complexity is O(1)",14.0,58
16676,16676,20921,5ad20b3b420c21e1fc2861df4f4257210672d867b8a024855b258388d20148643f1a94c77f0aa2d4b47f8fba4b85741287207442ff519080915f15fdfd0e21b1,"peeking at the front would require us to use indexing/pointer arithmetic to return a reference to the first item in the vector. This would take O(1) time.

Popping at the front would require us to remove the first item in the vector. In the best case, this will take O(1) time and in the worst case this would take O(n) time if reallocation is applied to the vector to reduce the size allocation.
the push back function would take O(1) in the best case and O(n) in the worst case where reallocation is required.

size would take O(1) time cause we will return n_items (a variable stored within the vector) which keeps track of the size of the vector.",11.0,58
16677,16677,20922,0fd0096c1497543ca0003b9e3ba007221cbda2328585a2f2260277e1c7038bb2ae7ad23e03908936421523651b3b5785ece380b977ac663ea4a02a050d012617,"a queue follows the Fifo (first in first out ) principle so to implement push you  to the back of the queue and pop, you pop at the front  of your queue .

you use the enqueue operation to push enqueue(int x);

you use the dequeue operation to pop dequeue ();

to return the size of the queue you use the size ( )

it will return the number of elements in the queue.

peek operation returns the front top elemenets

complexity its constant O(1) to push and peek

and its linear  O(n)  to pop",8.0,58
16678,16678,20923,e81419dfc1d9569cd33a892060afd65b53683380b098be177940b37177a69388dbc26f4b88ae9117e614069eb6d29407e325e18a19fd38be90fa494f6adff772,"For a stack using vectors as the data storage, we would take advantage of the vector's properties of push_back and pop_back to push and pop from the array. So to push a value onto the stack we would have to call the push_back function of the vector and pass it in the value that we are pushing at the top of the stack. This in the best case take constant time O(1) when there is space to add the element and in the worst case it needs to reallocate hence requiring O(n) linear time. To pop from the stack we would similarly call the pop_back() function from the vector and in the best case it takes constant time O(1) when reallocation is not needed and in the worst case is linear O(n) time when reallocation is needed. To get the size we simply return the size of the vector which is done in constant time O(1) as it is stored in the vector structure. To peek all that is done is we return our vector_name[n.items - 1] i.e. the last item in our vector which is also done in O(1) constant time. For the Queue what we would have is to push_back it would be very similar to the stack where in the best case O(1) where no reallocation needed and O(n) when reallocation is needed. To pop we would have to pop_front. There is no such function in STL vectors and we would thus have to delete the first element and then move everything over one spot. Thus it always requires linear time O(n). To peek is constant time O(1) as we would just call the first element by calling the front() function. Size would be constant time O(1) as we keep track of the amount of items in the vector.",13.0,58
16679,16679,20924,a0a0e3863f2cfe81dc13120d1d5fb28060efbca078cff0afc0ca4a53755acf909a3b28053a432d02251e8d53776e3aedf7eeff75f48fc36029b0d4fb7d46aa25,"In order to implement push, I would use the push_back function. This function uses pointer arithmetic to access the last Thing in the vector and then add another Thing after it. If the vector has enough space, this will take O(1) time. However, if the vector does not have enough space, all of the Things in the vector will need to be copied over to a larger vector and only then can we push_back. Thus, in the worst case, push would take O(n) time.

To implement pop, I would use the pop_front function. This function removes the first Thing from the vector and then moves all of the remaining Things one position closer to the front of the vector. Thus, pop will always take O(n) time because of the need for copying.

For peek, I would use pointer arithmetic to access the first Thing in the vector. We would use the front function of the vector. This function would always take O(1) time.

To implement size, I would use the size function. Vectors need to keep track of their size, thus accessing this value would take O(1) time.",14.0,58
16680,16680,20925,640080dea627eeb31a3d305d032f6df57a0ee21da5dcbd20ff6bbe259d5ca01d650ffa6e7bab08f963664be0fe5ab3d7fb527ab7ad27b3354df44960876962d7,"to push to the back we'd have to create a function that pushes front (using push_front) at the vector, because there are n copies made and one insertion than the complexity would be linear O(n) ",1.0,58
16681,16681,20926,92791654d3cd52922c5b338b34156b28fe55a4ccee1e7fc5905b97888cf317c2fcae873ea940af535130a211df4483d7fb93e8718b1976f9cc9aa146daf834aa,"time complexity 0(1)

push adds to the front of the queue, pop removes from the back of the queue while peek just accesses the element at the front of the queue  ",2.0,58
16682,16682,20927,56a9cf1853b1b03dca807886ec22074eec556b57734ef74dfe3d7a5ab906dc06e5ed46d46913780a3ebae603d6d67abd6ba7c9bc3ba254a5ffca3a3c25744144,"When you implement push, you add an item to the top of the stack, then the size of a stack increases by 1. If the stack is full, it is considered to be an overflow condition. 

When you implement pop, you remove the newest item in the stack, which is an item in the top of the stack. The stack size then decreases by 1. If the stack is left empty, that is then considered as an underflow condition.

When you implement the peek function, the item at the top of the stack will be returned.

When implement the size function, the code will return the number of items in the stack.",0.0,58
16683,16683,20928,55ff8d4f9ee8af9848a55dc4a2a3322adb850c959c61827806d583f4f72e4caf8076da8ae41627b21a0edd1eccee2cd496b303fbcb256d41e8ba6c3b55c02e66,"push - O(1) push to the top of stack of the data structure

pop - O(n) traverse through the data structure until you reach the element

peek - O(n) traverse through the data structure until you reach the element

size - O(n) traverse through the data structure until you reach the last element while keeping count through each traversal.",0.0,58
16684,16684,20929,67bc8fffe61d28188b3d7107d51be90441e6dd51c98f3db877749a2a97847646dc952b6812856f170fac011bfccdf49477179e4f3e8c4e51b5aea238df99b414,"Push: use a push_back function which will take each value entered and push it to the back of the queue.The time complexity will be constant O(1)  if there is already space allocated ,the worst case will be when there is no space allocated then time complexity will be O(n)

pop: use pop_front function which pops the value/object at the front of the queue when called.The time complexity will be O(n) because after popping the rest of the objects will have to be reallocated

peek: use front() function which will return the value at the peek of the stack.The time complexity will always be O(1)

size: use size function which returns size size of the stack .The time complexity will be O(1)",14.0,58
16685,16685,20930,d2c94c0dca7decb41292af9de73a32afa110cab818c0e296b000bfe9dd7b6bf221a0332e01f53ce869a1f4affd4abbea90b7e61d9504a5178a430b94bbde20af,"To implement push, you would use push_back(item) with time complexity O(1), but in worst cases, O(n).

To implement pop, you would use pop_front() with time complexity O(n).

To implement peek, you would use front() with time complexity O(1).

To implement size, you would use size() with time complexity O(1). ",11.0,58
16686,16686,20931,936c1ec869d8f0942d3b84b8b6c320188374f7b930016464dda43168d457286fd222e445f17b63344d55d3ca25f550407692016dc54317e807a5e1c9658269bd,"VOID PUSH(T)- ADD VALUE TO THE BACK OF THE QUEUE.0(1) .

VOID POP-REMOVE FROM FRONT OF THE QUEUE.0(N)

T & PEEK OR T&FRONT -RETURN A REFERENCE TO THE FRONT ITEM.

SIZE_T-RETURN THE NUMBER OF ITEMS IN QUEUE",7.0,58
16687,16687,20932,7c939bb7eae30ac9fde6bed7ba91e751cb79bad249785d6c36230c4d9e80b55aaaf08d983990b398d630a07852718c75269fe0b377bbd248cf1db616b416f57e,"When using a vector;

For our PUSH function, I would simply check if we have space in the vector and if we do I simply just add it to the back of the vector which will take constant time, if there is no space I would have to first reallocate a new buffer and copy all the items across and then add the new item at the back. and then increment my counter(NUM+1) of the number of elements stored thus far.

O(1) and in worst case O(N)

For the POP function, I would have to copy each item to the left(one index less) and then decrement my counter(NUM-1)

O(N)

For the PEEK/TOP function, I would simply return the element/reference to the element at index 0.

O(1)

For the SIZE function I would simply return my counter(NUM) which I would have been constantly updating during push and pop.

O(1)",13.0,58
16688,16688,20933,4ee5c3f6edd0831bd10d63a696f6638df5b754a34f97686d41e648c7e383b2fbf2f7080c3b7f108b718723955a3e61137ab00a8d8d64c8fb5453ee8eef444085,"* to push an element on the stack, we use push_back
	* to pop an element off the stack, we use pop_back
	* to retrieve the first element of the stack we use pea",1.0,58
16689,16689,20934,562a79f866657142ac8bf9d260020a41dd948177d2bce6c88383e228d52056cf2d2544e838847e98137352689514e6b5fccb58b9b8779b353c6c283dfc7313ad,"Using a vector and considering the back of the vector as the front of the stack.

push in the best case would be O(1) since no copying will occur and only pointer arithmetic will come into play wheareas in the worst case where we have to create a new buffer and then copy all of the elements into the new one which has a bigger capacity and copy the element into it would be O(n) since n+1 copies are made.

for size we could have a size_t n member which keeps track of the number by incrementing or decrementing as required when either push() or pop() is called,this will make our size() function to be O(1).

our peek functions will alwasy be O(1) as it always return data[0];

the pop() function will always be linear as a new buffer has to be made and then n-1 copies starting after the second element are to be made into this new buffer,",14.0,58
16690,16690,20935,6a787853e1f57b2d3b0d74f5ae62b179adb7413dd588b37a8f7082bdd65e471590c4f39498c937e59e73bcf33962fea95df098117d05b73852f11db547a99d9b,"-in a queue elements are pushed into the back of the container in our case the vector taking a complexity of O(1)

-also elements will be popped off from the front taking a complexity of O(1)

peek =O(1)

size=O(1)",4.0,58
16691,16691,20936,1d906c438dbb2a0adc2a7e04ed6b3c53c2ee28b5c43a5e83e583d5199a13a7bb6abb74579e2679fb4b6602b8efe2849ab290c6db2b1f573c02a4880312c09f25," we would create a function for pushing at the back of the queue (void push(Thing t))

 This would take O(1)

Then create a function to pop (void pop()) which removes the value from the top

 This takes  O(1)

Then peek (Thing& peek()) and return the value of the front item which would also take O(1)

 Then get the size of the stack which takes O(1)",10.0,58
16692,16692,20937,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,"Using the vector  to push to the queue I would use the push_back() function which would have time complexity O(1) in the best case annd O(n) in the worst case scenario because we would have to relocate the whole vector

for popping i would use the pop_front() function which has a time complexity of O(n) because we would need to copy all items to the left index of their current location 

for peek I would use  data.front() which returns the first item in the queue and its time complexity will always be O(1) because it does not matter how many items we have in the vector

for size i would us size() function which will always take constant time so  the complexity is O(1)",14.0,58
16693,16693,20938,6ce5c22e2014cf62c3f9857f1a5d029cd8403915d5de52ffef745d92a330418a129b81b3d1fc019ceb103f7414cb06b86a44ab05670ba63e692007c026c9822e,"implement push_back which would take O(1)

implement pop_back which would take O(1)

size - O(1)

peek - O(1)",2.0,58
16694,16694,20939,5f92eb6a07aed01e019162660614241903fd30335dc49cd736d18a97a0b8e4d8d8eaa7a31ce7cb8ad65e895e5a8906b98d2e7635d42d019af72333c76c35da1a,"With the vector, we would use the pop_back() function, access elements by their index. Their time complexity will be constant",0.0,58
16695,16695,20940,a09890d1b445c23fabb578b3483b14013fc02062f1b3aa1b4c6df4bdeb9b3b91a9c90e4c472aa2da65ecaa5b831c0625b91b1940398021966ddfe90195c5216f,"Pushing into the vector Thing will require O(1), the pop funtion will require O(n)> the peek will aslo require O(1).",2.0,58
16696,16696,20941,414c0211baa0f7785fed3a2ae8d654438eeb57e32a72d726d41fb80a14e5bb82594bc148b341e170426f496146bb1f57723f178ed8b08e3a2a9402960a0201df,"Push would have a linear time complexity, pop would have a constant complexity, peek would have constant complexity and size would have a constant time complexity. ",2.0,58
16697,16697,20942,22140328599cc90e71d5de22898862c3b0e2dd7b2d6733a618551afede59cd91597d571fd42b02414ce2cee43da486638d6f616c5d08e161d9d14ea8e7479b0a,"-push: we are adding an item to the back of our vector/queue so we will take constant time O(1) in the best case which is when we have space but it will take linear time O(n) when we run of space and need to reallocate which will be our worst case.

-pop: here we need to copy each item one over since we want to pop from the front and then we can call our pop_front function, this will always be linear time O(n)

-peek: this will always be constant time O(1) since it is just returning a pointer to a value

-size: here we are just returning a value so it will always take constant time O(1)",14.0,58
16698,16698,20943,2238995f0ead9a3412ecc8b42340b20d5862bf47d5493b0c9fbe94b4e46ffb57c2cf52b4dd296cee7b6850d8a44e160d6bd1d96e80ab144e928044e44043acc6,peak/pop has time complexity O(1) while push has time complexity O(n),1.0,58
16699,16699,20944,d262858bac7cd6476e0cd48b8622c751312997fe7fae4adba9c98bf17ceadac187d9de2b401de3d1895e85edc24940f00a102bf214f436104f37cd1b8669240b,"With push, I would use data.push_back() because the best case is O(1) and worst case is O(n).

With pop, I would copy the values to the left to pop the value that is in front. This is O(n) no matter the size or memory allocation of the vector

With peek(), I would index the first item by ""data[0]"", which is constant time O(1) because no matter the number of items are there or memory allocation, this would still be constant time. 

With size(), I would use ""data.size()"" because no matter how much memory is allocated it would still be constant time O(1).",14.0,58
16700,16700,20945,07076ad9a7e3813bce19a739ebedaab894d1a330269763e0925227d8822b601591c19afe0ea5ecf81637c9b73f442db6cacafab2329d262fef0fb68d97bef78a,"a queue uses a first in-first out method, the push and pop functions will have constant time O(1) because we will always push at the back of the vector and we will always remove at the front of the vector",2.0,58
16701,16701,20946,6accb08d7786944c71cd9b921787862856d4a3c42592fbffde311b7d0b92a8f983d0c4f430c2af6d29dc0b77bc121c3af33f1ea64f2b5de47c11c3122369896f,"I would implement the functions inside a stack class and the push and pop functions would be implemented by creating functions of type void that will have a parameter of the thing vector. These functions would be able to push values and pop values from the top of the stack i.e. Last In First Out. Peek would be implemented by referencing the top of the stack and size would be implemented by referencing the size of the stack. The push and pop functions would then be used by referencing push_back and pop_back, 

For both push and pop the time complexity would be O(1) in the best case and O(n) in the worst case.

The time complexity of both peek and size would be O(1).",3.0,58
16702,16702,20947,dc654a3d0a49a8045440d0a47a162366cb8c5b30f1fbfe16fd058e7bee5d840a459b70ea1468db1f0ce164b7af14bedf02e15cd2f876678ba6f0d0d5502b4093,We push to the back of the vector and pop from the front of the queue by erasing the item at the front and it will result in a time complexity O(1),2.0,58
16703,16703,20948,c66e418bde3624775409174d439f8c7a104e4c741d28aa9a32d3dff6f27ee3fc70a6b61ca496d004e7124e5afeca9e6a74cf0455c76878d506978153185a8efb,"There will be push_back, pop_front, size and peek functions. Push back will be used to add a Thing to the back of the vector and to make sure what is added first, is removed last, a pop_front function will be used to removed items that are at the front of the vector. Both the push_back and pop_back functions will have best time complexities of O(1) and worst time complexities of O(n). The peek will give information about the item at the front of the queue and will be done in O(1) time and the size will give the size in O(1) time.",8.0,58
16704,16704,20949,4a10096efbe473298c3ffaa590c64747a3f122d6138157d16b669b6d6757b1ee312e247b5d7de57197c1100b67d525e21d2bdf5719b1e5397849be3138642057,"To push, we'd use push_back, which is Best-Case O(1) if we have enough allocated memory, and Worst-Case O(n) if we have a small amount of allocated space and will have to reallocate..

To push to the front, we van add that item to the front, the reallocate the rest to the next item over. If there is no more allocated space, it'll have to reallocate to a new vector with double the space. It will always be O(n).

To pop the front item, it'll remove the front item, and copy the remaining items to the previous one. Time Complexity O(n).

To pop the last item, use pop_back, which is Best-Case O(1), Worst-Case O(n).

To Peek, we use top(), with is O(n)

To get the size, we use size() with is O(1)",7.0,58
16705,16705,20950,0a640b06ce1d454be947795a6308fcfcc73f66b49b60199788f434bf91f3e08719c4b7dee42514e49b76fea543dcbe6b2a18d9de0cfa87cc5f82c989cd2f76ff,"Push function -
Implementation would be to call the push_back() function of the vector

O(1)

Peek function -

Implementation would be to call the front() function of the vector

O(1)

Size function -

Implementation would be to call the size() function of the vector

O(1)

Pop function-

Implementation would be to write a pop_front for the vector, that is to shift every element in the vector except the first, to the left.

O(n)",13.0,58
16706,16706,20951,c6919e466976b48c2f7b3823eb90c377fa8e67b3a290bcb3ab3a7c56083193c911bc05ef76e986e61a0a361e9ed5a7fec55840ba6afe1022bc97e18b5eabbeef,I would implement push using std vector push_back.  I would implement pop using stand vector pop_front. I would implement peek as std vector front.  for size I would use the stand vector size funtion.  Push best case O(1) and Its worst case O(n). Pop best case O(1) worst case O(n). Peek always O(1).  Size also always O(1) ,10.0,58
16707,16707,20952,3065fd9b5327500ccd01f2dbaaeb4517f874d19bdf3e90a9e58fc3902fdfcf795607548f33b16d677a8bfdbfbec8dfd27757ca207e98b81490a4df15aab3c3f5,"When using a vector for the storage in implementing a queue , when we add/push data into the vector we use push back just like the stack and when we delete a data we use pop but we overwrite the item in front (i.e move the 2nd to 1st , 3rd to 2nd and so on. After that we call the pop back to delete the item at the back of the vector. The complexity for pushing best case (O)1 and worst case (O)n, for popping  (O)n , for peek and size (O)1.",14.0,58
16708,16708,20953,b33d5ec88a2b0658fe1e9d5e59ea13311491654c12fd5b13cd9e270e44a1a125acca1c56bf136302c950a009d693b09accad74b98f9de4d82034269663959b89,"Assuming the front of the vector is the top of queue, the first item added to the queue will be at the front of the vector at position 0. The second item added would be at position 1. When removing items, the first item removed would be removed from position 0.",2.0,58
16709,16709,20954,0425e17b97b62d847bfbb7a5f37fa98ed826dc582b46528b4a148c459379ead81390caacfd23b1628779d134c7092014f555b05833c612700ef174bd131b6587,"We could use either the back or front of the vector as the top or bottom of the queue, since one of push/pop will be linear and the other constant time on average (linear for worst case).

	* To push, we would add to the end of the vector. This is mostly constant time O(1), but linear O(n) when we must resize.
	* To pop, we would copy every element one index lower (disregarding the first element). this is always linear time O(n).
	* To peek, we would simply look at the first element in the vector. This is always constant time O(1).
	* To find the size, we would return our class variable that stores the number of elements currently in the vector. This is always constant time O(1).

** This can be implemented the other way around with the same complexity. The complexity of 1 and 2 would swap, the complexity of 3 would remain unchanged (since vectors can use pointer arithmetic), and 4 would remain constant for obvious reasons.",13.0,58
16710,16710,20955,5cd0a202ef51535fb2cf79db8f13b432c752afb35952cb0416813c6c757163698e13f6f62bd6292909baa9745f2197e7ed5a1f16eebc10eb62867568861dbf00,"Push: We would use the push function of the queue to push to the back of the vector. This would take us 0(1) time when there is space in the vector and o(n) time when there is no space and we would have to then reallocate before we push to the vector

pop: We would use the pop function from the stack which allows us to pop from the back of the vector. This pop function will take us 0(1) time in the best case and 0(n) in the worst case which would occur when we have to reallocate

peek: We would return the data at the index: size of the vector minus 1 to retrieve the back value. This would always take us 0(1) time complexity because no matter how big the vector is, we only want the back value

size: We return the number of items in the vector here. This will take us constant 0(1) time for any vector size",5.0,58
16711,16711,20956,d79246b4e37ca7cbd7cba0e73e77371bc01ee0686edc183593c8b72f08af7f56885ea93e866878670f104cfe50f22453d301d67ae7614531bda51a9f07fc7424,Vectors have a built in function to add to the back of it called push_back. This always takes O(1) time unless a size reallocation must take place in which case it will have to copy each value into another container taking O(n) time. We can peek the front of the vector with the front function which takes O(1) time. Then to pop we will have to write code to pop_front by copying each value one space sooner overwriting the first value then popping the duplicate last value off. This will take O(n) time.,8.0,58
16712,16712,20957,a18d348d984f5bd8aca6ebc4fccb86f8d160a802b4c7ee70a595f3b8caf6c18513e302bc5cfcbf90d284bd7a320b1536220dd429aa4a21d61efb3ef1771458a4,"Since with a vector we can only pop from the back we would have to start the queue from the back of the vector, that is we push a value by adding it in front of any previous value.

Since the 'first in' value is always at the back we can just use pop_back() which is constant O(1).
To push to the back we would shift all the current values in the vector over by one to make space in the front for the value we are adding, O(n).
To peek we would just use .back() to see the front most value in the queue ( the value at the back of the vector), cost would be O(1).",10.0,58
16713,16713,20958,202c8344f9f859aa64da3cc8ceffb88155f17aa53a21d20d5da4fef5e39546500eff34cbff57a9c00ff1871c748bb37a08181469555e6609e93120b6d7b83edc,"Push-  use the push member function....vector.push(t) which will have a complexity of O(1)

Pop- use the pop member function....vector.pop(t) which will have a complexity of O(n)

Peek- return what's at the front of the vector.... return data.front() which will have a complexity of O(n)

Size- return the size of this vector by counting how many items are in the vector since the size of a vector must be known.....return vector.size()...which will have complexity of O(1)",6.0,58
16714,16714,20959,ba67943d9c3f68c2a82bf70197366cb2cce1d21f6696fe648aaf7068ed18399b5899a40e2f0d4a0c53a04c7e84020c544f2b79e8fc23a17b4dca16bd22dbd15b,"We use push to add item at the back of the of the queue time complexity O(1)  worst case O(n)

We remove an item from the front using pop time complexity O(n)

Peek is used to return a reference to the front item time complexity O(1)

Size returns the the number of items in queue time complexity O(1)  ",4.0,58
16715,16715,20960,bc7ce8dcf81474ef89d407bc167ddbdc0ae686813582e07ef0e124f6d6fe081339ab3b2bb05c54a356b901c5c208933d91dbaf731894bf50cc25eab5e102a8e6,"The complexity for the push function would be constant in best case and linear in worst case.

The complexity for the pop function would be constant in best case and linear in worst case.

The complexity for the peek function would be constant

The complexity for the size function would be constant time",4.0,58
16716,16716,20961,571f4b857c687d9d563078992ce0d593248d2c9f52df5afb071f8e300cfd009d7831df6cd94d1fdf3131324af503b103a8881171137c2ca59df7ead36faf3f74,"Push: you will just push the value to the end of the vector O(1)

Pop: you will just pop the last item in the vector O(1)

Peek: you will return the value stored in the first cell of the vector O(1)

Size: create a variable called count. Then you use a loop to iterate through the vector with each time you iterate through a cell in the vector you add 1 to count until you get to the last cell in the vector. You then return count. O(n)",3.0,58
16717,16717,20962,b9d82cd7c247fea1955a43aaaf5bb439ce7f4f53d3df9728ceb44f0e1b947c368ff1574400183b4d31d82813774edfdb38a1fdb56e3256ef8ab3e682f8c08da1,"To implement push you would use the .push_back(item) function. This will allow the item to be added to the back of the queue. The time complexity for the best case would be O(1), constant time and the time complexity for the worst case would be O(n), linear time.

To implement pop you would need to remove the item from the front. This will allow the item to be removed from the top or front of the queue. The time complexity would be O(n), linear time.

To implement peek you would need to take the front item or the first item using .front() function. The time complexity would be O(1), constant time.

To implement size you would need to take the .size() function. This returns n_items that are stored in the vector and this is why it is O(1) time complexity, constant time.",13.0,58
16718,16718,20963,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,"the push function would use the push_back function to push the item to the stack then a top pointer could point to the element and make it the new top done in O(n) time, the pop function is just the pop_back()  the pointer pointing to he top element -1 done in O(1) time, the peek would just be the front function from vectors done in O(1) time, the size function would use the size() function for vectors done in O(n) time.",7.0,58
16719,16719,20964,a3989cc4476b1bbce9e79b34c3f0337ca13c9717a610fbe24ad51e9bdb052f2d445313904842463b1a859cd4d281ce72b5f85b0423f33b62cab82318e4116232,"I would first create a class called Stack which is public, then declare my vector. Then have the void function for push and time complexity of this function would be constant for best case and linear for worst case. Then I would create another void function for pop under my class(public), time complexity of this function would be constant for best case and linear for worst case.  And then create another void function for peek, time complexity will always be constant for this function. Lastly create a function for size and time complexity of this function will always be constant as vector keeps track of the memory.",6.0,58
16720,16720,20965,f83dd55ad9e075a60c5134f9bf47ed3397e5224c478fcc48237d4341af57f9ae0b4893b2d9bfdacde4458f44d6dacdaedccfab297dd76d28c1d773deaaf399e4,"Create a class called stack ,initialize the vector(Thing) and call it ""me"". The first function push will be data.push_back'.
For pop ,you copy all the items ,the first item becomes the first item in order to remove the first item.

For the size its me.size

Time complexity : pop is 0(n)

push is 0(1) but linear in the worst case.",8.0,58
16721,16721,20966,611e62668a69a44120f4c094b741411c87184ef32e42939a38515edfc5b988a4050fb89730be7833c2365cfa3031ef1f4593e6c36d340bca6106a175c159094f,"when using a vector  I can choose the front of the vector to be the top of the queue and the back to be the bottom of the queue . 

in this case to enqueue i would use push_back  which would be O(1) in the best case and O(n) in the worst case if we need to resize

To dequeue i would usethe vector pop_front() which is a function that i'll have to code for myself since it always takes O(n) amount of time (to add at the front you'll have to move n amount of items in the vector one step back yo make space for the new item )

for peak i would use the vector front() function which will always be O(1)

for size i will have to use the vector size () function which will give me a time complexity of O(n) since i need to iterate .  ",13.0,58
16722,16722,20967,662455ba865b7fa66132ae6520e999c9ea1b9fa1f85d0b16ee30bd84db7aa0bec3c7fd7269d6521a07e1ad16d091e298c84cb6c69ff3537fa78efdac09fa4677,"I would use the back of the vector as the back of the queue. Therefore using the vectors push function I am able to add an item to the queue in constant time.

I will then have to use the front of the vector as the front of the queue. This means that to remove the item in queue at front, I would have to shift every item in the vector one to the front. This would require a linear amount of work.

The peek function is a simple function that will access the thing at a specific index in the vector. This can be done in constant time due to pointer arithmetic.

The size function can be done by either keeping track of the size thereby making it a constant time function or by iterating through the vector while keeping count. This would require a linear amount of work.",10.0,58
16723,16723,20968,8a35389fd7c8ad2535687771b1bb68c8efb0b7de8dcab378f3a060f04342ee373ba7cc2c9fd072651f8268858486a9bd9dd5269dda1258346fc90ac33d038576,"For push, we would add to the back of the vector, for a best-case scenario, if there is pace, it will take O(1) and it will just add the item to the back. In the worst-case, if there is no space, there will have to be made a copy of the vector and then we can add, with the double size copy, this will take O(n). For Pop you have to remove the element from the front and move all items in one space, this will be O(n). The size will be O(1) as the vector has a counter that keeps track of the size, peek will just return the first value and this will be O(1)",13.0,58
16724,16724,20969,1524a034e009646803d7074c495cb1bd3919f40bf0c99261b282adc7801990411f97759342d2d5b53fea8bfcd2292ae00d0444e55290b251e7ed8a081caf06dd,"I would implement the push function by using the built in "".push_back"" function of a Vector to add to the back of a vector. This would take Constant time O(1) in best case scenario and linear time O(n) in worst case scenario as we may need to create a new vector and copy all the elements over.

I would implement the pop function by removing the first element in the vector and then copying all other elements one position towards the front of the vector. This would take Linear time O(n) as we have to copy every element one position towards the front of the vector.

I would implement the peek function by using the build in vector function "".front"" which will return a reference for the top element in the vector. This would take Constant time O(1) .

I would implement the size function by using the build in vector function "".size"" which will return the number of elements in the vector/queue. This would take Constant time O(1).",14.0,58
16725,16725,20970,fcd3cd6f6ab23272e8ef67866982250cf0b69308ab1f155fea93b78f0f8230cc3a80d03659b858f52503462ba79795983adf53baae8dc1b2c6482664286cb263,"implementation of push ill use thing t and the time complexity in best case is O(1) while in worst case is O(n)

pop it removes t from the function and the time complexity in best case is O(1) while in worst case is O(n)

peek is fetching an item on top of the stack  ill implement return data_back and time complexity is constant

size ill implement  return back_size and time complexity is constant",3.0,58
16726,16726,20971,c927373e71fe30f4255c61610bb88cd9a4bb26b4d4a5c6bc2711f05bbe84ffcf49fd97d920d1a706ea1e91d40784c2fadbc56f95b4fae450f318d7610a7daca1,"The push() function would insert an element at the back of the queue. The element is added to the queue container and the size of the queue is increased by 1. Time complexity is 0(1).

For the pop() function, the particular element is removed to the queue container and the size of the queue is decreased by 1. Complexity is 0(1)

For the peek() function, it returns the element at the top of the stack, and returns NULL if the stack is empty. Complexity is 0(1).

Size() returns the number of elements in the queue and time complexity is 0(1).",6.0,58
16727,16727,20972,1e61ac69c9ccec529a9d57595e183d7f2b1fa6a9903d4933718e237d1b12f704ba69dec35931222592238b7ab802821e4d5dd2c83c64cb9301a8bb0ced8b2cba,"The push function would insert a new value at the end of the vector so you would use the push_back() function. The time complexity would be O(1)

The pop function would remove the last item in the vector so you would use the pop_back() function. The time complexity would be O(1)

The peek function makes a reference to the first element in the vector so you would use the front() function. The time complexity is O(1)

The size function gets the size of the vector and you would use the size() function. The time complexity is O(1)",7.0,58
16728,16728,20973,7db17fd2acfdd980933bf2f92abec54feac68e8b60f672ae1ba7781b8dd15de47315f37d74c147384e68a3a01e88e6539391471e6490908578bb1e2cdf85e7c7,"to push to the back of the Queue  i would use pushback Thing t;This will take constant time in the best case but linear time in the worst case .For peek i would return data.front(),thi should take constant time.To get the size i would return data.size() which takes constant time",8.0,58
16729,16729,20974,2f2bbc70f8136ca3b18457b652aa1d5317919459278da63d7273a5c4e29eded00275f14d0a5826a3efa0a4d6a86ce51a6129f3ba53f25a66bc7e4755b291485f,"we would create a class, and within this class, we would declare public functions. We would have a push function that uses push_back(), which in the best case would be constant time, but worst case would be linear time. We would also have a pop function that uses pop_bacl(), which in the best case would be constant time, but worst case linear time. We would have another 2 functions, top and size, which would in essence return to top value of the stack and the size of the stack, using the functions back() and size(), which for both cases would be constant time.",10.0,58
16730,16730,20975,bacea88b3884d2acdf5b94b564c3ec6827ffca9c96b92221f37418e3f06607a9773dd54e02efe11a3f31dcc55f103233551301f8c7dbd6ce23f465133edd2ef3,"I would first take the back of the vector of things as the top of the stack. When I push, I will add the items at the back of the vector which is the top of the stack. Also with pop, I will remove the items from the back of the vector which is the top of the stack. I will also return the value at the back of the vector which will be the value at the top of the stack. Then to get the size of stack, I will return the size of the vector. All these functions will always take constant amount of time.",2.0,58
16731,16731,20976,ab50392a96c4c3025a5963370825a15241a679c25a4771a2853db32d86a5e0a874ed37e6f390b06f6b3a0755f5bc0190ec94f83a3fd5bf730ba4d34a04efb6d1,"push: vector.push_back an item, it will push the item to the top of the vector with a time complexity of O(1)
pop: vector.pop_back will pop an item at the top of the vector with a time complexity of O(1)

peek: vector.back will return the value at the top of the vector with a time complexity of O(1)

size: vector.size allows you to get the size of the vector with a time complexity of O(1)",4.0,58
16732,16732,20977,7c87322598f2ceacf4938051fa8e249fba61f740f1c131025859319c9334a0e7c5eed0d631406a69aaecd55c3154797379e9e557934a0c639e13848fc2a797db,"To implement push i would use the the push_back function that is already accessible since we are implementing using a vector and this will add Thing t to the back of the queue. It will take Big Oh (1)

To pop at the front i would implement a function that will delete what's at the front and shift everything in the vector to the previous index and this function will take O(n)

To peek I would use built in function that returns the reference to what's at the top of our vector which is the back() function which takes O(1)

And lastly use the size() function which calculates as we push and pop the queue ",7.0,58
16733,16733,20978,6c0c4055e14104657e8b2f93690d540761c32c74b87c67cb6acc284b0968521966239252478c024e2c1fdc28ec4e72c01b4f28c3de78e04b7bbf604f3bad167d,"Push: push_back O(1), unless memory adjustment then O(n)

Pop: pop_front O(1), unless memory adjustment the O(n)

Size: would be O(1) as that would be adjustment with the other pop and push functions to ensure the correct size is always in memory

Peek: O(1) as that only call the last value",8.0,58
16734,16734,20979,c9533083b36a5867d42e175e5d9226d460bac0f67119822f32ea58c60b5c8ae66655217031dc5ae111931d8c34d1a88f17b852726bf446acb3dd87422ab66355,to work with a queue create an array of some size and take 2 variables which are the front and rear of the queue.To pushback increment the rear by 1.this takes constant time.To  pop delete the first element of the array and move every position 1 unit left.This should take linear time.To pop at the front use arr[front].This takes constant time.To get the size return arr.size() in constant time,7.0,58
16735,16735,20980,763a776e81302d0ca35787de395275bfa7dace1cb9ac6ce690e840ef2f280482559135e73ff9334c7ef80b3304e1f6061c108364e0e55bf5e56d4aafbce8e073,"pushing an item we will be adding an element to the top of the stack which will take time complexity of O(1)- constant time in Big-Oh notation.

then secondly popping an item in the stack we will have to delete(remove) the item from the top of the stack which will also take constant time- O(1).

peeking an item simply means that we are looking and we want to get the most recent element(element from the top of the stack) which will also take constant time- O(1).

and lastly size, we would like to return the size of the stack which will take a time complexity of O(1)- constant time.",5.0,58
16736,16736,20981,b96308b5b954fc4c2086f6faec027fc8299af60a164d99cbdc75a0802d3bb5ac5823699b9e2e5c78a86bbf73886ed3408a16b29a0f7ee6dc90b05a8f2f91fcd5,"The front of the vector would be the top of the queue whereas the back of the vector would be the back of the queue.

In order to push to the queue we would add to the back of the vector and the time complexity would be O(1) in the best case and  O(n) in the worst case.

In order to pop we would remove from the front of the vector and the time complexity would always ne O(n).

In order to peek we would return the first value in the vector and the time complexity would be O(1). 

In order to get size we would need to traverse through the entire vector therefore the time complexity would always be O(n).  ",7.0,58
16737,16737,20982,4d5583055b5cf0ef4bd7f80832ec9b8940eedb6261741378493c7c1e768d88d15f96d3b8d5850288f3731056d59b3dbe1878b8c16bbb307054b4401de38adc38,"Push:

I would allocate a new block of memory if there is not enough allocated memory, insert the new item and then copy from the old block to new block then free up the memory of the old block. This would take O(n) as it depends on the number of items in the previous block of memory if there is no free memory which is the worst case. Best case would be O(1) if there is enough space. I can also use the vector functions to push_back normally.

Pop:

I would allocate new memory and copy the contents of the old block starting at the second item then I will free the memory. This would take O(n) as it depends on the number of items. 

Peek:

I would use the vector function to get the first item in the queue. This would take O(1) time.

Size:

I would use the vector function .size() to get the number of items in the queue. This would take O(1) time",11.0,58
16738,16738,20983,52b1f6fd8e6c0289a8004d7d61b231157f72159bdb1098720813eb6a4750543a581c16358208b2fe293a6bc58612fe418d8dd4bccc56d715f7137f43db02b99f,"push:
i would add a Thing to the top of the vector if there is enough space, otherwise double the space and then add to the top.

with an O(1) for the best case scenario;

and O(n) for worst case scenario;

pop:i would remove a Thing from the top of the vector; once the number of items in the vector is a quarter of the allocate space, i would resize the vector to the present number of items.

with an O(1) for best case scenario without the resizing;

and O(n) for worst case scenario

peek: i would return a reference to the top item;

and it would always be a O(1) time complexity;

size: i would return the number of items in the stack;

and it would always be a O(1) time complexity;",5.0,58
16739,16739,20984,6d04032d059678dcb346209e5f60e18a44d0c551ad3d7c0e551f1957033a386ffc9828dc7e1374b35e8828c43ed8d61ae22f6c2de063b8779cad31efc30f066d,"Create a class and declare a private and public within the class. In the private section of the class make vector<Thing>data. Create a push function which uses data.push_back(), best case is O(1) and worst case is O(n). Create a pop function which uses data.pop_back(), best case is O(1) and worst case is O(n). Create a top function that uses return data.back(), this function returns the value at the top of the stack and is always O(1). Create a size function that uses return data.back(), this function returns the size of the stack and is always O(1).",6.0,58
16740,16740,20985,bec70f18652f9b1ec67ee94e23471083fc0530aad868499d925d500e71ccfd4f82652eb49a909778379c4583e97ce1464a3ae78de3b07114cb3a9e4c1179d625,"When inserting items in the queue, you would implement push, and the time complexity would be O(1). To delete items from the queue, pop would be used and this will have a time complexity of O(n). ",1.0,58
16741,16741,20986,c879e65c8f9657768bbf6800906a28bff217c7ef9063d46acfccc25071a9fc3aef2ccd29821fdc92e96d2f98ca66aa74a3fa2a8f0df86509064e53b0fb9b54bc,"To use a queue with a vector as the underlying data storage we would implement the following functions.

Push: To push to the back of the queue we would use the vector's push_back function. It would have a best case of O(1) if their is space at the end of the vector, so the value is just copied. In the worst case it would have O(n) if their is no space at the end of the vector so we would need to make n copies of all the items to a new location with space for all the items.

Pop: To pop at the front of the queue we would use the vector's pop_front function. This would have a O(n) because n copies would need to be done to shift all the items  position to the front of the vector to preserve the order of the vector.

Peek: To peek at the front of the queue we would use the vector's front function. O(1)

Size: If the size of the queue is already stored then we would just call on that value, if it is not we would simply count the number of Things in the vector and return that value. O(1)",14.0,58
16742,16742,20987,fd0ace311926a44973b18eb55c0a2df285cc4ef58cf67836be1c2719041ca75111c81115da37e4e4879d8c00ffb63db68cb0de1c85a3fc373724acf7945dc463,"The push and peek functions will take O(1) times, and the size and pop functions will take O(n) time. Would implement these functions using built in functions with the push function adding at the back and the pop function removing the front function by shifting the items towards the front. The size function can just traverse throughout the entire vector, then return the number of items.",8.0,58
16743,16743,20988,ffb312171739bda8140d790d7e76d39d8cb251ebc0d6e983413e101fe068405632084409e60fc3615fbb0328c8c628ab617f395e064e10a0893ff352b3482def,"Push would use the normal vector push back function and have O(1) usually and O(n) runtime complexity in the worst case. Pop which would mean popping from the the front would need to create a new vector removing the first item, which would have O(n) runtime complexity. Peek would only need returning the first item which is O(1) runtime complexity. Size only needs returning the size of the vector which is also O(1) runtime complexity.",11.0,58
16744,16744,20989,e0c83344227ee0e9cbe053565e48a2fdd45505359ef079abf58dae6d4b8251e874c464186ed9d597d1e6bd62c45d87ea5c0897cd6938b6926936cb2def62d356,"In a queue the only two operations are allowed are enqueue and dequeue, this means that when you insert an item it inserts it at the back of the data and when you remove and item it removes it from the front of the data.  When using the push back and pop back function the time complexity remains constant in removing and adding the data and in Big-Oh the complexity will be 0(1).",0.0,58
16745,16745,20990,ed5a8c0425e8a7a0d2d402e42e3298539ec0ceb1b43ca8fa3f4b83dce862ed24fe276be92f07cf85365c96c7391564d1c0da45fd6e6ba4bd80ecb01a39467209,"push:
when pushing at the back of the vector we would use the push_back() function and in the best case where we do not fill up the memory buffer the time complexity would be O(1) and in the worst case due to reallocation of memory the function would take O(n)

pop:

when popping we would create a function with an iterator that is first initialized to zero referencing the item at the top of the queue(first item in the vector), when the function is called, we increment this iterator to reference the next item in the vector

this function will have a time complexity of O(1) because of the constant time it takes to increment

peek:

to peek we would use the iterator created for pop and use the [] operators to see what is at the top of the queue

this function will have a time complexity of O(1) because the [] operators will use pointer arithmetic to get the top of the stack

size:

for size we are going to use the .size() method that comes with the vector and then subtract the value of the size - our iterator +1 

these operations take O(1) to occur",7.0,58
16746,16746,20991,fd8a875c5398ac6c36a731d0d10a006399599403b9ee2f4994b116a012c4bd603697ca87421ae17a8eaaa96913f3870bb71641db61fda611c4a27d1aa224e5e0,"You create a class called stack, and initialize the vector(Thing) and call it ""me"". The first function push will be ""data.push_back"".

For a pop function , you copy all of the items 'the first item becomes the first item in order to remove the first item.

For the size you use me.size

The time complexity of pop is O(n)

Push is O(1) but linear in the worst case",6.0,58
16747,16747,20992,9082e5ab0ae09b23b5e0275a763493886db0b7f721520ca423ce3577e6b6ec09537f5d0b22aac121f7604a542a413dd81640198a15212f5aa5403c721b42c11e,"for push, say I wanna push Thing t, then I would make a void function called push that takes in a thing t and just pushes back t on the vector, for pop I would make a void function that just pops a Thing t at the front (which is at position 0). for peek I would make a function that returns a reference to a thing at the vector position 0, but for size I would make a function that return an integer of the vector size using size().",6.0,58
16748,16748,20993,3535a43df3300af7e5c3e95a4369804ca852c0470f1fe060d2a246291726064d9eeb362ff2318c56c2b2c1abd2d650cb0578f3dab1f0c9bef113f35bec7220b3,"Push :

We first have to push front, moving each element forward by one - O(n)

Adding item to the back - O(1)

Therefore O(n) time for a push back function 

Pop:

pop_back from the vector takes constant time - O(1) - Best case

O(n) - worst case, when we need to reallocate space.

Peek:

Return a reference to the front of the vector - O(1)

Size:

Return the size of the vector - O(n)",7.0,58
16749,16749,20994,acc027b1281fb7611892bbd9cd22b170d39dac509f3cbd3c4ae2298ef8fcce3e213c9bdb095b30f4b14371abefeb025cbed1bfbb0b3e1f2baccc7d74d415003e,"TIME COMPLEXITY:

push: best-case O(1)  worst-case : O(N)

pop:best-case O(1)   worst-case : O(N)

peek:O(1)-CONSTANT 

size:O(1)-CONSTANT",5.0,58
16750,16750,20995,df7c40110480895f223a4ad7a154ce6d14071ffef29c798823d9a68e307bd1447fc569c4b8f3e4353216405210fd26445fb7aeea3ad07da82c16c8e5aa5ac0cd,"If the back of the vector  corresponds to the front of the queue
We use push_front to add to the back of the queue  and it's time complexity is always O(n)

Use pop_front to remove from the front of the front of the queue and time complexity is O(1) in the best case and O(n) in the worst case.
We peek return reference to the item at the back of the vector using back() and it is O(1).
Size returns number of items in the vector using vector.size() which is O(n).
 
If we use the front of the vector as the front of the queue.
Use push_back to add to the back of the queue. Time complexity is O(1) best case and O(n) in the worst case when we no longer have space.
We use pop_back to remove from the queue
size is O(n)
Peek is O(1)",8.0,58
16751,16751,20996,27704af10f29b9fd01985b3a533f1213c119ce01a32f451e037e0491eede8c71f38ccb8abe4edd8c056927c76b6bf0c23fb2a88f8cca52e5000b6c906d6692ef,"I will set the top of the queue to equal -1 since the queue will have nothing, and I will update each time I add or remove an item. To pop an item to queue I will call the pop_front function. To push an item to the the queue I will call the push_back function. To return the number of items in the queue I will call the size function. Lastly, to return a reference to the item at the top of the queue I will call the front function. 

Pushing an item will usually take O(1) time (in the best case), but in the worst case it will take O(n) time.

Popping an item will always take O(n).

Getting the size of the queue will always take O(n) time.

Getting the item at the top of the queue will take O(1) time.",10.0,58
16752,16752,20997,bd13f3a1f05cded43b306e7cf672db1fa9cf812229ead4318a993e62aa7ff42541e39b6868fb05069f972d798f5a5b109e0e615acf69b7c88b8e2bf435bfc374,if we implement a queue then the push operation will take o(n) time and pop O(1) time,0.0,58
16753,16753,20998,e128973184d15ac7a750b822c9d3b3fe1c0b4d5c9ec9968806c119de2807128c5380243007b2944cf3a301c3270578e76aaa068c636326951a9eea7851758fdf,"Best time complexity of the push_back will be O(1) which is constant time and worst time complexity will be O(n) which is linear

Best time complexity of the of pop_front will be O(1) which is  constant time and worst case time complexity will be O(n) which is linear

we put the peek function in the public class and return the data 

Time complexity of the peek will be O(1) which is  constant time

we put the size function in the public class and return the data

Time complexity of the size is O(1) which is  constant time 

 ",5.0,58
16754,16754,20999,400853532d18057c486e48e90c2e3817295b0b8da4abab44abf1f9dd692996bce343aa72b93713cdef71a68aff30879c7ec75ca8ea25a59fd4c48084879663a5,"To implement all of these in a stack, a stack will have to be a template class, so that the push will only add an item at the top, the pop will delete the items at the top, the peek will return a reference to the top of the vector queue and the size will return the amount of items in the vector queue. The time complexity of these will be O(1).",2.0,58
16755,16755,21000,f11178d26d71b36980a2e031712b410b8887af4a2b6c48901c6a568377c95cf608d8bdb211ef99a8ec80760d046f982bcd08b27ff9c8f8cd3f71083f65b80c48,"Check if the stack is empty and then perform push operations which will take O(n).Now we will pop items and then put them into the other stack which is O(n). Once the elements are inserted, the top most element will be popped off and it is O(1). but before popping peeking would have been done first which is also O(1).",4.0,58
16756,16756,21001,c0e222e387522491c144bc66b8d4aac6d8899881b15676a75bd42f6939be2d68b02062c035d5f028531cde71d4b0b2bb7581d5e165c7c3be11bd4e67e796913f,"Create a stack class and initialize a vector of 'thing'. The push function would be push_back to vector and the pop function would pop_front of vector. The peek function returns the first item in the vector.

The size function returns the size of the vector which occurs in constant time O(1).

The push function takes constant  time O(1) and is linear O(n) in the worst case scenario which is when the vector is full.

The pop function is always linear O(n) because the items in the vector are copied n-1 times.

The peek function is constant O(1).",7.0,58
16757,16757,21002,8f4f0cec01fab6a6a49376ed0eca817677b16456497e4474dea2db6c84f10bbab5215841562427aec9d1d1cb57d57272e23d92898bef51a2205b3db761cea98d,"I would initialise a queue with the underlying container being a vector of type Thing.

I would then create a parameterised void method for pushing a Thing into the vector. This would be O(1) - Constant time.

I would then create a void pop function for popping a Thing from the vector. To pop from the front we would need to copy each item one space to behind in the vector. This would be O(n) - Linear time.

I would then create a peek function of type reference to a Thing, we would only need the return the address of the Thing vector at its index 0 as that would the frontmost item in the vector. This would be O(1) - Constant time.

I would then create a size function of type size_t which just returns the size of the vector. This would be O(1) - Constant time.",10.0,58
16758,16758,21003,bb69eebb6b9661fb2659b9201956c2d150fd7601de8f2339f22c3c3c7289abd28101e1b6206a923a6b9fd81f7d0d617c8b5485dd0958ad06769fcf98922a4e97,"For push ,It is more simple if we use push_back function so that the element  is stored at the back.for pop it is simple to iterate such that the elements in the vector to reverse then pop the last one using pop_back function then re-reserve the element once again this can take linear amount of time.for peek we just use thing& top() and for size we use size_t()             ",5.0,58
16759,16759,21004,d098e277cb3df3b25c9e42904322dbd46a16b60a20b139d8066f16584a8bb599eddc05cac924f310971f38fb613ad7daea71749bb268694cb7e0d2fdf74a35a0,"For the implementation of a queue using a vector, we may choose to use the front of the vector as the front of the queue and the back of the vector as the back of the queue. Or vice versa. In the first case, we would add to the back of the vector and remove from the front of the vector since a Queue is a Last in First out Data structure. For implementing the push function of a queue, i would add to the back the back of the queue using the push_back function of a vector( vector.push_back()), then to remove or pop an element from the front of the queue, i would use the pop_front function of a vector (vector.pop_front()). For implementing the peek function, that is a function that returns a reference to the first item, I would use the vector.back() function, which will return a reference to the first item in the vector which is also the item in the front of the queue. To implement the size function in the queue i would call the vector.size() function which counts the number of items in the vector, which would also be the number of items in the queue. The time complexity of the push function is (O(1) in the best case and O(n) in the worst case.) The pop function would always have O(n) time complexity. The time complexity of the peek function is O(1) and the time complexity of the size function is O(n).",10.0,58
16760,16760,21005,798235659bb9174e71b3ff61763ec292691ece6655d9ff85d1fbb65ede38be3c46ca62a6d523bf01e0f519090370eeadd560efded9ef16231507d4492e919473,"to perform a push we would use the standard library vector function ""push back"" for a vector. The time complexity is O(1) at best case scenario and o(n) at worst case scenario

to perform a pop we would move each element one position back which would reassign element position and would remove element at front of vector. The time complexity will always be O(n)

to peek we would return the element at index 0, the time complexity is O(1)

to get size we use the standard library vector function ""(vector name).size"" , the time complexity would be

O(n)",11.0,58
16761,16761,21006,95fcb6f4498706b42ae9b99b85ac88399a6d3275d00b87217fb05c5101d1dbf721727b60bf9e8e6b2dc1c2bdad3d13b66bf7f2d975e8a5f8863dd7d1ee3dcbef,We could use the push back function of a vector to add items to the back of the queue and this will use a constant complexity since only one item is added at a time (O(1)). To remove a item we could use the pop front fu,2.0,58
16762,16762,21007,ec66e4473040e8ee3556fe295a682aef55293bdc440d5beebc8fb799f1964c0abc0afc761e0c9e5b3dec6cb5d26467ba51d5e312925807725d0b86097bb74bce,"For push we would use our push_back() function to add our new value to the back of the vector, best case this is O(1), when we don't have to increase the size of the vector, worst case this is O(N), when we have to increase the size of the vector and copy all elements over. For pop we would have to remove the first element and copy all the following elements to the previous index, this will always take O(N). For peek we would return the value in the first index of the vector, this will take O(1) time. For size we can use the built in size function which uses pointer arithmetic and takes O(1). ",13.0,58
16763,16763,21008,55ea1e4f47f56380767c8e74fc048f88ea3f77cbdba15f1928ce2c49d72fc6281a93cc53faad127cf63dd846a712edf93d7e45216338f7bc4ae6a26df95dd66e,"CAN USE THE FUNCTIONS:

TO PUSH TO BACK

 push_back(t) 

Best case O(1) 

Worst case O(n)
TO POP AT FRONT:

pop_front()

Best case O(1)

Worst case O(n)
TO PEEK AT FRONT:

data.front()

O(1)

TO SEE THE SIZE:

data.size()

O(1)",10.0,58
16764,16764,21009,7ed1c803cb6942b25a462119e14146d3dfdc8b2d8405742d6e37974d2693c34f2838afb58a1bcf41b9fcd8829c1dff4d4b192c929c721bc46e1615dcea231b30,"When implementing a queue using a vector, we may choose to use the front of the vector as the front of the queue. Similarly, the back of the vector as the back of the queue or even vice versa. In the first scenario, we would add at the top of the stack",2.0,58
16765,16765,21010,680d91225cab44dd05e534f9e43db41735c5c1d374cc902f5585fb054238f603a599d4ef9dab5fa3942be1f948538952ecb942a66b8672d9ac04303366506ece,"You create a class called stack, and then you initialize the vector(Thing) and call it ""me"". The first function push will be 'data.push_back'.

And then for pop, you copy all the items after copying, the first item becomes the first item in order to remove the first item.

And then for the size, it is me.size

Therefore; Time complexity : pop is 0(n)

and push is 0(1) but linear in the worst case.",8.0,58
16766,16766,21011,828a54706b7956f06065af9a928b49958122a77b54a5e0593021ac1ee5bfac90e0bf9488291ceaad9b7538bfadd4796253d8359db184b0bd7f7e1ed456e8f30c,"To implement push we use the vector push_back to add at the back, and push_back is O(1) but is O(n) at it's worst case where we have to reallocate for more space. To implement pop we use the vector pop_front which is O(n) because then we would have to shift every element to maintain order. To implement peek we use vector front function which returns the value at the front of the list, and this takes O(1) to return the value at the front. Lastly to implement size we use vector size function which returns the size of the vector in O(1) because the size is always updated as the vector is updated.",13.0,58
16767,16767,21012,252668df997d55b86d753e14db9bb82d9a9ab0f27d714f3256c72a03986a906ffccf1958bf221d3ab998a7770edda41ec2de25393f1d9a62f105684cf09211ed,"push function for the stack would be used by implementing the next item at the top of the stack with complexity of O(1).
pop function would delete from the top of the stack which is the latest item with time complexity O(1)
to peek it would look at the top most element of the stack and will return it to the the functionfor us to see. complexity O(1)

size this would calculate how many elements are in the stack by iterating thorugh each of them in the stack and prsent us with how many elements are within the stack. complexity O(n)",1.0,58
16768,16768,21013,ac47e3ceebccb755b1987f028345ba571e2bbf0bc4ebc355e11ab520e9f3ffd71073789246ed0c633ccffb81e8b77e299c90427fa5f8a55f41455cee47d290e1,"For the push function I would make a void function that take a thing of type Thing and pushes back the thing onto the vector using the push_back() function, and for size it will have to be a function that returns an integer value specifying the size of the vector using our well know size() c++ function. These two functions would take constant time complexity. For peek we would make a function returning a reference to an object of type Thing situated at  vector position zero which would just take constant time complexity. For pop I would make a void function that pops off the item at vector position zero using our pop_front() approach and this would take linear time.",8.0,58
16769,16769,21014,49da1899a556de47c2ec5c0aee3103579dd1b8665560fbd2cb26362bd85bf2a291f8280bc21e1f838e024dcd8764915c6b880be08a2f6c8f404d85517511406c,"for push, we can use push_back, which is usually o(1) but can be o(n)

for pop, we would move every element in the vector back by one index by copying, and then using pop back. this is o(n)

for peek, we return the data at the front of time complexity o(1)

for size, we use vector size, with o(1)",14.0,58
16770,16770,21015,86a22e8a0f9641e87ca4e2ad806de08b394e73d2c41a296c66bdf8a43027f536887494504dc5545f0596ae97131302d63974f19424417f466775542fb23789e0,"In a vector we push to the back. As we  do so the best case will always be constant and the worst case will be linear
when we pop in a vector we use the pop_back() function as we will be removing from the back.in the best case it will be constant and the worst case will be linear. When we peek in a vector we use the return data.back() function which will always be at constant time.The size of items will also always be constant as they cannot be changed while the program runs.",2.0,58
16771,16771,21016,be31d5d430bb70d92105e501945893c26e6893599696162bc95d97dc68e8551bcabb0ec57e7e70881502e05fa1f8de1b8b173b3252cd099443fc870750db1827,"Push - The item that we are adding will be pushed back to the top of the stack, and so we will use a push_back function that is part of the vector class, to add the item to the back of the memory while updating the size and top of the stack automatically. The complexity will usually be constant O(1) in the best case unless there is a reallocation where it will be linear in the worst case O(n)

Pop - The item at the top of the stack will be removed using the pop_back function that is part of the vector class. The change in size and top of the stack will be changed automatically. The complexity will usually be constant O(1) in the best case unless there is a reallocation where it will be linear in the worst case O(n).

Peek - This function will return a reference to the top of the stack using the back function in the vector class. This reference is stored in the vector class and will always be a constant time complexity O(1).

Size - The size function returns the number of elements in the stack and this will be done by using the size function that is part of the vector class. This value is stored in the vector class and will always be a constant time complexity O(1)",7.0,58
16772,16772,21017,dd6537e6bbbf6c0e41a1bbe6d5c67d11fda8f22650f0a00de8c0f21aa0fa7af062e1f573fb1377a0dcf131388d028a89180134e7dc6dad9b0af65222ab5e4328,Return a reference to the front item,0.0,58
16773,16773,21018,675e836215b62d793972ecb9d5ace2eaf438e0e5d0d26f496ddc3442ba479da55ac029b8a4555f73c538c50ecac4b04edc042861ca9b743e991c19c46392aa72,"For queue we may choose to use the front of the vector as the front of the queue and the back of the vector as the back of the queue or vice versa. We add to the back of the vector and remove from the front of the vector since it is Last in First out. For push function I will add to the back of the queue using the push _back function with time complexity of O(1). To pop an element from the front I would use the pop_front function with time complexity of O(n).For the peek function which returns the reference of the element of the first element, i would use the vector.back () with time complexity of O(1). For the size function i would use vector.size () which shows the numbers of items in a queue with a time complexity of O(n).",8.0,58
16774,16774,21019,bf9f7563cc9f901b96502125e7d25475a0aeee128b8258ce038a51e3af3c4093e4ee3d48f8e688baf55d2e74c7a660d473b521169612f2e6991be2accf5a47f1,"you can make a class called stack then initialize a vector called 'thing' and rename it 'me', then the first function push will be data.push_back
for Pop, copy the items thus the first item becomes the first item in order to remove it

to get the size it will be me.size

the time complexity of pop is O(n)
the time complexity is O(1) and is linear in the worst case",8.0,58
16775,16775,21020,33903c4df6729a45e2485f57a528848aea77fb0ac81607f602f6f53f80eb513d5b18fef57c086d43fef4cdb3f78bbc1f8da0bcaa1e67afb26268e9484bbb4ded,"For pushing at the back of a queue we can use the push_back function found in the stanard library for vectors. Complexity is O(1). 

For popping at the front we use a for loop to traverse to the front since a vector does not have a pop_front function. Then after traversing we use the pop_back in order to remove the item in the vector. Due to the traversal the complexity is O(n). 

The peek function can be implemented using the front function which takes O(1) time.

Size can be implemented by using the size function of the vector. The time complexity is O(1).",14.0,58
16776,16776,21021,4541bddfe14df82661aaba793d25bb038432ba934014876821269e81b4029af8b6064a54828f0509d14ee3f303c32ee014b7221977ad133bace3b01a694e694c,"We would create a class named Stack and have the member functions under public (can be used outside of the class: void push(Thing t), void pop(), Thing &top(), and size_t size. We would have a vector of type Thing named data for example such that vector <Thing> data keeps track of our memory allocation on the heap and the amount of elements we have. 

To implement the stack we will be working with the back if our vector. To add to the stack we would push (insert) at the back of our vector. This will take O(1)- amount of time in the best case if there is space and will take On) if we do not have enough space to add another element.

To remove(pop we would once again be working at the back of the vector to take out the most recent element from the stack. This has a time complexity of O(1) in the best case but of O(n) in the worst case if we have wasted too much space.

To get the element at the top of the stack we would take a reference of the last item in the vector and return that. This is always O(1) as we do the same amount of work.

To get the amount of items inside the stack we would simpy return the size of the vector (data.size() ) which would take O(1)",5.0,58
16777,16777,21022,9ef08903fc9bcdb48895ecc5b1fae5cd197bde173b9729429afd0455acdabd651995bcf58c93f0a9f803a86fd3d68cb2f4b604260158eb5fae2f92dc6b1309cc,"I would create a class called stack, initialize vector(Thing) and name it ""me"" the first function push will be data.push_back.For pop I would copy all the items .

The time complexity for pop is O(n) whereas for push its O(1).",2.0,58
16778,16778,21023,6ba5306b04bb1c19ff5f5148036844fc07d1e828c1c4bdd9a403971c63a75670cfd9507d856d67663bf299025ddc744dc1aab73fcc8ad24aa24659b96dc9ae8e,"The push function will add at the back of the vector, if there's space in the vector this will take constant amount of time otherwise it will take a linear amount of time.

Pop will always take constant time",2.0,58
16779,16779,21024,72bbc5b06aa933675f586b02eb7091979ed0d9cd4489dbf74c1a3cab5f7664fc97395b4d5ff80f04c6b7fc94837ad7229b3d6417b2c8d007ae33e9006fc697c6,"For push back we use to add a new element at the end of the stack vector. To pop out, firstly check if the stack is empty and if not then you pop the element else use underflow condition and we can use 'back()' to peek the top element in the stack without being removed from the stack, size is increased by 1 on push_back and deacreas by 1 on pop_back

pop at the front and push to the back are both O(1) constant  in time",0.0,58
16780,16780,21025,3bf5a6c902e4bbf41f8d7229fb34d303a6721b98a13f667dc5f2cbb64cc24ce8b6caffed089bfaa8a9035860dae36438bbdda86f5a082d98f0cf239492dc448b,"Since I know that I am using a vector<Thing> for my underlying data storage, I would create a new stock and I would transfer each item from the top of the stock to the new stock until the whole stock becomes empty and I would reverse the vector. This would mean that the bottom of the new stock will correspond with the front of the reverse vector. The functions used are push back, pop back, peek and size. The pop back and push back both share the time complexity of O(1) for the best case and O(n) for worst case. Size and peek also share the time complexity of O(1). ",3.0,58
16781,16781,21026,d5a3f7d660aa30769e68a7c616a4942c8f05f0c2e034be1b4e61932df724917fd2a406f53a34e25ab412791ed6463a16ef1b087d401683c22430b89ba7a21be9,"Push function : would first need to check if the vector is full or not. Best case its not and you just add to the back of the vector which will be O(1). Worst case, the vector is full and the vector will be resized before being able to add to the vector which makes the time Complexity to O(n). Size of queue will be increased. you would use push_back

Pop function : First need to check there is at least one element in the vector. Then can delete the item from the front of the list but will then have to more the rest of the items one space down. Time complexity is O(1) as you are just accessing the first element. Would use pop_front

peek function : time complexity is O(1) as you are just accessing the front element. Would use front()

size() : time complexity is O(1) as whenever you add or delete a item from the queue, the size is automatically increase/decreased.",11.0,58
16782,16782,21027,67ade1890555ea7d6de913382858973bf82ef717e817e6295020978c59105278650d1bd8b5c2d42daf06ff2292f0b1f4096f4f20a6d3a8a92a4f522b583d867a,"Push:

The element can be added to the back of the vector(and hence queue) using the vector function ""push_back"". This function will add the element to the first available place in the vector . In the best case, when the vector is not full, this operation will take O(1) time. In the worst case, which occurs when the vector is full and requires reallocation, this operation will take O(n) time.

Pop:

The element at the front of the vector (and hence queue) can be removed by shifting all elements starting from the second element one place left. This will require n-1 copies and will thus take O(n) time.

Peek:

The first element of the vector (and hence queue) can be accessed using the front() function that exists for vectors. This will take O(n) time due to pointer arithmetic.

Size:

The size of a vector is always known and can be accessed using the size() function such operates in O(1) time hence the whole operation will take O(1) time.",11.0,58
16783,16783,21028,910daf6bb90bfaca5b8329327dbb6876d9a383514e01fe819f79abb1a27019ac7b7555a07d09a61e93831fa5c489e19d607608ea54797f25aad8bd641ed60e55,"We would need to create a class called Stacks and that class has void functions that would call on push_back, pop_back, peek as well as size. For peek and size the function should return data.back or data.size respectively. The best case time complexity for push and pop is O(1) and their worst case is O(n). For peek and size, the time complexity is always O(1).",7.0,58
16784,16784,21029,a8dcc87a24b584021a1bb3ffd592a4ea66a1679acf3b2b41f26aef4e481760f4e64990e460e4e26ec12a8fef5d2354f5070843ac6e40f4a1e24bc122bfa91df9,"For push, the standard library function push.back for vectors can be used.The time complexity is O(1) at best and O(n) at worst
For pop, each element will be moved from its current position and moved one place back. This will remove the element at beginning of the vector. The time complexity is always O(n)

For peek the element at index 0, the beginning of the vector will be returned.",7.0,58
16785,16785,21030,a58cc7a946eda613e1ba5b3286e27532a7ed6202aac74240dace327e45260834a089fa12052292c507fb1aec6f37cb1855be0992f9b6be6541ab2eebe4c77364,"since it is a stack one must push to the back of the stack, we must also pop at the back of the stack , because it is a last in first out, the back of the stack is the top there for we return reference to what is at the back of the stack, for size we must create a counter which counts every time we pop back, until the stack is empty. this all takes O(1) time complexity",0.0,58
16786,16786,21031,a483d97f2f6f4b566a91dffee7b0dc51b69866d7a50c6e53308e166eaac8f5373cd9dfbf9a10c25bd5d41a415c716306b0d1e020a1acf8282aad769edfdcc9c4,"The push function would have to be void and takes in an object of type thing and then pushes it to the back of the vector using c++ push_back() function, this would be constant time complexity. The size function would be one that returns an integer value that specify's the size of the vector using c++ size(), this would be constant time complexity. the peek function would have to return a reference to an object of type Thing, the object being at position zero of the vector this would just take constant time and lastly for the pop the function would have to chop off the item at position zero of the vector using the pop_front()  function approach and steps, this would be then linear time complexity.",11.0,58
16787,16787,21032,c6130d795cb6021c7594812b73d6b159744ce452f7f194d2a8acfd0f6313f2562bada8d95c7d6c5736c9d1d528be9655da041882fe8c7474badb6562243ddc74,"For pushing an item at the back I'd use the std::vector built-in push_back() function and time complexity will be O(1) in the best case and O(n) in the worst case.

For pop front I'd create a function that deletes the item at index 0 then move all the other items one index to the front and the time complexity is always O(n) since we'll always have to move the remaining items to the front and sometimes having to make a copy when the vector is less than a quarter full when resizing. 

For peeking at the front I'd use the std::vector built-in [] operator to access the item at the index 0, the time complexity will always be O(n) because it is just pointer arithmatic and the [] operator .",7.0,58
16788,16788,21033,9b5371bf3d8a67220ea9112f458e092347973d5a590a2ada7f6d386201210567493e4842dd7263535c03e1b4ce797297171327f4cefdbdd79731ace1f4e756bb,"We Create a class and give it a name , queue.

we then initialise the vector of things.

we then create the fucntion push fuction which adds to the back (vectorname.push_back) this will take O(1) constant time best case.

then the pop function, we copy all the items, the first item will be the one to be removed- this is O(n) linear time for the copies",4.0,58
16789,16789,21034,b9398cac04fafed43567a061ce43d1f6d47a11dc43ed26ca3b7c803119e60ccce5216c5b0d8f2fe86de25d577c66b8be90d26d4412d9f88f080c8ddc823e6bcb,"firstly since we have std:: built in vector functions i will use the push_back function in it to store the values in the data vector. In which the push_back function has a constant O(1) time complexity at best case and linear O(n) at worst case.

for a pop_front function I will have to create a function that deletes the first item in the data storage but using pointer arithmetic which will have a linear O(n) time complexity.

peek will be created in a way that it will take a value at index zero but using pointer arithmetic with constant time O(1)

As for the size function since we already have it in the std:: built in functions the best way is to call it while using to check the size of the data by saying data.size(); which in turn will take constant time.",13.0,58
16790,16790,21035,f1ba85bcb3cb35dd3a5763fa5946a3ff7df7d0bf7beb3182d0ecb801d8abdf353d4eeb7909c0cc4e94c0d221fea7a7c70e57bb1e1c70aaf71f4a7a0e8fe5269d,"push would behave similarly to that of stack. Push would add an element to the back of the queue, and this would take constant time (O(1)) for the best case where there is still space in the vector. For the worst case, it would take linear time, (O(n)), as there will be no more space in the vector, so new memory will need to be allocated and everything will need to be copied to the new vector and the old will be deleted.

pop would probably always take linear time (O(n)), as the first element in the vector is removed. (Assuming all the other elements in the vector are then moved 1 place closer to the first element in the vector)

size would probably work the same and would take constant time (O(1))

peek would probably take constant time(O(1)), as the .back() function could be used to see the last element",11.0,58
16791,16791,21036,d39f1221c1c1fa8d17ca77420f1bba8cbd56fd8e4b2efb35a70c05cd360218b8d98dd79e4c1abc4c057030cb040ef7358efbb5cda6b9051c1e5bddbf68b768c0,"To pop items at the front of the vector would take a linear amount of work since I have to copy all of the items over after I have popped from the front.

pop - O(n)
push - O(1)
peek - O(1)
size - O(1)",4.0,58
16792,16792,21037,61263672c5c532106e7f21122dcaab559eafcffe3f9da40ef6a4194409e8f1be9b62145c70c7a6a62ca846b85c63f3fbde4504110d16d1088e8621a2430bcdec,"Use push_back with O(n) to add to the stack.

Use pop with O(1) to remove least recently added element.",2.0,58
16793,16793,21038,23b5a4e63c9fefece084783cc1411977943e7d8d3612a093af2540d5bb113a4845b418786034d0d238575bbb9fe95d816e937dc9fe084e3f124b6dcce8457f10,"With vector implementation, memory is contiguous and we treat the back of the vector as the top of the stack. We always add and remove things on one side. The push and pop functions have either constant time (O(1)) if there is already space at the back of the vector (which is the best case) or they have linear time (O(n)) if there is no space and they have to make 'n' copies (n is the number of items in the stack), this is the worst case. Both peek and size_t will always be linear time (O(1)) as they're just returning a value. All four of these functions will be public in the class Stack but where one stores data (the actual vector) will be private so that no one outside of the stack can edit the vector.",4.0,58
16794,16794,21039,1db17093b11c1476f03e1842d3fd75c18d4034c323e18d85de2325fa751f6201dc73b8705d987e46f915cfc55474341bdc436a256b6ba4b925f54ea754c444c7,Push adds and pop removes from back of vector so top of stack,0.0,58
16795,16795,21040,eaeebfd434a43156f3712848577d3a5da6499b6e1784e16a24ab5777985e6e2eed30ffc0a110ed246a9badfba660cd9a812c4ed7d173d1a29f7e115ce4ad58b1,"The push function only needs to just push_back() the Thing object that was passed into the push function, the size function should just return the size of the vector, the returned size should be an integer. size and push would be of constant time complexity. for peek a reference Thing object should be returned the object being at vector position zero, this is constant time complexity. pop would take linear time and would have to be a void function that pops the object at vector position zero using pop_front().",8.0,58
16796,16796,21041,75a3383738a198a57b5bf911227bc1acefa5387a63447f6ac8def117cc9ca26c926b9a06fe676ff769e333554195eaa647257e22733d67710ae7508ceb7f3115,"I would say void push Thing value, which is going to add at the top of the stack.Void pop() is going to remove the item at the top,peek is going to return a reference to the top item and size return number of items in the stack.
They will take a constant time of o(1)",0.0,58
16797,16797,21042,a50f1f05303eb676c08e683fb412c46779741d1e408ab7173f3f3a12df3f04196b4fd7b7add1fd647d8efd191c43d6971e5cae7611afd814fbea2a7330f3ce46,"pushing from the back of the vector which will be constant time if there's space in the vector and linear time if the vector is full;

Therefore one will have to pop in front of the vector and thus if there's the only one item in the data structure the time complexity is constant time O(1) while if there are a items in the vector it is linear time O(n)

Due to pointer arithmetic peeking is always O(1);

Will have to keep a track of the number of inputs into the vector thus the time complexity is also O(n) ",4.0,58
16798,16798,21043,2f8068722efcb5acef0b043ef7eeece2ba76bc57f445239c4ee08b7c2bb5238f231cca575128f6a330204e13d52f6c557830c59595c0c60a57b982bbb0aba187,"push - Use vector push_back function and it would take constant time(O(1)) if there is already space at the back of the vector else it would take linear time(O(n)) if there is no extra space and the vector would need to reallocate its memory.

pop - Use the pop_front function which in the best case would take constant time(O(1)) if not too much space is wasted. If too much space is wasted we would need to copy all the items in the list which would take linear time(O(n)).

peek - Use the vector front function which will always take constant time(O(1)) as it uses pointer arithmetic.

size - Use the vector size function which return the number of items in the vector which will always take constant time(O(1)). ",11.0,58
16799,16799,21044,47a96f7fd37a4283bd96fcb03ba26cf7cdfd591682a3ab89197e64c489356cb4cf67ddd2623e0d973228f2c5400031304b672d076d17a1440971f1f289cb22d7,"If we are using a queue, then we have a head pointer that allows us to always peek and pop at the front. The peek and pop functions will both have constant time complexity - O(1)- as we have easy access to the top of the queue. Queues also have tail pointers, and this allows us to push directly to the back. This implies that the push back function will have a O(1) complexity as well.",0.0,58
16800,16800,21045,b8ff274cc91e39334247b9673eeb1e1ed2acdbcefc990de9bf2b4226b88349ab6bc97343b39be8aded8a6ab21d1bf5dc3045e9f7596480cb1279270e81abbd58,"Push: 

If the front of the vector is the front of the queue, to push to the back of the queue(also back of the vector) would be take constant time O(1) if the vector is not yet full. If the vector is full and we first have to reallocate the vector with double the previous size in order to be able to push, this would take linear time O(n)

Pop:

If the front of the vector is the front of the queue, to pop from the front of the queue(also front of the vector) would take linear time O(n) as we would have to copy the elements of the vector one item to the left and remove the first item. 

Peek:

Time Complexity = O(1) as pointer arithmetic always takes constant time.

Size:

Time Complexity is constant O(1) as we are returning a value which the vector data structure keeps track of.",11.0,58
16801,16801,21046,dba55105f290263eab690cc35467de21c1485b240568356b922de9e4385ff6cd7f9c33bdddf55cba48dae5962652c3708da244fefbb69455c6e660d7de9c7d15,in you class of vector<thing> you will have 4 functions. the pusback function will push an item to the last spot in the vectorr. if their is not enough space create a new vector with double the space and copy allthe itemsinto this vector. the add the new item.this is done in o(N).if their is space you can just pushback the value in so their is space. this is o(1).the pop is similar to the popfront func. it creates a new vector with everything except the 1st item. this is O(n) time.the peak is the first value.which can be refrenced as thing.front().this is O(1).and the size of the function runs through every element in the vector.using a loop.this is O(n) time.,7.0,58
16802,16802,21047,ab943cfa0d926aa21911a9961743ce4779859ba20a4ac4e15e75033134ef20f2d090435e99a19a4b2beb23e354a8983d0355213a926be357504dc13138c83605,"For a push function, I would create a void function that accepts a thing of type thing and pushes back the thing into the vector using the push_back() function, for the size it has to be a function that returns an integer value specifying the size of the vector using our well-known size() c++ function. These 2 functions would take a constant time complexity. For peek we would create a  function returning a reference to an object of type thing situated at vector position zero which would just take constant time complexity. For pop I would create a void function that pops off the item at vector position zero using our pop_front()approach and this would take linear time.",11.0,58
16803,16803,21048,a41ff85d7c3f46c972cdda9b8d99297a4177ec80aa4a317631762cd6ae04cc877e3ccd31e4fd09e41eccdaa2cd1266d20e5947fd82dfa31e5b04a9f5e1bd8e0c,"For PUSH function, we would add items to the back of the vector using vector's function that pushes to the back. If the vector is not full, the _time complexity_ of this procedure is O(1) since we would use pointer arithmetic which works quickly and would take roughly the same amount of time regardless of the size of n (the number of items in the vector). Hence, usually this would be O(1). If vector is full; _time complexity _is O(n) because before an item may be added to queue, all items already in the vector must be copied to larger newly allocated space and only thereafter will the new item be added. The time taken to copy each item depends on the size of n in a linear fashion, hence O(n).

To implement POP function, we will have to move each item after the first one in the vector one index forward (e.g. an item in the 4th position will now be in the 3rd, etc.) to remove first item then remove the duplicate item at the back. Because of this copying and shifting, the _time complexity _is always O(n) because this depends on the size of n, increasing linearly.

The PEEK function would require us to use vector's front function to access the item at the front of the vector. This uses fast pointer . This does not depend on the size of n, taking roughly the same time even as n increases. Thus this _time complexity_ is always O(1).

SIZE function may be implemented using vector's size function. This takes constant time because vector stores this value already. time Complexity is always O(1).",13.0,58
16804,16804,21049,7ee2a07ed8605f9b7e2a082751cb95a96baac16cb0bf39fd77ca963963f89dc899500eaec8aaa9621d868e97b67ab53ef71efa8d993d9a386011c08cc84fffc4,"pop - O(n)

push - O(1)

peek - O(1)

size - O(1)",2.0,58
16805,16805,21050,47f3a7bba3e31dce40c5cb73e1780ef17a7d27da797b9b8e1519bec1fa6b57a68e0e591111394becc40b5a2e1e2f5bfdb5b0b9727e966282c2516a6f687cab3e,"implement push by using push_back() function of the vector. Big Oh is O(1) in the best case but O(n) in the worst case.

implement pop by using pop_front() function of the vector. Big Oh is O(n).

implement peek by using  by using front() function of vector. Big Oh is O(n).

implement size by using size() function of vector. Big is O(n)",8.0,58
16806,16806,21051,6411a31397edca98a86156eda9fe940cd25214f5793edb40ff98bea1168dd2f02767f84a7d8f08cc5cbcf1da236fabf58172c048483fca623b7f16592128e03a,"we would use push_front() function for the push function and the time complexity will be always be O(n)

we would use std::vector built in size[] function for size function and the time complexity will always be O(1)

We would use  the [] operator built in the std::vector for peek to access  the item at index 0 and the time complexity will always be O(1)

we would use a pop_front function for pop that will remove items at index 0",6.0,58
16807,16807,21052,8278e2d003c29d98e8cfc7117cefa90b7503054f5b50b162eaded6981387fa2f1b8b8f0ae2fa0d58942ac81f9cf7fda1cd474d106727d602bcd9f2d647883b50,"to  push we would use push back  to add items to the back of the vector run time of O(n)
to pop we would have to remove the item at index 0 andshift every item to the left run time would be O(n)

peek use the at operation run time O(1) 

size we would use the size operator run time is O(1)",11.0,58
16808,16808,21053,a959a4bd23a818684dfb2a6c94ac89925575f3b11f0de3ed6d4df640b02681f2171e62de10059d8c04c758f13335e59b8e75b311b1045da8f168f89c32919f7f,"By using a vector as my structure, I would implement it to push to the back (enqueue) and peek/pop at the front(dequeue) - Using the principle of FIFO(First in First out), with time complexities being O(1) to push, and O(1) to peek/pop. The only difference between a this and a stack is in the process of removing.",7.0,58
16809,16809,21054,8c6eaf7f60009bf511475c1e1f0a55bd524f57db7075d81ac6324fa20c67170610813fd28d5d1a71cf68fd79649c07e7ddbcbaee618c9d5cb0d649f541152433,"* Add an item in the stack.
	* Remove an item from the stack.
	* Retrieve the element at the top.
	* Return the number of elements in the set. ",0.0,58
16810,16810,21055,639a68158c22ced38b469e5ff5439c6df90887f4ac511792920966a4b66fbbb0736453130f1e07f675685ab76215a4ca74f33ab5a9bf6fded51b150fcaa550e3,"Using a vector we would push the item to the back of the queue. It'll do constant time (O(1)) if there is enough space (best case) but do linear time (O(n)) if there is not enough due to having to copy all of the items as well.

With a pop it will remove the item at the end of the queue in constant time (O(1)) assuming more than a quarter of the allocated space is being used (best case) but will do linear time if it has to copy all the items again due to using too much space (O(n)) (worst case).

Peek will show the item at the back which will be done in linear (O(n)) time as the queue needs to be traversed.

Size will be done in linear time as the queue has to be traversed (O(n)).",3.0,58
16811,16811,21056,361f392a37237e8771b2917669c443ba6d28c45bed8ae51a0114890d3cb7412fbd4e346b3dea716ce0116bf5b6bbde572fb9792b9da8a90824dec67c0144ddfd,"Both Push and Pop operations will take constant (O(1)) time if you implement stack e.g Through an array, so both Push and Pop need just a few simple array operation which take constant time in order to secure a proper run time. ",0.0,58
16812,16812,21057,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"Adding  new elements at the front/back.When removing ,search the list for the highest priority element.Keep the contents of the queue sorted in priority order;this makes adding new elements O(n),but removing element is only O(1).",0.0,58
16813,16813,21058,c2c29b17660ccaffde93650bbaabbeca722766be9c7f4c24079c9b3711df082352b0623847e9af19ff96cf4f2d45d0bd1cd360dd8fa3d9a37f5041dcc804b8b1,"If we use vectors to construct a  queue, To push to the back, we will have to know the index of the last element. We can get it by using std::vector.size()-1.  Push to the back function will have a time complexity ~ O(N)

To pop from the front will always take a constant time. It will have time complexity of O(1).",3.0,58
16814,16814,21059,6e573d9284194cc7291f560a714a872dd47b4e061283e85a73d0f329ec03550a03a1a3f166b0239189f5a0ff40814ee55278425a8a226193ee0b842b340ab615,"for push ,i would use a push_back function which will push to the end of the vector that is treated as the top of the stack.the time complexity for push() will be of the best case if it's constant and worst case if it's linear as well as for the pop() .I will use the pop_back ()  function where the item on the end of the vector will be popped .

the peek() operation will return the reference to the top item,thus giving the address of the last item in the vector which is the top item on the stack.

The size() operation basically return the number of items on the vector ",4.0,58
16815,16815,21060,97b7f5ff46c1c824381cef505f20511747560e70b8b1e616642dc4fcce22c546867f43d01ab15335e8a2a57b9d3fba9ae8276c6347ded2ad2c8d88ebec13760a,"The following operations would be implemented using “First In, First Out (FIFO)”. In Big-Oh notation, remove(), peek(), and size() would be O(1) and pop() would usually be O(1), but O(n) at its worst case.",2.0,58
16816,16816,21061,c7fddd77b6fed9bc15d19de2718acf9bd47e63c47fabc90953d259ee95b77d6203c59c32fab4eab8591fe4a7373a9aafae0952036c94bc9ebef7955717c99e00,"I would pushback to insert an element in the queue and use popfront to remove element in the front of the queue ,time complexity for push,pop,peek and size they are  O(n) .",5.0,58
16817,16817,21062,144fe98b924f74a4cb0e0020ec3ddfeccf820bfabdc366ff5bf990f2f806b30158897deffdf43eaec7d0e8b090cab1bb52a2dedd43e24a988f1cada5b7d709f1,"I'll use stack as a vector to push to the back .O(1)

use stack as a vector to get the size of the vector.O(1)

use vector pop back function to pop. O(1)

use queue as a vector to peek at the front of the vector.O(1)",0.0,58
16818,16818,21063,75fb392795f510a47294b64115e91ce7d1c8b8f1a838562042230066b246ab6f5bab879c5a1a2a2cdc7ea648749734fcc5c1729a757ed2c29cd8f8187b92206d,"The push function would be implemented by indexing the back of the vector and simply adding to it. This usually has a O(1) time complexity, but a O(n) time complexity applies in the worst-case scenario.

The pop function would be implemented by indexing the front of the vector and simply removing from it. This usually has a O(1) time complexity, but a O(n) time complexity applies in the worst-case scenario.

The size function would be implemented by accessing a value already know by the vector library. This always has a O(1) time complexity.",7.0,58
16819,16819,21064,4f0d170bb113012c8d343271d925a96ef0e199ecdca36f51a1fc99d7e0e8c67fb97155bfa738d3317830adb88f58c316437e0cf62b20c43f4e89ab893b6e7471,"under public:

push : i would call the push_front() function whilst implementing the push function. Time complexity best case O(1) worst case O(n)

pop: I would call the pop_front() function whilst implementing the pop function. Time complexity is best case O(1) worst case is O(n)

peek: i would call the front() function while implementing the peek function. Time complexity will be O(1)

size:  i would call the size() function whilst implementing the size function. Time complexity will be O(1)

under private:

declare the vector

eg. vector<thing>data;",8.0,58
16820,16820,21065,407769fbf475dbb4360f6394c41bf1fe1b09a93e6d82ce4845a84070494a0f47c40c801c2682df7cfd3bd3657df86e3329652953a2e09d84c89aab85cdc47d86,"The push functions would use the push back function of the vector and the time complexity would be constant O(1). The pop function would require to call/index the last item in the vector and then removing it, its time complexity would be linear O(n). The peak function would require to index the last item in the list and display it, its time complexity would be linear O(n). The size would use the normal size function of a vector and constant time O(1).",6.0,58
16821,16821,21066,e8cc8f379686cf17ff7a79c51f234b372a7158c41925760d6a62468ac2bc253c196a10ef5af7f8e787abc174ba6435f331d902d6901bc07bc87271a8d067f35c,"For a circular array, push, pop and size will always be O(1) in the best case and O(n) in the worst case.  Peek will always be O(1) because we keep track of n.

For a vector where the front is at the front, push_back will be O(1) in the best case, unless we run out of space, then the time complexity would be O(n).  Pop_front will always be O(n) because we always have to copy everything over by 1. We can get the Front of the vector in O(1) and to get the size will always be O(1).  

For a vector where the front is at the back, push_back will have to shift everything over by one regardless of whether there is space or not, so the time complexity would be O(n) as n items would be shifted.  Pop_front will be O(1) in the best case if there is space in the vector, or O(n)  if we are wasting too much space. We can get the back of the vector in O(1) and we can get the size of the vector in O(1).",14.0,58
16822,16822,21067,87b26af5215183ea5d646e967e1e3374a7a4afb5a13a2967680ff8a29d219e9ac775560a42891913325361c21b3cb2f9b5121d0317fb7c951cff2c01aed37b66,"Use the push_front vector operator to implement the push function, time complexity O(N). Use the pop_back vector operator for the pop function, O(N) time complexity and the vector.size() operator for the size function , O(N) time complexity.",4.0,58
16823,16823,21068,3824a0678a0ee80961c81764186a1496645536aadc7127ac81665ef8825202d12ca91cc1dddb49cb3545dd95e3ab23ddf164ccd399cf03acc33959144061677d,"* push - I would check if the space of the vector is full and if it is  I would increase the space by two times its original size by reallocating the vector to a new buffer and then add all the old values to the original places and then add the new one, deleting the old one to free memory. 
	* pop -  I would move all the values of the in my vector to the position i-1 just before it and then if the size is less than a quarter of the allocated space I would half the vector in half by moving it to a new buffer half the size
	* peek - I would return the pointer pointing to the vector(i.e the first thing in the contiguous memory)
	* size - I would return the size attribute of the vector which will be incremented everytime I add a value to the object / vector",8.0,58
16824,16824,21069,09a1699e91053a97e967035388a9bb6bf2333dc132838738d78edc417a8028213044038d23bdf9e5be7458e9014620b5d4a10df02214eb4aa340c740ce44d5c1,"Queue has a public data field which is a vector of things. The push function is a void function that has a parameter of a reference to a thing. It will push a thing onto the back of the vector using the vector's push back function-O(n). The pop function is a void function that has no parameters, and will pop from the back of the vector with the vector's pop back function-O(n). The peek function is a function with return type of reference to a thing that will use the vector's front function to return a reference to the front of the vector-O(1). The size function has return type size_t and will return size using vector's size function-O(1)",8.0,58
16825,16825,21070,8127d4098ce90e5354b83277c230528a4f346dff2268e6e565e170f557f4828895b86ce9e4d45680788cfb7696e91c4b7e7c80cf0ef0611dfea212b6f772071c,"i will first implement a class and put vector in the private of the class 
, implement the each function push, peek, pop and size inside public where we can access them and change them.

Time complexity is constant time for push and pop (to remove an item at the front) for better time and linear  for worst time

we also get constant time only for both size and peek.",4.0,58
16826,16826,21071,02cb07161473723283d91a3c998f4ade4cb197abe855244e901ae8f3133fa745a87cf9dec28bee7621c8d3b8308477fc042faa7e0319e0ad9256c728f396d7bf,"void push(T value)

    add value to the top queuE

void pop_front()

  remove item from the front/bottom of the queue... O(n)

&T peek_back ()

    return a reference to the last/top item

&T peek_front()

   return a reference to the first/bottom item

size()

   return number of items",2.0,58
16827,16827,21072,78249ef9b62941992169ea6ab9335b72fe3732b0d62324e87cfd98782c3176ff3a0f6d77d1563959cb064ffef03d777dd5132e65d5820daed930a9e3247d9f38,"For the push function make a void function that take a thing type Thing and pushes back the thing onto the vector using push_back() function,and for size it will have to be a function that returns an integer value that specify the size of the vector using size() C++ function.These Two function take constant time complexity.For peek make a function returning a reference to an object of type thing situated at vector position zero which take constant time complexity for pop make a void function that pops off the item at vector position zero using pop_front() this would take linear time ",10.0,58
16828,16828,21073,16751d82a0250cf90230a736276250ecd4342c2e9097f12ebacee397740771d03e925ee189c3aaacf702dbec6f3610c7e13e7ed44667c2823433286e585becf2,we have a pointer that always points to the first item in the queue.when we add an item we access the next property of the pointer and point to the new item we added. in the case of removing we can do traversal but having a pointer to the last item and deleting the item. this all can be done in constant time.the size function is also done in constant time. doing a traversal throug each item would be the way to get the size. the peek function will return the first item and not deque the item. we can do this by accessing the value property of the pointer.,3.0,58
16829,16829,21074,20d849b0f14d796b315efcd61e863b25c7b0891949c9f1f08039226267e2ec02fc126e19dc6bac1596ae1c91066636280bb491c789bcd5f5ca3de77e3170945e,"For PUSH I would use the back of the vector and that will take constant time O(1) in the best case and linear time O(n) in the worst case due to reallocation.

For POP i would pop from the front which will take constant time O(1) in the best case and linear time O(n) in the worst case due to reallocation of the vector.

For PEEK I would return a reference to the first item at the front of the vector and the time complexity will be constant O(1)

For SIZE I would use the size() function of a vector and this takes constant time O(1).",13.0,58
16830,16830,21075,ba17ced0b845a961a4ba2b9f572020680e40bd19c35ccad68ac84e48d9cb5d04fd0000feb318fb1b5fed6a59256f91eb5d0cc5f4be4d4f154e8d52a24ea8af8a,Pushing an element will be done after checking whether the queue is full or not. Popping an element can only be done when there is at least an element to delete. Time complexity of push will be O(1) and time complexity of pop will be O(N).  ,2.0,58
16831,16831,21076,2b92088102e0af9a5553cb90ac0d16cccf7d22e656abd8591794202e3ad9e3740967e9bc58b6fe2de9b9f1fca59eea10df4f48ad04955724c20b00283b3e3844,1.firstly i would initialise my stack class,0.0,58
16832,16832,21077,9ab5ee6dcd1eeee42b584dd13d10dfb771aeae24b070596bf8e33f41840796cff5a58f61a4f76bd5d61ec8edd7ee76fc7e403b38a2b713cfce865554906c5149,"* In terms of the PUSH FUNCTION IN A QUEUE, I would add a value to the back of the queue and the TIME COMPLEXITY IS CONSTANT O(1). 
	* In terms of the POP FUNCTION IN A QUEUE, I would remove the item from the front of the queue and the time COMPLEXITY IS CONSTANT O(1)
	* In terms of the PEEK FUNCTION IN A QUEUE, I would return a reference to the front item and the time COMPLEXITY IS CONSTANT O(1).
	* in terms of the SIZE FUNCTION IN A QUEUE, I would return the number of items in the queue and the time COMPLEXITY IS CONSTANT O(1).",8.0,58
16833,16833,21078,fd3ac26e8f1d74669c591d17cfba292d301a38f59035e0e015254638e09238378ffbb05277661aa625df195230a27bb79b8964e830815de826a62bf695fefa00,"* PUSH

-I would use the PUSH_BACK function to push an element to the back of the vector since it is a Queue and in a queue we add at the back. 

-The time is CONSTANT O(1).

	* POP

I would use the POP_FRONT() function to remove/pop the front(first) element of a vector.

-The time is LINEAR O(N)

	* PEEK

-I would use the DATA.FRONT() function to obtain the front item in a vector since it is a queue.

-The time is CONSTANT O(1).

	* SIZE

-I WOULD USE THE DATA.SIZE() FUNCTION TO GET THE TOTAL NUMBER OF ITEMS IN A VECTOR.

-The time is LINEAR(N)",8.0,58
16834,16834,21079,97a01199b925330f29640cdb86e45eea363ff96eb767b66ea518348ab8ed24fd59b309226c6a592a7f7ea6b67fef81cbfd1daad02d4a32f29300da894c457dc7,"when we add data to our vector we will have to add at the back of our data.

if we want to pop/remove some data we will have to remove/pop from the front.

when finding the peek/top we select the last data entered that will be our peek.

finding size its just counting the amount of data we have

time complexity for push back, peek and pop at the front is constant.

time complexity for size is linear.",3.0,58
16835,16835,21080,fa9e03d0ca767f086bcd9ef36b2098757508e1e31055329ce57a6c2012e0fc52ea26b7511314fd601a7a535cdf128ba0717226b541ddae15232dd77b79a7f243,"time complexity will be O(n)

for pop function

data. pop_back( );

for push fuction( )

data.push_front(t);

for size fuction()

data.size( );

for peek fuction(0

data.bact( );",4.0,58
16836,16836,21081,2f3e315687119ead6a818da568e78a6a6a1fca8ffa33209c3dff24c186275e23df6af032db0ab8c3cc902f57fda3972c9cc02a021860b531f2f8a447436717fc,"the void push of any object will add a value to the top of the stack, the time complexity of it 0(1) at constant and  0(n) at linear 

the void pop or peek of any object will return a reference to the top of the item, the time complexity of it is 0(1) at constant and 0(n) at linear",0.0,58
16837,16837,21082,5f87218a9157c9f2740bbc5a076009259b8932c2104f99371f2e9e9e870c16111399d5c3a60f311aebd8ac847ff222666d98c8552349e85bf1bc07e6e8aaa00e,"The element is added to the container and the size of the stack is increased by 1.

The time complexity would be constant.",0.0,58
16838,16838,21083,e1c10c192c9b6713ee5530dae2906c490884e9be67695456a693eb32bfedb4efb69953c8625279092ed97ffe2902abb90cc745c3952924b4e2ed73997890c89f,"For a vector queue, you would make these functions similarly to a vector stack except that the top would refer to the beginning of the vector and the bottom to the end. This way pushback could be used as normal to add elements and a peek at the front would return the beginning value. Pop would use the erase function at the beginning. ",4.0,58
16839,16839,21084,3c19a4ca3efa7d86230abf2250f098b931301930e60c23aba57d34a20945975cd4cccaccd719a3026ae41c4cbdfeb48a8b4d80928036af9a93a5f7cdfaaab709,"For push:

To push back, data.push_back(t).

Time complexity, O(1) usually, O(n) worst case.

For pop:

To pop, data.pop_back()

Time complexity, O(1) usually, O(n) worst case.

For size:

data.size() to get the size

Constant time.",6.0,58
16840,16840,21085,e8ac13437ca4eb4696e3ef433ae3842afba862c0118c6894733767a015023753193111e7d4c262c3227484acd644f4e441faf59e7cd3f61df893fbe34d31e198,"To implement Push:

Simply use the pushback function in which in the best case, there is still enough space from the vector, which will be a constant amount of work. 

If the vector is full, Just create a new vector with twice the space compared to the previous one. Then copy all the items to the new vector, and then pushback the next item. Which will take linear amount of work and thus a worse case.

To peek or Pop  ",2.0,58
16841,16841,21086,7034e661a6b51c59ff4e839b7430fa79082c9a14de4d5507d8b8f51bcf2e8507159f0b9ac4f2f0968d640ca40b95ebbbfcb9a489ff8f5bfe6ee49d4e9a458d5c,"The push function would usually take one push_front vector function which usually has the time complexity of O(1) unless there isn't enough space then it would require a loop to copy the old data to new and bigger space. This has the time complexity of O(n).

The pop function would use the pop_front vector function which always has the time complexity of O(1).

We would need to peek at the front of the queue to know who is next. For this, we would use the vector function front() to see what is at the front of the vector. We would have the advantage of pointer arithmetic which has the time complexity of O(1).",3.0,58
16842,16842,21087,615a61127c6c0ce82fff3b905af9891145f1a8b7de3c813ff28357e83206738e51030e5e11f925cb1ff08e1e1848b449cb4a5ebd866eaf249477de58f163ccf4,"There are different ways to set it out resulting in different complexities. However if you would have a simple linear vector, you could have it so that the top queue is the back of the vector.

You would have to implement a pop_front however.

This would make it so that you would have to

push front in order to add values to the back of the queue, taking O(n) time. This is as to add a value to the queue you would have to shift all the previous values to the right to make space for the insertion

removing a value from the front would be pop_back(), taking O(1)

getting the element currently first in the stack would be O(1) time

and size would be O(1).",14.0,58
16843,16843,21088,6faeacee0c2269025dd90b7721d39fd6ea59274d1116063ca6e894050048f55cfc48de8438d931d22afb7e2c6e6e2971358b83dd0ec2d867cc557d7b6b500315,"If we make the front of the vector the front of the queue we can implement a queue and it's functions in the following way:

Push: we would push_back() the element to the end of the beginning i.e the back of the queue O(1)
Pop: pop_front(), remove the element from the front of the vector by moving each element over by one to the left taking O(n)
Peek would be to get the element at the front O(1)
Size would be O(1)",11.0,58
16844,16844,21089,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"The size function will be implemented using the vector size function and it will have a complexity of constant time O(1).

If the back of a vector is the back of the queue, the pop function will be implemented using the push back function. The complexity of the pop function is constant time O(1).

If the front of the vector is the front of the queue, the peek function will be implemented by returning the first element of the vector. The complexity of the peek function is constant time O(1).

If the front of the vector is the front of the queue, the the elements would to be reversed and the last element then removed by pop back function. The complexity of the function will be linear time O(n).",10.0,58
16845,16845,21090,0210a9d3772d4f5814d5d585f47b6503d720f89ae8ca72b5fb7136f3da85dccbdba73ac11df998e73774b6321c99446733c7c479dc009a4e0dc92678413ef102,"i would implement a push_back ,pop_back which will return push and remove last thing on the vector and this will take O(n) time .the peek and seize functions will return the the reference of the back item and size of the vector and this will take O(n) time.",0.0,58
16846,16846,21091,9140ffa3b52741e2ae246773dfeed94b1141ba7c3dc70e8cb17fb6410cd6b017d81c18ceaa0264d9c4b8354cae095d12f4a720da352b65b62d37bdd0fc9fdc69,"For the push function I would  push to the back of the vector. This would be O(1) but will be O(n) in the worst case

For the pop function I will move every item one place to the left so that the first item is replaced by the second item. This would always be O(n)

For the size function I would return the size of the vector. This would always be O(1).

For the peek function I would return a reference to the first item in the vector. This will always be O(1)",13.0,58
16847,16847,21092,9b486d212bcbfc98bcb7006334a7bd057c017b3b5d6ddec828a1e7c71b279d57abf5933826cc5cd40f31ce09e30273c03c034afd55ad69a350c76adfabdffc7c,"Since a queue pushes to the back, I can simply implement the push_back() function for the vector and store the variable of type thing at the back of the vector and this operation will have a time complexity of O(1) in the best case and O(n) in the worst case(i.e. the allocation of more space is required for the vector).

To peek at the front of the queue would also be relatively simple as I can can just call the front() function for a vector, which will return a reference to the first item in the vector. This will always have a time complexity of O(1). As no traversal of the vector or any other operations are required and the function simply accesses the first element of the vector.

The pop function however will always require the vector to be essentially copied excluding the first item. As a queue pops from the front and a vector does not have a function for this due to it being inefficient and always having a time complexity of O(n) due to the entire vector needing to be copied, excluding the first item.

The size function can be implemented simply by returning the size() function native to vectors, which will have a constant time complexity of O(1) as it is just returning the number of items stored within the vector.",13.0,58
16848,16848,21093,0ddebbd83df885f86ba1c96720608778be815c854a9f153df224b96b22cf260eb651e6e1d04778d3c06f6de0d3c75049a5f3bb4b6575599d6f50e21a7074d16e,"I would use the vector push_back function and the time complexity in the best case would be O(1) and worst case O(n)

For popping at the front i would use the vector front(), function to get the location of the element at the front then set it to null and move every element in the vector one space back. This will have a time complexity of O(n)

For peek i would use the front() function of the vector which will be O(1) and for the size i would use the size() of a vector and will take O(1)",14.0,58
16849,16849,21094,db0698cd03866d48da0c9cab1c327e767c6fb2c70ab318867db7094af47e41c16fc1528b63425d8d7a1a4e5cc071eef840fd0e4c5113866d0139015edb52f238,Void the push function. increment the top position.  Then insert the element on incremented position. This will be a linear O(n) complexity.,0.0,58
16850,16850,21095,efa2c5b70f1ad8f0aebabd9a8317831d8e117c559aa0a29951f0659587ce28ce45a8ffe00e2d128d5b1b92e6f8033ccb1e7464d9f2f119aa95332037f62a3b76,"The back of the vector will be on top.

Push(), allows one to insert an element but only at the top of the stack. best case when there is space will be 0(1), if there is no space in the vector and a copy needs to be created the worst case is 0(n)

Pop(),, removing an element but from the top, best case is 0(1). worst case is 0(n) when there is additional space that needs to be reduced.

peek() allows one to view on the top of the stack, using pointer arthimetic. 0(1).

size(), n_items returns which is the stored values 0(1)",4.0,58
16851,16851,21096,1b575ce85f9fe9d462e1de73f4e66ff04c921a768d297956a2d166b33e02a5691d14de4e07fdb716975b3003397dd6ecfd657024c0a233117dfee4b6480ebdcd,"push -> I will use the pushback function of the vector data structure to push items to the back of the queue.

    complexity -> O(1) for best case and O(n) for worst case scenario.

pop -> There is no popfront function of the vector data structure so I will have to traverse which means n - 1

    complexity -> O(n)

peek -> I will use the vector's front function to access the front(peek)

    complexity -> O(1)

size -> I will use the vector's data.size() function(in built size function) to implement it

    complexity -> O(1)",14.0,58
16852,16852,21097,c2e3a17d6cc0156e335ca9215e55053ddbc80682871f8957ca1d1b73d39dbe24e0950e6728cd273bbd1fbaac4e9fc1f8fc1eeb009c8b2565447f198e841deab0,"In a queue I would have to use the push_back function in the vector, which is constant and in its worst case when there is no unallocated space its notation is linear.
In order to pop I would simply use the pop_front which is constant.

For the size the function would then return the number of items in the vector and the peek will return the first item of the vector.

The peek and the size will be constant.",10.0,58
16853,16853,21098,e1db971413a3e8370e48a08bd90e6c532854614ec97bf2846a8b6f64d7d2d64fceb404c5b40a925c2c496078dab9556b9aedc866e91bea3a7a6a8dc8cc19eb5b,"Using a vector<Thing> as the underlying data storage for a queue where items are added to the back and removed from the front, the push function would be constant O(1) time in the best case, where there is available space to add to the back of the items in the vector, in the worst case, there is no space left and the vector has to reallocate and copy n items into a new vector with more space, this would be linear time O(n).

The pop function would be linear time O(n) in all cases as reallocation and copying of items across would be necessary. This is because vectors are allocated on the heap, and a pointer is required to point to the first item in the vector in order to access the rest of the items.

Peek would have a constant O(1) time complexity as this would be accessing the first item of the vector. Size would also be constant O(1) time as the vector keeps track of the number of items that it contains.",14.0,58
16854,16854,21099,ca7ca134b5efdd7b26013cdee3bcba7329b07570412673ca953a2b1fc000b358026f967889f2b4b641fef26d116ce971213d8a9f77c08db97c244ae7f54e090e,"I would use the Vector defined in the STL

I would call the pushback function to push a value to the back of the queue : O(1) COMPLEXITY

I would call the the back function to peek into the queue : 0(1) COMPLEXITY

I would call the pop front function to remove an element from queue  : 0(1) COMPLEXITY",4.0,58
16855,16855,21100,83c5e0cccc2c84d6aa6c84996703c9788a4c77ad197dc9cbe544f356daab1002c8cb4669771a7a17cb1f5a0ca37aa675d40cb959b05635bc4844ce29a466fa7e,"For the push() function, the vector member function push_back() is used to define it. The complexity is O(n). front() will be used for the peek function. The complexity is O(1). size() will be defined by the vector member function size. The complexity is O(n). For pop(), vectors do not have pop_front() so a new empty vector would have to be created, then starting from the second item, the values are pushed to the back of the new vector, making it seem as if the first item was removed. The complexity is O(n).",11.0,58
16856,16856,21101,5c96945f14d6fc788ed8c6c36dabf314debb1526e588422f61ac844f148e394c747509da6ebf3fac148319b89d19dab295d5360db7c4991b8db71ccf538d7808,"For the queue, I would use the normal push_back function to add objects to the vector(it would take constant time(O(1)). 

I would create my own pop_front function that copies each object in the vector 'one space to the left' and deletes the last space to remove the first object in the vector, which will take linear time(O(n)).

For the peek function, I would use the front() function, which takes constant time (O(1)).

For the size function, I would use the normal funtion for the vectors which takes constant time(O(1)).",13.0,58
16857,16857,21102,eec934572d7644ba0121c8b2feb2c582e9f3f4f5b58187b8858bc2ee24ad1c13bedfb2cdb5029267bc11b865502439fbacde60c9046792350b575350ddc17ef6,"For the push, one would use the push_back(item) function as that makes the item go to the end of the vector and become the last structure. Time complexity: 0(1) in the best case as one would just have to add an item to the back of the vector. 0(n) in the worst case as one would need to create a new larger vector (by copying the first vector to the new one and allocating more empty spaces in the new one) to store the new item as the previous vector was not large enough.

For the pop, one would use the pop_front() function as that makes the first item in the vector get deleted. Time complexity: 0(1) in the best case as one would just have to remove an item from the front of the vector. 0(n) in the worst case as one would have to create a new smaller vector (by copying the first vector to the new one and removing excess empty spaces in the new one) so that the vector does not have unnecessary empty spaces.

For the peek, one would use the front() function to get the item stored in the first place. Time complexity: 0(1) as it is returning the topmost item which will always be in the first place regardless of the size of the vector.

For the size, one would use the size() function which gets the size of the vector. Time complexity: 0(1) as it is returning the size of the array, just returning a number.",11.0,58
16858,16858,21103,267e2a74684712f40153e983cf911454f693aaba7aeefb5a018f4e1b42bb05582faee8c5c865be8869988dea6e1c2f220a507c49209244aad2cd13359f2247d7,All functions will be constant besides size which will be linear.We'd use push and pop to move the queue and peek to know when exactly certain things are.,0.0,58
16859,16859,21104,b1b3e86f0d270a61f8fd878f224a3849ed613dcb005f40bfd930beec1496e89a0e58f28b9b719a548b167e0db0c44afd5aae82094d2f118c0287dc3bf2b65cac,"push , use push_back () ,O(1) .

pop , use the pop_front ( ) , O(n) 

peek , use the .front ( ) , O(n) ,since we traverse through the vector and return an item at the front of the vector ,using the at (i) function .

size , use the .size ( ) ,O(n) , since we traverse through the vector and return a count.",3.0,58
16860,16860,21105,89502ac0aa9bcc7e1f53c6f2ab1184a643f5c96abf038408f562f5cb7340154d0c96d136d3c4ce774773aa13f3d95a0a98c70e80020a05dce05a8835fe30adf5,"1.void push(&Thing) add values to the top push time complextity is o(1)

Adding to the top of the stack

2.void pop//remove items to the top

T& top(_)  complexity o(1) worst case scenario O(n)

size_t_size()  O(1)",1.0,58
16861,16861,21106,ef56d487f412ffdca7b3412858b2ccd1fa21fc365016661f00994f5e06683c6e545b948b70c4775a9a839e6049995e36f03b1f06a7374933a80a9013b6052c37,"you would have to push back , which means you transverse through the entire vector and this will result in a time complexity of O(1) in the best case and O(n) in the worst case. with peek and pop front , we will not traverse as we can just remove from the front and get out first element , hence a time complexity of O(1) and the size function will work as normal and this will have a time complexity of O(n)",7.0,58
16862,16862,21107,f2a1d44943cafd29447c9cc6d850c73ca115efbe45cc60a50c497d9c39593f6c44e4c2d4facba5ee2393c40106c70b0307d8a427a20ee6b2ecb0031a02f6d25c,"In a queue, push() inserts an element to the back. After executing this function the size is increased by 1 and uses a 0(1) complexity. pop() is used to remove an element from the front and uses a 0(n) time complexity as it has to traverse through the queue from the top.",4.0,58
16863,16863,21108,3d924476d27d7afee3c446be78c3bfa807a26922031bb4eac61f97a7c6f17eb08bf7666e6b4cc961e48bd773db3725b57e5ee0d093b4129e2c89bae53ea3a074,"push_back time complexity O(1)

pop_front time complexity O(1)

size_n time coplexity O(n)",0.0,58
16864,16864,21109,dc1d80fcfca2cd7f4c0d66c0e3645622562d53654a85ac238b9c0b928dfd07eeca15aea65682a467ac6bd4135a13a6043d96321ee55136fa0664700d6e749201,.,0.0,58
16865,16865,21110,e627fede4d8a070ca528e22154030076326cf75a860ce09e9231ab5eb164fd945cbc3f05b7190cc8d307288292134d5c83514ef1ec1b1c4974bcf393c3c20f68,"NB. I didn't know if implement reffered to how to make the function or rather how we would use(implement) the functions.

To push back you would need to insert the value at the end of the vector, the standard vector has a ""back"" accessor (as well as an already made push_back function) using this we would be able to find the last element and add the new item to the queue making the time complexity O(1).

To pop back we could access the first element via the ""front"" accessor and from there remove the first element, however due to the nature of vectors this would require every other element to shift one down making the time complexity O(n).

Peeking at the front would be much less time complex as only the ""front"" accessor would be needed making the time complexity O(1)

The size function of a vector is constant due to their nature making the complexity O(1), however if we were to do it ourselves we would need a function to count each element making the complexity O(n)

In terms of implementing them 

pushback is used whenever a new element is added to the queue O(1)

pop is used when the oldest (i.e. the first) element must be removed O(n)

peek is used to check the oldest (first) element O(1)

size is used to get the total number of elements left in the queue O(1)(if using std::vector.size()) O(n) if we are making it ourselves",11.0,58
16866,16866,21111,0dd6ddfbe50025d9a72df696362b0bdfb49434124c6d6642bcd0c15ba9544de38a86488e790b653cf1d9ab0bbd206e27a92d4ffa059eb91de07bea325c7f7613,"To push an element x onto a stack, we increment the top of the stack and the set the top of the stack to be the element x. The best-case for this is O(1)-constant time complexity, and the worst-case for this is O(n)- linear time complexity. 

To pop an element from the stack, we go back to the top of the stack and decrement the top of the stack. The time complexity is constant for best case, and linear for worst case.",0.0,58
16867,16867,21112,1ec073b8c8fd76df82abd5195dc059b3bb969a0dcda29a3183557cfcb9cf9edfa565003c0b81e18a702d15e745574294a8e18968fa713fdba196a2197d0ea2e5,"If in a queue I add an item to the back of the vector and remove an item from the front of the vector, I am assuming that queues use a first in first out principle. 

Pushing an item in a queue would be the same as pushing an item in a stack since it is being added at the back of the vector. I would use the push_back function to push an item. For the best case scenario the Big-Oh notation for push would be O(1) and for the worst case scenario the Big-Oh notation for push would be O(n).

 As far as I know, std::vector does does allow for the pop_front operation. Since I have to remove the first item (A) I added to the vector but cannot use pop_front, I would first check if the vector has enough space then reverse the vector using the reverse function and then use pop_back to remove item (A). The Big-Oh notation would be O(1).",5.0,58
16868,16868,21113,0cd06500f6bc04ca04d6df402c164435dd4b1e3f62d49a5f81d45b91f4a6f4ac2ae8232fc2f485e2ef108625ecea2f61c466c82dcbccacd3d327b9b3b7efa90a,"In this case, I would implement the queue using vector<Thing> by having the back of the vector as the bottom of the queue, and the front of the vector as thr top of the queue.I would have four functions which would pull from vector<Thing> which supports push,pop,peek,and size . Push would be push_back and it would have a best case being constant and worst case being linear since we would have to reallocate memory. Pop would be linear since i would have to move each item to the left/n-1 over. As for size it would linear because i have to traverse through the vector in order to get its size. Peek would be constant since the front of the vector would be the top of the queue.",8.0,58
16869,16869,21114,65a6873c33aadcc2f385dcf41fe7257442b3db3e7c6b66b6512e8c943bfc186cd6a55217da7df9053eb7519b0f2cce5a776966d54e638536f0ae9c05ec98e97b,I would ,0.0,58
16870,16870,21115,bf4b5731c3c3bd0f2b59e631e277805959da8b9efedbe010df49f525b49b713ed8678bb3e54ddfd542bb302e79e236dfb9ec30ec253f0f80d3cd72c6a5094fbc,"The pop function would have to make a new copy of the vector and as it adds the new values in it it will see the value it intends to delete and not add it to the copy thus deleting it from the vector O(n). The same will happen with peek except it will copy the value it finds into the vector and return the value, O(n). the push function will function the same except it will add a new value into the new vector ,O(n). For size we also create a new empty vector as with the others and add the values one by one while increasing a counter as we go and returning the counter value at the end, O(n).",1.0,58
20059,20059,24304,6c39b5e6a07e95287c054b22b9b14ae724def23d44c2473ffa57fa66d0dc3ed81fdc207205fd37cd3342b92b02f8364dc720791f8b6724f778e183c98d663fa5,"A circular array works by using a standard array while having the ""functional"" index of the array loop iterate dynamically through the standard index of the array.

By storing values for the ""functional"" front index of the array, size allocated to the array and amount of items in the array, one may achieve dynamic allocation of the ""functional"" index. Pointer arithmetic is used to ensure the indexes never leave the scope of the allocated memory of the array but instead loop around said memory. As items are added(pushed) and removed(popped) from the array, the front index and amount of items in the array are changed accordingly. Pointer arithmetic allows these functions to operate in constant time(with the exception of new memory allocation due to a lack or excess of memory availability). The storing of the value of the beginning of the ""functional"" index and by arrays using pointer arithmetic allows for the value stored in the first position of the ""functional"" index to be accessed in constant time.The storing of the items of the array allow for constant time to return that value.",10.0,68
20060,20060,24305,be6529d2c60e9c3e44398e6d6378522b796199a001be8bd7e7bf876610ef85fd8204961bc4cabc5a2506d1dd5b074658c765a8f7b3311d9493c6efa1d870167b,"So the circular array is a normal array but what happens that when the array has reached its last block it will use the module operator to go back to the first block in the array. We need to keep track of the allocated memory in the array (a), the number of items in the array (n) and as well as the first block that has been allocated which is (f). Every time the pop function is used the n is decreased by 1 and f is increased by 1 as the first item is removed and then first item become the next block next to the item removed from the block. and then when we want to use the push function we use use the module operator so we would say data((f+n)%a) this will help us to keep the array to go back to the block 0 even when the block has reached it last block.",11.0,68
20061,20061,24306,af813686acb18a064eece7968dc86f7e1ba2e2c4ebcbfb61de992275f213a5fe2248d15ae968c61ff6c270f401a739d21132339ee0a42afa471e88a17c352ab9,"In a circular array the front of the queue(first item entered) is tracked and the number of items in the queue and space allocated are also tracked. To add to the back of a circular array the equation (front + items)%allocated is used which allows the array to be ""circular"". To remove the front item the front tracker is increased by 1 and ""modded"" by the space allocated ""(front+1)%allocated"" and items is decrease by 1. Eventually the front of the circular array will be overwritten by adding items to the back of the queue. Due to the ""mod"" the circular array will never be accessing memory that it hasn't declared. The queue can then be implemented in constant item because there is no traversal through anything and pointer arithmetic is used. All functions are therefore constant time.",10.0,68
20062,20062,24307,7a27fb1fa642a9bd3d76e8ce98be5e4779f4184eab8b901b0ee0d165d466de6122db493ca631d33ef289f724ffb838136d578f3b72df159667217c69ae154ed3,"A circular array is an array that keeps the first element of the array as the next element of the last element.

It can be used to implement a queue in O(1) time by making use of the modulo. A cicular array makes use of empty spaces unlike normal arrays after deletion and insertion. A queue can be implemented by circular incrementation, once we reach the end of the queue, we start from the beginning of the queue. This is where we will use modulo division with the queue size to loop through the circular array. 

We need to keep track of the SIZE OF ARRAY, the number of ELEMENTS ALLOCATED in it and the INDEX TO THE FIRST ITEM (the one in the front of the queue). The size remains constant unless reallocation occurs. The num_allocated (n) is updated whenever we use push (n++) and pop (n--). The index of the first element (F) is updated when we use pop (F++) because the first item in the array has been removed and the element next to it (F + 1) must now become the ""head"" or the first in the array.",11.0,68
20063,20063,24308,f7bbac457e26e926aa83f65c706f322284bcae4a69df367438ec5060865432bf63d2eef51ed308d86119a8e1745e619fe74662cd103d43378e65328b7630ff57,"A circular array works by taking a normal array and coding it so that it loops back around itself rather than constantly having to add/remove and copy data with each addition/deletion. You need to keep track of the amount of data allocated (a) as if all data points are full you would the need to copy the data into an increased array. You would also need to keep track of number of items (n) currently in the array to ensure that the number of items is equal to or less than the amount of data allocated. Lastly, you would need to keep track of which item is the front item (f) so that you can correctly add to the back and push to the front. This allows for O(1) time complexity as you are able to do pointer arithmetic for ""push_back"" with the formula (f+n)%a as well as with the ""pop_front"" with the formula (f+1)%a. ""Size"" will be O(1) as the data is contigious and ""front"" will also be O(1) as you are keeping track of which data is first using f. ",14.0,68
20064,20064,24309,c318ecd5c05d3ffa65238b75e8aa9e67390cc6fb32c2fdbfaf84c4d21eee7f78cf713a8bc77a69838390c129742df9afc0ddd3cf48a8b7ef5ea2fb0f43dc4114,"A circular array loops over from the end of an array to the front of the array again through iterations of the indexes (using the modulus operator in implementation).

We use it to be able to pop and push in constant time if there is still space in the array. Push would do as a normal array (but using the modulus operator to wrap around the array) and add the new item at the back. Pop would simply increase the value if the variable storing the value of the index of the front item by 1 to make the next item the front item and then decrease the value of n_items by 1 . The other functions would work the same as they did with a normal array and in constant time.

We keep track of the number of allocated spaces for the array, the number of items in the array and the index of the front item of the array. Each time we pop, the number of items in the array decreases and the index of the front item is increased. Each time we push, the number of items in the array is increased and  the new item is added to the back of the array. The number of allocations increases and decreases depending on the number of items allocated as with normal reallocation ( doubles when array is full, halves when array is quarter full).",11.0,68
20065,20065,24310,c75c72f439ed0a1083505ca2fb274424bfa93184c45c67c47245732cd59fc54e342192b7a0a8538fb3676603ded389cab9a3431e9d476a9d9b140adb5ff30721,"We need to keep track of the head pointer and size of the array, this way we can push back in constant time and pop front in constant time since we will have easy ways of finding the addresses of the according items in the array.",0.0,68
20066,20066,24311,06f90aca60b4b2db0e6d8bb78d0ed0da22ceb02b561b842eee51951b0e04be81e8817f795eb9597349f2e3c12b7befca0ed36322cff788052acb9b91388f1fdc,"a circular array works in that once all the memory has been used, it will loop around to the front of the array.

we need to keep track of the number of items (n), the front item (f), and the allocated space (a).

in the best case for a circular array all the 4 functions will have a O(1) time complexity, but the worst case for push and pop will be O(n) which will occur if we run out of space and need to reallocate.

the values mentioned above (n, f, a) are kept track of in the push and pop functions.

push - _data[(f+n)%a]_ will make sure that when the end or the array is reached it will wrap around to the front and add the new value in at the front at place 0. _n++ _will then increase the counter that keeps track of the number of items in the array. because the same function of arithmetic is being done, the time complexity will be constant O(1).

pop -_ f=(f+1)%a_ will allow for the pop function to wrap around to the front when it has reached the end of the array and remove the item at place 0. _n--_ will then decrease the counter that keeps track of the number of items in the array. because the same function of arithmetic is being done, the time complexity will be constant O(1).

the size and front functions are the same and will always be O(1) as they are accessing one thing (size is getting n, and front is getting the value at f)",15.0,68
20067,20067,24312,3227954877ff6b3d6e5d415eabaacb6ee56a5809874f349fcc72cbd6b74b9924802065f3198d52fa435eef46404fa2ce0465698400217a4b7b18ef03d8cc91ec,"A circular array is a block of contiguous memory like a normal array, except that we treat it as circular, once we reach the end of the array we can loop back to the beginning. We can use pointer arithmetic and as long as we keep track of where the front of the queue is and the number of items in the queue, this can be achieved.

ENQUEUE

We want to insert an element at the back of the queue. We look at the index at which the first value is stored and the number of items. By adding the two together and taking the value % n_allocated, which is the capacity of the array, we can insert the next item at that position so long as we have not run out of space. The % operator will take our index back to the front of the array if its value exceeds the capacity. As a result of pointer arithmetic this can be done in constant O(1) time. The only issue arises once we have filled the array (queue) and must do a reallocation. By using clever reallocation techniques this can too be scaled down to O(1) - amortised constant. Our number of items should be increased by 1.

DEQUEUE

We remove the first element to dequeue. We do not have to do any copies, all that has to be done is for the first index to move one to the right, so we increase our index of the first item by 1. The calculation would be (first + 1) % n_allocated, and decrease the number of items that we have. This takes the same amount of time always so this is O(1).

FRONT

Using pointer arithmetic we can return the front of the queue in constant time

SIZE/EMPTY

We do keep track of the size so that can be returned in O(1) time, to check if the queue is empty all that needs to be done is to see if n_items = 0.",15.0,68
20068,20068,24313,aba8ccda4763601c960552191c4b4ea7d3e94521d25f84c03f905aac0bf9578acabd1a7e87e98918c1a32dbc6bc0f00b14222dbc9e37a19a4efb13f1c52924d7,"A circular array is a circle-like structure. Here we use FIFO. Our last item is connected to the first item, just like a full circle. The circular array keeps track of the number of items in the array, the index of the front of the array.  It also keeps track of how space has been allocated to the array.

When we push an item, number of items variable  gets incremented (the number keeping track of number of items), similarly when we remove/pop an item, the number of items variable  gets decremented. This shows that everytime we push and pop, the number of items variable has to be updated.

The last item can be fetched by adding the index of the array to the number of items. Also remember to update the front when we use the pop function.

To get the size , it will take O(1) time, since we are already keeping track of number of items.

Pushing an item will also take us O(1) because to add an item, we reference the items index by using data(front + number of items) % number of space allocated). This operation gives us the freedom of going back to the front of the array when we reaxch our last item.

front() also takes constant time since we are already keeping track it. pop also takes constant time and works very similarly like the push.",11.0,68
20069,20069,24314,c2a635a9bcf4ad40fa50102eeb50a8298caf1f43a284d43931e8d6ff78372592382df0d5a087e759cf9a231e99eb6b2b3a8890e03edb12bf9295b2611174eebb,"A circular array is an array that has each end connected to each other, i.e we have our first item next to the last item of the list. When using a circular array we need to keep track of he number of items in the array and the position of the front of the list as this will continously alter. To implement this we use modulus arithmetic (%), therefore when we enqueue a value to the array we using the front+number of items in array to determine position and place the value there, for dequeue operation we use (front +1) modulus number of items in array and this gives the position of item. After using either one of these functions we need up update the number of items and front position. For peek function just return the value at front and for size return the number of items that we were tracking.",11.0,68
20070,20070,24315,e7c9b4fd869eb791a63c71759d17fa7e8a93618d661588fa6ae371946756531c0923d86aafe2bfd7289d74b69cb5fe841e3839957a75e6446f2d8394b4178536,"A circular array is an array that is continous/wraps around such that elements can be accessed in a roundabout way. It can be used to implement a queue in constant time by making use of the modulus operator which gives more efficient access to its content.

In order to achieve this we keep track of the following values: 

1. allocated space(n_allocated)

2. position of 1st element (f_pos)

3. number of elements (n)

When pushing(back) we INSERT THE NEW ITEM AT THE POSITION [(F_POS+N)%N_ALLOCATED], then INCREMENT OUR N.

When popping(front) we DECREMENT OUR N and keep UPDATE OUR F_POS TO BE (F_POS+1)%N_ALLOCATED",11.0,68
20071,20071,24316,666d09a4d8260961dbb488b896e8680fe46f9012a9bfa6adbe518edfaed179e00538132a0e660a988cc51e3f8b8695b7b78d6679f0a1e7d0f26361ce20a96384,"A circular array is very similar to a normal array but it wraps around itself, as we add and remove items from the array, we change the front member to index the new front of the array.

Enqueue: ( O(1) )

data[(front+size)%n_allocated] = new value;

size++;

Dequeue: ( O(1) )

output = data[front];

front =(front+1)%n_allocated;

size--;

size: ( O(1) )

We use the size function

front: ( O(1) )

We would keep track of the front of our array.",14.0,68
20072,20072,24317,8988e05f865164f4560af96560c21e55905eac0bb5f61f3d6e278f9698c3b2aef4e2c138e098da5e867aaa523133fd657970eaa9429e994d798d7fd717f54fcc,"A circular array is an array that stores items in a contiguous block of memory that is treated as a circle i.e. when the last cell is used we go back to the first cell of the array if it is empty. This way, we can access the first item in constant time - O(1), and the last item in constant time - O(1), as we can use pointer arithmetic for both.

For this structure, we need to keep track of the index of the first item and the number of items stored (which allows us to use pointer arithmetic). 

When we push or ""enqueue"", we add the number of items stored to the index of the first item to get the index of the next cell and we increment the number of items stored.

When we pop or ""dequeue"", we decrement the number of items stored and increment the value of our first index (since we remove from the front of the queue).",8.0,68
20073,20073,24318,ab914ab560d18c5aef3e43bda3ed23f3106afabfcaabd71fb45ebbdc423746252b1d705ea396aa70f877858829d5c8d335f73b945106c9ea584789a7d7f0ea77,"A circular array allows us to loop around our array. We do this by keeping track of the number of items in our array as well as the position of the front of the array. We add items to the array by adding the new item at the position given by the sum of the front position and the number of items unless the sum is greater than the indexes we have in which case we loop back to the start using modulus (%) division. Every time we add a new item, we increase our number of items tracker. Every time we pop, we just increase the tracker for the position of the front and decrease the number of items tracker.
Push achieves O(1) complexity as we just add an item at the index, worse case is that we have no space left and have to reallocate with double the space.

Pop achieves O(1) complexity as we just remove the item at the front tracker index and increment our front tracker, worst case is that we have too much free space and have to reallocate with less space.

Peek achieves O(1) complexity because we have the index of the front and can use pointer arithmetic to access it in constant time.

Size achieves O(1) complexity because we simply already have a tracker to keep track of the number of items that we have in our array",11.0,68
20074,20074,24319,8f8e96eb5a28d15c7802d177c96b97e53c9c9c2a37389d558dc50a5be6ad84289d3986f782da265340d7d86d9d174957d8d67890ddc79dd4587dd919a3bfb09b,"a circular array is an array where the beginning(index 0) of the array is treated as the ""next"" of the back(last index) of the array

when the last allocated space of the array is reached, it will ""loop"" back around to the first allocated space

we would need to keep track of:

	* where the front of the array is
	* how many items are currently in the array
	* how much allocated space the array has

how are they updated:

	* number of items is incremented when an element is added to the back of the array, and is decremented when an element is popped from the front of the array
	* the allocated space of the array is updated to double the amount of the previous allocated space if the array needs to be reallocated (needs more space), allocated space is decreased if there is too much space not being used

	* where the front of the array is is updated using the modulus operator

push_back, back, size and empty are part of the STL and take O(1) time

to pop an item is O(1) time as where the front of the array is simply needs to be updated
we keep track of the front of the array O(1) time",11.0,68
20075,20075,24320,17a5fd9d02d6fba8d8046ace71c42e033c0f094c5a424e213efe17ca2b15dcda4339210b67d2e20cb931a5cb55e9b6fb5621dde12a8a5e6da612e051b176b44e,"A circular array is just like a normal array except when there is no more space, you loop around to the front of the array.

TO IMPLEMENT IN CONSTANT TIME:

PUSH: You start at the first index and add to the back. To get the first index, you find the mod of the front index + the number of items in the array and the amount of space allocated.

POP: You move all the items in the array one step forward by finding the mod of the front index + 1 and the allocated space in the array.

FRONT: you just return the item at the first index

SIZE: return the number of items in the array

VALUES TO KEEP TRACK OF:

	* amount of space allocated
	* number of items in the array
	* the position (index) of the front",11.0,68
20076,20076,24321,c7d75d976a010a38db71e259afee15ce7c42ba18fa8ef2214021124356299e2bc696f235d69042a2e7d6021b611ee4096167f90988dc7b1e755fca98c40f31fd,"A circular array is almost the same as a normal array, except that fact that it allows us to loop from the back of the array to the front. It also gives us the ability to change the index of the value which is in front of the queue. We need to keep track of the allocated space of the vector, the number of items in the vector and the index which is considered the front of the queue. We updated theses value by incrementing the size when we add items and decrementing when removing items. We update the front index by adding one when we remove an item from the queue. We add values to the array using pointer arithmetic to determine the index in the array. Taking the mod by dividing the index number of the front of the queue plus the number of items stored in the array with the number of spaces allocated from the vector allows us to loop over the array. Since we keep track of the number of items in the array, it takes O(1) to get the size. We use pointer arithmetic to add values into the array at the back of the queue and it takes O(1).",10.0,68
20077,20077,24322,d5eef99882213e9e893ef6d31b163cddd65b11b328a038af368c63b9dea5c55582d674f73b7f44a7ffb0e808a2c14f224354666b5c8da68a3cf145583cdbcada,"values to keep track of are the front, allocated space, and the number of items in the circular array. To update

allocated space, you multiple allocated space by 2 if the number of items is equal to the allocated space.

 ",6.0,68
20078,20078,24323,cb120576f9fc254cce2a2bdcc2fab8a2f95f1ad24a5398cde6a97bb68344852b25ff6ddb6448c5c344141e6c8f5ee1dd504e841ca984819c02a7811908c51bc8,"A circular array will keep track of three values, firstly the number of items in the array, secondly the amount of allocated memory blocks, lastly it will keep track as to what index holds is set to be the front of the array. 

Each time we push to the circular array we would so by starting at the front index of the array and pushing to a position that is the, number of items in the array, away from the front index, we will also then increase the value that keeps track of the amount of items we have, the number of items allocated ensures that we can still push to the array if there is an item at the back of the array. As we do not have to do n traversals to push to the value in it is done in O(1) constant time. 

To pop from the array we will start at the front and pop that item, once we pop that item we have to update the front value to be the next value in the array once again we use the number of allocated memory to enable us to set the new front index at the front of the array incase the value we're popping is at the back of the array. This ensures that it is all done in O(1) constant time and not n times.",10.0,68
20079,20079,24324,16f09d60ea55f541a3437e3e2ab8e9c69f838f50f98dec712996c73779cd9f654e7fa72007ae7a3b8d9cb813c8fad8d686dc40ba57c222e292c85b1a88fc8b53,"* it works like an array but in a circular form. We can loop around as long as we have space in the array, we can insert into the array. Memory is arranged continuously. 
	* it can be used to implement a queue in O(1) time because we don't need to shift every single item in the array by 1 (like a vector which is very slow). Inserting at data at the front plus no. of items in the queue. and popping is n--; F++. we can wrap around the circular array using the mod function which enables us to push and pop in constant time.
	* We need to keep track of the number of items that are currently being stored in our array and the position of the front item inside the array. This enables us to work out where the back of our array is at any time. 

these values are updated by updating the number of items. and seeing where the front is. ",8.0,68
20080,20080,24325,db2da6294f4863255b8e851f3219cc1d358a9a52af31fcce04dfd21a77bd1b6105ebfb54ad3aa0cbea5dc9fb93c67b5af9e1ff40b17fbd626a20ad3636813679,"For circular array we will need to keep track of the:

   number of allocated spaces ,which is simply the size of our array.

   number of items in our array so after a push back we add one and after the pop front we subtract One.

   the index of our first item in the array after a pop front we add One on our index that will be our first item

   after the pop front.",10.0,68
20081,20081,24326,66ba5975b098f5fa2bae0b86dceb6b280b99b8f4c6fff5dafe0a067b8a9153b49a39abe1525261732c63d25886c01c121ff46cf2ab2721a603f04674ea202257,"A circular array works in a similar way to a normal array in that the memory is contiguous and you can use pointer arithmetic. Unlike a normal array, the elements of the circular array need not be from the beginning of the array. We therefore need to keep track of the number of items in the array and where the front of the array is. By knowing these two values we can work out where the end of the array is. As a result of not having to copy items to the left or right when removing or adding elements to the circular array, we are able to perform these operations in constant time. For example, when removing the first item, we simply remove it and then update the size variable and where the front is. We do not need to copy every element to the left. ",4.0,68
20082,20082,24327,a0a0e3863f2cfe81dc13120d1d5fb28060efbca078cff0afc0ca4a53755acf909a3b28053a432d02251e8d53776e3aedf7eeff75f48fc36029b0d4fb7d46aa25,"A circular array works by having a pointer to the first element which can shift when items are popped from the front. This is useful because it saves us from having to copy every item when we pop_front, thus allowing us to perform pop_front in constant time.

For a circular array, we need to keep track of the front element, the number of allocated spaces, and the number of filled spaces. In order to place items at the correct index value, we use modular division and insert new elements at index: (front + number of filled spaces) % allocated spaces.

When the array is full, we reallocate, ensuring that we make the front index item of the old array zero in the new array.",11.0,68
20083,20083,24328,4a10096efbe473298c3ffaa590c64747a3f122d6138157d16b669b6d6757b1ee312e247b5d7de57197c1100b67d525e21d2bdf5719b1e5397849be3138642057,"A circular array works by allowing an item to be inserted in the array, such that, as long as there is space available, it can loop around the available allocated space of the array without constantly having to reallocate, i.e., the the next item after the last item, is the first item.

It keeps track of the number of items currently stored in the array, as well as the position of the front item of the array.

The no. of items is increased/decreased whether we add or remove an item of the array. The position is incremented as we remove the item in the front (that was inserted first).

It can be used to implement a queue in O(1) time by: continuously being able to push another item through pointer arithmetic (unless it runs out of space) ; being able to pop items simply by decrementing the number of items and by incrementing the position of the front item ; being able to return the data at the front (by keeping track of it); and by constantly keeping track of the size (by keeping count of the number of items).",11.0,68
20084,20084,24329,562a79f866657142ac8bf9d260020a41dd948177d2bce6c88383e228d52056cf2d2544e838847e98137352689514e6b5fccb58b9b8779b353c6c283dfc7313ad,"In a circular array we think of the last element as being close to the first element such as in a circle

For most implementations of this buffer it can be associated with how a std::array is created,  with constant capacity.

A possible implementation of a queue from a circular buffer would  be to create a circular array of length 2n if we require n elements in our queue and we would use the std::vector for our implementation of the circular buffer.

We would have to keep track of a variable which tracks where the first element in the second half of the circular buffer is , for eg when we pop from the back we would nullify(data type dependent) the item at the n + variable position and in so doing  we would have popped from the front of the queue

enqueue would use push_back as required on the first half of the circular array which would extend into the second half. The problem with this implementation is that it uses up 2 times the required memory without ever doing anything on the first half 

the push_back() will be different in the circular buffer as it will be using the [] operator, we would also need another variable which keeps track of when we enqueue so that we dont enqueue  at the same nth position everytime but would be updated by k if we enqueue k items,another problem with this occurs when we enqueue many items  withouth dequue which would then overwrite the existing elements at the frornt'",0.0,68
20085,20085,24330,33903c4df6729a45e2485f57a528848aea77fb0ac81607f602f6f53f80eb513d5b18fef57c086d43fef4cdb3f78bbc1f8da0bcaa1e67afb26268e9484bbb4ded,"A circular array is very similar to a normal array. We need to keep track of the number items and the position of the fron item. Since we don't have to traverse backwards in the circular array, the complexity of these functions remain O(1). The size of the array is updated by incrementing the size everytime at new value is pushed back into the array. The same is true for the front. The array is then filled up in this way until it reaches the end. In order to get back to the beginning of the array we use the mod function. If the front is not the front of the array then you can use the mod of the sum of the front and position and the allocated size to return to the beginning of the array since the mod function is periodic. However, if all the allocated memory blocks are full a new array has to be allocated.",7.0,68
20086,20086,24331,dec98074973763aa35f767e29ff1a337a2f96e27f7bb719852891850a70e146d6ceeda2c5cff7d622832dba02534fa96620c763e3c53dc17c1734a3ec63ba166,"A circular array is an array that wraps around itself. If you were to get the next element after the last one(the back) it would give you the first element(the front). This will allow you to pop_front in constant time since you won't have to shift every element in the array once towards the front after popping the first element (which would take O(n) time) like you would in a normal array.

This allows you to use the array as a que since you would be able to push_back() and pop_front() in O(1) (constant time)",4.0,68
20087,20087,24332,1e61ac69c9ccec529a9d57595e183d7f2b1fa6a9903d4933718e237d1b12f704ba69dec35931222592238b7ab802821e4d5dd2c83c64cb9301a8bb0ced8b2cba,It is a fixed size array. however the elements in the array can be used over and over. We are traversing through the array in a clockwise way. We keep track of the front of the queue and the back of the queue to know where we can insert new values. We arent actually removing items from the array we are increasing the head to point at the next item.,6.0,68
20088,20088,24333,725a0125b367c6f17c35c11b2109d01e495cc98a9983ee64edff98f1e31691682af784e585cb9ffd4450baefac075cf1659b1b9f4409ec665f5bbef7fd4002df,"A circular array works the same as a normal array expect when we reach the end of the array we just carry on from the beginning if there is space and if we were to remove elements from the array the element next to the element that got removed becomes the front of the array. We keep track of the size of the array, the number of elements in the array and the front of an array. By keep track of these 3 elements, we can implement a queue in O(1) time. We will always be able to keep track of the index where we need to pop and push from by using the modulus operator. When we push to the back of the queue we would take the front and add it to the number of elements and then divide it by the size of the array and then take the remainder, the remainder would be the index of the where the new value would be added then you would increment the number of elements. To implement the pop function you would add 1 to the index of the front and divide it by the size of the array and get the remainder which will be the index of where you need to pop from and then you would decrement the number of elements in the array and add one to the index of the front variable as the front is moving up.",11.0,68
20089,20089,24334,b62aa4d567faf4c8c2d7b435cab87c30c9d1e6af89f8a0e3d7867630ef600446840f333742c814bc8a0c9d2f0ab23474abdecc13d41d7312f08a47b7fc5bb67c,"A circular works by having the first data point as the point after the final data point in the array.

it works by having a pointer to the front of the data as well as a predetermined amount of space (n).

It also uses contiguous memory.

it works by adding to the back of the array and popping from the front (a qeueu-like FIFO), when an item is popped the ""front"" pointer must be updated to point to the item after the one that was popped.

when the end of the array is reached, the modulus(%) should be used within a program to loop back to the 0th item's space in memory from the nth.

this implementation of a circular array will enure 0(1) time, unless we were to run out of space, therefore needing to increase size and make a copy, or decrease size of an array after a pop.",8.0,68
20090,20090,24335,74ac16aad9cffebc9a82a3d84552ea746b2a726fb003881a5a45ccd11c8a938caed3d1a49b6f0f3b5bc663c85f99ca3ae1d10cb0f79247d51859bb82beada81b,A circular array is an array shaped like a circle and allows items to be stored in a circular form. We can insert as many items as we want as long as we have enough space for allocation.The first element of the array is always next of the last item. We can use the size function to get the size of the function which takes O(1) time.,0.0,68
20091,20091,24336,52b1f6fd8e6c0289a8004d7d61b231157f72159bdb1098720813eb6a4750543a581c16358208b2fe293a6bc58612fe418d8dd4bccc56d715f7137f43db02b99f,"A circular array is like a vector which utilises a mechanism to loop back through to the beginning of the vector using Modular Arithmetic. We need to keep track of the number of items in the array, the front of the array using an index, and the allocated space in the array. When doubling the allocated size of the array, we copy using the front index of the queue and not the index. ",8.0,68
20092,20092,24337,7f4b419d2ced93d50fb8649f87b2fa3a1ab4c6a1ecc8b63f150aeb372237c21eae97c5eba18c0880eb018ac5d3fb68e9a7180e8af2cbb1d90dc8d7f06f63f097,"A circular array has the last position connected back to the first position. When you get to the end, you go back to the beginning in a circular sequence. 

To implement a queue, pointers play a big role and there are 4 main operations:

the front, which gets the front item from the queue.

the rear, which simply tells us about the last item of the queue.

the enqueue, this inserts an element at the rear(last position) if it is free so it can satisfy the O(1) time. After that what was the rear before now isn't and the pointer points to the newly added element and the number of items/ rear itself is increased by 1.

the dequeue, this removes an element at the front of the queue. Since there is a pointer to the front, for it to be O(1) we check if the queue has an element, if not the front is 0 and the element is returned.

in short the values that we need to keep track of in queues are mostly the first and last values as the whole idea of queues revolve around them and their pointers as well.",8.0,68
20093,20093,24338,615a61127c6c0ce82fff3b905af9891145f1a8b7de3c813ff28357e83206738e51030e5e11f925cb1ff08e1e1848b449cb4a5ebd866eaf249477de58f163ccf4,"a circular array works by having a linear vector, but through the nature of modulus, and some manipulation using the we are able to make it so that if at the end of the array, yet another value is to be added, we will loop back to the front of the array and continue inserting values from there.

it can be used to implement a queue in O(1) time by keeping track of where the current front of the vector is and adding values to the back of the vector.

The values that we need to keep track of are:

the current position of the front of the vector, when the front is popped off, we will have to update the current front of the queue to the next in line.

the amount of element which are currently in the vector. updated when elements are added or removed .

and the current maximum size of the vector (how many elements it can hold). Updated when vector shrinks or expands in capacity. i.e when vector capacity == amount of elements and we want to add another value.

This will therefore give us a constant time in

Push_back() as we would only need to add the current position and the number of elements currently in the vector modulus the capacity to find out where the vector will need to add the new element.

O(1)

pop_front() would remove the element at the position of the variable which store the location of the front.

O(1)

size would be kept track off through a variable.  O(1)

front() we can just get the location from the position which is stored in the variable. O(1)",15.0,68
20094,20094,24339,6faeacee0c2269025dd90b7721d39fd6ea59274d1116063ca6e894050048f55cfc48de8438d931d22afb7e2c6e6e2971358b83dd0ec2d867cc557d7b6b500315,"A circular array works by having the front and back ""connected"" to each other
If we move from left to right i.e clockwise when enqueueing items we increase the back value.
If we dequeue items we then have to increase the front value.
But when the back index increases out of bounds of the array (the end) we wrap around the back index using the mod. The same is done to the front when it reaches the end.
The queue will run in O(1) time because we always dequeue at the front index and enqueue at the back index_.____
_",2.0,68
20095,20095,24340,18f6254c7b196766dbebfb4556ef6c2f9ff5e44918d8ea60921fbe90c8a42515b04ace17b80ecdd7f09efd69961a6da2d4a21f100e3ebd5acf67acba7ebaae55,"A circular array is an array which allows for items to be popped from the front without having to copy all the elements to the left, but only changing the index of the first item to be of the following item. also when there last block of memory is reached you can wrap around the array using modulus arithmetic. All of this removes the possibility of linear time.

The circular array keeps track of three things: The number of elements in the array; the amount of space allocated and the index of the first(front) element.

This allows for the front item to be removed and the index of the first element is of the following item. The number of items is incremented when push is used or decreased when popped.",10.0,68
20096,20096,24341,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"A circular array is an array that reverts to the front when the back is full through the use of (number of elements % capacity of array ) to determine position of the element to be processed. The front value, the back value, number of elements value  and the capacity value are needed to implement the circular array.

the pop function will be implemented by increasing front by 1 and obtaining the modus when front plus one is divided by capacity.

the push function will be implemented by increasing the back by 1 and obtaining the modus when back plus one is divided by capacity.

the size function can be obtained by increment the size integer variable when an element is inserted.

the peek function would be to return the element at the position (no of elements % capacity).",10.0,68
20097,20097,24342,336c0de60905df4ae163484013b5cc72929683b64ebae6f69a61ca7bbc767084419ba7cf9291246a9b63bc7e686a397f48c33976b41fb34999f9b50eee045aba,"circular array works almost the same  as an array, but you can randomly push or pop at any block in the vector as long as you update number of items stored and the front of the vector. I would implement a queue using underlying container as an array. I will keep track of the number of items in the array and the position of the first element of the array. After pushing an item  I will increment the number of items by one and decrement when popping at the same time incrementing the position of the fist element in the array. when pushing I will used pointer arithmetic by taking the modulo of the sum of the front of the queue and the number of items with the size of the array. When popping I will update the front by taking the modulo of the front plus one with the size of the array and decrement number of items stored. ",8.0,68
20098,20098,24343,fd0ace311926a44973b18eb55c0a2df285cc4ef58cf67836be1c2719041ca75111c81115da37e4e4879d8c00ffb63db68cb0de1c85a3fc373724acf7945dc463,"To keep track of the nodes in a circular array, one has to track of the front and back of the array no matter where it might be located in the circular array. These are updated by making the last item added to be the back each time it is added. And for the one before the front to be the front each time an item is being removed or popped.",1.0,68
20099,20099,24344,e394539baa7fd0006de5096759d1db9943b0b453927105fc99e564a56547ecb01587d2f0348be0224bd521c0377577b713f00c14b60183a6d229e89193dcb643,"We will need 2 pointers,one will pint the first element in the queue and the other will point the last element in the queue.  When ever we add to the queue the pointer moves tot he last item. Whenever we remove the first element the pointer moves to the element that follows the one removed and it now the first element.

We need to keep track of the first and the element following the first element. ",6.0,68
20100,20100,24345,3833aa3ef06cafdc78971652ad20444fe164affcf92c03de12570129a147987ae3263043850e741f6f77f4965176d32cb0f7b6200e6f1f08cf0158b373dc6fbe,"a circular array is a contiguous memory implementation of a queue. it allows us to loop over from the back of the contiguous memory space to the front if the front of the memory has space instead of having to reallocate(if there is space). this is done by keeping a pointer to the front of the array, which is where the first element is and not the first memory space. the number of spaces allocated as well as the number of items present is also kept. when a dequeue occurs the pointer to the first item is incremented by one, the variable storing the number of elements is also reduced by one. when an enqueue occurs, the pointer to the front remains unchanged since the element is added to the back and the number of items stored gets incremented by one. The index to the last item is found by adding the number of items to the index of the front of the list. to adjust for the wrapping around effect of the circular array it instead uses modular division to find the back of the array which makes it : (index of the front+number of items) % number of spaces allocated. this allows for us to add things to the beginning of the array if there are spaces available meaning no elements have to be copied over during an enqueue or dequeue. therefore they are both constant time except if the spaces allocated are equal to the number of items which is a worst case and results in a reallocation which takes linear time. the fact that the size is updated at each process makes it constant time as well. and access to the front and back is constant time as arrays use pointer arithmetic ",13.0,68
20101,20101,24346,662455ba865b7fa66132ae6520e999c9ea1b9fa1f85d0b16ee30bd84db7aa0bec3c7fd7269d6521a07e1ad16d091e298c84cb6c69ff3537fa78efdac09fa4677,"A circular array is an array where the first element is next to the last element. (Circular) It works by maintaining variables to keep track of which index in the array is currently the front of the array, another to keep track of the size of the array, and the last variable to keep track of which index is the end of the array. When we add to the queue, we increase the size and the 'last' index is increased by one. When we dequeue an item, we simply decrease the size and increase the front index. This allows us to implement the queue in constant time as we can push and pop in constant time due to pointer arithmetic. We can also peek at what's at the front of the queue in constant time as we have the index of the front of the queue and lastly we can find the size of the queue in constant time as we keep track of the size of the queue. ",11.0,68
20102,20102,24347,efe8bbe0531a8edbaeccdc4f50ad7d19da4ae088aef554a1013cb2ff8b78ba31a24fa0e8f957d84b8c738910275c42c68da1550413f3ef77aa9c38fb88257b54,"A circular a way is a data structure that stores stores items contiguously in memory. This structure also ""wraps around itself"", meaning that continuing from the end will bring us back to the beginning of the array. 

To implement a queue with this structure, we need to keep track of the number of items currently stored in the array as well as the position of our first item. By doing this, we can always find the back of the array (queue), wrapping around if we need to.

Starting with an empty array, we have the number of items allocated assigned to 0 and we have the position of the front of our queue set to 0 (i.e index 0). When we push for the first time, we increment the number of items to 1 while the position of the front of the queue remains the same. As we push, we add to the index queue[f + n] where f is the location/index of the front of the queue and n is the number of items currently in the queue.

If we have to pop, we simply remove the item at the front of the queue and increment the value of our variable indicating the index of the front of the queue. By doing this, we now have the item at the next position/index as the front of our queue (which makes sense since we have popped the item that was previously before it in the queue). Furthermore, we also decrement the number of items 'n' in the queue since we have removed an item by popping.

In order to implement ""wrap-around"" (because otherwise using [f + n] may cause a segmentation fault) we use modular arithmetic. We do this by instead accessing our last item as follows: QUEUE[(F + N)%A], where 'a' is the amount of space allocated in our array. All our operations in a circular array would take place in constant time since we can make use of pointer arithmetic to access the front and back of our queue.

Finally, in the case where our array is full and we need to reallocate to a larger block of memory, we copy the items in our previous array over - staring at the position that we have indicated to be the front 'f' - wrapping around using modular arithmetic as need needed. After we have copied to the new block of memory, we need to reset the variable of our index of the front of the queue to 0 again (because in the new block of memory, the first item in the queue is now at index 0). We also need to update the value of the space allocated 'a' to ensure that we will wrap around correctly in this new block of memory.",14.0,68
20103,20103,24348,f1847bb5d29f39224664df29173ee4eea8241f8aa777b795f86bafdb3b6165e8679750df7902af2beb1387f258e9970c22324224cff020b701254fc8b35d988f,"The main difference between a circular array and a standard array is that a circular array allows certain operations such as popping from the front to happen in constant time instead of linear time. 

The values we would need to keep track of are the number of items in the array and the index of the 1st item in the array. The size of the array is updated when an element is popped or pushed from the array. The index of the 1st item is updated when the front of the array is popped (the new front would then be what came after the previous front). Because we always keep track of the front of the circular array, to implement the peek() function we would just need to return the front of the array. To return the size of the queue we would use the size() function for a circular array. To push we would keep track of the front and the number of items, and then add a value at index[(front + number of items) % size of array] and to pop from the front, we would just delete the value of the current front of the array and reassign the front to the next item.",14.0,68
20104,20104,24349,7c939bb7eae30ac9fde6bed7ba91e751cb79bad249785d6c36230c4d9e80b55aaaf08d983990b398d630a07852718c75269fe0b377bbd248cf1db616b416f57e,"A circular array is an array in which we imagine or/and implement in such a way that after the back of the array, in we have space in the previous indices(more precisely the first index) but the last index is occupied and we want to push, we can do so by inserting at the start of the array, (we go around).

In order to implement a queue using circular array we need to keep track of:

FRONT-which keeps track of the front of the array

N_ALLOCATED- which is the space/capacity of our whole array

N_ITEMS- which is the number of items currently in the array

When we PUSH, we must first check if N_ITEMS is equal to N_ALLOCATED, if so then we must reallocate a new buffer and copy items to the new buffer, by looping and starting at index (FRONT+I)%N_ALLOCATED, where I is the INT of our loop.

If N_ITEMS is not equal N_ALLOCATED then we must insert the value being pushed at index (FRONT PLUS N_ITEMS) MODULO WITH N_ALLOCATED. in order to make sure we go round the array if the space is at previous indices. And then increment N_ITEMS.

For POP we must simply update the FRONT and N_ITEMS.

FRONT will be equal to (FRONT + 1) modulo with N_ALLOCATED. decrement N_ITEMS.

For SIZE we simply return N_ITEMS.

For FRONT we simply return the reference to FRONT.",15.0,68
20105,20105,24350,833bd82b84984eac1561a2aa471c7fa8ce8fc83eb43410d162adbb99836f9c60ca90f110500d0a4cfae027c10757354954059b39ea510643c3c10d5e8f6e1bb9,"* a circular array is where we consider the first element as next of the last element. We enqueue at the back, and when our array is full we will have a loop that is going to insert where we first started, but we first have to check if the array is full or not. When we delete we always delete at the front but we first have to check if our array is empty or not. As we delete we have to keep track of the number of the element by decreasing the elements. And as we add also we have to keep track of the number of elements by increasing the counter.

	* we need to keep track of the number of elements, number of allocated and the front element as well.",6.0,68
20106,20106,24351,a18d348d984f5bd8aca6ebc4fccb86f8d160a802b4c7ee70a595f3b8caf6c18513e302bc5cfcbf90d284bd7a320b1536220dd429aa4a21d61efb3ef1771458a4,"A circular array is an array whose first value is the taken to be the next value after the last value in the array. It is usually an array of a set maximum size i.e (max_size). I would keep a variable called front that would keep track of the front of the queue and would initially start at the first value of the array, as I dequeue values however I will move the start of the queue one block over by incrementing front. For example if my queue starts at arr[0] (front=0) and I dequeue a value then I will update the queue so that it starts at arr[1] (front =1).  I would keep a variable (call it size) that I increment (decrement) every time  enqueue (dequeue) is called that tells me how many values have already been inserted and through size I can implement enqueue  as a function that just inserts the input value at arr[size+1]. I would have to ensure that the value of size never exceeds the maximum size of the array as this stops me from overwriting values already placed in the queue by looping all the way back to the front of the queue.

size() would just return the size variable.

empty() would return whether the front of the queue and the size of the queue are the same index.

front() would return a reference to arr[front]

back() would return a reference to arr[size]",10.0,68
20107,20107,24352,74594d76e743115e9e80c4119a5039c4fec5aed2b1eb9af70c89d53a42b69ad2163ffd8ce8a40f97632e4be0cb18aad097e1d70fac3137214bb4656688c9555b,"A circular array is a normal array that makes use of modular arithmetic to make the array behave in a circular array.

A circular array works by storing three values and a normal array. The number of reserved memory blocks(a), the number of used memory blocks(n) and the front index of the array(F). Using these three values it is possible to make the array behave in a circle. This means that the last element of the array is ""next"" to the first element and all push and pop functions take place in constant time.
This is done by the push function using the formula (index = (F + n) % a) to determine the index that the element should be placed into of the normal array. It will then increment the value of n.
The pop function uses the formula (new_F = (F + 1) % a) to get the index of the normal array that now corresponds to the new front of the circular array. It then decrements the value of n.
Accessing an element of the circular array is done by returning the element of the normal array given by the formula (element_Index = (F + input_Index) % a)

Using this circular behaviour it is possible to implement a O(1) queue:
push - The new queue element will be added to the circular array with the array's push function
pop - The circular array will use its pop function
front - This will return a reference to the front element of the circular array by accessing the first element of the circular array.
size - Returns the size of the circular array.",13.0,68
20108,20108,24353,7db17fd2acfdd980933bf2f92abec54feac68e8b60f672ae1ba7781b8dd15de47315f37d74c147384e68a3a01e88e6539391471e6490908578bb1e2cdf85e7c7,"Using circular array you need to keep track of the Front of the list ,the number of items in the list and the space that is allocated to the vector .To push to the queue use pushback. This function will increment number of items .When you run out of space it will reallocate and place your new value to the position of your front without the front .To dequeue use pop. This increments the position of the front and decrements the number of items in the vector .To return the number of items just return  the  size of the vector and to return the front of the Queue return the front of the vector which we keep track of front the start of the implementation  ",10.0,68
20109,20109,24354,263fd6b7e81bd2b0bd84f67415866c3d75bf78011a0e0748b552d65d3fb35fc4bf5dca96f9ccb82225afdb2c9f73d9593526bb28fe17ab6d85ae420a8a33d70d,"A circular array works by allowing the user to loop back to the beginning of the array when the user tries to access the element past the last element in the array. We make use of the modulus function in order to know when to loop. This allows us to pop and add elements to the array in constant time as we do not have to shift elements. We need to keep track of the size of the array, the number of elements in the array and where the front of the array is.",11.0,68
20110,20110,24355,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"Circular array works by allocating an array that stores the items where there is a front where the first item is stored . We enqueue when adding items to get a new value and we dequeue when removing an item.

we need the value of the front and the number of items to keep track and we update them by pushing and popping.",2.0,68
20111,20111,24356,d31899b98e7fb3e761998737c0078a84e48727b178f33ae85b1caf85762f7c95a36780c3f84b13e4c3f8980c15788bdfcc7bddbb75a6b63b7a164f238d74d926,"Similar to an array or vector a circular array makes use of contiguous memory.

The main benefit of the circular array is that we can use a clever mathematical implementation to simply loop around the same section of contiguous memory and make use of the same space in memory if it has been dequeued. Without this, we would not be able to use any memory that had been popped. 

To do this we need to keep track of the number of items stored in the array, the space allocated, and the position of the front. This allows us to simply add 1 to the front value whenever we pop from the queue, and work out where the back is mathematically. When we push we will use index [front + numItems]. Now we have acheived pushing and popping in coinstant time. However we encounter an issue when we reach the end of the block of contiguous memory, we cannot add to the next space in memory this will result in a seg fault. Obviously we could just increase the size of the buffer but this would defeat the point of a cirucular array (we would still do this when we are out of free space).

What we need to do is loop back to the beggining of the block of memory. To do this we make use of the mod (%) function which retrurn the remainder. To push we would now add the value at index [(front + numItems) % allocated] this allows us to loop around. To allow our pop to loop around we would need to remove at index [(front + 1) % allocated].",11.0,68
20112,20112,24357,17af69de9b004cebc772407eb454a4695fd215d61e6315c9d12ef0dd3a08b8a8642b4cc8dfc787e7755ff0571045a1730ffe50dbf1069009256ea87e870d4fed,"In a circular array, we need to keep track of the number of items currently stored and the front of the array. Whenever we want to add an item we need to use modular arithmetic - the front added to the number of items mod the allocated space for array - this will be our index of the new value we want to add and increment the number of items stored. We use the same arithmetic for when we remove an item, except, we apply it when we update the front of the array and we decrement the number of items stored.  ",11.0,68
20113,20113,24358,0a1930b4d16e62ac7ee353c6144c568d9ee6c791d0d3632d3ce78fd24bb2c65d328c4924d6cafd1daed9790efaefb16fe2a520125cf9396ef372146945ae0496,"A circular array works when the first element of the array is next to the last element, and can be used to implement a queue.

 To do this, we will use functions such as push_front to add t the front of the queue and push_back to add to the back, as well as pop_back to remove an item from the rear of the queue. We can also use front and back, and each of the items returned here respectfully should be next to each other.

When implementing a queue using a circular array, we need to keep track of what is returned at the front and back functions. We push at the front and back(enque) as well as pop(deque) rom both the front and back.",0.0,68
20114,20114,24359,2238995f0ead9a3412ecc8b42340b20d5862bf47d5493b0c9fbe94b4e46ffb57c2cf52b4dd296cee7b6850d8a44e160d6bd1d96e80ab144e928044e44043acc6,"a circular array loops around itself, so the back of the array can be found by subtracting the number of items stored from the location of the front of the queue. thus we keep track of front and the number of items stored.

they are updated by

push{ data[front+items] = value; n++}

and by

pop{items--; front++}
using a for loop where temp[i]=data[(front+i)%number of spaces allocated]",4.0,68
20115,20115,24360,5cd0a202ef51535fb2cf79db8f13b432c752afb35952cb0416813c6c757163698e13f6f62bd6292909baa9745f2197e7ed5a1f16eebc10eb62867568861dbf00,"A circular array follows a contiguous layout. The way the circular array works is that if we have filled the space allocated at the last index of an array , we will loop back to the beginning of the array and if there is space, store the next item that we want to add to the array there.

To implement a queue for a circular array in 0(1) time , we would need to implement the push (must push to the back of the array) and pop(must pop from the front) operations in such a way to accommodate for a changing front position of the array. 

For our size operation to be 0(1), we need to track the number of items in our array. The front operation implementation is fairly simple, we return the value at the front index position.'

Push: We would need to set the value of the index of the front position of the array as the reference index and we would need to increment the number of items every time the push function is called. We can do so by using the code:

data[(front index position + number of items) % number of spaces allocated] = value_inserted

and then number of items++. 

Pop: For pop, we would just decrement the number of items since we removing an item , and would need to update the front position in our array -the code for this would seem as follows:

front index  = (front index +1) % number of spaces allocated.

We use modulus operator because we are pushing and popping with reference to the front position.

Front: We would just return the value at the front position: data[front]

size: We simply return the number of items in the array

We will thus need to keep track of the space allocated , number of items in our array and the position of the front of the array. We update the number of items in our array whenever the pop and push functions are called: increment for push and decrement for pop. For space allocated, we would double this amount each time our space is equal to our number of items in our array , which we then copy to the new array of size 2*previous allocated spaces. We update the position of the front of our array each time we call the pop operation.",15.0,68
20116,20116,24361,912a17c5532a85cc610facff6c98d42b64fb259b767c809567c65cce318eb3dc8f21bcbe5e653de87fe40d2502ab66869bc553e63fc3a1d7697be613c3b49a69,"A circular array is an array, where the array indexes wrap around to form a circular structure. So if you were to access one element past the last element in the array, the array would loop back to the front of the array and return the first element. It does this using the modulus operator to calculate the indexes. 

To implement a queue in O(1) using a circular array, we need to keep track of the number of items in the array, the position of the front of the array and the number of allocated memory. Once we have this, we can implement the push() and pop() operations on the queue.

So, if we want to push an item to the back of the circular queue, we can do this by finding the index of the back of the array and then changing its value to the one of the item we are pushing to the array. To find the back index, we would need to add the front index and the number of items in this array, and then take this value and apply the modulus operator using the array length. We would then need to increment the number of items in the array by one.

If we wanted to pop the first item off the circular queue, we can do this by finding the index to the front of the array and then updating it's current value to the value obtained when the front index is incremented by one and mod the array length. We would also need to decrement the number of items in the array by one.",11.0,68
20117,20117,24362,c33667ae11b7bded2337c08d116fa497bbbd12dbb6b1affa7fb94c650c68ba165865aab5e81895db475a23ff725c4bc69da22573104a9522dcaf9138fd9b447c,We need to keep track of the size of the queue so we dont have an overflow error and they are updated by removing values that are not needed.,2.0,68
20118,20118,24363,6accb08d7786944c71cd9b921787862856d4a3c42592fbffde311b7d0b92a8f983d0c4f430c2af6d29dc0b77bc121c3af33f1ea64f2b5de47c11c3122369896f,"A circular array is an array that has a set size. It works by constantly pushing items into the next available space after the last item and popping the first items that are available at the front of the array. This allows the array to operate in a circular way. It can implement a queue in constant time O(1) because when a value is popped from the array, no shifting is required. 

There are two values that we need to keep track of. The first one keeps track of the number of items in the array. Each time an item is removed from the array the variable that keeps track of the number of items is decreased. Similarly, if we add an item to the array the variable that keeps track of the number of items in the array, is increased.

The second value keeps track of the index of the front of the array i.e. where the first item is stored at (as the array is circular the front of the array is constantly changing). Each time an item is removed the index variable is updated to the current index + 1, which represents the next index which is now the front of the array.",4.0,68
20119,20119,24364,92791654d3cd52922c5b338b34156b28fe55a4ccee1e7fc5905b97888cf317c2fcae873ea940af535130a211df4483d7fb93e8718b1976f9cc9aa146daf834aa,"it works like a  regular array accept when it gets to the end it wraps around and goes back to the front of array. When we use it we need to keep track of the number of items, memory allocated and the position of the front of the array. 
When we call the pushback function on the queue it runs in constant time because all it does is add an item at the back of the array. When call the popfront function it runs in constant time because all its doing is remove an item at the front of the array. When we call the size function it also runs in constant time because all its doing is return the amount of items in the array. When we call the front function it runs in constant time because all it just returns the value at the front. ",4.0,68
20120,20120,24365,482f7dae015b4c467d12506c33e2fe66aeff1ddddb85f2c9bce0e0756918b84a46072cd434d5bf20b674533a59b9c793d9d747268246eec497aed1c0f31a1c3c,"A circular array is when we change the front of the array and the size/number of values in the array every time we add or remove (push and pop) an element from the array. This allows us to have O(1) time. 

We need keep track of 2 things, the value of the front (where the front is) of the array and the value of the size of an array

We use a mathematical operation called mod and the size allocated to the array to help us implement the circular array.

Every time we push a value onto the queue we get where the front is add it to the size of the array and mod it by the allocated space, then we update the size of the array by one

Every time we pop a value off the queue we get where the front is, we add 1 then mod it by the allocated space of the array, then decrease the size of the array by one- this changes the front value of a circular array",11.0,68
20121,20121,24366,2639eb56a1989682f1b8fb8c5a3437ea6a5d663be094f02f4aaae47dc57a1af7165cfaae33d61d670e26c96083744d494e42187a468df938459fc0c70030a175,A circular array is a normal array in memory but we think of the memory in a circle. We always need to keep track of the number of items in array and the position of the front of the array and then we can work out the back of the array. We do this we allocating memory and number of items in the array. We starting inserting elements in the array by pushing the array. When we adding elements we always make sure to update the number of items in the array. When we remove the item in the front of the array that position in the front is no more the front of the vector. Now the front of the vector changes and to the next item and position in the array. We don't have to push values to the next index this allows it to be constant time. We use modular arithmetic in order to go back to the front of the circular array. We would say the front index plus the number of items modulus number of allocated memory will allow us to loop back to the front and allow us to move back to the front.,11.0,68
20122,20122,24367,5b79e321acf32f26a1c6cc9091fa349a8baa70385c6fb736e55b942fea1901b561d1f53857749ead207a2933e580c9dfc66c9af868e9b035d1dff322ef7cd5be,"A circular array is basically a an array that allocates contiguous memory but works in a circular way because our first item is not neccessarily at the first memory location always.
In order to implement a queue using a circular u  need to keep track of the size that is allocated ,the number of items in the array and the position of the front/first item in the queue.
For the push function : Lets say F is the position of the front and a is the allocated and the name of the circular array is data then in order to push we would say data[(F+n)%a) = value ; and we increment the number of items , we use the modulus operator so that when we do not access random memory when doing pushback.This will take constant time.

In order to do pop from front we would say  F= (F+1)%a and we decrement the number of allocated items,again here we use the modulus operator so that we do not access random memory. This will take constant time

When space is full and we need to reallocate we need to make sure our front is placed at front postition so:

for loop {

temp[i] = data[(F+i)%a)

}

We do this because it is not always the case when our front item on the queue will be the first time in the array.

For size we would just return the number of items as we keep track of it and it would be constant time

For the front function we just return the reference to the first item in the queue and it would be constant time as we keep track of its position.",16.0,68
20123,20123,24368,1d469feec8dabc8efe190b91bf2431897a77efbd16b2d85bdc6124d89beaeb95e4c3d1758db03e27ba5dac6295ff2b30f3eaaa927d0748ab45ecd18c4991abfb,"By usinging the functions of an array for each function of a queue 

we can use the push_back to add elements to the queue, and empty by using the size() function and if it returns 0 then the queue is empty, and for the size, use the size function of the array and to remove the first element we just delete the first element of an array.

the value we need to keep track is the first element of the queue the last element and the size of the queue and if the queue is empty or not",2.0,68
20124,20124,24369,d7dfb51332e1c950aa433a238f3273834b82e31a54a773c512e9c88094b5b27c10ba7527d092402ee28c450551c97d4efc1d9a6fab4f18a9a6df9f32cd052165,"we need to keep track of the space allocation, number of items in the array and the index of the front of the array.

to implement a queue using a circular array we would use:

to push an item data[(f+n)%a]=value;

                          n++

to pop an item f=(f+1)%a

                         n--

circular array uses a contiguous memory, and a FIFO structure. the last position is connected to the first position.",11.0,68
20125,20125,24370,6ce5c22e2014cf62c3f9857f1a5d029cd8403915d5de52ffef745d92a330418a129b81b3d1fc019ceb103f7414cb06b86a44ab05670ba63e692007c026c9822e,"Can use a circular array to implement a queue in O(1) time because a circular array considers the first element as next of the last element. Need to keep track of the number of items in an array, the position/index of the front of the array, and keep track of the number of items allocated for the array (n_allocated). Using modular arithmetic can easily access the elements of the circular list. In the push_back function, the number of items in the array is incremented and in the pop_front function, the number of items in the array are decremented while the position/index of the front of the array is incremented. Thus allowing for a queue in O(1).",10.0,68
20126,20126,24371,d2c94c0dca7decb41292af9de73a32afa110cab818c0e296b000bfe9dd7b6bf221a0332e01f53ce869a1f4affd4abbea90b7e61d9504a5178a430b94bbde20af,"A circular array needs a ""Front"" (F) value, an ""allocated"" (A) value, and a ""size""(S) value. When inserting into a circular array, you do not particularly insert into the first empty index of the array, but the index at (F+S)%A. The S value will then increase by 1. Once you have inserted until the last index of the array, it will go back to the beginning of the array and continue inserting from there. When deleting from the array, it will delete the F index and make the next value F, but will go back to the beginning of the array if necessary. The S value will decrease by 1. The A value will be the allocated size of the array.

To implement a queue using a circular array:

To add to the array, you would use array[(F+S)%A]=value and would then increase S by 1.

To delete from the ""front"" of the array, you would delete the existing F and make F=(F+1)%A and decrease S by 1.

Size will be constant time.

the front function will be constant time as you get it with array[F].",14.0,68
20127,20127,24372,9b486d212bcbfc98bcb7006334a7bd057c017b3b5d6ddec828a1e7c71b279d57abf5933826cc5cd40f31ce09e30273c03c034afd55ad69a350c76adfabdffc7c,"A circular array is simply a way of visualising contiguous memory allocation in the form of an array. In a way it could be thought of slightly differently compared to how other structures implement a queue (with the structure being contained in the queue.) in this case the queue can be though of as being contained within the array. This is because the front and back of the queue can move around within the array and loop back around. 

Things that need to be considered are the number of items in the queue, the begin and end of the of the queue in relation to the array's memory. As well as the size of the array. Simply put, the n_items, n_allocated, and front of the queue are the most important values to keep track of. Each need to be updated when pushing and poping from the queue and by extension the array.",8.0,68
20128,20128,24373,42e6b01ab1466ecf4c88357c8a87857e5ecc872afb213048e4751c77af636050d8f2879e14708bfee7041cabe10a1172a27eeed61b6595ddc757a30713e14d62,A circular array works by adding elements circularly and use 2 variables to keep track of start element and the end variable.,2.0,68
20129,20129,24374,3065fd9b5327500ccd01f2dbaaeb4517f874d19bdf3e90a9e58fc3902fdfcf795607548f33b16d677a8bfdbfbec8dfd27757ca207e98b81490a4df15aab3c3f5,"A circular array stores items like a contiguous data structure , we push from from the back but this time we use the front index and the number of items in array along with the number of allocated space in an array so that we can store the value/item in the right index. We pop from the front then we increase the front index and reduce the number of items stored.",8.0,68
20130,20130,24375,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,"circular arrays are a block of contageous memory where the the last item point to the first item in the list. To Implement a circular array we allocate the size of the array and we have to take note of where the front item is. The values we need to keep track of is the item infront(the first item in the queue), the size of the queue and the space allocated for the array

To use it to our advantage we use the values we keep track of when we add items in the array

for enqueue  data[(front+size)%a] = new value will insure that adding items in the queue takes O(1) time. And increase the size of the array(size++) 

for dequeue  outputvalue = data[front];

                      front = (front + 1)% a

                      size --",11.0,68
20131,20131,24376,c879e65c8f9657768bbf6800906a28bff217c7ef9063d46acfccc25071a9fc3aef2ccd29821fdc92e96d2f98ca66aa74a3fa2a8f0df86509064e53b0fb9b54bc,"A circular array  works by allowing items to be removed and added to the array without the need to move all the items over by 1 when removing from the front of the array to keep the order of the array correct. It does this by keeping tracking of these variables: (n): this is the number of items in the array. (F): This is the index of the front item in the array. (a): This is the size of the array.

Keeping track of these variables will allow us to keep constant time across all functions of the queue. It will always be in constant time until the array is full and we want to push_back another item into the array which will require us to do a reallocation and copy all items across which would be O(n).

Push_back: To push to the back of the array we would assign the index pointing to the back of the circular array the item and then increment the (n) variable. To find the index of the back of the array we use [(F+n) % a]. The code would look like this:

data[(F+n)%a] = value;

n++;

Pop_front: To pop from the front of the array we would increment the (F) variable and decrement the (n) variable. Incrementing the (F) variable need to take into account the looping to the front of the array mechanism whenever the front of the queue moves from the last available index in the array to the first. Using mod takes into account this circumstance and it looks like this: F=(F+1)%a. Overall the code would look like this:

F = (F+1)%a;

n--;

No deleting of the item needs to occur because we can simply ignore that value and if we need that space in the array for a push_back then we simply overwrite the data left in the array.

Front: This function will return the item at F.

Size: This function will return the variable n.",16.0,68
20132,20132,24377,e128973184d15ac7a750b822c9d3b3fe1c0b4d5c9ec9968806c119de2807128c5380243007b2944cf3a301c3270578e76aaa068c636326951a9eea7851758fdf,"When using circular array we keep track of the number of arrays and the front so that we can know the array start after r4emoving the item from the array . We have to use the modulus arithmetic in order to position an array after is has been re-arranged 

when push function is implemented inside this function front will be added to the position of an item  and multiplied the modulus of number of array ,then we will get the value

when the adding an item in the array that is full  we just have to re-arrange the array

when popm function is implemented  we just remove an item and shift the front to the current item on the list

size and peek function will just return the data then our queue will be in current time",4.0,68
20133,20133,24378,571f4b857c687d9d563078992ce0d593248d2c9f52df5afb071f8e300cfd009d7831df6cd94d1fdf3131324af503b103a8881171137c2ca59df7ead36faf3f74,"a circular array in an array that allows you to loop from the beginning of the array to back and once at the back get looped to the beginning of the array again 

the variables that need to be tracked are:

front (which cell represents the front of the queue)

number of items

number of cells in array

you read the data in the front with data[front]

you add data to the back by using data[front + number of items] % number of cells in array. The % number of cells in vector is very important because the modulo will allow us the loop back to the first cell in the array in O(1).

When you want to pop the front all you need to do is to front++ and number of items--",14.0,68
20134,20134,24379,936024d8e9328998a220b77c48098f57a0d619263f7c2ad0ac4157dfe9370e11abee7f579d65a28c46224757256e636c01fe798d4c5eb4d7e1574b7de8511fbf,A circular array is a normal array that is in a shape of a circle. As we insert values we would loop through the array as long as we have space. We need to keep track of the number of items as well as the front items and then we can work out where the back is at anytime. ,2.0,68
20135,20135,24380,5ad20b3b420c21e1fc2861df4f4257210672d867b8a024855b258388d20148643f1a94c77f0aa2d4b47f8fba4b85741287207442ff519080915f15fdfd0e21b1,"A circular array is structurally the same as a normal array. We use this array in such a way that we can enqueue and dequeue in constant time by keeping track of where the front of the queue is. 

When we remove items from the front of the queue (dequeue), we do not copy each item in the array to the previous block of allocated space and delete the last item in the array. Instead, we remove the item and add 1 to our front variable (F) which helps us keep track of where the front of the queue is.We can find the front of the variable by saying data[F We also reduce our variable which keeps track of the number of items in the array (n).

When we enqueue, if the vector is not full and F>0, we can add an item to the end of the queue and have it appear in the front of the array but not be the front of the queue.",11.0,68
20136,20136,24381,b33d5ec88a2b0658fe1e9d5e59ea13311491654c12fd5b13cd9e270e44a1a125acca1c56bf136302c950a009d693b09accad74b98f9de4d82034269663959b89,"The front and back of a circular array are next to each other. We need to keep track of the number of items that are stored inside our circular array, as well as the position of the front. We also need to keep track of the amount of space allocated. In order to add an item we need to check where is the position of the front and then add the item to the back which is the position after the front. ",4.0,68
20137,20137,24382,4d5583055b5cf0ef4bd7f80832ec9b8940eedb6261741378493c7c1e768d88d15f96d3b8d5850288f3731056d59b3dbe1878b8c16bbb307054b4401de38adc38,"A circular array works in a similar way as a normal array except that it loops from the back to the front again. We can achieve this using a modular calculation. We need to take into account the number of allocated blocks of memory: n_allocated, the number of items in the array: n just as we would in a normal array with the exception that we need to store the location of the first item in our array. By keeping track of the location of the first item we can add n and divide by the n_allocated to get the remainder which we can use to push the next item at that location. We would then increment n which keeps track of the number of items in the array. This would take O(1) time in the best case if there is enough allocated space or O(n) in the worst case if there isn't enough space in which case we need to increase the size of memory allocated and copy n items. Since its a queue this would always add the item to the back of the array. In order to pop from the front of the array we use the variable that stored the location of the first item which we would then need to update the location also using a modular calculation where we would increment the location of the first item by 1 and then divide by n_allocated and then set the remainder to the variable which stored the first location while also decreasing n.  The other functions of the queue will also be calculated in constant time as the array keeps track of the location of the first item to return to the front() function and also the number of items in the array which would return to the size() function. ",10.0,68
20138,20138,24383,c2e3a17d6cc0156e335ca9215e55053ddbc80682871f8957ca1d1b73d39dbe24e0950e6728cd273bbd1fbaac4e9fc1f8fc1eeb009c8b2565447f198e841deab0,"The value of at the front of our array

The value at the back of our array

The value of how much space has been allocated

The number of items in the array",4.0,68
20139,20139,24384,798235659bb9174e71b3ff61763ec292691ece6655d9ff85d1fbb65ede38be3c46ca62a6d523bf01e0f519090370eeadd560efded9ef16231507d4492e919473,"A circular is a contiguous data structure, like an array.

The circular array keeps track of the number of allocated spaces for elements; the element in front of the circular array and the number of elements in the circular array. When an element is added the number of elements is updated by increasing it by 1, when the back of queue is popped the front of array index is increased by 1.If the array is full and push is called, the array will be made bigger and the number of allocated space is increased.

The circular array will store elements in a circular way. It will allow the addition of elements without reallocation if the exists space. If the last index of the array has an element, but the is still space in array, and push is called the element push will be added to the position that is open which will be determined by (f+n)%n, n being allocated space and f being the index of front of list.

Since memory is contiguous the implementation will be O(1), and only a reallocation which will not happen very often will be the only O(n) opreation.",11.0,68
20140,20140,24385,a3989cc4476b1bbce9e79b34c3f0337ca13c9717a610fbe24ad51e9bdb052f2d445313904842463b1a859cd4d281ce72b5f85b0423f33b62cab82318e4116232,"Circular array works by connecting the last position to the first position to make a circle. It can be used to make a queue in O(1) time by keeping track of all the memory and allocating enough space for our memory.

We need to keep track of number of items stored in our array, position of the front item, how much space we have allocated. When we push a value, number of items stored in our array gets updated. When we pop, position of the front gets updated.",6.0,68
20141,20141,24386,20820f051ab9e7b5dde112869be67e2e49734267d017f30c8e3086343a31575407d74708ebc5d385e1b1a34dd7dd81fa4425af4e6cb2bbdba32928c419b4a8da,"- we create a circular array which is similar to a normal array but it will be a circular or round shape.

- we keep track of the size or number of space allocated for the array, number of elements in the array as well as the front of the array . Since we have these we will also know where the back of the array is.

- when we add values we would push to the back of the queue

- when we remove values we would pop from the front of the queue and then update the front of the queue

- since its a circular array we can loop from the back of the array to the front if there is space at the front of the array

- we need to also get the modulus to be zero to ensure we dont go off the array and rather llop back to the front",8.0,68
20142,20142,24387,88e4f79f72acbc7dd458837989d41695a9b36b9c96cdb3ba66c7b90921d69150d478abfb1ed6fc7e89594f6b4ccd5c2a5625a644a888136358b59b68dc7b8205,"in a circular array indexes starts back at 0 after reaching maximum value. when the max index is reached then the next index will become 0 starting from the beginning. The rear of the queue is somewhere clockwise from the front. To enqueue an item , we move rear one position and insert the item in that position. We would need to keep track of the rear and front values. To determine the end of the list we can say array[head+size() %array.length] and to calculate the front , array[head+length].",4.0,68
20143,20143,24388,c2c29b17660ccaffde93650bbaabbeca722766be9c7f4c24079c9b3711df082352b0623847e9af19ff96cf4f2d45d0bd1cd360dd8fa3d9a37f5041dcc804b8b1,"A circular array doesn't have an ending. If  we are at the last element of the array, then the array will start over from the first element again.  We need to make an integer counter of the number of elements in an array. When an element is added to the array the we increment the counter by one or when an element is removed we subtract one from the counter. ",4.0,68
20144,20144,24389,854bde56afcd2bd2c31fbe39384369ef7c0ac613a004a4b239a7a7d08872fa336ab049f8f45358abb5e93ca8dfc33e8954bf246487197e2265435ed3c204826b,"A circular array is an array that is used when we need to add and pop items frequently to an array, if we pop front no reallocation occurs but he space is reserved so that if the last index is not empty and we call push back the item to be added will be added at index 0 of the array and so on. We need to keep track of the number of allocated space, the number of items in the array, the index of the front item. The enqueue function of the array would call the push back of the array and add an item to the back of the array, this would take O(1) time if the number of allocated space is not equal to the number of items in the array . The pop function would take O(1) time since arrays support indexing. The size and empty functions will always take O(1) time",4.0,68
20145,20145,24390,6a787853e1f57b2d3b0d74f5ae62b179adb7413dd588b37a8f7082bdd65e471590c4f39498c937e59e73bcf33962fea95df098117d05b73852f11db547a99d9b,"A circular array is laid out as a contiguous array in the memory but we think of this array in a circular shape. 

-we loop around as long as there is still space available.

WE KEEP TRACK OF:

*number of items

*position of the front of the queue

*allocated blocks of memory

-if we pop an item from the front we have no need to move all items to the front rather the second item becomes the front of the queue. This gives the pop function a constant time O(n).We then decrement the number of items in the queue by one , increment the position of the front by one also.

-if we push an item in the back it also take constant time  since we wont be moving items .O(1).

- if we reach the end  of our allocated memory if we would like to push back we will fall into into segmentation error so the solution would be to use the modular (%) approach  that returns the remainder making the pushed item be the front of the queue",10.0,68
20146,20146,24391,4bd03f3c8f89617686a3536f1302b8ad51345512ea9473aae1ca497c4f25a59a5466e4df9b3e8a550246d3f93ec44b2398abe8c256bf5d3e51474d7b6863abb1,circular arrays are used to implement queue using FIFO(first in first out) principle . circular  arrays take O(n) time. the last item is linked to the first item to form a circle. we push back using constant time and pop front using constant  time also the size and front functions are O(n). ,0.0,68
20147,20147,24392,9082e5ab0ae09b23b5e0275a763493886db0b7f721520ca423ce3577e6b6ec09537f5d0b22aac121f7604a542a413dd81640198a15212f5aa5403c721b42c11e,"We should keep track of the Front, the Number of elements we have and the space allocated, Basically the circular array works as follows. When pushing into the array we push back as we normally would, when we do a pop-front we delete the front element the update the number of elements we now have and continue with our procedures but when we push back to the very least or end of the array, we no longer push analogically to the next address in memory cause it is not ours, rather we push front to the space that was made free due to the result of popping front, we continue so on till there is no space in the array, what makes all these processes possible is that when we push we push to index (front + number of elements in array) modulus of allocated space, in symbols indes (F+n)%Allocated,  then after that increment number of elements, And when we pop we decrement number of elements of course then increment the Front by 1 modulus of allocated space in illustration (Front + 1) % allocated space",11.0,68
20148,20148,24393,2dd5e2f41652664c7010e9c75b107a0a619a9b54063e68bd2c6a9b76a1fcac07a9bceac7ca7bf3cdecc54ef1490301f90259c5d418e4b888c5d3f0477b59ef3c,"In a circular array the last element of the array is modelled as being next to the first element of the array. We keep track of the indices of the array using modular arithmetic, allowing us to access every nth item ",0.0,68
20149,20149,24394,2f2bbc70f8136ca3b18457b652aa1d5317919459278da63d7273a5c4e29eded00275f14d0a5826a3efa0a4d6a86ce51a6129f3ba53f25a66bc7e4755b291485f,"you have to keep track of the number of items in the array, the position of the front of the array and then the back of the array. They are updated by using the push function which is linear time, and then the number of items are increased by 1. The pop function will decrease the number of items and increase the front position. If youve gone through everything in the array, it becomes circular, which you have to check by uing modular. (f + n%a). We then make the front the initial value.",8.0,68
20150,20150,24395,db0698cd03866d48da0c9cab1c327e767c6fb2c70ab318867db7094af47e41c16fc1528b63425d8d7a1a4e5cc071eef840fd0e4c5113866d0139015edb52f238,"Circular Queue is a linear data structure in which the operations are performed based on FIFO (First In First Out) principle and the last position is connected back to the first position to make a circle. Here, we can insert elements until the queue becomes full, but once it is full we cannot insert any new values. The required functions are Front, back, enqueue and dequeue and it is in O(1) time.",0.0,68
20151,20151,24396,c6919e466976b48c2f7b3823eb90c377fa8e67b3a290bcb3ab3a7c56083193c911bc05ef76e986e61a0a361e9ed5a7fec55840ba6afe1022bc97e18b5eabbeef,"A circular array helps us to store items in a contiguous memory. This helps to implement Queues and mostly doing our pop and push operations at constant time unless we have to re-allocate memory which does not happen often. The advantage is that we benefit from cache. All we need to do is to keep track of number of items stored in our array, keep track of the position of the  front so we can lastly work out where the back of the array is at any point.  We are able to implement queue O(1) time because we are able to keep track of where we are at any time.  Also when we reach the end of the queue and we have to push, we use modulas arrithmentic to swing back to position zero.  the formula would be (front+number of itimes) % allocated memory.",8.0,68
20152,20152,24397,c66e418bde3624775409174d439f8c7a104e4c741d28aa9a32d3dff6f27ee3fc70a6b61ca496d004e7124e5afeca9e6a74cf0455c76878d506978153185a8efb,"The array is used in a fashion such that once the upper index of the array has been reached, but, there is still space in the front of the array, using modular arithmetic, items will start being stored from the front of the array again. 

The allocated space for the array, the index of the front of the queue and the number of items stored in the array are all the values that need to be stored/kept track of. 

Since the index of the front of the queue is stored and the number of items stored in the array is also kept track of, these values can be used to calculate the position of the back of the queue in the array (by adding the two values together and using modular arithmetic). Items can be removed in constant time since the position of the front of the queue is known, items can be added in constant time since the position of the back of the queue is known and the size of the queue will be returned in constant time as it is simply calling an integer value that is stored (the number of items stored in the array).",8.0,68
20153,20153,24398,c0b5209a0b10c8dcfcb6cf4b7392c868a8a0f46868d7ead3603a66886d165a2ffbe1f975845aa3417da4caad2884f87961b388a20ee21c66a3e2d9cec38ed42f,a circular array is an array that loops itself traversing from its n-1th value( of array size n) back to data[0] where it began by using the modulus operator and keeping track of the size of the circular array and the amount of elements currently in the array.,2.0,68
20154,20154,24399,5dcf09a63d08f8fcf484a27b8188aca8e05117584de8c4c8e580d2681056a972e8271fbb1e9e69a616d3a8d13ef9009ce7fbd4e4c680807f0aa62ce637934a9e,"We need to keep track of the: size of circular array(a) , number of items in the circular array(n) and the front of the circular array(f).

Push function:

We  would use the underlying std array function push_back that takes in the value as it's parameter. Then add the value at the end of the circular array by the following calculation : data[(f+n)%a]=value. % function takes the remainder of two integers after integer division. Then we would increment n : n++

Pop function

We would increment the front variable : f=(f+1)%a and decrement n by one : n--.

size :

we would return n ;

front :

we would return the data at the front index : data[f].",13.0,68
20155,20155,24400,49da1899a556de47c2ec5c0aee3103579dd1b8665560fbd2cb26362bd85bf2a291f8280bc21e1f838e024dcd8764915c6b880be08a2f6c8f404d85517511406c,"A circular array is an array wherein the first element is considered to come after the last. When inserting at the front, we insert into the array at an index of the front+the number of values, mod the size of the array - incrementing the number of items by one. when popping, the index of the back is set to be one further forward, and the items decrease by one.",0.0,68
20156,20156,24401,ab50392a96c4c3025a5963370825a15241a679c25a4771a2853db32d86a5e0a874ed37e6f390b06f6b3a0755f5bc0190ec94f83a3fd5bf730ba4d34a04efb6d1,"a circular array is when you consider the first element as the element after the last element. it allows you to loop around it as long as there is enough space. it keeps track of the number of items in the array, the position of the front item in the array and the size of the array.

as you add or delete items from the array the position of the front item gets update along with number of items in the array",8.0,68
20157,20157,24402,f1ba85bcb3cb35dd3a5763fa5946a3ff7df7d0bf7beb3182d0ecb801d8abdf353d4eeb7909c0cc4e94c0d221fea7a7c70e57bb1e1c70aaf71f4a7a0e8fe5269d,"A circular array is an array structure that through some manipulation and tracking of certain variables, can behave and store data in a 'circular manner'. To implement a circular array one should keep track of the position of the Front of the array, the number of elements in the array and the total allocated space for the array. When the array is empty, pushing items to the back of the array will be as it usually is. When removing, one should update the front and number of elements variables by incrementing and decrementing respectively. When one reaches the end of the allocated space, but still has empty cells before the element at the updated front, then one could use some modulus arithmetic to get the correct index at which to store the new element. Eg, if an array of 8 allocated spaces, that has 6 elements stored and has the front variable stored at index 2, then one could say : (front + number of items in array) % total allocated of array. so in this example: (2 + 6) % 8 = 0. Therefore the new element that was pushed to the array will be at index zero, the number of elements in the array will be updated. The pop_front function would work in a similar fashion, however we would use modulus arithmetic to update the front variable. Eg, front = (front + 1) % total allocated. Additionally, the number of elements would decrease by one. These functions would perform some simple arithmetic and some assignment, so the time complexity for these functions would always be constant time (O(1)). Size and front functions would just be returning an already stored value so also constant time. The only time push and pop functions would become linear time is when we have run out of space for the array or if our array is much larger than the amount of stored elements thus wasting space. In these cases we will need to make new arrays with appropriate sizes and copy everything over.",16.0,68
20158,20158,24403,e81419dfc1d9569cd33a892060afd65b53683380b098be177940b37177a69388dbc26f4b88ae9117e614069eb6d29407e325e18a19fd38be90fa494f6adff772,"A circular array is basically a normal array where we use modular arithmetic to loop round and round (making it seem circular). It is imperative that we keep track of values of a (the amount of blocks allocated on the stack), n (the amount of items in the array), F (the index of the front items). Circular arrays are very efficient we can use it to implement a queue in O(1) time. When enqueue a value to the circular array we need to calculate where the back of the array is to insert while keeping in mind of the possibility to loop or reallocate. So to push we data[(F+n)%a] = value; n++; We have thus calculated the back of the array (F+n) with the modular arithmetic accounts for when we need to loop around (we have reached allocated and need to start at index 0). And then we increase the amount of items in the array. To dequeue from the front all we have to do is remove the item at index F. To do this all we do is we update the F value +1 and then modular a to account for the loop and then decrease the amount of items in our array; F = (F+1)%a; n--; For the size function, we already have a variable n which keeps track of the amount of items in the array so O(1) and empty is if n = 0. To return the front all we do is return the reference stored at index F which again is 0(1). Thats how we implement a queue in O(1) time. All we have to remember is if n==a then we must reallocate which takes O(n) but that happens infrequently.",14.0,68
20159,20159,24404,bec70f18652f9b1ec67ee94e23471083fc0530aad868499d925d500e71ccfd4f82652eb49a909778379c4583e97ce1464a3ae78de3b07114cb3a9e4c1179d625,A circular array is a data structure that uses an array in which the first item and last item are next to each other. A circular array can be used to add and remove items from a queue in O(1) time. We need to keep track of the first and last values in the array.,2.0,68
20160,20160,24405,d098e277cb3df3b25c9e42904322dbd46a16b60a20b139d8066f16584a8bb599eddc05cac924f310971f38fb613ad7daea71749bb268694cb7e0d2fdf74a35a0,"In a circular array, we must keep track of the number of items in the array (n_items), the size of the array(n_allocated) and the index of the item at the front of the array (front). A circular array is able to implement a push_back and pop_front functions in constant time ie O(1), because in a circular array we do not have to shift all items 1 place to the left after implementing the pop_front function as opposed to a normal vector where we have to do so. For implementing a push_back function in a circular array; this also takes O(1) time because we simply place the item at a specific index. To implement these functions for a circular array, we make use of the modulus function which helps us go back to index 0 if we have reached the last space in our vector; for the push_back function we simply use the code data[(n_items+front)%n_allocated]= value; then we increment n_items since there is 1 more item we have added to the array, this will almost always take constant time except for cases where n_items= n_allocated and we have to reallocate, which takes O(n) time. Then for the pop_front function, we increment the index of the item at the front of the array by using the code: front = (front+1)%n_allocated; which will shift the index of front 1 place to the right and if we are at the end of our vector, it will go back to index 0; then we decrement n_items ie use the code(n_items --) since there is 1 less item after we pop from the array",13.0,68
20161,20161,24406,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,"Create an array. To enqueue an element, increment the size of the array ie add an element to the array. To dequeue an element, we set the return value to the front of the array, decrement the size of the array, and then increment the index of the front element.",6.0,68
20162,20162,24407,a0052d1186f3fa53f67763ddf5dc1148fc540657d42f0891ff3ac99ce8c9f5c8c2cc81fa44f5583e909b3bdda1a0f1e6a21067a67ce2ede8b9d60f7eef57955f,"A circular array is not actually physically circular but rather uses normal contiguous memory just like a normal array.

However, a circular array keeps track of the number of items it stores and the front item, as the front item is not necessarily at place [0]. This allows us to remove the front item in O(1) as we don't need t shift everything up, all we need to do is increment the front value. When we run out of values at the back but still have in the front, we just add the new values in the front, hence circular. Thus adding is also O(1) as pointer arithmetic comes in.

Size is O(1) as we keep track of number of elements

Getting front is O(1) as we just use pointer arithmetic with stored front value. ",6.0,68
20163,20163,24408,e5714a4c20e7bdae287b7c08ee230173a746342e508a1fdf6f9b0ca3985863c9a9c50fab8cf85194e61c4743030f16659c52ffd068494fd5d94fc6ea4ec382de,"An array is called if we consider the first element as next of the last element .circular arrays are used to implement queues .

There are two ways of implementing a queue in O(1) time and that is using two stacks or using a queue and a deque ,under the deque implementation we can use push operation or remove operation ",0.0,68
20164,20164,24409,0ddebbd83df885f86ba1c96720608778be815c854a9f153df224b96b22cf260eb651e6e1d04778d3c06f6de0d3c75049a5f3bb4b6575599d6f50e21a7074d16e,"A circular array is an array that can loop back and use the space that popped off elements used. We have to keep track of the allocated memory, number of elements in the array and the position of the first element. The number of elements is incremented per push(thing) function call and the decremented per pop() function call. It updates the index of the 1st element by adding one to the current index then finding the modulus between that sum and the space allocated",10.0,68
20165,20165,24410,1b575ce85f9fe9d462e1de73f4e66ff04c921a768d297956a2d166b33e02a5691d14de4e07fdb716975b3003397dd6ecfd657024c0a233117dfee4b6480ebdcd,"A circular array basically is a normal array where we can pop and push items but with the functionality that as the first items in the array are popped, we have the ability to reuse that space and continue that way in a loop unless we run out of space.

How we can implement it:

push -> We use pushback and so we have best case and worst case scenarios. Best case O(1) - There is space available and so we just push the value. Worst case O(n) - There is no space and so we have to reallocate by copying the items to a bigger array(generally *2).

pop -> We use popback and so once again we have best and worse case scenarios. Best case O(1) - We just pop off the item. Worst case O(n) - We might decide that we are wasting space and so we decrease the size of n_allocated which then results in linear time.

front -> We keep track of the front index value and therefore we can call it in constant time, complexity = O(1)

size -> We also keep track of the n_items and so we can make use of it in constant time therefore complexity = O(1)

We need to keep track of values such as n_items; n_allocated and the front index. These are very important because we need these to perform some arithmetic with modulus(%) and these variables when we need to reallocate some more space in the array.

They are updated every time an item is added or popped off as well as when we reallocate space in the circular array.",10.0,68
20166,20166,24411,ab943cfa0d926aa21911a9961743ce4779859ba20a4ac4e15e75033134ef20f2d090435e99a19a4b2beb23e354a8983d0355213a926be357504dc13138c83605,"in a circular array everything is based around a certain domain I have, meaning I revolve from 0 to n and keep rotating around that, n being the last index, I use push_back to push as we normally would, to do a pop_front I delete the first element of the array and update my front to be the following element, say after that we do a push_back on the array and it happens that we were on the last index of the array, I push_front now to fill the space or spaces that were made free as a result of the popping, we continue so till every space in the array is accommodated, for this type of pushing and popping to be possible we do the following when pushing, the index in which I am pushing to should be: (Front + Number of elements) % allocated space, and for popping I increment the front as follows: Front = (Front + 1) % allocated space. we need to keep track of the variables, the Front, the number of elements in an array, and the allocated space.",11.0,68
20167,20167,24412,a483d97f2f6f4b566a91dffee7b0dc51b69866d7a50c6e53308e166eaac8f5373cd9dfbf9a10c25bd5d41a415c716306b0d1e020a1acf8282aad769edfdcc9c4,"in a circular array everything revolves around a certain domain we have, meaning we revolve from 0 to n and keep rotating around that, n being the last index, we push using push_back as we normally would, when we do a pop_front we delete the first element of the array and update our front to be the following element, say after that we do a push_back on the array and it happens that we were on the last index of the array, we push_front now to fill the space or spaces that were made free as a result of the popping, we continue so till every space in the array is accommodated, for this type of pushing and popping to be possible we do as follows when pushing, the index in which we are pushing to should be: (Front + Number of elements) % allocated space, and for popping we increment the front as follows: Front = (Front + 1) % allocated space. we need to keep track of the variables, the Front, Number of elements in array and allocated space.",10.0,68
20168,20168,24413,bef6837a7fdfe1da5fe1293f44c76b96d3b8dcc796faa186ced378d3238a30c359695c10ba31e008e6450186def6f4c6da86e1819e6310ac4629db0e4ae2f7c4,"A circular allows us to use contiguous memory by allowing us to connect the first position to the last position, like a circle. It can be used to implement a queue in O(1) because it has operations based on FIFO so it won't travel to get to another item. You need to keep track of the front values.",2.0,68
20169,20169,24414,a2e71f759079413d4f87ec8f397142f2bf7f364e3ac1403027655c606e40a1106c0bace5c922e3aa206700cf3aa5120aeba8f93363e62c778029029dcc2335f1,"Using modulus (%) arithmetic, the programmer can ""loop"" around the array. This is by keeping track of the space allocated, the index which indicates the front of the queue and the number of items currently stored in the array.

When inserting items using modulus arithmetic for updating the array, by ,[front + number of items] % allocated, this is used to first check that if there is remaining spaces at the back of the array and if it not it will go to the front of the array to the worked out index and insert the value there therefore not needing to traverse resulting in constant time. 

When popping from the array [(f+1)%a) is used to update the front and accounts for if items are stored in such a way the program would need to ""loop"" around the array to find the new front of the queue therefore no traversing is needed and thus takes place in constant time.",10.0,68
20170,20170,24415,df0d62df6145f98b9d8d85662b958119c20c6015becf9534b762b6d6c7c046d872ff37d4ccc77da23e1570c5a7712fc862bda45087171a56e4c5cfc3750e2ad2,"1) It is a block of contiques memory. (array)

2) You need to keep track of

2.1) by pointer to the front of the queue (stored in F-pointer)

2.2) Items in the list (stored in)

2.3) How many memory positions there are in the queue. (Stored in a)

3) A item will be allocated a memory block and will not move till it is removed form the queue.

4) Working for left to right, if we have 0,1 we will push at position 0 = (0+0)%2 [(F+n)%a] (F,n,a = 0,1,2) we push at position 1 = (0+1)%2 [(F+n)%a]

5) we pop position 0 stored at F-pointer (F,n,a = 1,1,2)

We push again (F+n)%2 = (1+1)%2 = 0

6) To be able to keep track of the pointer when it has to loop back to the front of the contiques memory we use (F+n)%a to work out the memory position",11.0,68
20171,20171,24416,ec66e4473040e8ee3556fe295a682aef55293bdc440d5beebc8fb799f1964c0abc0afc761e0c9e5b3dec6cb5d26467ba51d5e312925807725d0b86097bb74bce,"We need to keep track of the allocated space of the array, the index of the front of the queue, and the number of elements in the queue. A circular array works by keeping track of the aforementioned variables so that we can add and remove elements from the array without having to copy its elements unless there is not enough allocated space. When adding to the array you get the remainder of the sum of the number of elements and the position of the front of the array, divided by the allocated space in the array, this will add your value to the back of the circular array, this works in O(1). To remove from the array you increment the value of the variable storing the front, and decrement the value of the variable storing the size, this works in O(1) time. Size is stored in a variable and can thus be accessed in O(1) time. The index of the front is stored in a variable and can thus be accessed in O(1) time.",11.0,68
20172,20172,24417,e1db971413a3e8370e48a08bd90e6c532854614ec97bf2846a8b6f64d7d2d64fceb404c5b40a925c2c496078dab9556b9aedc866e91bea3a7a6a8dc8cc19eb5b,"A circular array allows one to wrap from the end of the array to the front of the array so that the issue of reallocating and copying items to another array when removing an item from the front (in a normal array) can be avoided. In order to allow for this wrapping or looping of the array, the values that need to be tracked are the number of items in the circular array, the index of the item representing the front of the queue, and the allocated space for the circular array. 

By keeping track of the front item and the number of items in the circular array, it is possible to calculate which index corresponds to the back of the array, and thus it is possible to determine which index the next item should be added to (i.e. the index after the last item in the circular array). When adding an item using the push function, the number of items is incremented. Therefore, the push function can be implemented in constant time as all of these steps are constant O(1) time.

In order to implement the pop_front function where the item at the front of the queue is removed, the front item's index is recorded in the variable that keeps track of the front item, therefore, removing from the front involves incrementing the front variable by 1, and decrementing the number of items in the circular array, these steps can occur in constant O(1) time. 

When the number of items in the circular array is equivalent to the space allocated to the circular array, reallocation is required, this is linear O(n) time, however, the occurrence of reallocations is relatively low as each reallocation allows for twice the space as before. Therefore, the number of items that can be inserted before another reallocation is needed grows with each reallocation.

In order to ensure that the items added or removed remain within the bounds of the circular array, modular arithmetic can be implemented.",11.0,68
20173,20173,24418,f7abd04c97a647b1e757bccd7284173478fbf8f28e28e3102567ab244a63fd5c67a5e953a932ab1f774cb73ace52fda53cdbbded4668ee4660e933d867e532bd,"A CIRCULAR ARRAY IS AN ARRAY THAT WORKS AS A NORMAL ARRAY BUT ATTENTION IS PAID TO THE POSITION OF THE FRONT,,NUMBER OF ITEMS AS WELL AS THE NUMBER OF BLOCKS ALLOCATED SINCE IT WORKS THROUGH CONSTANT UPDATING OF THESE THREE VARIABLES DURING OPERATIONS ON IT. ITEMS CAN BE ADDED AS PER NORMAL THROUGH PUSH_BACK AS LONG AS THERE IS SPACE IN THE ARRAY,,ANYWHERE IN THE ARRAY IN O(1) EXCEPT WHEN REALLOCATION TAKES PLACE YIELDING O(N) WHICH IS NOT FREQUENT. HOWEVER REMOVING FROM THE FRONT OF THE ARRAY DOESN'T CAUSE DOING N-1 COPIES TO THE LEFT INSTEAD THE FRONT POSITION IS UPDATED TO ITS PRECEDING INDEX THUS YIELDING O(1) FOR A DEQUEUE FUNCTION. IT WOULD THEN BE EFFICIENT TO IMPLEMENT THE CIRCULAR ARRAY WITH THE FRONT OF THE ARRAY CORRESPONDING TO THE FRONT OF THE QUEUE  AND THE BACK OF THE ARRAY AS THE BACK OF THE QUEUE. WE THEN NEED TO KEEP TRACK OF THE NUMBER OF ITEMS IN THE ARRAY,,THE FRONT POSITION AND THE NUMBER OF BLOCKS ALLOCATED.  WHEN AN ITEM IS REMOVED FROM THE FRONT THE POSITION OF THE FRONT GOES TO THE NEXT ITEM IT'S NOW THE NEW FRONT RESULTING IN IN NO NECESSITY TO SHIFT THE REMAINING ITEMS TO THE LEFT AND N_ITEMS IS DECREMENTED BY 1. WHEN AN ITEM IS ADDED TO THE BACK N_ITEMS INCREMENTS BY 1, HOWEVER IF THE PUSH HAPPENS WHILE AN ITEM IS ALREADY OCCUPYING THE LAST BLOCK/INDEX A CALCULATION IS MADE SO THE ARRAY LOOPS TO THE BEGINNING OR INDEX 0 PROVIDED THERE IS SPACE. IF PUSH HAPPENS WITH N_ITEMS == N_ALLOCATED THEN REALLOCATION TAKES PLACE AND A NEW ARRAY IS CREATED. ",10.0,68
20174,20174,24419,910daf6bb90bfaca5b8329327dbb6876d9a383514e01fe819f79abb1a27019ac7b7555a07d09a61e93831fa5c489e19d607608ea54797f25aad8bd641ed60e55,"The last node is connected to the first node to make it into a circle. This makes it follow the First In First Out principle which means that all new data is added to the back of the queue and removed from the front of the queue. To ensure that the program runs in constant time, we take the index of the front of the queue and add the number of elements in the queue. We then take the modulus of the result we get from that and any remainder we get tells us where to enque our next element. If we run out of space we do a reallocation only this time instead of copying from the beginning we copy from the front of the queue onwards using a for loop.",6.0,68
20175,20175,24420,4541bddfe14df82661aaba793d25bb038432ba934014876821269e81b4029af8b6064a54828f0509d14ee3f303c32ee014b7221977ad133bace3b01a694e694c,"A circular array works by allocating a specific  amount of space/memory in which we can insert our elements. We have to keep track of the number of items in the array and where the front of the queue is .

The front is important as we use its index and take the index value (the first element in our queue) and add that position to the number of elements we have present in our queue. We take the sum of this and say (front + number of items present) % (the amount of memory allocated to the array which then equals our new element. Subsequently we increase the amount of elements we now have. (This is Enque)

The to deque we remove from the front and then the element that was after our now removed element becomes the front of our queue. ",10.0,68
20176,20176,24421,675e836215b62d793972ecb9d5ace2eaf438e0e5d0d26f496ddc3442ba479da55ac029b8a4555f73c538c50ecac4b04edc042861ca9b743e991c19c46392aa72,"Circular array keeps  track of the number of items in the array through (n_items),the size of the array (n_allocated ) and the index of the item at the front of the array (F). The size of the array is always  known, if we add a new item we increment the number of items by 1 and it changes. A circular array iis able to implement a push_back and pop_front functions in constant time O(1) as we do not have to shift all items  aftwe implementing the pop_front as in a normal vector.A push_ back function is implemented in a circular array  and takes constant time O(1) as we place the item at the specific index. To implement this we makes of the modulus arithmetic whic helps to go back to index O if we have reached the last space in the vector. Push_back function uses the data[(n_items +F)%n_allocated ]=value then increment n_items., this takes always takes constant time unless n_items =n_allocated  where we have to reallocate which takes O(n).For pop_front function we increment using the code Front =(Front+1)%n_alloacted and if we are at the end of our vector, it goes back to index 0 ,we decrement N_items using (n--) because there is one less item after we pop rom the array.",13.0,68
20177,20177,24422,16751d82a0250cf90230a736276250ecd4342c2e9097f12ebacee397740771d03e925ee189c3aaacf702dbec6f3610c7e13e7ed44667c2823433286e585becf2,"we need to keep track of allocated, size and the index of the first item. the emty function will check the number of items stored. the front function will have a pointer to the first item.the push back function will add a item to the back of the queue.the pop frnot will decrease the number of items by one and increase the index of the first item by f+1%nallocated",8.0,68
20178,20178,24423,a7fd82a5660b8b1764aaf3905cfa33ae20bea31c698c90051afd8871bc86a6b25112ca62d2256ae4d96fc9b6c6488d5d0378685fcf8bb4b9bc5b8b918494fd4f,"A circular array is like a normal array but when you push an item to the back of the array and there is no space, it will be pushed to the front.
We need to keep track of number of items, the position of the front, the position and the number of allocated memory. For pop_front we decrease the number of items by 1 and increase the index of the front by (F + 1)%n_allocated and pushback, it will be O(1) because its a reference to memory. For push_back it you add an item to (F+size)%n_allocated and increase number or items by 1 and both will happen at O(1). For back and front we already have their location because we have the number of items and the index of front so we can easily access the first item and last item. Size is already being kept track of at constant time.",14.0,68
20179,20179,24424,8ccaa62cbbe76ea20aad42f0abeb4aea6b057f35352db9aef1c4c8bb791949070df63d7ca3789507be754a64de8d3383c759c83cb767d9e10e045b387bce8a09,"a circular array is basically a  array used in a circular form , when u reach the end of a circular array you go back to the beginning, it is linear array where the elements are accessed in a slightly roundabout\circular way. we can implement  a queue using it by using index 0 as the head of the queue then enqueue is simply an add to back operation which we know is 0(1). ",2.0,68
20180,20180,24425,acc027b1281fb7611892bbd9cd22b170d39dac509f3cbd3c4ae2298ef8fcce3e213c9bdb095b30f4b14371abefeb025cbed1bfbb0b3e1f2baccc7d74d415003e,"If we have an array of default size(>=1) with references to back(set to -1) and front(set to 0), each time we enqueue an item, the back index increases, and when we dequeue an item, the back index increases.

As we enqueue ""back"" reaches the last index in the array and the space for adding new items runs out. There is now, however, available space before the front index and it can be used for enqueueing new items.

Using the modulo, the circular queue can be simulated as back%array_size.

Finally, when the back and front are next to each other and we want to enqueue more items we can double the size of the array or throw in an exception",5.0,68
20181,20181,24426,78249ef9b62941992169ea6ab9335b72fe3732b0d62324e87cfd98782c3176ff3a0f6d77d1563959cb064ffef03d777dd5132e65d5820daed930a9e3247d9f38,"Roughly speaking,say you keep track of the index of the first and last element.Say you start first at 0, and last at 10 (where this indicates nothing in the queue). When you add a new element ,you increment last index ,the stuff the new into that position.When you ""pop"" something off the queue ,you copy it from the first index,then increment the first index .",0.0,68
20182,20182,24427,d34efe98a2513ac08acc6faef18dfc38310a4938c3e2400c3ec9b606c14e0455c45534357347e63004ac9d2c3c1e1d7805afa99ff5f4d271c3dc0f7c2153d7d4,"How The Circular Array Works

	*
	* Circular array works almost in the same way as the normal vector/array. When working with Circular array we would declare the size of it as we would with an array. The circular array differs from vector/array by that when we reach the last index we go back to the first index if we want to push back something as long as number of elements is less than n_allocated.

	* When the number of elements is equal to n_allocated we then reallocate twice as much space as before, as we would do in vector
	* To go back from the last index to the first index we would usually use the modulo arithmetic
	* Circular Arrays also have pop_front,push_back,front and size functions which are in O(1)

How We can Implement a Queue using Circular Array

	* We would have basically 4 functions(we can have more) which are push,pop,size,front
	* Push would be the push_back of the Circular array, we will push to the back and the increment variable  holding the number of elements
	* Pop would use Pop_back function of the CA, we would pop from the front in O(1) time and decrement the variable holding number of elements

What Value We Need To Keep Track Of?

	* We need to keep track of the number of elements in the array and increment it whenever we call push to the back
	* We also keep track of the Front Index and we increment it whenever we pop from the front
	* We can also keep track of the size allocated and we should update it to be twice as the size of the previous array whenever we call the reallocate function",11.0,68
20183,20183,24428,ca7ca134b5efdd7b26013cdee3bcba7329b07570412673ca953a2b1fc000b358026f967889f2b4b641fef26d116ce971213d8a9f77c08db97c244ae7f54e090e,"We need to keep track of both the front and the back. 

Their indexes will be used to keep track of their values. The back is the sum of the index of the last inserted element as well as the index of the first element. ",2.0,68
20184,20184,24429,6d04032d059678dcb346209e5f60e18a44d0c551ad3d7c0e551f1957033a386ffc9828dc7e1374b35e8828c43ed8d61ae22f6c2de063b8779cad31efc30f066d,"Keep track of the number of items stored inside the array and the position of the front item which lets us find the back position of the array. Using the push function(O(1)) the array is then updated which increases the number of items in the array by 1. The pop function both decreases the number of items in the array and also increases the front position. It becomes circular when the allocated space is finished so you have to reallocate to the start of the array, we copy from the front of the queue, reset the front to 0 and increased the allocated size. The modulus(f + n%a) allows us to go to the allocated spot  and also allows the array to be circular.",12.0,68
20185,20185,24430,ea2a1bfcbe729f7621c917f77c54d68d14594e336635f36baf52750af4fc628657adce12683b4083425f0f9b883a0f335d02fe57cab5815e5cb77320840dd672,"The circular array works the same as a normal array except that we use it as a loop by making use of the modulus in order for the array to ""wrap"" around to the beginning meaning that when we reach the last position in the array we won't experience a segmentation error because the loop will simply go back to the first position of the array. We can achieve this by making use of the modulus - the modulus should be the same size as the the size of the array. and this will be used with within the index increment of the array (data[F+n]%a) in order to make it possible to access the first index again.",2.0,68
20186,20186,24431,5d0d60194fd1b05c809499adb963afbac0ab800c552d7666ea7779f6183d17839f234e9ecee3ed11e567d9e2e5d5f869bc08bd2cc74894f9ca624282e8055b10,"A circular array is a data structure that, provided that it contains empty spaces, will wrap around to the beginning slot of the memory location for that array and start using those spaces to store values. By storing the number of items in the array, the position of the 'front' of the array, and the amount of allocated space for that array, the array becomes 'circular'. If the last space of the array memory is filled, but the front memory location is not, the structure will store the next value in the array at the front of the memory location. The array never accesses memory that it out of its range due to the calculation, (F+n) MOD a, which ensures that accessing data stays within the bounds of the array

A circular array stores: 

	* The number of items in the array, for example, denoted as 'n'
	* The position of the front of the array, for example, denoted as 'F'
	* The amount of allocated space for that array, for example, denoted as 'a'

How it can be used to implement a Queue:

	* void push(T value) or void enqueue(T value) - since the position of the front of the array is always known, as well as the number of items in the array, adding values to the back of the array requires no traversal of the array. To add to the back of the array, you must perform the calculation: data[(F+n) MOD a], and this will take you to the back of the array for you to add an items. This calculation takes O(1) or constant time and therefore the function will take O(1) or constant time. This will only be linear, O(n), if all the allocated spaces are filled. 
	* void pop() or void dequeue() - since the position of the front of the array is always known, removing the first item takes constant or O(1) time
	* T& peek() or T& front() - again, since the position of the front of the array is always known, it will take constant or O(1) time to return a reference of the value at the front position of the array
	* size_t size() - since the number of items in the array is always known, i.e is always stored, returning the number of items in the array will take constant or O(1) time
	* bool empty() - since the number of items in the array is always known, i.e is always stored, this function will always be constant as it will return false if the number of items is greater than 0, or true if the number of items is equal to 0",11.0,68
20187,20187,24432,b9d82cd7c247fea1955a43aaaf5bb439ce7f4f53d3df9728ceb44f0e1b947c368ff1574400183b4d31d82813774edfdb38a1fdb56e3256ef8ab3e682f8c08da1,"A circular array is basically an array that can be looped.(We imagine it as circular since the back touches the front but in truth it is a normal contiguous array that can move from the back to the front.)

Once it reaches the back it can move all the way to the front again, as long as there is space to insert an item. It can be used to implement a queue in O(1) time because it can pop from the front since it keeps track of where the front is and it can push back from the back since it knows where the front is and can loop around. 

To implement the push function (push from the back) you would need to keep track of the index so you know when to insert the value. data[(front + n_items) % allocated_items] = value can be used.

To implement the pop function (pop from the front) you could do something similar and say, front  = (front+ 1) % allocated_items

To implement the size function you would take the n_items since it's kept track of. And so is the front.

So all the implementations would be O(1) time.

 It keeps track of:

	* The number of items inside an array. Which can be updated whenever an item is added in the push function, it increases by one and when an item is removed in the pop function, it can decrease by one
	* The position of the front. Which is updated in the pop function, the front variable can be incremented, increasing the position or index of the front variable.
	* The amount of space allocated. Which is only updated in a reallocation when an item is added and there is no space, the space allocated is doubled. Or when there is too much space and the space is halved only if the items are a quarter of the space allocated. Only then does space allocated change.

All of these can be kept track of with variables such as 'a' for allocated, 'f' for front and 'n' for number of items.",11.0,68
20188,20188,24433,a4513e9eefe06c5d06cd544fbaa5db795547b8f01893c660dc4a8e31a77cbc61bded840bbf0b3fd52a94491adbe0a21a3d4396c46fe19d46198e8b7b21695be6,"A circular array is a normal array in memory, but we keep on looping to the first cell of the array when reaching the last cell of the array as long as we have not run out of space for inserting.

We need to keep track of the number of items stored in our array, and the position of the front of the array, and with those two values, we can work out where the last item in the array is (the back of the array).

In order to add to the circular array, we first check if we need to re-allocate space, then to insert at the back of the que, we would start at the front of our circular array, so we would make a variable to store the position of the front value of the array, and keep on pushing into index[front+size] if we want to add more values. This would happen in O(1) time. We would keep track of the size accordingly as values are added which is O(1)

In order to remove from the circular array, we would want to remove from the front of que, so we will look at the front of our circular array, and using our stored front index values, we would remove index[front], then increment our front value so we can assign the new front to the next value in the que. This would happen in O(1) time.

In order to loop to the front of the circular array, when reaching the end of our circular array, we would have to use modulus and implement the formula ((front+size) % maxarraysize) as our index. This would happen in O(1) time.

To make an O(1) que using circular arrays, it would have to be limited to the space initialized by the programmer, but If we run out of space, we would have to copy from the front of que onwards, which would be O(n) time.",11.0,68
20189,20189,24434,d5a3f7d660aa30769e68a7c616a4942c8f05f0c2e034be1b4e61932df724917fd2a406f53a34e25ab412791ed6463a16ef1b087d401683c22430b89ba7a21be9,"we need to keep track of how much space we have allocated, the number of items in the array and the front of the array. 

Space allocated will remain constant, number of items will be updated (increase/decrease) depending on if we pop/push and the front of the array will be updated when we pop (will update to the next position in the array).

Circular arrays use modular arithmetic when popping or pushing, this allows the array to be updated and will flow like a circle when all positions in the array ( from the front position) are filled, we'll use modular arithmetic to be able to access the positions before the front position for our push function or when we need to increase our front position but its position will be greater than the allocated space.

the push function will insert a function at the position of the front position plus the number of items modulus the allocated space and the remainder will give us the position. The remainder will never be greater than the allocated space so when inserting or removing items in the array we will be going around the array as if its a circle until there is no more space.",11.0,68
20190,20190,24435,5c96945f14d6fc788ed8c6c36dabf314debb1526e588422f61ac844f148e394c747509da6ebf3fac148319b89d19dab295d5360db7c4991b8db71ccf538d7808,"A circular array works as an array that is constantly looping with its storage space. If it has a certain block of memory and the number of items are not equal to or larger than the allocated space, then the array is able to continuously loop within its array to allocate space for whichever object needs to be added in it. If the space runs out, a new block of memory of double the size gets allocated and all the items from the first block get copied onto the new block with the object at the front of list gets placed once again at the beginning of the memory block. We need to keep track of the values that lie between the front and the back of the list, as well as the number of items in the queue. 

The values are updated by ensuring the operations can work with the sum of the front and number of items and remainder of these as they get divided by the allocated space code. For example, the enqueue(push) operation can be calculated by saying 

void enqueue(Thing value)

{

DATA[(F+n_items)%a] = value;

 n++;

}",8.0,68
20191,20191,24436,9a6d2e6e6e0c1b575d6fd6f9cd31a3d7ef05b9fbb8f9b527d2f24c66326f4e25fb885d747e3511e370820c0e5c65531a52fb8637b76c7b43895037c2420cfc80,"We would implement the circular array the same way as a regular array but we would link the front to the back of the array by using modulus arithmetic.

The values we need to keep track of are the number of items in the array, the position of the front item and the number of blocks allocated.",4.0,68
20192,20192,24437,b8ff274cc91e39334247b9673eeb1e1ed2acdbcefc990de9bf2b4226b88349ab6bc97343b39be8aded8a6ab21d1bf5dc3045e9f7596480cb1279270e81abbd58,"Values to keep track of are:

Number of items & Position of front

The main improvement from normal arrays is that circular arrays don't move one element over to the left when we pop at the front or move one element to the right when we push at the front but rather update the value of position of front in the ""circle"", the value of number of items and use pointer arithmetic in order to pop from the front or push to the front. Hence we achieve constant time for enqueue when using the front of the circular array as the back of the queue and constant time for dequeue when using the front of the circular array as the front of the queue.

size() is constant time since we keep track of number of items in linked list.

front() is constant time since pointer arithmetics takes constant time regardless of position in array.",8.0,68
20193,20193,24438,4fe3ddceb8532be5264d396e27eca9f3430928d2debfbdca391cfa468f769445f07ae40650717eb0131d20465c9068c4b8bf87a2c7932640884394a0094fc8e5,"Say we have an array of default size(>=) with reference to back(set to -1) and front(set to 0), each time we enqueue an item, the back index increases and increases again when we dequeue an item.

As we enqueue, 'back' reaches the last index in the array and the space for adding new items runs out. There is however, available space before the front index and it can be used for enqueueing new items. 

Using the modulo, the circular queue can be simulated as back%array_size.

Finally, when back and front are next to each other and we want to enqueue more items we can double the size of the array or throw in an exception.",6.0,68
20194,20194,24439,6398cd3a19a3d471bc5a210dfd041039aa199f2840055e48507502bec88a8f8eb3f128de790430daa8207ba0fde7dea8a8fb8416bcb584e1bb9e76ef88b1e1f2,a circular array is an array in which we take the first element of the array as the next of the last element in the array. ,0.0,68
20195,20195,24440,b96308b5b954fc4c2086f6faec027fc8299af60a164d99cbdc75a0802d3bb5ac5823699b9e2e5c78a86bbf73886ed3408a16b29a0f7ee6dc90b05a8f2f91fcd5,"A circular array works by declaring an array and using indexing to add values to the array such that they are stored contiguously. 

We must keep track of the size of the array which is a, the number of values added in the array which is n and we must also keep track of the front index (f). 

The push is implemented in O(1)  by adding a value we want to an index in the array. We the use modulus arithmetic to make sure that we keep track of our last index using data[(f+n)%a]=value and the increment the n which is number of values in the array. 

The pop is implemented in O(1) by using modulus arithmetic to remove the value at the beginning of the array by using the algorithm [(f+1)%a] and then decrementing the the number of values in the array.

Both the these operations work in O(1) because we wouldn't have to copy all values in the array like we do if we use a vector. 

The size is O(1) by counting number of values in the  array and peek ",13.0,68
20196,20196,24441,252668df997d55b86d753e14db9bb82d9a9ab0f27d714f3256c72a03986a906ffccf1958bf221d3ab998a7770edda41ec2de25393f1d9a62f105684cf09211ed,"A circular array uses the First in first out method , where the last item in the circular array is connected to the first item in the same array. This allows use to insert items into the circular array until the array is full or the memory allocated is full. by implementing the queue system here it will allow us to insert elements within the array and remove elements as well using the functions of enqueue and dequeue.

We need to keep track of the number of items in the array, and the position of the front item in the array. they would be updated by first checking if the number of items is greater than the memory allocated if not then we would procced to add in any items to the array or remove any items in the array.",6.0,68
20197,20197,24442,267e2a74684712f40153e983cf911454f693aaba7aeefb5a018f4e1b42bb05582faee8c5c865be8869988dea6e1c2f220a507c49209244aad2cd13359f2247d7,So it is a first in and first out system and the last position is connected to the first. Need to keep track of the first and the last value plus values are always added at the rear.,1.0,68
20198,20198,24443,4f0d170bb113012c8d343271d925a96ef0e199ecdca36f51a1fc99d7e0e8c67fb97155bfa738d3317830adb88f58c316437e0cf62b20c43f4e89ab893b6e7471,"The main idea about the circular array is that the end of the array sort of loops/wraps around to the start of the array. 
We can find the back of the array by keeping track of the values: number of items in the array (n), position of the front of the array (first element)(F), and the number of space allocated in the array these values are updated as values are being pushed or popped in the array(a). 

In order to implement the queue you need need a:

- push function ( it pushes a value in the array by parameter in the position of (F+n)%a ) if n==a then you need to reallocate the array to store more values 

- pop function( it pops from the front of the array using the code F=(F+1)% a and then by decrementing n by 1.

- front function to return F the front of the array.

- size function to return n (the size of the array)",13.0,68
20199,20199,24444,9b5371bf3d8a67220ea9112f458e092347973d5a590a2ada7f6d386201210567493e4842dd7263535c03e1b4ce797297171327f4cefdbdd79731ace1f4e756bb,"A circular array loops around the contiguous inserting and removing items.

*push_back in the circular array uses modulus arithmetic where the front plus the number of items modulus of allocated , then we assign the value data[ (front +n_items )% n_allocated ]=value. this all happens in O(1).

*popping an item we increment the front and find its modulus to n _allocated and we decrement the number of item.

f=(f+1)%a

n_item--

*finding the size of the array is easy as we just return n_allocated.

we keep track of:

Front

n_allocated

n_items",11.0,68
20200,20200,24445,89502ac0aa9bcc7e1f53c6f2ab1184a643f5c96abf038408f562f5cb7340154d0c96d136d3c4ce774773aa13f3d95a0a98c70e80020a05dce05a8835fe30adf5,circular if we consider the first element as next of the last element.,0.0,68
20201,20201,24446,0bce68d12d4bb423184167950cec8450c2529233502545e57429beb9cfc6f093c786ba9febad285f8197b7bbc233a3b506a933f196c9852e05b5416cd8c68c8e,"A circular array is stored as a normal array in memory.

we need to keep track of the number of items stored inside the array, and the position of the front and then we can work out where the back of the array is at any point and we need to know how much space we have allocated",4.0,68
20202,20202,24447,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,"we would keep track of the current position, the next position and the previous position, update the next by taking the modulo of the current position +1 with the number of cells in the array, the previous position by taking the modulo of the current position + the number of cells + 1 with the number of cells, a circular array is an array when we take the first element of the next of the last element.",0.0,68
20203,20203,24448,ef56d487f412ffdca7b3412858b2ccd1fa21fc365016661f00994f5e06683c6e545b948b70c4775a9a839e6049995e36f03b1f06a7374933a80a9013b6052c37,"a circular array is one that is linked for head to tail , so in other words its wrapped around. you will need to keep track of the beginning of the queue and the last item as well , using pointers .

when you add to the queue, you will need to update the last pointer and when you remove you will also need to update the head pointer . by removing items , you will be creating more space in order to add more items to the queue",0.0,68
20204,20204,24449,a50f1f05303eb676c08e683fb412c46779741d1e408ab7173f3f3a12df3f04196b4fd7b7add1fd647d8efd191c43d6971e5cae7611afd814fbea2a7330f3ce46,"There's declared variables which keep track of the number of items(a), the first item in the vector(f) and the number of allocated space(s).

When an item is added to the structure a is incremented and f is initialised to zero for position of the first value, as values are added and the array is full, new array is allocated with double the same size, then items are copied to the new array and then push back the new item then the old array is deleted.

If the function pop is called, the first value that was pushed will be deleted from the array using the f variable which is the position of the first item, then f is incremented again to hold position of the following.

If the peek() function is called one can return a reference to the front value using the f variable which holds position of the array's front element ",11.0,68
20205,20205,24450,27704af10f29b9fd01985b3a533f1213c119ce01a32f451e037e0491eede8c71f38ccb8abe4edd8c056927c76b6bf0c23fb2a88f8cca52e5000b6c906d6692ef,"A circular array is an array that works in a circular way, meaning that when you get to the last item in the array, you go back to the first item in the array. The first item is the next item of the last item.

We need to keep track of the number of items in the circular array, the amount of space we have allocated/capacity of the array, as well as the position of the first item in the circular array. 

When we enqueue, we insert the new item at position (front+size)%capacity and we increase the size of the circular array by 1.

When we dequeue, we remove the item at the front of the array, and update the front to be the position (front+1)%capacity and we increase the size of the circular array by 1.",10.0,68
20206,20206,24451,ba67943d9c3f68c2a82bf70197366cb2cce1d21f6696fe648aaf7068ed18399b5899a40e2f0d4a0c53a04c7e84020c544f2b79e8fc23a17b4dca16bd22dbd15b,"When dealing with a circular array, we need to keep track of the number of items, the front item and the allocated space. When we push back an item it becomes the front item, and the allocated space is decreased by one and the number of items is increased by one. When we pop an item the front item gets removed and the space is empty, After filling in all the items and the first space is empty , we will add the front and the number of items in order to find the total spaces they allocated. Then find the modulus of that sum and the space allocated. We do this in order to know where to place our next item.",6.0,68
20207,20207,24452,dba55105f290263eab690cc35467de21c1485b240568356b922de9e4385ff6cd7f9c33bdddf55cba48dae5962652c3708da244fefbb69455c6e660d7de9c7d15,"A Circular array is very simlar to a normal array, the main difference is the time complexity of a circular array is 0(1) and a normal array is 0(n) for functions like pushback, popback. There is 3 main value u need to keep track of in a circular array.1. front(f). 2. Amount if allocated memory(a). 3. Number of elements inside the array(n). the push function adds the element into the array if its within the allocated space  the same as it would with a standard array. data[f+n] = value. if the n exceeds the memory allocated it would usually lead to create a second array wheir u copy everything. but with a circular array  data[(f+n)%a] which allows reallocate to the start of the array. we copy from the queue reset the front to 0. and double the allocated size. Similarly with the popfront function u remove the 1st item and inc the front value. we avoid the seg fault error by using the % which allows to continue to remove from the front even at the end. by using the queue value. 

 ",13.0,68
20208,20208,24453,5888307e6e5630e26d91393f9d95b55394aa59f773d80fc5cba42e8220ea74538fd7609c1185eaef557523bfd3715cc3b2307d7a31ddf68499df84fa7da160d9,"a circular array always had the first element as the front even when the first element is deleted the front is updated to point to the second element which will then be the first element. For each space left empty the circular array will add an element to the empty space even if the last spot is full and will then double the size if a new element is to be added and there is no room for it.

in order for a circular array to be used to implement a queue in constant time then whenever a new element is pushed: data[front + n elements] = value;

take the front elements and add it to the number of element to push in the new value hence it is important to keep the number of elements;

for pop we decrease the number of element and increment front so that front can be the next element

enqueue and dequeue will be constant, the size will be constant since we are already keeping the number of elements and front will always be constant since it is the first element. In this way a circular array can the return to the first index whenever it reaches the end if there is space. In order to loop back we need 

to do data[(front + i) % the number of elements] so that our front can always be front.

circular arrays always loop back as long as there is an empty position and a new element is to be added.",11.0,68
20209,20209,24454,c6130d795cb6021c7594812b73d6b159744ce452f7f194d2a8acfd0f6313f2562bada8d95c7d6c5736c9d1d528be9655da041882fe8c7474badb6562243ddc74,"A circular array works in a way that if an item is removed from its front, instead of the items left in it be copied and shifted one index to the front, the front index is shifted to the next item and that space is freed and ready to be reused to store another item in the circular array. It keeps track of the space allocated (_A_), the number of items in it (_N_), and the index with the first item/front (_F_). By being of this nature it can pop_front in O(1) time as there's no copying of the remaining items when the front is removed. It can also push_back in O(1) time by just using one pointer arithmetic (using _F_ and_ N_) and one assignment. It can easily wrap around itself using modular arithmetics to fill empty spaces if they exist at the front of the contiguous memory. It can return the item at the front in O(1) time as it keeps track of the front index and it can just access that index. It also returns the size in O(1) time as it already keeps track of the number of items in the array. _A_ is updated when the array is resized._ N_ is incremented when an item is pushed and decrement when an item is popped. _ F_ is incremented when an item is popped at the front.",14.0,68
20210,20210,24455,8f4f0cec01fab6a6a49376ed0eca817677b16456497e4474dea2db6c84f10bbab5215841562427aec9d1d1cb57d57272e23d92898bef51a2205b3db761cea98d,"A circular array is essentially a standard array that we are able the pop from the front of in constant time. This is achieved by treating the array as if it's end location is actually next to it's beginning location. When pushing, we say the i-th item in the array = the new value where 

i = (Location of the First Item in the queue + number of locations occupied by the queue) % size of the array. We then increment number of elements in the array. 

(Modulus will return the remainder so if we try to push 1 position ahead of where the array ends, we push at the start of the array again)

This formula for i allows us utilise extra space in the array that we may attain from popping items from the front as the position of the front item shifts backwards as we pop. We also use a similar formula for popping where we say the: 

Position of the First Item in the ""queue"" = (Position of the First Item in the queue + 1) % size of the array. We then decrement the number of elements in the array.

This also ensures that if we pop 1 position behind where the array starts, we pop from the end of the array again.

We must then keep track of the Position of the First Item in the ""queue"" (F), the number of elements in the array (N) and size of the array (S) and update them as I have done above.

This all results in Popping and Pushing happening in O(1) time unless we need to reallocate the array's size, which would unfortunately be O(N). Empty, Size, Front and Back can all too occur in O(1) since we can use the values we have to determine these functions in constant time.",14.0,68
20211,20211,24456,a41ff85d7c3f46c972cdda9b8d99297a4177ec80aa4a317631762cd6ae04cc877e3ccd31e4fd09e41eccdaa2cd1266d20e5947fd82dfa31e5b04a9f5e1bd8e0c,"Since the only way to pop at the front of a vector (using self-implemented pop_front function) is inefficient -- takes linear time, a circular array works to make this constant time. This array works so that instead of ending at the back of the array's allocated spaces, the array wraps around to the front of the array's allocated space. This way, the value at the front does not have to be at index 0 and pop_front may be implemented to run at constant time. 

We need to keep track of variable F_INDEX, which stores index of value at the front, N_ITEMS, which stores number of items currently inside the array, and N_ALLOCATED, which stores the total number of spaces allocated to the array. 

To implement PUSH_BACK function, we find the back to the queue using (f_index + n_items)%n_allocated and adding value at that position then increment n_items.",8.0,68
20212,20212,24457,fcd3cd6f6ab23272e8ef67866982250cf0b69308ab1f155fea93b78f0f8230cc3a80d03659b858f52503462ba79795983adf53baae8dc1b2c6482664286cb263,Circular Array is almost similar to the usual array but when we remove the item at the front we dont push the other items to the item we removed we will start our index on the next item.,4.0,68
20213,20213,24458,23b5a4e63c9fefece084783cc1411977943e7d8d3612a093af2540d5bb113a4845b418786034d0d238575bbb9fe95d816e937dc9fe084e3f124b6dcce8457f10,"A circular array is laid out in contiguous memory. It works just as a normal array would (in memory) but when we get to the end of the circular array, we can use a mechanism to wrap around back to the beginning to add another item. This mechanism is using modulus. If we remove an item in an array, there will be space in there so once we have filled spaces to the end (except for that one space where an item was popped off earlier) we can calculate at what index that space is using data[(f+n)%a]=value; where f is the front (how many items were added to the front which always increases when an item is removed) and n is the number of items in the circular array (when popping, this number decreases by 1 but increase by 1 when pushing). 'a' is the number of blocks in total in the circular array. 'value' is the item in which you would like to add to the circular array. So the formula (f+n)%a calculates the index number in which there is space to add an item. All 4 functions (pop_front, push_back, size and front) are all in constant time (O(1)) as no traversing or reallocating and copying is needed (unless n==a which is very very rare). We need to keep track of the number of blocks in the circular array (a), the number of items (n) and the front (f). Pushing updates 'n' (it increases the number of items by one) and popping updates 'n' and 'f' (decreasing the number of items by one and increasing the front by one). ",11.0,68
20214,20214,24459,dc1d80fcfca2cd7f4c0d66c0e3645622562d53654a85ac238b9c0b928dfd07eeca15aea65682a467ac6bd4135a13a6043d96321ee55136fa0664700d6e749201,.,0.0,68
20215,20215,24460,03af6c40b97133a1240dcc22b0dd356e3929ea04c9cf63c336ed0f2605d19efb0d0a0e5a6c60e766990694456ae922f3a477316845f8028bca7fb236d74cb185,"A circular array is an array that has both the front and rear indices move through the array, it is difficult to detect which is the first and which is the last item. A counter can be used to detect the total number of items in the queue and to keep track which item is the first and whch is the last. To update the queue we need to know if there is space to insert an item.",2.0,68
20216,20216,24461,bc7ce8dcf81474ef89d407bc167ddbdc0ae686813582e07ef0e124f6d6fe081339ab3b2bb05c54a356b901c5c208933d91dbaf731894bf50cc25eab5e102a8e6,"A circular array is like a normal array in memory but it's thought to be in a circle.If there were indexes from 0 onwards,we can insert a number beginning at the first index 0  and move onwards,and when we want to remove then we can also remove from the beginning onwards.It will be layed out continuously in memory.We need to keep track of the number of items that are currently stored in the array and the position of the front item.Everytime an item is added or removed then the number of items in the array must be updated as well as the position of the front item.If we wanted to copy the items then we would start at the front of the queue and not at the front of the vector,if space runs out then reallocation will take place.A loop can be used to copy the items into the new memory.",4.0,68
20217,20217,24462,d02795a14cf200c3a4e42da8fa77ef31727a409d797dd41af60f44aca9829ba9ae25ee3cf59e3f4d5058d031c70d2bc7493c09427e32e68aa4eb4dcf5128f375,"circular array is just a like a normal array except unlike normal array the next item of the last element is the first element. 

first we have to keep track of the front and size of the circular array at all times. for enqueue assign the value to the data ith item where the ith item is determined by modulo operation when the front is added to the size and divided by the total space available and then we increase the size by one. the dequeue we assign the front of the array to be the remainder of the front added by one and divided by the total space available. ",6.0,68
20218,20218,24463,f2a1d44943cafd29447c9cc6d850c73ca115efbe45cc60a50c497d9c39593f6c44e4c2d4facba5ee2393c40106c70b0307d8a427a20ee6b2ecb0031a02f6d25c,A circular queue is similar to a linear queue as it is also based on the FIFO (First In First Out) principle except that the last position is connected to the first position in a circular queue that forms a circle.,0.0,68
20219,20219,24464,1db17093b11c1476f03e1842d3fd75c18d4034c323e18d85de2325fa751f6201dc73b8705d987e46f915cfc55474341bdc436a256b6ba4b925f54ea754c444c7,Circular Array: the idea is we simply loop round and around. Here you don't have to move every element over by one after removing a number from front. So new front would be 1 and not 0 and so on. So it would be [(number of items + first) mod the number of allocated space] as the position to insert into the back  of the queue. Then increment the number of items. When removing from the front [(front +1) mod number of allocated space] will give the new first and the number of items decreases.,8.0,68
20220,20220,24465,a0053c94d18ea0e087a62013f5ac80c5b6b5b2b0c4aa9dd88e21096fafa1947351de1bc64c5f102a231a8bd4d8d7cf40acc72747f50d8fe1ae800f7aa85e0eed,"A circular array, stores memory in a contiguous way. The front of the array needs to be known to then keep track of the space still available.  The front and size functions are constant time. In the best case both the push and pop functions are in constant time however when in worst case, they are in linear time.",2.0,68
20221,20221,24466,144fe98b924f74a4cb0e0020ec3ddfeccf820bfabdc366ff5bf990f2f806b30158897deffdf43eaec7d0e8b090cab1bb52a2dedd43e24a988f1cada5b7d709f1,"we insert at he front and remove at the back , we are looping round and around as long we have space .
we keep track of the number of items that are currently stored in the array , as well the position of the front

to update it we can work out where the back of the array is .",3.0,68
20222,20222,24467,b9398cac04fafed43567a061ce43d1f6d47a11dc43ed26ca3b7c803119e60ccce5216c5b0d8f2fe86de25d577c66b8be90d26d4412d9f88f080c8ddc823e6bcb,A circular array is a an array that works works by placing the first element as first of the last element ,0.0,68
20223,20223,24468,1524a034e009646803d7074c495cb1bd3919f40bf0c99261b282adc7801990411f97759342d2d5b53fea8bfcd2292ae00d0444e55290b251e7ed8a081caf06dd,"A Circular array keeps track of the front of the array, the number of elements in the array and the amount of space allocated to the array. Therefore a circular array would need a variable that references the front of the circular array, a variable that references the number of elements allocated in the array and a variable that references the amount of space that has been allocated for the circular array.

The push_back function would be implemented by assigning the element in the array to the position in the array that is the sum of of the front variable and number of elements variable and then modulus by the allocated variable. The number of elements variable would then  be increased. This would take Constant time O(1). 

The pop_front function would be implemented by deleting the value stored in the array at the front variable position. The front variable would be increased by one  and then modulus by the allocated variable. The number of elements variable would be decreased. This would take Constant time O(1).

The Size function would be implemented by using the build in array function "".size"" which will return a reference to the size of the array. This would take Constant time O(1).",13.0,68
20224,20224,24469,c927373e71fe30f4255c61610bb88cd9a4bb26b4d4a5c6bc2711f05bbe84ffcf49fd97d920d1a706ea1e91d40784c2fadbc56f95b4fae450f318d7610a7daca1,"A circular array is the most efficient implementation of a queue. It is a type of array that considers the first element as next of the last element. 

The circular array can implement a queue in O(1) time by making use of the mod operator(%). 

Where 'a' is the amount of allocated space, 'n' is the number of elements in the array and 'F' is the value at the front of the array, the PUSH() FUNCTION WOULD BE IMPLEMENTED AS FOLLOWS: 

data[ (F+n) % a] = value;

n++ ;

Here, we need to keep track of the number of elements in the array and we update this value using the increment operator.

THE POP() FUNCTION WOULD BE IMPLEMENTED AS FOLLOWS:

F = (F+1) % a;

n-- ;

Here, we need to keep track of the number of elements in the array and we update this value using the decrement operator. We also keep track of the value 'F' at the front of the array.",11.0,68
20225,20225,24470,c0e222e387522491c144bc66b8d4aac6d8899881b15676a75bd42f6939be2d68b02062c035d5f028531cde71d4b0b2bb7581d5e165c7c3be11bd4e67e796913f,"A circular array loops around the allocated contiguous memory. After the last allocated space, it returns to the front of the array which is the first item. An item can be inserted in the array as long as there is space.

The enqueue function can be implemented by adding to the back of the array which is the next empty space. This is done using pointer arithmetic and modulus arithmetic resulting in constant time.

The dequeue function can be implemented by accessing the first item and removing it them incrementing 'first' to point to the next item. This is also done using pointer arithmetic and modulus arithmetic resulting in constant time. 

We need to keep track of the allocated space which is updated every time the array is full and space is reallocated.

the number of items in the vector is updated by initializing a counter and incrementing  when we enqueue and decrementing when we dequeue.

Also keep track of the first item in the vector and it is updated  when we dequeue by incrementing 'front' and finding its modulus to the number of allocated items.

Size function is also constant as we return the number of items which is kept and updated.",13.0,68
20226,20226,24471,c7fddd77b6fed9bc15d19de2718acf9bd47e63c47fabc90953d259ee95b77d6203c59c32fab4eab8591fe4a7373a9aafae0952036c94bc9ebef7955717c99e00,"In Circular arrays we have the last element following the first element and we need values like front to get the first item ,the rear to get the last element,enQueue to insert a value in the queue and deQueueu to remove from the front position.",0.0,68
20227,20227,24472,20a63554bf7ab6e06ce970a9c763f370f49fc1a727f591ec7304c432565faf9d2b891194e01cc67ff029c1fe6de8363ececadce22ee4af544785f47985cda509,Front of the array is the front of the queue and the back of the array is the back of the queue. ,0.0,68
20228,20228,24473,79e7d7f9dd31af42dafc3f30ed17b2ec3bfb7c371aeb90fda49a78ac5ff634413c5502ef51e48fca99485ebc6751e35a6357de07c8799c082943fd8aca0f76df,"A circular array works by wrapping around the last item to index 0, so long we have space we can keep adding (enqueue) to the back, since we are implementing with queue, to achieve O(1) and remove/dequeue/pop from the front at O(1) since we will be keeping track of the front item in the list, by incrementing by 1 modulo number of allocations in the array. We also need to keep track of the number of items in the array.",4.0,68
20229,20229,24474,52f183a2edd50f67bf9165da2ed344e6b1dbef117bcc8a87e8fdd544cade3eccfad6434b2157d981bfdc96048e52a8b1696fb090b734b452d891d2f61d866105,"In a circular array,the first item is next to the last item connected end-to-end.If an item is removed from the array the front index shifts to the next space and the space is freed and can be used to store another item in that array.There is no need for copying items.It keeps track of the amount of space allocated,number of items stored in it and index of the first item in the array.Due to these reasons pop_front takes O(1) time.Push_front also takes O(1) due to the use of only one pointer arihmetic and an assignment.Empty cells are filled are filled using modular arithmetics an thus can wrap itself around.Returning an item takes O(1) time since we keep track of the index of the first item.Returning size also take O(1) since we kept track of the number of  items stored.The amount of space allocated is updated when  the array is resized.The  number of items stored increases when an item is pushed to the back and decreases when it is popped.Popping at the front increases the index of the first item.",11.0,68
20230,20230,24475,87b26af5215183ea5d646e967e1e3374a7a4afb5a13a2967680ff8a29d219e9ac775560a42891913325361c21b3cb2f9b5121d0317fb7c951cff2c01aed37b66,"A circular array is an array were the last element is followed by the first element. The values that we need to keep track of are size, front and rear. Declare a circular array. When we enqueue we push data [( rear +1) % size] and when we dequeue we pop data, which will be in O(1) time provided that we do not have to reallocate memory. Size value will = 0 if the queue is empty, O(1) time. ",8.0,68
20231,20231,24476,2f8068722efcb5acef0b043ef7eeece2ba76bc57f445239c4ee08b7c2bb5238f231cca575128f6a330204e13d52f6c557830c59595c0c60a57b982bbb0aba187,"When using circular arrays we would need to keep track of the reference of the first item(front), n_allocated and n_items. When we pop from the queue we would need to decrement n_items (n_items--) and update front to be equal to the reference of the item that was next to the item that was removed(increase the index of front). If we want to push to the queue data[front+n] because we would be adding an item at the back and we also need to increment n_items. For the size function we would return n_items. Front would return the reference of the first item. In order to go around the array we would need to use data[(front+n_items)%n_allocated] (this is when looping around the array). If the n_items is equal to n_allocated we would need to create a new array of 2*n_allocated and copy all the items from the old array and then delete the old array.",16.0,68
20232,20232,24477,dc654a3d0a49a8045440d0a47a162366cb8c5b30f1fbfe16fd058e7bee5d840a459b70ea1468db1f0ce164b7af14bedf02e15cd2f876678ba6f0d0d5502b4093,"a circular array allows us to to keep track if we still have space and if we still do we continue to loop around and round.we need to keep track of the number of items in the circular array ,we update the number of items by pushing to the back .we also need to keep track of the position of the front.we update the front by poping or by removing an item from the queue. we keep track of the size of the circular array  ",4.0,68
20233,20233,24478,ed5a8c0425e8a7a0d2d402e42e3298539ec0ceb1b43ca8fa3f4b83dce862ed24fe276be92f07cf85365c96c7391564d1c0da45fd6e6ba4bd80ecb01a39467209," We have to keep track of :

	* size
	* number of spaces allocated in the array
	* number of items in the array
	* index of the value in front

In a push operation, to get the index of that last item, we take the sum of the index of the front item (F) and the number of items in the array (n) and use modulus by the number of spaces available (a) like so:  data[ (F+n) % a ] . We then increase n, the number of items in the array.

In the pop operation, the index of the front value must increase, while the number of items in the array decreases. Since it is a circular array, we use modulus on the index of the first item by the number of spaces available, like so:  F = (F+1) % a. helps us work out the index of the item at the back.

How it works

a circular array works like a normal array, such that we insert from the front and pop from the back. The idea is that we loop round and round as long as there is free space -- we can push items into the first index when we have reached the end of a list -- provided there is space. If there is no space, we can reallocate space, copy all the items and free the old memory.

every operation will be constant because it will make use of pointer arithmetic, unless (in push and pop) we run out of space, this will result in linear time. We  do not have to shift over or copy items when we pop and push.",13.0,68
20234,20234,24479,0210a9d3772d4f5814d5d585f47b6503d720f89ae8ca72b5fb7136f3da85dccbdba73ac11df998e73774b6321c99446733c7c479dc009a4e0dc92678413ef102,"It works by the FIFO principle ,the first in is the first thing to be removed . I would implement the enqeue which inserts the element at the back ,check if the size is not full ,if so set tail to 0 then insert. Also implement the deqeue which removes the the front element ,check if the size is not empty amd set head to 0 and return the element. We need to keep track of head and tail. Head and  should be head == size - 1 when removing and adding.",4.0,68
20235,20235,24480,0a640b06ce1d454be947795a6308fcfcc73f66b49b60199788f434bf91f3e08719c4b7dee42514e49b76fea543dcbe6b2a18d9de0cfa87cc5f82c989cd2f76ff,"A circular array is one data structure  in which the first element is always next to the last element, all operations are based on the idea of First In First Out. It is like a ring structure. Because of the idea that it is based on it can be used to implement a  queue, the functions enqueue and dequeue can be all made to be constant, because an item can be added to the front of the array, or in the front position and then another item can be removed from the back position at once, in constant time, as there are no loops, only pointer arithmetic is needed. we need to keep check of valies of front",2.0,68
20236,20236,24481,a8dcc87a24b584021a1bb3ffd592a4ea66a1679acf3b2b41f26aef4e481760f4e64990e460e4e26ec12a8fef5d2354f5070843ac6e40f4a1e24bc122bfa91df9,"The circular array keeps track of: the number of number of spaces allocated; the element in the front of the queue; and number of elements in the circular.

Number of spaces allocated is updated, when array is full and the space will be increased.

Front is updated when the element at index of front of array is popped and front index will be increased by 1.

Number of elements is updated when pop or push occur.

The elements are stored contiguously pop and push are constant.

To push in a circular array the element will be placed at [(F+N)%N], F is the index of front of array and N is the number of elements in the array. If push is called and index [N] is filled, the element to be pushed will be wrapped and placed in the next available space.The only time a reallocation and increase of space is performed is if the circular is full . Since memory is contiguous operations like pop;push;size and empty will be performed in constant time.",11.0,68
20237,20237,24482,936c1ec869d8f0942d3b84b8b6c320188374f7b930016464dda43168d457286fd222e445f17b63344d55d3ca25f550407692016dc54317e807a5e1c9658269bd,"For a circular array to work we need to get to the end to go to the beginning.We remove from the front .We loop around.

implementaion: front,get the last item from queue and enqueue value.",2.0,68
20238,20238,24483,f83dd55ad9e075a60c5134f9bf47ed3397e5224c478fcc48237d4341af57f9ae0b4893b2d9bfdacde4458f44d6dacdaedccfab297dd76d28c1d773deaaf399e4,"A circular array uses looping around the contiguous memory. It allows pushing and popping items from the array. Since an array is of a fixed size ,however a circular array can be looped around and items are added and removed using the modulus arithmetic. When popping an item we increment (n++) the front of the array and find the modulus of the incremented items and decrement the number of items.Pushing is done using the push_back function and also makes use of the modulus arithmetic. Both of these processes take 0(1) time. Returning the number of the allocated items returns the size of the circular array taking 0(1) time.

We keep track of the Front , n_allocated , the size.",9.0,68
20239,20239,24484,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"-When last index is reached next index is zero.

-Shifting of elements is not required when an element is deleted.

-When an element is to be added rear increases by 1, when an element is removed front increases by 1,it has to be ensured that total elements in queue are not more than the size of array.",4.0,68
20240,20240,24485,6411a31397edca98a86156eda9fe940cd25214f5793edb40ff98bea1168dd2f02767f84a7d8f08cc5cbcf1da236fabf58172c048483fca623b7f16592128e03a,Circular array is a linear data structure in which the operations are performed based on FIFO (First In First Out) principle and the last option is connected back to the first position to make a circle.,0.0,68
20241,20241,24486,df7c40110480895f223a4ad7a154ce6d14071ffef29c798823d9a68e307bd1447fc569c4b8f3e4353216405210fd26445fb7aeea3ad07da82c16c8e5aa5ac0cd,"We need to keep track of the number of items stored in our array and also the position after front. We then work from the back of the array. Every time add an item to our queue, we are inserting at the back of the array and we increment number of items stored by 1. and also update the position from the front. The index of the last item inserted will be the front of the circular array plus the number of items stored in the queue and that is set equal to number of items. To remove from the queue we simply increase the index of the front and decrease the number of items.  Thus push, pop, front and size will clearly be O(n).",8.0,68
20242,20242,24487,bd13f3a1f05cded43b306e7cf672db1fa9cf812229ead4318a993e62aa7ff42541e39b6868fb05069f972d798f5a5b109e0e615acf69b7c88b8e2bf435bfc374,Our array loops around the number of items in the array mod the size of the array. Memory is laid out contiguously. Every time we add an item we are inserting data and the index of the last item will be the front plus the number of items in the queue and set that equal to the value of the new item. TO remove an item we increase the index of the front by one and decrease the number of items. Doing all this we need to keep track of the number of items currently stored inside our array and the position of our front. From there we can simply work where the back of our array is.,8.0,68
20243,20243,24488,a6a1956dca8537b87c581329dd539be0e1754c767a458496056c957b37b7d5cf8e38e7b6a815b9c917caee9a53108cd46c4caa581c67b0f0565e27d0605c7826,"A circular array is fixed. The size of the array can be used repeatedly in a clockwise or anti-clock wise direction. It operates on a first in first out method .

To implement a queue using a circular array, you should get the front item from the queue, then get the last item from the queue. Then use Enqueue then Dequeue",2.0,68
20244,20244,24489,cd3aa55745b79deafb0802ba9ebe30e68fbd1c089c006450727570d34769934d2b1c5a098a7d318146af21d8981711dce0bb006308d97edfcf9a088eb56e4532,"A circular array is a data structure that has its last element placed next to its first element. It uses modular arithmetic to perform operations just so it can keep track of where we are in the array in order to prevent segmentation faults or corrupting the values stored in the array (data). First and foremost we have to keep track of our allocated space. We need to keep track of the Front of the array which is determined by incrementing the current Front and taking the Mod between Front and the amount of space allocated i.e. F = (F+1)%a when popping items. We also need to keep track of the number of items that are in the array. Each time an item is pushed, the number of items increments by 1, and each time an item is popped the number of items decrements by 1. If the number of items is equal to the allocated space, then we have to reallocate this data into a larger array and this would be linear O(n). Because we keep track of the front and the size of the array, we can obtain ""Front"" and ""size()"" in constant time O(1). This also allows us to push and pop items at constant time O(1), since we always have Front and size(). ",14.0,68
20245,20245,24490,12066f8f6a7f4cd1c9586b77b6e85c69168c3e639d8a7cc579d0737f33e85026e0fc0bba1f43d9a6c097e420e073f5dd573d48b38e1cf440a6f948554edb9454,"1.1) Circular arrays use contiguous memory whereby the first element is right next to the last element. In order to use these we keep track of the number of elements(n) stored in the array every time and the position of the front element(F). We should also know the  allocated space(a).

Whenever one needs to add an element to the back(push_back) we add the position of the front element(F) and the number of elements(n) modulus allocated space(a)[(F+n)%a] , in this way we just access the next last available position to push back hence this takes O(1) time in the best case. After such an operation we then increase the number of elements(n).

In order to pop at the front we add the one to the position of the front element(F) modulus allocated space(a) [(F+1)%a] and use the result as the location of where the front element is to be popped. This takes constant time to achieve in the best case hence O(1). We then decrease the number of elements by one.

Accessing the front element is always constant time because we always keep track of the position of the front element(F) hence O(1) in any case.

Getting the size is also always constant time as we always keep track of the number of elements(n) after every activity/operation hence it is O(1) in any case.

1.2) We need to keep track of the number of elements(n) and the position of the front element(F), n gets updated whenever we push back(n++) or when we pop front(n--) . When we pop front front our front position becomes (F++).",13.0,68
20246,20246,24491,50ac02db01dc47f0f24bb2a0e8bc1bebe3aac1ecfe652f1c87b260f45da4def0a267392e043e67a0b0f3a39374188322db34615d5257a196fc0978d4d004e1ed,"formulate a new index such that it is = (f+n)%a.This is for the enqueue to be in contant time

formulate the index such that (f+1)%a ,then decrement n.This will make the dequeue function to be in constant time

front and back are always in constant time",6.0,68
20247,20247,24492,0fd0096c1497543ca0003b9e3ba007221cbda2328585a2f2260277e1c7038bb2ae7ad23e03908936421523651b3b5785ece380b977ac663ea4a02a050d012617,"i_n a circular queue , we keep track of the follo_wing:

	* allocated numbers(a)
	* n_items (n)

	* front (F)

so with  a circular array every time we push, we are add the index of the Front element to  the number of items in the vector, to get the value, (DATA [F + N ] = VALUE) and increament the number of items by 1(n++) in  CONSTANT TIME.

however, they come situations were we have reach the end of the array and trying to access will result in segmentation fault so w e then you the modulus technique to to get the remainder to return the index back to the front of the array ( DATA [F + N ] % A = VALUE)

and when we pop it will just be (pop  n - -, F = F+1       (F = (F+1) % a)

 

and the good thing of this circular array we do not need to push everything over every time.",10.0,68
20248,20248,24493,4c6239f4837a7e4857168ce1d90eccb0590dbff5755d1452f6eced3fa662d6b3d452d78b9021e9f1b0bb440c88d3e31a3396f8ac92fb89f14b2269d4512bdaa8,"enqueue in O(1) - we'll formulate the index of the new value such that it is equal to : (f+n)%a ; f=where front is in the array, n = number of items in the array and a = size of the array. then we'll increment n. this allows us to loop around the array, so as long as we have enough space.

dequeue in O(1) - we'll formulate f as (f+1)%a, then decrement n. which works well until we run out of space when n==a and we have to reallocate space and copy our objects from the front of the queue, which takes linear time. 

for front and back, we'll just index the first and last objects respectively using the array functions which take O(1).",15.0,68
20249,20249,24494,3b71cded09878fac739a748b2fcbc2d9e2bef1d7260004d93fa1cfe93d9b6830fe9dca43a0e8ef309e85cefb7f4580ca47263177668c6f4b88b993ec3fb19c7e,"-It is a block of contiques memory

-keep track of the pointer to the front of the queue, items in the list and the number of memory positions in a queue.

-An item is allocated a memory block and will not move until it is totally removed from the queque.

-Work for left to right.

- Pop positions zero stored at a pointer.

-We then work out the position of the memory whenever there is a loopback to the front of the contiques memory.",4.0,68
20250,20250,24495,1d906c438dbb2a0adc2a7e04ed6b3c53c2ee28b5c43a5e83e583d5199a13a7bb6abb74579e2679fb4b6602b8efe2849ab290c6db2b1f573c02a4880312c09f25,"We need to keep track of the number of items stored inside our array (n).

We need to keep track of the position of the front item (f)

We need to keep track of the space we've allocated (a)

To push at the back and keep looping in the array: We take the position of front (say initially F = 0) and add it to the number of items (say there's 2 elements in the array. i.e., n = 2) and the capacity of our array is 5 (a = 5). To push in this case we'd take the modulus operator (%, which allows us to keep looping each time we run out of the capacity) of the front position and number of items and the space allocated ((F + n) %) and equate it to our new value. Then add the number of items since it get increased by 1. 

To pop at the front: We'd shift the first item to be at the following index (F = F+1). When we run run out of capacity, we'd take the modulus operator to keep looping. Therefore we'd have F = (F+1) % a. Then minus our number of items since they are now decreased by 1.

Both of these would take us a linear amount of time.",11.0,68
20251,20251,24496,eaeebfd434a43156f3712848577d3a5da6499b6e1784e16a24ab5777985e6e2eed30ffc0a110ed246a9badfba660cd9a812c4ed7d173d1a29f7e115ce4ad58b1,"to keep track of the size of the circular array we can update our number of items variable in an array and update it as it gets push back and popping.

we can also keep of position of the back item in the array as we loop around and around of the array so that we do not lose track of where to push back items.

We can use the size and number of items to check if our data structure memory needs to be updates to a new one if it is full or out of memory . then we can reallocate it to a new buffer.",4.0,68
20252,20252,24497,e083cbbf008c42438bc396229643f759537dd38e9f70943e360360b6f27f45207e60ac5070353bd70bc7b26433e973228b25ccf89b152c434341d5c266f31945,"A circular array is implemented using a vector. Let us assume that the front item on the vector is the first item on the queue and the last item on the vector is the last item on the queue.

Say we have A = memory allocated for the vector, B = number of items in the vector, C = The position of the item that is at the front of the queue.

When adding an item in the queue, we have to push back at the vector. If A > B then the function will operate in constant time. On the contrary(A=B)this will take linear time. as we push back, the number of items in the vector increase by one. Also the memory allocated will be updated and will be doubled if A = B.

When removing an item in the queue, we have to apply the pop front function which will take constant time unless B < A/4 , then it will be in linear time. Here, the number of items in the queue will decrease by 1 and the position of the front item will be incremented. The memory allocation will be halved if B < A/4.

To get the reference of the front item, we use the front function and is always in constant time.

We also always get the size of the queue in constant time using the size function.      ",11.0,68
20253,20253,24498,a959a4bd23a818684dfb2a6c94ac89925575f3b11f0de3ed6d4df640b02681f2171e62de10059d8c04c758f13335e59b8e75b311b1045da8f168f89c32919f7f,"A circular array works by tracking the size of the array as well as the front of the array, this way the back of the array can be solved. If you wanted to insert an element to the back of the queue, you would still track the front of the array and the memory used. It is circular when we consider the first element as next of the last element. When removing an item from the queue, we need to consider that there will be 1 less item in the queue, and increase the index at the front to the next, with constant time. e.g. data[...] = item,

                 n++;",4.0,68
20254,20254,24499,0cd06500f6bc04ca04d6df402c164435dd4b1e3f62d49a5f81d45b91f4a6f4ac2ae8232fc2f485e2ef108625ecea2f61c466c82dcbccacd3d327b9b3b7efa90a,"a circular array is one where when we pop we do not have to move things to the left but just use the front. Easy to trace

In a circular array the values need to keep track if are the number of items, position of front, and the allocated space. Number of items is decreased by one when we pop and Front is assgined to (F+1) mod a.. Allocated can be changed through reallocation. During push number of items is increased by 1 and in data at position (F+1) mod a, the value is inserted.",10.0,68
20255,20255,24500,fd8a875c5398ac6c36a731d0d10a006399599403b9ee2f4994b116a012c4bd603697ca87421ae17a8eaaa96913f3870bb71641db61fda611c4a27d1aa224e5e0,"The way a circular array functions is that when it gets to the end, it loops back to the beginning.
It can be used to implement a queue in O(1) time by allowing us to remove from the front and add to the back without having to copy over any data in memory while looping around the block of memory we actually have. As long as we don't run out of space . 

The values we need to keep track of are the number of items in our array, the position of the front and the number of ""spaces ""allocated in memory",4.0,68
20256,20256,24501,e627fede4d8a070ca528e22154030076326cf75a860ce09e9231ab5eb164fd945cbc3f05b7190cc8d307288292134d5c83514ef1ec1b1c4974bcf393c3c20f68,"a circular array is an array in which the capacity is limited and the ""front"" of the circular array is the oldest item added to the array. As elements are removed the front of the array is moved to represent this. Since memory is limited when the end of the array is reached the next element is stored at the beginning of the allocated memory, assuming at least one element has been previously removed. To turn this into a queue with time complexity O(1) all that would need to be done is keeping a reference to the first item, for dequeuing and a reference to the last item (back), to queue a new item. whenever a dequeue is processed the ""front"" would move one element up and the previous front element would be cleared. whenever a queue is processed the back would move one element forward.",5.0,68
20257,20257,24502,2e87414379efcd8b6abefa082fd766ea6bbd6a7c49327da9b14527216de652d464a74ad3edb281cf63c53ec51b9a87c17ffe7ae230ea816e625650e59f9bd068,"a circular array allows for easy tracking of whether or not a computer still has space, upon finding space, a circular vector allows for a continuous looping around it.

we need to keep track of the number of items in the circular array, keep track of the front of the circular array and also keep track of the size of the array.",4.0,68
20258,20258,24503,5f92eb6a07aed01e019162660614241903fd30335dc49cd736d18a97a0b8e4d8d8eaa7a31ce7cb8ad65e895e5a8906b98d2e7635d42d019af72333c76c35da1a,"A circular array works by using a fixed-size buffer. It has a fixed maximum size due to having no shifting in the queue. The whole array can be used up for storing all the elements. It can be used to implement a queue in O(1) time by having a tail pointer . We need to need to keep track of the front and they can be updated by taking the index of the addition of the index of front and the number of blocks allocated, and the modulus of the resulting addition. In that way, there will not be a segmentation error. ",4.0,68
20259,20259,24504,a09890d1b445c23fabb578b3483b14013fc02062f1b3aa1b4c6df4bdeb9b3b91a9c90e4c472aa2da65ecaa5b831c0625b91b1940398021966ddfe90195c5216f,"circular arrays allows us to loop around the pre-allocated space in memory as long as we have it. When we dequeue from the array, the index of the front of the list as well as the back and the number of items in the array. so we therefore need to keep track of the amount of space we have in memory as well as the index of the front and the number of items in the array.  This helps us to know which is the next event to be processed and and the amount of  ",6.0,68
20260,20260,24505,8127d4098ce90e5354b83277c230528a4f346dff2268e6e565e170f557f4828895b86ce9e4d45680788cfb7696e91c4b7e7c80cf0ef0611dfea212b6f772071c,when the first element is also regarded as the last element ,0.0,68
20261,20261,24506,407769fbf475dbb4360f6394c41bf1fe1b09a93e6d82ce4845a84070494a0f47c40c801c2682df7cfd3bd3657df86e3329652953a2e09d84c89aab85cdc47d86,"A circular array is an array that allows us to enter an item even if the queue is full, it does this by going back to the beginning. A circular array operates on a first in first out basis which allows it to work well with queues. It allows for a linear amount of work in a queue as there is no loops in any of the operations. In a circular array we need keep track of the space allocated, number of items and the index of the first item.",4.0,68
20262,20262,24507,cc4a3429058a6fb36c1c14635322568c508206ceead8cb4bef1f46c77dd76f655277f72ba9b8a42e6d49805547432d6dea2f783f4c165e7598b53d607e545ad2,"Class CircArray{
public:

        Thing *data;

        size_t, n_allocated, n_items, front;

}

Keep track of the number of spaces allocated",4.0,68
20263,20263,24508,9b13f2d70694a174cc296db2532a81cde5f414c86e87388e32c45d14a1b85a47b70cc54fdcb2f6455012d569323883da99f34aab409453d8e838e0ae2bf41aff,"a circular array is an array in which we consider the first element as next of the last,we consider the first in first out operation .we always add from the front

 enqueue is  used to add an element at the back and it is always added at a rear position,you should first check if the queue is full and use (F+n)%a to find a remainder that can be added so that you can fill the empty space.

dequeque is used to delete element from the back,and checking whether queue is empty means u have to check if (front==-1)and to delete element : F=(F+1)&a

we have to check values that are deleted at the front and inorder to update the deleted value,you have to use the push_front function where data[F+n] = value.

we use the modulus function so that we get a remainder .

the enqueue and dequeue operation is O(1) if there's no looping.

the front and size are always constant time .",10.0,68
20264,20264,24509,639a68158c22ced38b469e5ff5439c6df90887f4ac511792920966a4b66fbbb0736453130f1e07f675685ab76215a4ca74f33ab5a9bf6fded51b150fcaa550e3,Circular array are arrays in which the first element is considered the element after the last element. These arrays are thus used to implement queues as they use the first in first out concept. Since the first element is considered the element after the last element a pop back function can be used to remove the element in constant time(O(1)). The last element is still considered the last element though and thus a push back function can add an element to the array in constant time(O(1)). Therefore circular arrays are essential to implementing queues. ,0.0,68
20265,20265,24510,525cefc66631b9eb601410acc1c632cc3a6d9976bb8f3ac653d46807a4053f29a6c3c85a0e8a38a43486b45bae46acd949e27f910bf00828afed11257c7034f3,"A circular array basically is an array that has no starting point, how it works is we return to the first index when we run out of space. When using a circular array to implement a queue we'd need to make the array one block bigger than the number of elements we have(i.e if we have n-1 elements our array size has to be n) then we'd have to pointers one pointing to the first element and the other to the empty block.",0.0,68
20266,20266,24511,2c32439612d29606cd7276c7d7327878252b82b353a0e5c5a38f508a89318428edb5d433b571f4ed85a8cddd2dbf4c9c5eb5b82d38c65addb4bffc9179a95b21,"A circular array is essentially just a regular array with the back pointing to the front. This array can implement a queue in a way such that items do not need to be reallocated each time a value is popped from the front. The index of the value is kept the same. The, this now takes a constant amount of time as we are only concerned with removing an item and not reallocating space. This also means, however, that we need to keep track of where the front of the queue is, because the index of this is no more 0. It is always changing based on how many values are removed. This is established through adding the amount of items that have been removed to the index. Thus, we need to also keep track of how many items have been removed. Furthermore, the amount of space allocated into the array needs to be noted in the case where more items are removed than space allocated. The push back function also takes a constant amount of time, unless space needs to be reallocated. This is because the addition of another item in the list is not directly dependant on the size. Only one thing needs to happen. Through this, the amount of space available within the array needs to be noted. we need to keep track of the space allocated within the array to do this. After this, we find the index of the beginning of the list and the end of the list and subtract this allocation range from the entire allocation value. Therefore, we have the amount of space available within the array.",6.0,68
20267,20267,24512,01414e21ecb9a1334890023f94a0d282ee23097fe9f9524ae17a5a130cb936a59877f182817dee70cef409eabab63c6b47a25ed1ae4ef0dfef7f2566f253e2b1,"A circular array considers the space after the last element to be the first element( like a circle as its end is also its beginning). We can use it to implement a queue by storing the data in each element of the array whilst keeping track of where the first element in our array is stored ( allowing us to access it in constant time (O(1))) and the number of elements populating the array. Using this information, we can deduce the size in constant time (O(1)). We need to use modular arithmetic to loop around back to the beginning of the array if we reach the last space in it. Assuming the array has space, we can enqueue easily by going to the back of the array (front + #of elements) and adding a new element at the back of the array (Constant time O(1)). A circle array (like any other array) has a set number of blocks and cannot be expanded. If there is no more space in the array for more elements to be entered, a new duplicate which is double the size of the original array will be created and all the data from the original array copied to the new array.",8.0,68
20268,20268,24513,3824a0678a0ee80961c81764186a1496645536aadc7127ac81665ef8825202d12ca91cc1dddb49cb3545dd95e3ab23ddf164ccd399cf03acc33959144061677d,"A circular array works by checking if the number of items equals the allocated space and if not it moves values to empty spaces behind or in front of the index of the front, the circular array keeps track of the index of the FRONT, the NUMBER OF ITEMS in it, and the ALLOCATED SPACE.

A circular array can be used to implement a queue in 0(1) time as follows :

	* To get the FRONT, the index of the front being tracked is referenced this provides O(n) to any index in the array
	* To add another value to the array, modular mathematics is used the index (NUMBER OF ITEMS + INDEX OF THE FRONT) % ALLOCATED SPACE is used to add values in O(1) time.",8.0,68
20269,20269,24514,ac47e3ceebccb755b1987f028345ba571e2bbf0bc4ebc355e11ab520e9f3ffd71073789246ed0c633ccffb81e8b77e299c90427fa5f8a55f41455cee47d290e1,"The circular array it's also a FIFO in structure. With the circular array is that the last position is connected back to the first position to make a circle. It has own operations but they're much similar to the normal queue operations and in order for us to achieve the given goal we will use front() which is used to get the front item from the queue and this will just take constant time because we will be taking the first item, meaning we will be taking the item that arrived first in the circular array. We will use rear function to get the rear item from the queue. We will use the enQueue function to insert a new item in the queue which will take constant time assuming that there's space. We will use the deQueue function to remove an item in the queue since this only take place place from the front end it will take use constant time because we don't need to traverse through the circular array. ",0.0,68
20270,20270,24515,22140328599cc90e71d5de22898862c3b0e2dd7b2d6733a618551afede59cd91597d571fd42b02414ce2cee43da486638d6f616c5d08e161d9d14ea8e7479b0a,"in a circular array, the last pointer which would normally point to null now points to the first item. this creates a circular movement in our array resulting in a sort of loop. Now adding to the queue will always take constant time unless we are reallocating which will result in linear time. removing an item will also take the constant time almost always, then taking linear time when reallocating. returning the reference to the first item or checking the size of the array will always take constant time.",4.0,68
20271,20271,24516,d39f1221c1c1fa8d17ca77420f1bba8cbd56fd8e4b2efb35a70c05cd360218b8d98dd79e4c1abc4c057030cb040ef7358efbb5cda6b9051c1e5bddbf68b768c0,"A Circular Array is just a normal array, but this time we loop around the array and when we run out of space at the back of the array, but there is still some space available before the position of the First Item in the queue, we can still add the items that follow in the queue.

We need to keep track of the number of items currently stored inside our array (N). The position of the front item at the front of our queue (F). We also need to keep track of the amount of space we have allocated for our array (A)",4.0,68
20272,20272,24517,3dc26b747d97da3ab4afec05ff58fc24d9456624d1de4e773000cee11c5770c4305e55aba8a358eac1e51ad690a762f5e637a6ce6a5554139fe18ecd7662a5af,"a circular array is an array that loops over when it reaches the end it goes back to the first item or slot of the arrray.

it can be used when we dequeue it updates the front by incrementing the index of the front and then decrement the n items so that the size can be in constant time.

when we reach the end of the array it will go back to the first slot of the array to add an item there or enqueue and increment the n items .

so that it can loop over we need to index of the front plus n items ",4.0,68
20273,20273,24518,61263672c5c532106e7f21122dcaab559eafcffe3f9da40ef6a4194409e8f1be9b62145c70c7a6a62ca846b85c63f3fbde4504110d16d1088e8621a2430bcdec,"Circular arrays are arrays where the first and the last elements are next to each other.

To implement a queue in array in O(1) time, we create another array with the similar size, and cancel the reference of the old one.

We need to always keep track of the number of times currently stored, the position of the front item. To update them we firstly check if number stored is not equal to number allocated so we can proceed if we have space, then we start from index 0 and insert our item and update the details by adding one. We the push to move to the next space and insert the next item, and update the values again by adding an additional one. And we carry on pushing till we have stored all items we wanted to store.",2.0,68
20274,20274,24519,97b7f5ff46c1c824381cef505f20511747560e70b8b1e616642dc4fcce22c546867f43d01ab15335e8a2a57b9d3fba9ae8276c6347ded2ad2c8d88ebec13760a,"A circular array works on the FIFO data structure, where the last element of the array is connected back to the first element, thus making a circle. We need to keep track of the first and last values",1.0,68
20275,20275,24520,7034e661a6b51c59ff4e839b7430fa79082c9a14de4d5507d8b8f51bcf2e8507159f0b9ac4f2f0968d640ca40b95ebbbfcb9a489ff8f5bfe6ee49d4e9a458d5c,"A circular array works by keeping track of the index of where the object in the front of the list is stored. This could be used to implement a queue in O(1) since a circular array removes the need to coping objects to the first index every time we remove an object in the front of the queue. 

In a circular array, we need to keep track of the index of where the object in the front of the list is stored. We also need to keep track of how many objects are in the array. We need to keep track of how much space we have in the array. The position of where the next object should be placed is determined by summing the index of the object in the front and the number of objects in the list and finding the modulus between the result of the summation and the space available.",4.0,68
20276,20276,24521,d262858bac7cd6476e0cd48b8622c751312997fe7fae4adba9c98bf17ceadac187d9de2b401de3d1895e85edc24940f00a102bf214f436104f37cd1b8669240b,"A circular array is a normal but is thought in circular form, which loops around the array for as long as the the memory is still available and enough. We need to keep track of front, number of items and number of allocations. When we enqueue, we use modulus so that when we get to the last item, loop through the array so we say (front + number of items) % number of allocations which gives us the position in the array and we would have to increment the number of items. If our number of items equals the number of allocations then we have to reallocate but because the front might not be at the front of the array, so make sure the front will be in the front of the new array . When we dequeue, we decrement the number of items and and then increment the front, but because we want to loop through we then also (% number of allocations). If the number of items is less than a quarter of the number of allocations, we would have to reallocate with a half of the number of allocations. To peek, we would return the value of the front because we kept track of it. To return the size, we return number of items because we kept track of it.",16.0,68
20277,20277,24522,efa2c5b70f1ad8f0aebabd9a8317831d8e117c559aa0a29951f0659587ce28ce45a8ffe00e2d128d5b1b92e6f8033ccb1e7464d9f2f119aa95332037f62a3b76,"For a circular array we need to know the size/capacity of the array, number of items and the index to the front.

allocated = a

number of items = n

front index  = f

enqueue:

data[(f+n)%a]= value 

n++

dequeue:

value = data[f]

f=(f+1)%a

n--",14.0,68
20278,20278,24523,bf9f7563cc9f901b96502125e7d25475a0aeee128b8258ce038a51e3af3c4093e4ee3d48f8e688baf55d2e74c7a660d473b521169612f2e6991be2accf5a47f1,"the circular array is a FIFO structure. in a circular array, the last position is connected to the first that forms a circle and has unique operations but they are similar to the normal queue operations. for us to get the item in front of the queue we can use the front() function and this will take constant time since we are taking the first item in the circular array. then we can use the rear function to get the last or rear item in the queue. We can use the enqueue function to place a new item in the queue which will have a constant time complexity if there is space available. We can use the dequeue function to take out an item in the queue and this time complexity will also be constant because we do not have to traverse through the circular array.",0.0,68
20279,20279,24524,97a01199b925330f29640cdb86e45eea363ff96eb767b66ea518348ab8ed24fd59b309226c6a592a7f7ea6b67fef81cbfd1daad02d4a32f29300da894c457dc7,"An array is called circular array  if we consider the first element as next of the last element.it works same why an array works just little bit differently. first front has to be the first element in the queue if we haven't removed any items. A circular will always be constant unless we run out of space and we have to reallocate. 

When we remove the first items it will automatically change front to the next items leaving free space behind. If it comes to a point where when we push back of the queue there i s no longer space we are able to add items behind front using a loop involving modulo ,front and number of items.

we need to keep track of front values and last values/peek. when add values at the back of the queue and front will change as long as we remove front items.",9.0,68
20280,20280,24525,6c0c4055e14104657e8b2f93690d540761c32c74b87c67cb6acc284b0968521966239252478c024e2c1fdc28ec4e72c01b4f28c3de78e04b7bbf604f3bad167d,Well arrays are constant time access. So you front will always be the front or end of the array depending on the orientation you would be using. This is easy to keep track of as you can use n(1) for the first value and n(size) for the final value. Empty could be used with size(). Enqueue and dequeue could easily done with you front and end values.,0.0,68
20281,20281,24526,ef46ab4c4baea61ce39205f3f8b9ba2f08ab48270b777e4f042aafc6410a82e9cddc1dd033e57ccba5e191584e8763e9b5c270df38cd4daee3f921d844f6b7a8,"In a circular array the first element is considered to be next to the last element, by keeping track of the number of items in the array and also the position of the front of the array. That will allow us to calculate where the back of the array is.  The back is updated by using an index.

To implement O(1) time we can use a mod operator to access the elements of the circular list. We use i % n and run the loop from i-th index to n+i-th index and apply mod we can do the traversal in a circular array within the given array without using any extra space.",1.0,68
20282,20282,24527,7ed1c803cb6942b25a462119e14146d3dfdc8b2d8405742d6e37974d2693c34f2838afb58a1bcf41b9fcd8829c1dff4d4b192c929c721bc46e1615dcea231b30,"For a circular array, we must keep track of  the number of items in the array(n_items), the index of the item in front (front) and the size of the array(n_allocated). A circular array is able to implement push_back and pop_front functions at constant time. to implenent a queue at constant time, the push_back function in a circular array is at constant time  since we place the item at a specific index. To implement such functions for the circular array, we use the modulus operation which is used to go back to index 0 if we have reached the last point/space in the vector. 

 ",6.0,68
20283,20283,24528,2f3e315687119ead6a818da568e78a6a6a1fca8ffa33209c3dff24c186275e23df6af032db0ab8c3cc902f57fda3972c9cc02a021860b531f2f8a447436717fc,"At the start the is a head also know as the front of the queue and the tail(rear).
The process or the removal takes place at the head of the queue.

Since the queue is know as the first in first out data structure , meaning the element that is entered first will be taken out first. 

since at the start the is a head and a tail , as we add elements to the queue the tail will keep moving ahead while the head will remain at the first block.",4.0,68
20284,20284,24529,02cb07161473723283d91a3c998f4ade4cb197abe855244e901ae8f3133fa745a87cf9dec28bee7621c8d3b8308477fc042faa7e0319e0ad9256c728f396d7bf,"The idea of a circular array is an array that keeps its first and last items next to each other so the block of memory used can be thought of being like a circle.

Implementing a queue using a circular array would allow us to get the front() (reference to the front item) in O(1) time as we simply look at the first item in the array. Keeping track of the number of items in the array would allow us to get the size() in O(1) time. Pushing would require the following code: data[First +numOfItems]=value; numOfItems++; 

The values that we need to keep track of are ;the number of items, the position of the front, number of allocated blocks of memory. Number of items is simply updated as (++n) we add items into the array and a simple counter can be used for this. The position of the front changes when the first item is removed' whereby the second item now becomes the front",6.0,68
20285,20285,24530,1ec073b8c8fd76df82abd5195dc059b3bb969a0dcda29a3183557cfcb9cf9edfa565003c0b81e18a702d15e745574294a8e18968fa713fdba196a2197d0ea2e5,"A circular array is a regular array thought of in a circular way. As long as there is space in a circular array, an item can be added in it. We have to keep track of the number of items in the array and their indexes. The Big-Oh  notations for push, pop, front and size is O(1), implememnting a qu ",2.0,68
20286,20286,24531,3b012b96c98d84ed8e9f88d92fde8d672f449955feec04f1b94283d72586d2586b31cd4b32cb1464ddc219af63c953c4b0015e421667a55126d1bf7700e02016,"A circular array considers the first element as the last element, it is contigous. It can be used to implement a queue. We need to keep track of :
1.The number of elements in the array/n, 

2.The size of the array and/a,

3.The front of the queue/F

For an emplementation of ENQUEUE, the number of items n in incremented by finding the value to increment from, we find the value by data[F+n]

For an emplementation of a Dequeue, the number of items decreases ( n--) as the Front increments by 1",10.0,68
20287,20287,24532,888a700ecff48b8e58609f74298e3e913836c7525e3508cee74dcd45d73e3b5cb35996869dd34b3342eba886899eba46a61c603fc724f15dfcf45804ca8c7ece,An array is called circular if we consider the first element as next of the last element. Circular arrays are used to implement queues in constant time. A circular array represents a queue or FIFO structure that allows the head to chase around to meet the back. The array indexes wrap around to form a circle. The next open slot index is calculated by the modulus operator: next_index := (last_index + 1) MOD array_length . Modular types provide wrap-around arithmetic. E.g. declares type Buf_Index to be mod 10. This means that the valid values for this type are 0 through 9. If an instance of Buf_Index containing the value 9 is incremented the resulting value is 0. The Put entry can only add a value when the buffer is not full. The Get entry can only extract a value when the buffer is not empty. The buffer acts as though it is infinitely large because it behaves in a circular manner.,11.0,68
20288,20288,24533,e0c83344227ee0e9cbe053565e48a2fdd45505359ef079abf58dae6d4b8251e874c464186ed9d597d1e6bd62c45d87ea5c0897cd6938b6926936cb2def62d356,A circular queue is a linear data structure in which the operations are performed based on FIFO principle and the last position is connected back to the first position to make it a circle. As long as there are no loops the time complexity of enqueue and dequeue will be 0(1).,0.0,68
20289,20289,24534,9140ffa3b52741e2ae246773dfeed94b1141ba7c3dc70e8cb17fb6410cd6b017d81c18ceaa0264d9c4b8354cae095d12f4a720da352b65b62d37bdd0fc9fdc69,"An array is considered circular if the the next element following the last element is the first element in the array. For implementing a queue using a circular array, we would create an array of size n then  we keep track of the front variable  and the back variable in the array, where the back variable of the array would correspond to the actual size of the array. We can only add after checking if the array is full or not, if we found that the array is not full we would add at the back variable position and then increase the back variable by one, this would continue until the array is full. In order to delete from the front we would shift every element one place to the left so that the second item replaces the first item in the array. Then to get the front element we would just use our front variable as it is the index of the first item in the array we would just say arr[front]. ",8.0,68
20290,20290,24535,e8cc8f379686cf17ff7a79c51f234b372a7158c41925760d6a62468ac2bc253c196a10ef5af7f8e787abc174ba6435f331d902d6901bc07bc87271a8d067f35c,"The circular array keeps track of the number of items currently stored in the array(n), the amount of space allocated(a), and the position of the front of the array(f).  We add an item to the back of the array by inserting it at index (f+n).  Once we have done this we update the number of elements in the array (n++).  To pop an item from the front of the vector, we have to decrease n by 1 and increase f by 1.  This updates where the front of the vector now is.  We use modular arithmetic to ensure that we stay within our allocated memory.  (%a - this ensures that every time we get to the index a, for as long as n does not equal a, the next index will then loop back to index 0.) The remainder returned will be the index at which the item will be inserted.  If n = a, we would have to do a reallocation and copy the items across, in this case, however, we need to ensure that f is the first element within our new, bigger array.  w",14.0,68
20291,20291,24536,f2976011447672b5ea82a6f5b8159ecc9f0a4e8ffd33b6bddff412fce7c94244abe57dd0112220156e401a16e24a98cea2bd0caaf73b10b6bd34dde0d715c467,wen using circular arrays we need to keep track of the number of items in the array and the position of the front item. Circular arrays store data in contiguous memory. It works like a loop. Wen you reach the last index you can loop back to the beginning. Until it runs out of space and you ave to reallocate the array.,4.0,68
20292,20292,24537,20d849b0f14d796b315efcd61e863b25c7b0891949c9f1f08039226267e2ec02fc126e19dc6bac1596ae1c91066636280bb491c789bcd5f5ca3de77e3170945e,"A circular array is one where we think of the last element as next to the first element. The elements are stored linearly on memory but we are able to loop around the array and add elements so long as there's space. We need to keep track of the number of allocated space, number of values, and the index of the front. When we reach the last index of the array we use the mod operator to loop back to 0. Pushing will always be constant time and popping will also be constant time since we do not have to copy every item over, we just have to update our front variable. We also use the mod operator to  update the front and avoid accessing memory that doesn't belong to us which may result in a segmentation fault.",6.0,68
20293,20293,24538,f11178d26d71b36980a2e031712b410b8887af4a2b6c48901c6a568377c95cf608d8bdb211ef99a8ec80760d046f982bcd08b27ff9c8f8cd3f71083f65b80c48,"It is just a regular array whose elements area accessed in a roundabout way. It works in a way that the end of the array wraps around to the start of the array, in other words, when you get to the end go back to the beginning. We can implement it using contiguous memory wherein push are constant time if we still have enough space. For pop is also constant time  unless we want to reallocate to make the array smaller. Front and size are always constant time when using contiguous memory.",2.0,68
20294,20294,24539,fd3ac26e8f1d74669c591d17cfba292d301a38f59035e0e015254638e09238378ffbb05277661aa625df195230a27bb79b8964e830815de826a62bf695fefa00,"A circular array is basically like a normal array but the difference is on a circular array we keep the FRONT in mind and it can be changed and updated (explained below). 

WE KEEP TRACK OF 3 VALUES:

	* number of items = n
	* Position of the front = f
	* How much space we allocated = n_allocated

PUSH_BACK O(1)

In order to insert an item in an array , we need to ask how many items are in the array e.g. n=3, then we would insert our item on index (f+n). and then n++.

But if our memory allocated has reached the end but it is not full , we just loop around and start at zero by using [(f+n)%n_allocated].

_data[(f+n)%n_allocated] =value_

_n++_

POP_FRONT O(1)

In order to pop front we decrease number of items by 1 and increase f by 1.

_f++;_

_n--;_",11.0,68
20295,20295,24540,f6f17fb0d6ed2ee394666ab57ff8bd41ae8d4cb739854dc87e46a47f80236a49aeffac32c2aff43a7f1a1c2bab91b37fa0dd5d365978db82be6ca12abbe4f2d0,"Circular arrays are used to implement queues. They are based on the FIFO principle, except that the last position is connected to the first position in a circular queue that forms a circle. The values that we need to keep track of are the elements in the queue. These valuesare updated through the enQueue(value) and the deQueue( ) functions which are used to insert a new element in the queue (from the rear end) and to delete an element from the queue (from the front end) respectfully. When a new element is inserted using the enQueue(value) function, the rear gets incremented by 1; and when an element is deleted using the deQueue( ) function, the value of front gets decremented by 1. The circular queue can be used in memory management, CPU scheduling, etc.",4.0,68
20296,20296,24541,fa9e03d0ca767f086bcd9ef36b2098757508e1e31055329ce57a6c2012e0fc52ea26b7511314fd601a7a535cdf128ba0717226b541ddae15232dd77b79a7f243,"Circular arrays are contiguous. it can be used to implement a queue by keeping track of how many spaces of blocks we have and knowing which item is the first in the queue.

we can use the push function to add items at the back of the queue. until the are no more blocks to add from then we relocate and double the blocks and copy all the items and continue adding more items if required. by doing so we keep adding more items but the first memory location remains constant.

we can also use the pop function to remove items but we can only remove the one in the front but that don't mean we no longer have an items in front the following item that was next to the first item will now be in first memory location. Items can be added in the empty spaces that had items removed. number of items decreases and the items to take the first position increases because when we remove we removein the front of the queue.  ",8.0,68
20297,20297,24542,bb69eebb6b9661fb2659b9201956c2d150fd7601de8f2339f22c3c3c7289abd28101e1b6206a923a6b9fd81f7d0d617c8b5485dd0958ad06769fcf98922a4e97,"The size of the queue and the position of the front are important.Circular array is able to show if there's still space available,and if there is,we can can easily add and remove items. ",4.0,68
20298,20298,24543,95fcb6f4498706b42ae9b99b85ac88399a6d3275d00b87217fb05c5101d1dbf721727b60bf9e8e6b2dc1c2bdad3d13b66bf7f2d975e8a5f8863dd7d1ee3dcbef,We would use a vector with a specific size. The push back functions will be use but pushing back the item we want to add by adding it to the index of the first item plus the amount of items in the list and modulus by the size of the vector allowing us to loop back to the front. For the pop front function we would add 1 to the index of the first item and modulus by the size of the vector. using these functions in this way will allow for the use of constant time. We would keep track of our first item by updating its index to a variable that we could use in the operations,8.0,68
20299,20299,24544,e3fe34fe397fdba954ee04d79db645b0148c5938ca6f2f7a2907aa58749a445701d138ec6de61364a9d6a738e1bd62c299a45c7a655f0f5a3aa7fe48b798bb3b,"we can picture a circular array as a circular structure where the block after the last is the first.  we need to keep track of the space allocated for the array, the number of items in the array and the position of the first item in the array. they are updated each time we add, or remove, or rea",4.0,68
20300,20300,24545,ba17ced0b845a961a4ba2b9f572020680e40bd19c35ccad68ac84e48d9cb5d04fd0000feb318fb1b5fed6a59256f91eb5d0cc5f4be4d4f154e8d52a24ea8af8a,"The circular array runs through the array, then after n-th index, the next index always starts from zero. ",0.0,68
20301,20301,24546,eec934572d7644ba0121c8b2feb2c582e9f3f4f5b58187b8858bc2ee24ad1c13bedfb2cdb5029267bc11b865502439fbacde60c9046792350b575350ddc17ef6,"A circular array allows us to store values at the start when the end is already occupied (wrap to the start) and the front of the array is not always the index 0 (it can be adjusted according to our needs). We use the mod (%) function to wrap an item to the start. We calculate the position a new item should be inserted at by using: (front index + number of items in array) % size of array. 

We keep track of the index of the first item in the array, the size of the array, and the number of items in the array. The index of the first item inputted is 0. We update the index (add 1 to it) every time we remove (deque) an item from the front. As it is an array, we cannot change the size and if we need to add more elements, the array can hold we would have to reallocate a new larger array and copy all the items to that array and the size of the array would be double the old one. So if we allocate a new array, the index would start from 0. When a number is added to the array (enqueue) we add 1 to the variable storing the number of items and we subtract 1 from the variable storing the number of items when a number is removed from the array (dequeue). ",14.0,68
20302,20302,24547,9ab5ee6dcd1eeee42b584dd13d10dfb771aeae24b070596bf8e33f41840796cff5a58f61a4f76bd5d61ec8edd7ee76fc7e403b38a2b713cfce865554906c5149,"HOW CIRCULAR ARRAY WORKS

An array is considered as a circular array if we consider the first element as the next of the last element. When dealing with a circular array in implementing a deque, we need to  make sure that we keep in track of the front and the rear part of the queue. In a way we will enqueue an item at the rear and dequeue an item from both rear and front end. And it actually works with FIFO(First In First Out) method

HOW IT CAN BE USED TO IMPLEMENT A QUEUE IN O(1) TIME

One of the ways in which we can implement this array in constant time complexity O(1) is when there is no loop in any of the operation.

WHAT VALUES WE NEED TO KEEP TRACK OF AND HOW ARE THEY UPDATED

	*",4.0,68
20303,20303,24548,ba47d803e26988b75d891eb0e76061b355587a9834711cd75248db6b2b1c6cccc9c5cadcd161a1c0dfe6bd2d1a8b1014e37dd57461b73e39268808ede1fe4392,"a circular array is firstly looks contiguous in memory. We first allocate memory to it, then the goal is to push and pop with out stepping out off the bounds of our allocated space; we can keep control of that by adding our  front value and number of items and getting the modulus. This prevents us from going outside of bounds . if ever we are to fill all the space then we would allocated new memory to the array.  Keep track of the size of memory allocated to the array, the number of items in the array and the value always at the front which makes things easier for us because : pushing an item will always almost be constant time unless we run out of space and have to reallocate, popping will also always almost be constant time due to also reallocation. For front, we always looking for the item in front and that only requires constant time. We always keep track of (n) the number of items when working with the array the fore we just carry the value over and it brings the size, which takes a constant amount of work",10.0,68
20304,20304,24549,2b92088102e0af9a5553cb90ac0d16cccf7d22e656abd8591794202e3ad9e3740967e9bc58b6fe2de9b9f1fca59eea10df4f48ad04955724c20b00283b3e3844,"* firstly i would initialise  my class for queue.
	*  inside my class i will initialise the front and the back as integers.
	* i will then initialise size 
	* make a pointer for array
	* create a void function for enqeue
	*",2.0,68
20305,20305,24550,9ef08903fc9bcdb48895ecc5b1fae5cd197bde173b9729429afd0455acdabd651995bcf58c93f0a9f803a86fd3d68cb2f4b604260158eb5fae2f92dc6b1309cc,"A circular array has the last position connected to the first making it a circle.I would use  front() to access the first item from the queue which would take constant time.To get the rear item from the queue I'd use a rear function.I would use an enqueue function to insert a new item which would take constant time provided there's space I 

would use the dequeue function to remove an item and this takes constant time.",4.0,68
20306,20306,24551,0c11d203426fce7b3dc05c5b901a557cc9648e7fd3384bd9d8800631c383636176c5236339b82c8cac354a014c4e904c016c4f55b6e4ea8b971819143c0b5cb5,"A circular array is an array where iteration wraps around the array, so the first element is next to the last element in a way.

Values needed are 

	* n_items
	* position of the front element
	* n_allocated

n_allocated is the number of blocks in the array and every time we push in  the array n_items is incremented. When we pop the position of the first element goes to the next value next to it and if we reach the end of the array we wrap around and decrement the n_items.",10.0,68
20307,20307,24552,64e451748c8e64219c1dcf31828cb7ded38a1447346285c9e9b6559aebe71fd6c492c0cffcdb5c0c6a652b339b2aa51ca0d8310a628f12a661261dc55ced044f,"The following are the operations that can be performed on a circular queue: FRONT: IT IS USED TO GET THE FRONT ELEMENT FROM THE QUEUE. Rear: It is used to get the rear element from the Queue. enQueue(value): This function is used to insert the new value in the Queue. In the circular queue, THE LAST NODE IS CONNECTED BACK TO THE FIRST NODE TO MAKE A CIRCLE. The circular array list follows the First In First Out principle. Elements are added at the rear end and the elements are deleted at the front end of the queue. A circular Queue is a linear data structure in which THE OPERATIONS ARE PERFORMED BASED ON FIFO (FIRST IN FIRST OUT) PRINCIPLE AND THE LAST POSITION IS CONNECTED BACK TO THE FIRST POSITION TO MAKE A CIRCLE. It is also called 'Ring Buffer'. In a normal Queue, we can insert elements until the queue becomes full.",6.0,68
20308,20308,24553,73f479b1c32665dbc26a876d65d907d7b668722d4500809cc0e92a0c3b8fb6ef14ebbb966ba42d9df836ec685dff74ba0f52590c3d881cbfcb8d972c3fe69336,"Circular array list fallows the First In First Out principle. Elements are added at the rear end and the elements are deleted at the front end of the queue.

IMPLEMENTATION:

Initialize the queue,

 with size of the QUEUE DEFINED ( maxSize ), and head and tail pointers. enqueue :

 Check if the number of elements is equal to maxSize - 1: If Yes, then return Queue is full",0.0,68
20309,20309,24554,0acf933aafd8ccfefdb0a07c9cd769ff21b003c332b8b90f6edffc1573664ade1e2d7b54669b2cee7b03b35091d029450c66d87d0c0afdf5016d3799c57a4fc9,"circular array is a data structure that used an array to connect the front to the back

can be used to implement a queue by connecting the last position to the front position

enqueue - can be used to insert an element into the circular queue

dequeue - used to delete an element from the circular queue",0.0,68
20310,20310,24555,e7c7348f23786b9e18a28e68e5d9ba68b1b693a74a0d58100a7db9e2aeee706b92e8dc4a38b20cb50289290e86666a9bfd49334f05b1673c8db1a8b26f9c9689,A circular array is one where by the first element of the array is considered as next to the last element. It can be used to implement a queue but we will have to know our number of Allocations and number of Items in the list and also we will have to know and keep track of the front of our Array.,4.0,68
20311,20311,24556,09a1699e91053a97e967035388a9bb6bf2333dc132838738d78edc417a8028213044038d23bdf9e5be7458e9014620b5d4a10df02214eb4aa340c740ce44d5c1,"Circular array is an array that allows us to wrap back to the front of the array if we attempt to access an index that is after the last one. 

Values that are kept track of are: a (allocated size of array for a certain number of elements), n (number of elements), f (index of front element).

When deleting last element of array with pop function, the index of the front element must increase. Incrementing one after last index will lead us to access memory that isn't meant for the array, leading either to a segmentation fault or crashing of program. Instead we will wrap back to the beginning of the array, where the index is 0, and update _f_ to that value. _n_ is decremented with erasure of last element.

When adding an element to the array with the push function, you might find the next empty space with the formula _f_+_n_ (index of front element + number of items in array), which gets you to the index of the next free element. However if _f+n _index exceeds that of last element you can get a segmentation fault again or crashing program. Instead formula for wrapping to index back to front of array is used.

_a_ only gets updated when you attempt to add an element but n=a already (number of elements = number allocated), so enough space will be reallocated for a new array, and a changes to this number.",10.0,68
20312,20312,24557,400853532d18057c486e48e90c2e3817295b0b8da4abab44abf1f9dd692996bce343aa72b93713cdef71a68aff30879c7ec75ca8ea25a59fd4c48084879663a5,A circular array allows the queue to be circular in such a way that it can perfom FIFO ,0.0,68
20313,20313,24558,763a776e81302d0ca35787de395275bfa7dace1cb9ac6ce690e840ef2f280482559135e73ff9334c7ef80b3304e1f6061c108364e0e55bf5e56d4aafbce8e073,a circular array is an array whereby we would take the first element is connected to the last element. we would need to get the front item of the queue and then get the last item and thereafter insert an item into the circular queue where the new item is inserted at the last position. we would also dequeue to remove the last item from the circular array. we would also like to know the size of the queueas  we would like to check to see if the queue is empty,2.0,68
20314,20314,24559,bf4b5731c3c3bd0f2b59e631e277805959da8b9efedbe010df49f525b49b713ed8678bb3e54ddfd542bb302e79e236dfb9ec30ec253f0f80d3cd72c6a5094fbc,Circular Array work by pointing first element as front and last element as rear. To insert using circular arrays we must use linear time so to use contant tim we have to assign front() of circular array to  be back() of queue and rear of circular array to front() of the queue. The big-O to insert at the back will be constant. the push_front will work as enqueue for our queue.,4.0,68
20315,20315,24560,6c39b5e6a07e95287c054b22b9b14ae724def23d44c2473ffa57fa66d0dc3ed81fdc207205fd37cd3342b92b02f8364dc720791f8b6724f778e183c98d663fa5,"A doubly linked list would be necessary to implement a queue of constant time operations.

Having a head and tail pointer with ways of accessing the next and previous link respectively allows for adding(pushing) and removing(popping) without the need to iterate through the links. This makes these functions operate in constant time.

Having the head pointer gives constant time access to the value at the front of the list.

Due to doubly linked lists storing the amount of items in the list, accessing this amount is done in constant time.",9.0,69
20316,20316,24561,be6529d2c60e9c3e44398e6d6378522b796199a001be8bd7e7bf876610ef85fd8204961bc4cabc5a2506d1dd5b074658c765a8f7b3311d9493c6efa1d870167b,The type of linked list we would use is the double linked list with a tail in it to help us keep track of the last item in the linked list. The double linked list will help as we will not have to iterate every time because each block will have the location of the previous block and also have the next block location in it which makes accessing the block much easier with the tail also there to assist to access the last block so there will be no need to iterate so there will be constant time instead of 0(n).,5.0,69
20317,20317,24562,af813686acb18a064eece7968dc86f7e1ba2e2c4ebcbfb61de992275f213a5fe2248d15ae968c61ff6c270f401a739d21132339ee0a42afa471e88a17c352ab9,You would need to use a doubly linked list. The pushfront and popback functions would both be constant O(1) due to there being a tail pointer and the fact that the last link in the list pointing to its previous link which would then become the last link after the popback function is called. The size and front function would also be constant O(1) due to the link keeping track of its items and the front only retrieving the first item in the list.,9.0,69
20318,20318,24563,7a27fb1fa642a9bd3d76e8ce98be5e4779f4184eab8b901b0ee0d165d466de6122db493ca631d33ef289f724ffb838136d578f3b72df159667217c69ae154ed3,"We will need a DOUBLY LINKED LIST (DLL) to implement a queue where all operations are constant time. 
For implementing this, we need to have two pointers: The front and tail. With these two pointers, we can push items at the tail and pop from both head and tail. The reason that the operations can be done in constant time is because it is only dealing with insertion or deletion of nodes at the beginning or the end. ",9.0,69
20319,20319,24564,f7bbac457e26e926aa83f65c706f322284bcae4a69df367438ec5060865432bf63d2eef51ed308d86119a8e1745e619fe74662cd103d43378e65328b7630ff57,"You would need to use a doubly-linked list as each node points to both the node before it as well as the node after it. Because there is always a pointer to the first link as well as the last link, all operations will occur in O(1) time complexity. ",5.0,69
20320,20320,24565,c318ecd5c05d3ffa65238b75e8aa9e67390cc6fb32c2fdbfaf84c4d21eee7f78cf713a8bc77a69838390c129742df9afc0ddd3cf48a8b7ef5ea2fb0f43dc4114,"I would use a doubly linked list to implement this queue. I would have a head pointer, a tail pointer, and each item in the linked list would have a pointer to the next item in the list and the previous item in the list. With all this, I would be able to access the necessary items at the front and bock of the queue to be able to pop, and push in constant time. The front, back, size and empty functions would also be constant as I can access them using the pointers and counters in the standard double linked list.",9.0,69
20321,20321,24566,3d98aadbc95f1ceaf5723fac50fb4583048e99f3a608962c3b1c8cd33d79fc21685534ca4e509a1fb097360bbcf66d5d96593eff3b861f7814afdcae8fecdd1e,A doubly linked list would be suitable. Having a head pointer will allow us to pop from the front in constant time. Having a tail pointer will allow us to push back in constant time. Size and Empty functions will work at a constant time because they are built in functions.,9.0,69
20322,20322,24567,c75c72f439ed0a1083505ca2fb274424bfa93184c45c67c47245732cd59fc54e342192b7a0a8538fb3676603ded389cab9a3431e9d476a9d9b140adb5ff30721,A singly linked list would allow us to push back and pop front in constant time since we wouldnt have to traverse the whole list to perform those operations.,7.0,69
20323,20323,24568,06f90aca60b4b2db0e6d8bb78d0ed0da22ceb02b561b842eee51951b0e04be81e8817f795eb9597349f2e3c12b7befca0ed36322cff788052acb9b91388f1fdc,"in order to always have a constant time complexity of O(1), a doubly linked list would need to be implemented.

because the links in the list are all double linked, no traversing will need to be done, rather the items and values can just be accessed.

there is a variable _n _that will keep track of the size of the list (whenever a link is added in push _n++_ will happen, and whenever a link is removed in pop _n--_ will happen). and for the size() function, it will just need to return that variable _n_.

the main thing from a singly linked list to a doubly linked list is the size() function, which is now constant time.

however in a DLL all the memory is not together so a circular array would be better to use.",9.0,69
20324,20324,24569,3227954877ff6b3d6e5d415eabaacb6ee56a5809874f349fcc72cbd6b74b9924802065f3198d52fa435eef46404fa2ce0465698400217a4b7b18ef03d8cc91ec,"A doubly linked list would be required or a forward_list with a tail pointer.

Enqueue - Since both use a tail pointer, we are able to add to the back of the queue in O(1) time with no need to traverse to the end. We assign the tail pointers next to the element we are adding to the list.

Dequeue - We can remove from the front in O(1) time since pop_front() for the forward_list and doubly linked list require constant time O(1). The second element becomes the head of the list (front of the queue) and we delete the previous first item.

Front - Can be accessed in constant time since it is the head.

Size - We keep track of the size and can also be returned in O(1) time.

If the back was treated as the front then a similar approach applies.",9.0,69
20325,20325,24570,aba8ccda4763601c960552191c4b4ea7d3e94521d25f84c03f905aac0bf9578acabd1a7e87e98918c1a32dbc6bc0f00b14222dbc9e37a19a4efb13f1c52924d7,"A doubly linked list will be the most efficient in comparison to others.

Every operation takes O(1) time.

push back will O(1) because we have a tail pointer which we keep track of, this makes adding items much easier at the back in O(1) time. Similarly we have a head pointer pointing to the 1st item, this makes it easier to remove the 1st item in O(1) tiem.

front will be O(1) due to the head pointer and back would be O(1) due to the tail pointer. 

size will be O(1) because the double linked list keeps track of the number of items.

empty will be O(1) tiem.",9.0,69
20326,20326,24571,c2a635a9bcf4ad40fa50102eeb50a8298caf1f43a284d43931e8d6ff78372592382df0d5a087e759cf9a231e99eb6b2b3a8890e03edb12bf9295b2611174eebb,"A doubly linked list with a tail and a tracker for number of items in a list would be the best implementation where all the operations are of constant time. To implement this we would need a tail pointer as well as a temporary pointer and once an item is added (push) to the list using tmp pointer we would link tail pointer to tmp and link tail.prev to head, we also need to  update the number of items in the list to +1. The same thing needs to happen for the pop function where we make a pointer (tmp) point to head and make head equal to the link directly after head (head.next) and delete the tmp pointer but also decrementing the number of items in the list and updating pointers. For size operation just return number of items (which we tracked) and the front operation just return head.next's value. ",9.0,69
20327,20327,24572,e7c9b4fd869eb791a63c71759d17fa7e8a93618d661588fa6ae371946756531c0923d86aafe2bfd7289d74b69cb5fe841e3839957a75e6446f2d8394b4178536,"I would implement a doubly linked list in which the push_back function takes constant time as it simply creates a new link, points the link before the tail's next pointer to the new link, points the new link's previous pointer to tail and points tail to the new link; the pop_front function would also take constant time as it simply points a temp pointer to the item to be deleted, points the head to the 2nd item then deletes the 1st item. Similarly the size(keep track using tail pointer) & front functions would take constant time. ",9.0,69
20328,20328,24573,666d09a4d8260961dbb488b896e8680fe46f9012a9bfa6adbe518edfaed179e00538132a0e660a988cc51e3f8b8695b7b78d6679f0a1e7d0f26361ce20a96384,"We would use a Doubly Linked List. Where we consider the front of the list as the front of the queue.

Enqueue:

We could use push_back function and this would take a constant O(1) amount of time because we can access the end of the list (tail pointer).

Dequeue:

We could use a pop_front function and this will take a constant O(1) amount of time because we have the head pointer.

Size:

The Doubly linked list has a size function the keeps track of the number of items in the list for us in constant O(1) time.

Front:

We could use head->value to get a reference to the first item in the queue in constant O(1) time.",9.0,69
20329,20329,24574,8988e05f865164f4560af96560c21e55905eac0bb5f61f3d6e278f9698c3b2aef4e2c138e098da5e867aaa523133fd657970eaa9429e994d798d7fd717f54fcc,"We could implement a queue using a Doubly Linked List with a head and tail pointer in order to have our functions operate in constant time - O(1). 

If we treated the front of the list as the front of the queue, then dequeue() would be O(1) as pop_front() for a doubly linked list is O(1). For this reason front() would also be O(1).

If we treated the back of the list as the back of the queue, then enqueue() would be O(1) as push_back() for a doubly linked list is O(1).

For size() and empty(), it could be constant time O(1) if we kept track of the number of items in the queue as we added and removed from it i.e. have a counter variable such as ""n_items"".",9.0,69
20330,20330,24575,ab914ab560d18c5aef3e43bda3ed23f3106afabfcaabd71fb45ebbdc423746252b1d705ea396aa70f877858829d5c8d335f73b945106c9ea584789a7d7f0ea77,"We will make use of a Doubly Linked List as the underlying container for the queue. This gives us a tail pointer and the ability to traverse backwards that allows us to achieve O(1), constant time complexity for the dequeue ( ) function. Besides that, enqueue will always be constant, so will peak( ), as well as size.",5.0,69
20331,20331,24576,8f8e96eb5a28d15c7802d177c96b97e53c9c9c2a37389d558dc50a5be6ad84289d3986f782da265340d7d86d9d174957d8d67890ddc79dd4587dd919a3bfb09b,"you would need a doubly linked list

all operations needed are part of the STL

queue<Thing, list<Thing>> q;

since the list contains both a head and a tail pointer, front and back will take O(1) time (you would just need to return the value of head and tail)

size() and empty() both take O(1) time

push_back and pop_front both take O(1) time as the list contains a head and tail pointer, and tail is able to point to the previous link",9.0,69
20332,20332,24577,17a5fd9d02d6fba8d8046ace71c42e033c0f094c5a424e213efe17ca2b15dcda4339210b67d2e20cb931a5cb55e9b6fb5621dde12a8a5e6da612e051b176b44e,"Use a doubly-linked list with a tail pointer.

_PUSH_

_Create a temporary link (tmp), make tail -> next point to tmp, make tail -> prev point to tail and then make tail = tmp. This will all be in constant time._

_POP_

_Make tail = head, head = head -> next and then delete tmp to ensure no memory leak. Constant time._

_
_

__

__

__",7.0,69
20333,20333,24578,c7d75d976a010a38db71e259afee15ce7c42ba18fa8ef2214021124356299e2bc696f235d69042a2e7d6021b611ee4096167f90988dc7b1e755fca98c40f31fd,"I would use a doubly linked list in order for all the operations to be constant for the queue. 
I would use a doubly linked list that has a tail pointer. This way adding and removing items would take O(1) time as i can change where the head pointer and tail pointer points. The front function would take O(1) as i will return the value stored be the head pointer. The we can keep track of the size as we add and remove items by incrementing and decrementing and this will make the process of determining the size of the queue have O(1) time.   ",9.0,69
20334,20334,24579,d5eef99882213e9e893ef6d31b163cddd65b11b328a038af368c63b9dea5c55582d674f73b7f44a7ffb0e808a2c14f224354666b5c8da68a3cf145583cdbcada,"The type of linked list you need is the doubly linked list.

Since the doubly linked list has a tail that points to the previous node, I would use the back of the list to enqueue objects by using the push back function. After adding the object I would update the tail to point to the object.

To dequeue I would use the pop front function and update the head of the list. To peek I would use the front function and, to check the size of the list I  would use the size function.    ",9.0,69
20335,20335,24580,cb120576f9fc254cce2a2bdcc2fab8a2f95f1ad24a5398cde6a97bb68344852b25ff6ddb6448c5c344141e6c8f5ee1dd504e841ca984819c02a7811908c51bc8,"We would use a doubly linked list that has a tail pointer and a head pointer both if which will have a next and prev value. Using a doubly linked list will allow us to use the ""push_back"" and ""pop_front"" which are always O(1) constant time in a doubly linked list.",9.0,69
20336,20336,24581,16f09d60ea55f541a3437e3e2ab8e9c69f838f50f98dec712996c73779cd9f654e7fa72007ae7a3b8d9cb813c8fad8d686dc40ba57c222e292c85b1a88fc8b53,"* use a Doubly linked list. 
	* with a tail and a head pointer, we can push_back and pop_Front using a tmp pointer. 

tmp = new Link (v);

tail->next = tmp;

tmp->prev = tail;

tail = tmp; 

and 

tmp=head;

head= head->next;

delete tmp;

n--;

	* in this way, Front, size, push and pop is all completed in constant time.",9.0,69
20337,20337,24582,db2da6294f4863255b8e851f3219cc1d358a9a52af31fcce04dfd21a77bd1b6105ebfb54ad3aa0cbea5dc9fb93c67b5af9e1ff40b17fbd626a20ad3636813679,"I will us a double linked list so that to get the size of the queue it will take constant time also to the the link of the front item.

To pop front I will use the head of the list and to push back I will use the tail of the list.",9.0,69
20338,20338,24583,66ba5975b098f5fa2bae0b86dceb6b280b99b8f4c6fff5dafe0a067b8a9153b49a39abe1525261732c63d25886c01c121ff46cf2ab2721a603f04674ea202257,"In order to have all the operations take constant time, you would need to implement the queue using a doubly linked list. This means there must be a head pointer, tail pointer, previous pointer, next pointer, and a size variable. Keeping track of all these values will allow us to perform the enqueue, dequeue, peek, and size functions in constant time. ",9.0,69
20339,20339,24584,a0a0e3863f2cfe81dc13120d1d5fb28060efbca078cff0afc0ca4a53755acf909a3b28053a432d02251e8d53776e3aedf7eeff75f48fc36029b0d4fb7d46aa25,"In order to implement a queue using a linked list where all operations are constant time, you would need to use a doubly linked list which has a pointer to the head and the tail.

To add an item to the queue, one could use the push_back function. This function would create a new link with the desired value. The 'previous' pointer of the new link would point to the current last item and the 'next' pointer of the new link would be a null pointer. Then, the 'next' pointer of the item that is currently last would be updated to point to the new link and the tail pointer would be updated to point to the new link as well. This would take constant time.

To remove an item from the front of the queue, you would use the pop_front function. This function does the following:

	* Creates a temporary pointer to the first item in the list

	* Sets the head pointer to point to the second item of the list (head->next)
	* Make use of the temporary pointer to delete the old first item.

This would take constant time.

The size function of the list class could be used to implement the size function of the queue.",7.0,69
20340,20340,24585,4a10096efbe473298c3ffaa590c64747a3f122d6138157d16b669b6d6757b1ee312e247b5d7de57197c1100b67d525e21d2bdf5719b1e5397849be3138642057,"You could do so by using a Doubly-linked List with a tail pointer, because: you can use the head value for front; size is always constant; you can use push_back for push; you can use pop_front for pop. ",6.0,69
20341,20341,24586,562a79f866657142ac8bf9d260020a41dd948177d2bce6c88383e228d52056cf2d2544e838847e98137352689514e6b5fccb58b9b8779b353c6c283dfc7313ad,"For this we could either use the std::list since it has a tail pointer or we could use a singly linked list which has a tail pointer but std::forward_list wouldnt be desirable since it doesnt have a tail pointer and consequently doesnt have a push_back() function since it requires a traversal.

std::list's push_back() and pop_front() are constant since they always take the same number of operations each time independent of the size of the container because of the tail and head pointer and we would use them to implement enqueue and dequeue respectively .

front and back would just derefence the head and tail pointers and thus being O(1) also.

using std::list is advantageous since it has a member variable  which keeps track of the modifications done to the list through pushing and popping and so would make our size() for the queue be constant also and consequently empty as empty only calls size()",9.0,69
20342,20342,24587,33903c4df6729a45e2485f57a528848aea77fb0ac81607f602f6f53f80eb513d5b18fef57c086d43fef4cdb3f78bbc1f8da0bcaa1e67afb26268e9484bbb4ded,A doubly linked list allows for O(1) complexity for all its functions.,9.0,69
20343,20343,24588,dec98074973763aa35f767e29ff1a337a2f96e27f7bb719852891850a70e146d6ceeda2c5cff7d622832dba02534fa96620c763e3c53dc17c1734a3ec63ba166,"You would have to use a doubly linked list with a head pointer that points to the first element so you can call front() and deque() in constant time (O(1))

And you would need a tail pointer so that you can add elements to the back (enque()) in constant time (O(1))",9.0,69
20344,20344,24589,1e61ac69c9ccec529a9d57595e183d7f2b1fa6a9903d4933718e237d1b12f704ba69dec35931222592238b7ab802821e4d5dd2c83c64cb9301a8bb0ced8b2cba,You would use the enqueue() and dequeue() functions which are O(1). This would be doubly linked list,9.0,69
20345,20345,24590,725a0125b367c6f17c35c11b2109d01e495cc98a9983ee64edff98f1e31691682af784e585cb9ffd4450baefac075cf1659b1b9f4409ec665f5bbef7fd4002df,"You would use a doubly-linked list. You would need a tail pointer, a head pointer and a tmp variable in order to make it constant time. This will allow for the push, pop, size and front function to occur in constant time as you can access the back to push to due to the tail pointer and you can access the front to pop the front element due to the head pointer.",9.0,69
20346,20346,24591,b62aa4d567faf4c8c2d7b435cab87c30c9d1e6af89f8a0e3d7867630ef600446840f333742c814bc8a0c9d2f0ab23474abdecc13d41d7312f08a47b7fc5bb67c,"For a strategy like this, you would need a doubly-linked list that also has a tail pointer.

For push, pop, size, front etc... you could get a constant time O(1) by having a tmp pointer.

this tmp pointer would first point to the data the head is pointing to (tmp = head;).

you could then traverse with your head pointer to the next item if say the first item was dequeued.

You could then delete what is stored at tmp and have a new head pointing at the first data item.

to push to the back of the queue we could simply use our tail pointer to do this.",8.0,69
20347,20347,24592,74ac16aad9cffebc9a82a3d84552ea746b2a726fb003881a5a45ccd11c8a938caed3d1a49b6f0f3b5bc663c85f99ca3ae1d10cb0f79247d51859bb82beada81b,"To do this we'll need to use singly-linked list. We create a push function that takes O(1) time, size() function that takes O(1)...A pop_front() function which removes items from the front of the queue , takes O(1) time.",9.0,69
20348,20348,24593,52b1f6fd8e6c0289a8004d7d61b231157f72159bdb1098720813eb6a4750543a581c16358208b2fe293a6bc58612fe418d8dd4bccc56d715f7137f43db02b99f,"You would use a doubly Linked List with ""next"" and ""previous"" members, as well as a head and tail pointer.",2.0,69
20349,20349,24594,7f4b419d2ced93d50fb8649f87b2fa3a1ab4c6a1ecc8b63f150aeb372237c21eae97c5eba18c0880eb018ac5d3fb68e9a7180e8af2cbb1d90dc8d7f06f63f097,"A forward list can be used to implement a queue. Where all operations are constant time, since a node in a linked list has 2 parts: the data and link parts. I would take the head pointer and make it the front as it points to the first element and is an easy way of maybe removing the first element. After removing that element, the head pointer would then point to the element that is now at the front. To add to the back of the queue, a tail pointer would be best so as to maintain the O(1) time. After adding that node's link part will then point to null.",8.0,69
20350,20350,24595,615a61127c6c0ce82fff3b905af9891145f1a8b7de3c813ff28357e83206738e51030e5e11f925cb1ff08e1e1848b449cb4a5ebd866eaf249477de58f163ccf4,"You would need to use a doubly linked list.

this is so

if we make the back of the linked list the front of the queue

when you dequeue, you would remove the back which would now be in constant time as you would not need to traverse the list to remove the element at the front therefore O(1) time

Adding elements to the front of the list which is the back of the queue will be in constant time as you would be able to insert a value by changing a few pointers. therefore O(1) time.

size would be constant as we would keep track of all enqueues and dequeues O(1)

peek front and peak back would be constant as a result of the tail pointers and head pointers O(1)",9.0,69
20351,20351,24596,6faeacee0c2269025dd90b7721d39fd6ea59274d1116063ca6e894050048f55cfc48de8438d931d22afb7e2c6e6e2971358b83dd0ec2d867cc557d7b6b500315,"We would need a doubly-linked list.
We would then be able to enqueue and dequeue using the head and tail pointers.
Enqueue: Call the tail pointer and add our new item on and then set a new tail to the new item.
Dequeue: Call the head pointer and remove the item at the front, then set the head to the next item in the list.",9.0,69
20352,20352,24597,18f6254c7b196766dbebfb4556ef6c2f9ff5e44918d8ea60921fbe90c8a42515b04ace17b80ecdd7f09efd69961a6da2d4a21f100e3ebd5acf67acba7ebaae55,"To implement that queue you could create a linked list with a head, next and prev pointer and a tail. This will make sure that if you want to enqueue or dequeue you take constant time, as you do not need to traverse at any time. This list also keeps track of the amount of items stored in it, so the size is returned in constant time.

This type of Linked list is called a doubly linked list.",9.0,69
20353,20353,24598,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"A doubly linked list would be required.

If the back of the list was the back of the queue, then the push function would be implemented by assigning the new link to tail->next.

if the front of the list was the front of the queue, then the pop function would be implemented by temp pointer being assigned to the head pointer. The head should be assigned to head->next and temp pointer should be deleted.

The size will be determined by incrementing a integer variable upon each enqueue.

The front function may be implemented by returning the head->value. ",9.0,69
20354,20354,24599,336c0de60905df4ae163484013b5cc72929683b64ebae6f69a61ca7bbc767084419ba7cf9291246a9b63bc7e686a397f48c33976b41fb34999f9b50eee045aba,"I would use a doubly linked list where the head will point to next node, such that the next node will have two links, the first one pointing to the next node or to NULL if the it is the last node, and the second link will be pointing to the previous node. This will help in traversing both forward and backward thus making the operations to operate in constant time.",2.0,69
20355,20355,24600,fd0ace311926a44973b18eb55c0a2df285cc4ef58cf67836be1c2719041ca75111c81115da37e4e4879d8c00ffb63db68cb0de1c85a3fc373724acf7945dc463,"We can have two pointers that will point to our ""head"" and ""tail"" in the linked list. As we add items or other nodes into the list we update our tail to be the recently added node and every time we pop from the list, we update our head to be the item or node that was following the pop item or node. A circular linked list is the list I would use.",5.0,69
20356,20356,24601,e394539baa7fd0006de5096759d1db9943b0b453927105fc99e564a56547ecb01587d2f0348be0224bd521c0377577b713f00c14b60183a6d229e89193dcb643,The head will be the first element in the queue ,0.0,69
20357,20357,24602,3833aa3ef06cafdc78971652ad20444fe164affcf92c03de12570129a147987ae3263043850e741f6f77f4965176d32cb0f7b6200e6f1f08cf0158b373dc6fbe,"A doubly linked list that pushes to the front and pops from the back.

The doubly linked list would also include a pointer to the last item in the list this allows for a new item to be added to the back of the list in constant time as there is no need to traverse. pushing to the front is constant time because there is a pointer to the head and no need to traverse. A variable that stores the size of the linked list is also included and it decreases and increases based on the action performed. If an enqueue occurs, the size is incremented, if a dequeue occurs the size is decremented.",9.0,69
20358,20358,24603,662455ba865b7fa66132ae6520e999c9ea1b9fa1f85d0b16ee30bd84db7aa0bec3c7fd7269d6521a07e1ad16d091e298c84cb6c69ff3537fa78efdac09fa4677,"We can implement a queue using a doubly-linked list. The doubly-linked list has pointers to the front and the back of the queue which allows for constant-time insertions and deletions. We can peek at the item at the front of the queue in constant time as we have the pointer to the front and by keeping track of the size with a size variable, we can also access the size in constant time. ",5.0,69
20359,20359,24604,efe8bbe0531a8edbaeccdc4f50ad7d19da4ae088aef554a1013cb2ff8b78ba31a24fa0e8f957d84b8c738910275c42c68da1550413f3ef77aa9c38fb88257b54,"In order to implement a queue using a linked list where all our operations would be in constant time, we would make use of a doubly-linked list with a tail pointer.

	* push(): Adding an item to the end of the queue would take place in constant time since we already have a pointer to each end of our list (head and tail). Thus, to add a new link we simply have to dynamically allocate that link using temporary pointer and then update our tail or head pointer (depending on which end is the front of our list). This will all take place in constant time.
	* pop(): Removing the item at the front of the queue follows a similar logic in that we already have direct access to the ends of the queue and thus we can simply remove the item in constant time.
	* size() and front() both also take constant time in a list",9.0,69
20360,20360,24605,f1847bb5d29f39224664df29173ee4eea8241f8aa777b795f86bafdb3b6165e8679750df7902af2beb1387f258e9970c22324224cff020b701254fc8b35d988f,"A doubly linked list could be used for this. A forward list with a tail pointer could also be used for this. To pus to the back we would just create a new link, set tail.next to point to that new link and then reassign the tail. To pop from the front We would need to create a temporary pointer to point to the head, reassign the head to the next value and then delete the item that the temporary pointer is pointing to. To implement the peek function, we would just need to return a reference to the head of the linked list. To get the size in constant time we would need to update the size of the linked list by one each time an element is added, meaning once it is added, the size of the linked list would be updated. That way the size() function of the queue could be implemented by returning the size of the linked list.",9.0,69
20361,20361,24606,7c939bb7eae30ac9fde6bed7ba91e751cb79bad249785d6c36230c4d9e80b55aaaf08d983990b398d630a07852718c75269fe0b377bbd248cf1db616b416f57e,"I would use a Linked list with a TAIL POINTER plus a COUNTER which would keep track of the number of items in the list.

For the PUSH function, I would push_back using the TAIL POINTER. O(1)

For the POP function, I would pop_front using the HEAD POINTER. O(1)

For the TOP/PEEK function I would simply return the reference to the HEAD POINTER. O(1)

For the SIZE function, I would return the COUNTER which I would have kept on updating when pushing and popping. O(1)",5.0,69
20362,20362,24607,833bd82b84984eac1561a2aa471c7fa8ce8fc83eb43410d162adbb99836f9c60ca90f110500d0a4cfae027c10757354954059b39ea510643c3c10d5e8f6e1bb9,"* you would need a doubly linked list for all the operations to be constant time.

	* I would create a boubly linked list that has a tail and have a temporary pointer that will be pointing to the new link.",2.0,69
20363,20363,24608,a18d348d984f5bd8aca6ebc4fccb86f8d160a802b4c7ee70a595f3b8caf6c18513e302bc5cfcbf90d284bd7a320b1536220dd429aa4a21d61efb3ef1771458a4,"I would use a doubly linked list that starts with its size=0. I would then make my enqueue add a value to the head of the linked list and increment size every time I call it. I would dequeue by first making the second last node and the header node point towards one another and then delete the tail node (and therefore making the previous second-to-last node the new tail), and also decrement the size by one. The size function would just be a call to the size variable which is constant. The empty function would just return whether the size variable is equal to zero or not.

Front would just return the header pointer, while for back I would return the tail pointer (which I would be able to access by the link between the head and tail nodes).",6.0,69
20364,20364,24609,74594d76e743115e9e80c4119a5039c4fec5aed2b1eb9af70c89d53a42b69ad2163ffd8ce8a40f97632e4be0cb18aad097e1d70fac3137214bb4656688c9555b,"You would use a doubly linked list or a singly linked list that tracks the tail link and its size.

To add to the queue, the list would have a new link pushed onto its front.
To remove from the queue, the list would pop the back link.

(In the case of a doubly linked list, the side added to and removed from is not important for efficiency so long as the push and pop operate on opposite ends of the list.)

The front/peek function would return a reference to the back link of the list.

The size function would return the stored size of the linked list.",9.0,69
20365,20365,24610,7db17fd2acfdd980933bf2f92abec54feac68e8b60f672ae1ba7781b8dd15de47315f37d74c147384e68a3a01e88e6539391471e6490908578bb1e2cdf85e7c7,"i will need a Doubly linked list with both tail and head pointer .Let the front of my list be the front of my queue .To push i will simply use data.push_back().This function will make the tail of my list to point to a new link then set the the new link to be the tail and let the current tail point to null .To pop i will simply use pop_front() ,This function will take a pointer and let it point to the same link that my head is pointing to ,then it will let the head to point to the next link and finally delete the pointer that is pointing to my initial head .To peek at the front just return data.Front .This will return the value of the head .To return the number of items in the queue return data,size().",9.0,69
20366,20366,24611,263fd6b7e81bd2b0bd84f67415866c3d75bf78011a0e0748b552d65d3fb35fc4bf5dca96f9ccb82225afdb2c9f73d9593526bb28fe17ab6d85ae420a8a33d70d,"If the queue is implemented with a tail pointer, it will allow us to make a queue where all the operations are in constant time. We would need to make use of a doubly linked list in order for this to work.",2.0,69
20367,20367,24612,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"I would need a Doubly linked list.

I would use a tail pointer.

I would use push_back to add at the back of the list and pop_front to remove from the list ",9.0,69
20368,20368,24613,d31899b98e7fb3e761998737c0078a84e48727b178f33ae85b1caf85762f7c95a36780c3f84b13e4c3f8980c15788bdfcc7bddbb75a6b63b7a164f238d74d926,"The most efficient way to implement a queue using a linked list is to use a doubly-linked list. This is due to the fact that we can push to the back of the list in constant time compared to the singly liked list where this is not possible.

To add to the queue we would call the linked list's push_back function, which would use a temporary pointer while we change the tail pointer so as to not lose access to any data. This would be made possible by the prev pointer (only possible with a doubly-linked list) allowing for constant time.

Similarly, we would make use of the pop_front function to dequeue our queue which would allow for constant time.

As with a standard list, all the other functions would allow for constant time",9.0,69
20369,20369,24614,17af69de9b004cebc772407eb454a4695fd215d61e6315c9d12ef0dd3a08b8a8642b4cc8dfc787e7755ff0571045a1730ffe50dbf1069009256ea87e870d4fed,"In order to achieve constant time for all operations, we would need to use a doubly-linked list. In order to add a new link, we would set the last link's next pointer to point at the new link and the new link's previous point to point at the last link and increment the size of the list. To remove a link, we set head to point to the second item from the front and delete the first link and decrement the size of the list.",4.0,69
20370,20370,24615,0a1930b4d16e62ac7ee353c6144c568d9ee6c791d0d3632d3ce78fd24bb2c65d328c4924d6cafd1daed9790efaefb16fe2a520125cf9396ef372146945ae0496,"To implement a queue using a linked list, using a singly linked list would be efficient because a tail pointer can be implemented and used to ensure constant time. In this way ahead pointer allows constant time for the pop_front function and a tail pointer allows constant time for the push_back function because we do not have to traverse through the list. To get the size function working at a constant time, store the tail and size variable and increment and decrement each time you add.",9.0,69
20371,20371,24616,2238995f0ead9a3412ecc8b42340b20d5862bf47d5493b0c9fbe94b4e46ffb57c2cf52b4dd296cee7b6850d8a44e160d6bd1d96e80ab144e928044e44043acc6,implement using a doubly-linked list. ,2.0,69
20372,20372,24617,8f3267fb35d28eb10e3fc9fcbb0f22bf91f2506cc5526c9b2d0ca2807bf6f55a3324c012d8567781f2f103a5869506dd55924327b0937c914d8880e993d33ca9,"I will just use a single link list. Because it has all the operations that I will need such as pop_front() to remove at the end, at begin() at end() to return reference to first and last item and pop_back() to add at the back.

 ",0.0,69
20373,20373,24618,5cd0a202ef51535fb2cf79db8f13b432c752afb35952cb0416813c6c757163698e13f6f62bd6292909baa9745f2197e7ed5a1f16eebc10eb62867568861dbf00,"For a linked list to have operations that perform at constant time, we would need that the links point in both directions. This way we could traverse from the back or from the front of the list, making push and pop operations as well as back, front and size operations constant time. The type of linked list needed for this strategy is a Doubly Linked list where the links point on both directions  and there exists a tail pointer.",9.0,69
20374,20374,24619,912a17c5532a85cc610facff6c98d42b64fb259b767c809567c65cce318eb3dc8f21bcbe5e653de87fe40d2502ab66869bc553e63fc3a1d7697be613c3b49a69,"Using a Doubly Linked List as a container to implement a queue will yield constant time for all operators. 

When the enQueue() operation is called, it would take constant time on the doubly linked list. Since the the link the tail is pointing to, it's next pointer would need to be updated to the temporary pointer pointing to new Link, and the current Link's previous pointer would need to be updated to the tail itself, then the tail pointer should point to this temporary link and the number of items in the list should be incremented by 1. This whole process takes O(1) time and so the enQueue() operation would take O(1) time.

When the deQueue() operation is called, it would take constant time on the doubly linked list, since the the link the head is pointing to would need to be updated head's next pointer, and the the number of items in the list should be decremented by 1. This whole process takes O(1) time and so the enQueue() operation would also take O(1) time.

The front() operation would take O(1) time since we would just return what the head pointer is pointing to. 

The size() operation would take O(1) time since it returns the size of the doubly linked list.",9.0,69
20375,20375,24620,7f5c90bc96b8c221313ac508a43f033a9cfd125b9a640028ec5de2c16d24018446de1823b9e0fbe3c2dc3484e86b2c9f0b03562cf165d778f49b41194d7ad86b,We can implement the queue with a linked list that has a back pointer. Push function will take constant time because the back pointer has reference to the last item and all the other functions take constant time,2.0,69
20376,20376,24621,c33667ae11b7bded2337c08d116fa497bbbd12dbb6b1affa7fb94c650c68ba165865aab5e81895db475a23ff725c4bc69da22573104a9522dcaf9138fd9b447c,"A linked list data structure can be used for this strategy because with a linked list data structure you can have a infinite amount of number values and therefore the size of the queue doesnt need to be stated in the beginning,   ",0.0,69
20377,20377,24622,6accb08d7786944c71cd9b921787862856d4a3c42592fbffde311b7d0b92a8f983d0c4f430c2af6d29dc0b77bc121c3af33f1ea64f2b5de47c11c3122369896f,The type of linked list we would need to implement is a doubly-linked list. I would need to have a head and a tail pointer and a variable n that stores the number of items. The head pointer would point to the head of the next link (if we have more than one list) and the tail pointer would point to the tail of the previous link. This would allow all the operations to be implemented in constant O(1) time.,8.0,69
20378,20378,24623,92791654d3cd52922c5b338b34156b28fe55a4ccee1e7fc5905b97888cf317c2fcae873ea940af535130a211df4483d7fb93e8718b1976f9cc9aa146daf834aa,"I use a doubly linked list...

when you call a push, you're just adding a node to the list and that process is constant because you're just changing the tail pointers - next and previous pointers

The pop function is also constant as it just removes the first element and updates the head pointer to point at the second element

Size function is constant because it just returns the amount of items in the queue.

Front is also constant because it just returns what the head pointer is pointing to.",9.0,69
20379,20379,24624,482f7dae015b4c467d12506c33e2fe66aeff1ddddb85f2c9bce0e0756918b84a46072cd434d5bf20b674533a59b9c793d9d747268246eec497aed1c0f31a1c3c,"We would implement a doubly-linked list, having a head and tail pointer, we would have a linked list where the head points to a link and that link points to another link till we have a tail pointer, it will also point in the reverse way and point back to where it is pointing to. This will speed up any operations we have to do to an O(1) time.

For us to have a doubly-linked list we will need two pointers per node which will point forward and backward.",9.0,69
20380,20380,24625,2639eb56a1989682f1b8fb8c5a3437ea6a5d663be094f02f4aaae47dc57a1af7165cfaae33d61d670e26c96083744d494e42187a468df938459fc0c70030a175,We would use a doubly linked list to implement a queue where all the operations are constant time. We would implement this by using a tail and a head pointer. Since we have access to the front and the back of the list. This will allow us to easily use the Push back and Pop front since we have access to the front and the back making it constant time since we don't have to iterate through the list to go to the element at the back. Front will be constant time because we have access to the front element without iterating through the list. since a doubly linked list always keeps track of the number of items in the list it makes finding the size constant.,9.0,69
20381,20381,24626,5b79e321acf32f26a1c6cc9091fa349a8baa70385c6fb736e55b942fea1901b561d1f53857749ead207a2933e580c9dfc66c9af868e9b035d1dff322ef7cd5be,"In order to implement a queue using a linked list that achieves constant time we could implement it using a doubly linked list .We use the front of the list as the front of queue and back of the list as the back of the queue.
With a doubly linked list we  have the head pointer , tail pointer, next and prev pointers and n items to store the number of items in it .

To push we just do data.push_back and the no of items will be incremented  . This will take constant time as the push back function of a doubly linked list takes constant time

To pop the first item in queue we do data.pop_front  and the no. of items will be decremented .This will take constant time as the pop front function of a doubly linked list takes constant time.

for the size we would return data.size().This will take constant time as the size  function of a doubly linked list takes constant time.

for the peek function we return data.front().This will take constant time as the front  function of a doubly linked list takes constant time.",9.0,69
20382,20382,24627,1d469feec8dabc8efe190b91bf2431897a77efbd16b2d85bdc6124d89beaeb95e4c3d1758db03e27ba5dac6295ff2b30f3eaaa927d0748ab45ecd18c4991abfb,"I would use a double linked list

for empty i will look if the linked list head points to null if it does then the queue is true if not then false

for size of the queue use size function of the list 

dequeue use pop_front 

enqueue use push_back 

front we return the element that the head is pointing to

back we return the element pointed to by the tail ",7.0,69
20383,20383,24628,d7dfb51332e1c950aa433a238f3273834b82e31a54a773c512e9c88094b5b27c10ba7527d092402ee28c450551c97d4efc1d9a6fab4f18a9a6df9f32cd052165,"to add at the back of the tail we would use data.push_back implemented as:

tmp=new link(v);

tail->nest=tmp;

tmp->prev=tail;

tail=tmp;

to remove from the front/head we would usedat.pop_front implemented as:

tmp=head;

head=head->next;

delete tmp;

n--

the type we'd use is a doubly linked list",9.0,69
20384,20384,24629,6ce5c22e2014cf62c3f9857f1a5d029cd8403915d5de52ffef745d92a330418a129b81b3d1fc019ceb103f7414cb06b86a44ab05670ba63e692007c026c9822e,"Need a Doubly Linked List

add to the back when pushing O(1)

remove from the front when popping O(1)",5.0,69
20385,20385,24630,d2c94c0dca7decb41292af9de73a32afa110cab818c0e296b000bfe9dd7b6bf221a0332e01f53ce869a1f4affd4abbea90b7e61d9504a5178a430b94bbde20af,"You would use a doubly linked list with a head and tail pointer. To pop (delete) from the front, make a temp pointer equal to the head pointer, point the head pointer to the next link from temp, and then delete the temp link.

To push (add) to the back, make a link, point the existing tail pointer to the new link, and then make the tail pointer point to the new link.

With a doubly linked list, the size() function will be constant time.  ",9.0,69
20386,20386,24631,9b486d212bcbfc98bcb7006334a7bd057c017b3b5d6ddec828a1e7c71b279d57abf5933826cc5cd40f31ce09e30273c03c034afd55ad69a350c76adfabdffc7c,"A doubly linked list has this benefit as for both pushing to the back or front, the time is constant because of both a head and tail as well as pointers allowing for traversal in either direction of the list. For the same reason popping, peeking and finding the size will also have constant time. ",9.0,69
20387,20387,24632,3065fd9b5327500ccd01f2dbaaeb4517f874d19bdf3e90a9e58fc3902fdfcf795607548f33b16d677a8bfdbfbec8dfd27757ca207e98b81490a4df15aab3c3f5,"A singly linked list with a tail , keeping track of the head and tail. We can  insert new item using the tail by letting the tail pointer point to the new list and update tail next to null. Then push back ,pop front, front will be constant time O(1) and if we store the tail and the size variable then we can increment and decrement so we'll be able reduce it to constant time O(1).",7.0,69
20388,20388,24633,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,"for all the operations to work in constant item we would need to use a tail pointer and add items at the back of the list using the tail pointer when we enqueue

we would need to remove from the front of the list when we dequeue and the type of  list to use for this strategy is the doubly linked list ",5.0,69
20389,20389,24634,c879e65c8f9657768bbf6800906a28bff217c7ef9063d46acfccc25071a9fc3aef2ccd29821fdc92e96d2f98ca66aa74a3fa2a8f0df86509064e53b0fb9b54bc,"You could use a doubly linked list.

Push_back: You would implement the queues push_back function using the doubly linked lists push_back function, which will add an item to the back of the linked list and update the tail pointer accordingly.

Pop_front: You would implement the queues pop-front function using the doubly linked list's pop_front function, which will remove an item from the front of the queue and update the head pointer accordingly.

Front: You would use the doubly linked list's front function which would return a reference to the first item in the queue.

Size: You would use the doubly linked list's size function, which would return the value of the counter that counted the number of items in the queue.

All of these will be O(1)",9.0,69
20390,20390,24635,e128973184d15ac7a750b822c9d3b3fe1c0b4d5c9ec9968806c119de2807128c5380243007b2944cf3a301c3270578e76aaa068c636326951a9eea7851758fdf,"To implement this queue I would use Double Linked List 

To implement the operation in constant time I make sure of that my queue have head and tail, for easy access of the elements in it .Then we put our operational functions such as push_back in order to push the data/add the data then pop_front in order to remove elements and place in peek and size in order to return the data ",9.0,69
20391,20391,24636,571f4b857c687d9d563078992ce0d593248d2c9f52df5afb071f8e300cfd009d7831df6cd94d1fdf3131324af503b103a8881171137c2ca59df7ead36faf3f74,"You would need a doubly linked list.

The head would be the front of the list and the tail would be the back of the list

You should a have variable to store the number of items in the list. When calling size() it should return the variable that stores the number of items

To push the the back all you would need to do is use the push_back()function

To pop from the front all you would need to do is the pop_front() function

To see whats at the front of the queue, you need to return head->value

To see if the queue is empty all you need to do is return size() == 0 ",9.0,69
20392,20392,24637,936024d8e9328998a220b77c48098f57a0d619263f7c2ad0ac4157dfe9370e11abee7f579d65a28c46224757256e636c01fe798d4c5eb4d7e1574b7de8511fbf,Create a singly linkedlist that has a headpointer and a tailpointer .We would add values to the back (push_back) and we can remove values from the front (pop_front). Since there is a tailpointer we don't have to traverse from the head to the last value we can just push_back values at the tail. We should also save the size variable to ensure we have a constant time for all functions. The strategy is a Singly LinkedList with a tailpointer.,9.0,69
20393,20393,24638,5ad20b3b420c21e1fc2861df4f4257210672d867b8a024855b258388d20148643f1a94c77f0aa2d4b47f8fba4b85741287207442ff519080915f15fdfd0e21b1,"We can use a doubly linked list where the beginning of the linked list is the front of the queue and the end of the linked list is the back of the queue to implement a queue with all of its operations being of constant time.

To push back (enqueue) in constant time, we can create a new link and add it to the back in constant time by using the tail pointer. 

To dequeue in constant time, we can use a temporary pointer to point at the link at the front, move the head to the next link and delete the link that the temporary link.
Doubly linked lists keep track of the number of items in them so we can implement the size function by returning the value stored in that variable.

the top() function can be implemented in constant time by returning the value stored in the link that the head points to.",9.0,69
20394,20394,24639,b33d5ec88a2b0658fe1e9d5e59ea13311491654c12fd5b13cd9e270e44a1a125acca1c56bf136302c950a009d693b09accad74b98f9de4d82034269663959b89,I would implement a doubly linked list. The doubly linked list has both a head and a tail. To add items to the back of the queue I would add an item to the tail.  To remove an item from the front of the queue I would remove an item from the head.,9.0,69
20395,20395,24640,4d5583055b5cf0ef4bd7f80832ec9b8940eedb6261741378493c7c1e768d88d15f96d3b8d5850288f3731056d59b3dbe1878b8c16bbb307054b4401de38adc38,"A doubly linked list is needed to achieve constant time for all operations. 

You would also need a variable to store the amount of items in the list in order to achieve constant time for the size operation.

For pushing an item to the back of the list we would set up a new link using a temp pointer and setting the tail pointer to get the last link to point to the new link and making the new link point to the previous link and then setting the tail to point to the last link which is the new link.

To pop an item from the front of the queue you would set a temporary pointer to point to the head and then setting the head to point to the next link in the list. Then we free up memory by deleting the temporary pointer. Then you would decrease the variable that holds the number of items in the list.

To get the front item I would just call the head pointer also achieving constant time.",9.0,69
20396,20396,24641,c2e3a17d6cc0156e335ca9215e55053ddbc80682871f8957ca1d1b73d39dbe24e0950e6728cd273bbd1fbaac4e9fc1f8fc1eeb009c8b2565447f198e841deab0,I would use a doubly linked list,2.0,69
20397,20397,24642,798235659bb9174e71b3ff61763ec292691ece6655d9ff85d1fbb65ede38be3c46ca62a6d523bf01e0f519090370eeadd560efded9ef16231507d4492e919473,To implement a linked a doubly linked list that has node that keep the pointer to the previous and next values.The previous and next would make pushing and popping a constant time complexity operations. Size and front would also be constant time operations. A doubly linked list would be the linked list that would be used.,9.0,69
20398,20398,24643,a3989cc4476b1bbce9e79b34c3f0337ca13c9717a610fbe24ad51e9bdb052f2d445313904842463b1a859cd4d281ce72b5f85b0423f33b62cab82318e4116232,"I would first create a class, then define all my functions. And then create a doubly linked list. Type of linked list we need for this strategy is doubly linked list.",2.0,69
20399,20399,24644,20820f051ab9e7b5dde112869be67e2e49734267d017f30c8e3086343a31575407d74708ebc5d385e1b1a34dd7dd81fa4425af4e6cb2bbdba32928c419b4a8da,"- create singly linked list with head & tail pointer

-we add the first element at the head and then continue add elements towards the tail with last element being the tail (we use push_back function and basically add to the back of the queue)

- we remove elements from the front of the queue using pop_front function

- we dont need to traverse to the last element since we have a tail pointer

- ensure you save the size of linked list to ensure that the size function will be constant time

- the strategy was a singly linked list with a tail pointer ",9.0,69
20400,20400,24645,88e4f79f72acbc7dd458837989d41695a9b36b9c96cdb3ba66c7b90921d69150d478abfb1ed6fc7e89594f6b4ccd5c2a5625a644a888136358b59b68dc7b8205,"you would use a singly linked list. Nodes are connected in a chain by links and the head of the list is the front of the queue , the tail is the rear of the queue.",7.0,69
20401,20401,24646,c2c29b17660ccaffde93650bbaabbeca722766be9c7f4c24079c9b3711df082352b0623847e9af19ff96cf4f2d45d0bd1cd360dd8fa3d9a37f5041dcc804b8b1,I would use a circular linked list to implement the queue. I would use the front of the linked list as the front of  queue. Pushing items to the front of the linked list will take a constant time.,0.0,69
20402,20402,24647,854bde56afcd2bd2c31fbe39384369ef7c0ac613a004a4b239a7a7d08872fa336ab049f8f45358abb5e93ca8dfc33e8954bf246487197e2265435ed3c204826b,"I would need a doubly linked list to implement the queue. The enqueue function would push an item to the back of the list, this would take O(1) time since push_back of a doubly linked list takes O(1) time . The dequeue function calls the pop_front of the list which removes the front item of the list, this also takes O(1) time . The size , empty and front functions also takes O(1) time since there is no transversal of the list.",9.0,69
20403,20403,24648,6a787853e1f57b2d3b0d74f5ae62b179adb7413dd588b37a8f7082bdd65e471590c4f39498c937e59e73bcf33962fea95df098117d05b73852f11db547a99d9b,"-a linked list that uses constant time is a doubly linked list.

-The list would be able to move both forward and backwards so if we want to push back we simply go straight to the back and add an item without the need to transverse through the whole list.

-also if we want to pop an item we go to the front of the list and remove the item and update the header to point to the second item making it the front of the queue.",9.0,69
20404,20404,24649,9082e5ab0ae09b23b5e0275a763493886db0b7f721520ca423ce3577e6b6ec09537f5d0b22aac121f7604a542a413dd81640198a15212f5aa5403c721b42c11e,"For this a Doubly linked list is needed, the head and tail pointers keep track or rather addresses of both ends of the data structure and hence make it easier and efficient to push and pop, to implement the queue I would create a class with functions on public, the functions being dequeue, size, enqueue and front. The head will be considered the front of the queue hence front returns the value at the head, for dequeue I would make a temporary pointer that points to the head and update head to point to the next object then after delete the temporary pointer, for enqueue I would make a new link with the value we want to push then make a temporary pointer that points to the tail and update tail to point to the new link, make tail->prev point to the tail then after delete the temporary pointer, for size I would return the integer value of the number of items in the list from head to tail which can be done by traversing through the list.",8.0,69
20405,20405,24650,2dd5e2f41652664c7010e9c75b107a0a619a9b54063e68bd2c6a9b76a1fcac07a9bceac7ca7bf3cdecc54ef1490301f90259c5d418e4b888c5d3f0477b59ef3c,"Use a doubly linked list with both a head pointer and a tail pointer, allowing you to traverse the list quickly in both directions and insert or remove as needed.",3.0,69
20406,20406,24651,2f2bbc70f8136ca3b18457b652aa1d5317919459278da63d7273a5c4e29eded00275f14d0a5826a3efa0a4d6a86ce51a6129f3ba53f25a66bc7e4755b291485f,"youd need a doubly linked list, and wed make a function, push and pop,and then in inside those functions you would use data.push_back and data.push_front. This will also make the push and pop function constant, and then generally the front and size function are constant.",9.0,69
20407,20407,24652,db0698cd03866d48da0c9cab1c327e767c6fb2c70ab318867db7094af47e41c16fc1528b63425d8d7a1a4e5cc071eef840fd0e4c5113866d0139015edb52f238,Define a node structure with 2 members data and next. Define 2 node pointers front and rear then set both to null. ,0.0,69
20408,20408,24653,c6919e466976b48c2f7b3823eb90c377fa8e67b3a290bcb3ab3a7c56083193c911bc05ef76e986e61a0a361e9ed5a7fec55840ba6afe1022bc97e18b5eabbeef," A link list with head tail and stores number of times this would be  the doubly linked list. this works becase we can add at the back at constant time using push and we can remove from the front using pop front.

tail->next = new link.

and 

temppointer->prev=tail

and lastly

tail=tmp.",9.0,69
20409,20409,24654,c66e418bde3624775409174d439f8c7a104e4c741d28aa9a32d3dff6f27ee3fc70a6b61ca496d004e7124e5afeca9e6a74cf0455c76878d506978153185a8efb,"A singly linked list with a tail pointer that stores the size of the queue. The front of the queue will be at the front of the list and the back of the queue will be at the back of the list. The pop_front function will be done in O(1) time since the head pointer allows one to remove immediately from the front of the list. Due to the tail pointer, the push_back function will also be done in O(1) time as the tail pointer allows one to add immediately to the back of the list. Since the size is stored in the class, calling an integer will take O(1) time as well. ",9.0,69
20410,20410,24655,c0b5209a0b10c8dcfcb6cf4b7392c868a8a0f46868d7ead3603a66886d165a2ffbe1f975845aa3417da4caad2884f87961b388a20ee21c66a3e2d9cec38ed42f,you would implement a doubly linked list which has both a head and a tail pointer allowing to enqueue and dequeue in constant time as you can freely acces both the front and the back of the queue in O(1) time,9.0,69
20411,20411,24656,5dcf09a63d08f8fcf484a27b8188aca8e05117584de8c4c8e580d2681056a972e8271fbb1e9e69a616d3a8d13ef9009ce7fbd4e4c680807f0aa62ce637934a9e,"We would need to use a doubly linked list with a tail pointer. This will keeps track of the number of items (n), The head pointer (head) , next pointer(next) and the previous pointer (prev)

Size :

we would return the value ,n, as we kept track of it .

Front :

we would return the element which the head pointer is pointing towards. 

Push :

v is the value we are adding to the queue 

tmp= new Link(v)

tail->next=tmp

tmp->prev=tail

n++

Pop:

tmp=head

head=head->next

delete tmp

n--",9.0,69
20412,20412,24657,49da1899a556de47c2ec5c0aee3103579dd1b8665560fbd2cb26362bd85bf2a291f8280bc21e1f838e024dcd8764915c6b880be08a2f6c8f404d85517511406c,"we would use a doubly linked list. for pushing to the back, we use tail->next and add a new link, also using [link]->prev and setting it to the tail, finally updating the tail to be said new link. for popping, we would move the head forward, via a temporary link and head = head-> next and then deleting that link. we would then decrement the number of elements by one.",9.0,69
20413,20413,24658,83c5e0cccc2c84d6aa6c84996703c9788a4c77ad197dc9cbe544f356daab1002c8cb4669771a7a17cb1f5a0ca37aa675d40cb959b05635bc4844ce29a466fa7e,"To implement a queue using a linked list, it is simply queue<Thing, list<Thing>> q1 where Thing is the type of the objects the queue is storing. For this strategy, a singly linked list would be used.",2.0,69
20414,20414,24659,ab50392a96c4c3025a5963370825a15241a679c25a4771a2853db32d86a5e0a874ed37e6f390b06f6b3a0755f5bc0190ec94f83a3fd5bf730ba4d34a04efb6d1,"you would use a doubly linked list.

functions: push, pop, size and front will have O(1) time",2.0,69
20415,20415,24660,f1ba85bcb3cb35dd3a5763fa5946a3ff7df7d0bf7beb3182d0ecb801d8abdf353d4eeb7909c0cc4e94c0d221fea7a7c70e57bb1e1c70aaf71f4a7a0e8fe5269d,"The type of list that would be most appropriate for a queue where all the operations are in constant time would be a doubly linked list. Using a doubly linked list while having a head and tail pointer as well as a variable storing the number of items in the list. Adding to the back of the list is made simpler with the tail pointer, which can be made to point to a new link in the list added to the back. This operation will take constant time as we don't have to traverse the entire list. Similarly, to remove the first link, a temp could be pointed to the first item. The head pointer can then be pointed to the next item after the first and the temp can then be deleted. This also takes constant time. The front can be easily returned in constant time and the variable that is updated with number of elements can also be easily returned in constant time.",9.0,69
20416,20416,24661,e81419dfc1d9569cd33a892060afd65b53683380b098be177940b37177a69388dbc26f4b88ae9117e614069eb6d29407e325e18a19fd38be90fa494f6adff772,"To implement a queue with all operation in constant time with a linked list we would have to use a Doubly Linked List where each link has a next and prev pointer. A head and tail pointer also exist and n variable to store the amount of links in our structure. So to push all we have to do is have to create a new link (temp = new Link(v)) then make tail.next = temp and temp.prev = tail this is done to link the new link to the previous one and the previous link to the new link in a 2 way link. Then we update the tail to point to the last link (tail = temp), increment the amount of links (n++); Now to pop all we do is create temp to point to the head (temp = head); then make head point to the next link (head = head.next) then delete the old link from memory (delete temp) and decrease amount of links stored (n--);  The size is tracked by the doubly linked list so it returns it in O(1), the empty is just is size == 0 so O(1); and the front we just return the value to which the head points to (head.value()) so O(1). That is how we use a Doubly Linked List to implement a queue and all its operations in constant time. ",9.0,69
20417,20417,24662,d098e277cb3df3b25c9e42904322dbd46a16b60a20b139d8066f16584a8bb599eddc05cac924f310971f38fb613ad7daea71749bb268694cb7e0d2fdf74a35a0,"We could use a doubly linked list with a tail pointer to implement a queue that will take O(1) time for every operation om the queue. The doubly linked list will have prev, value and next.

For the size, we achieve constant time ie O(1) time by recording the number of items in the list. For pop_front, we achieve O(1) time by assigning a new pointer (say temp) to the head pointer (ie temp= head); and then we say head -> next = the next link (which will make the head pointer point to the next link), and then we finally delete the temp pointer. For push_back to take O(1) time, we would use a new pointer (say temp) and then make it point to the same link as the tail ->next pointer; then temp-> prev should be equal to the tail pointer and finally the tail pointer should be equal to the temp pointer.

For front to take O(1) time, we just return the the value in the first link of the linked list, we recall that the head pointer always points to the first link, hence this will be fairly easy to do",9.0,69
20418,20418,24663,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,Use a singly linked list. Push by inserting an element at the back of the list. Pop by deleting the element at the front of the list.,5.0,69
20419,20419,24664,a0052d1186f3fa53f67763ddf5dc1148fc540657d42f0891ff3ac99ce8c9f5c8c2cc81fa44f5583e909b3bdda1a0f1e6a21067a67ce2ede8b9d60f7eef57955f,"I would use a double linked list.
It does not really matter but lets say the head of the list is the front of the queue. 

To push, simply use the tail pointer to get last element and add an element that the last element points to O(1)

To pop Simply use the head pointer to access the first element and get the next element and set the tail to the second one O(1)

The size would be stored thus accessing it is just O(1)

To get front would be just following Head thus O(1)",9.0,69
20420,20420,24665,e5714a4c20e7bdae287b7c08ee230173a746342e508a1fdf6f9b0ca3985863c9a9c50fab8cf85194e61c4743030f16659c52ffd068494fd5d94fc6ea4ec382de,"In the linked queue,each node of the queue consist of two parts i.e,data part and the link part.Each element of the queue points tyo its immediate next element in the memory.In the linked queue there are two pointers maintained in the memory i.e front pointer and rear pointer.The front pointer contains the adress of the last element of the queue.Insertions and deletions are perfomed at rear and front end respectively.If front and rear both are null,it indicates that the queue is empty .",0.0,69
20421,20421,24666,0ddebbd83df885f86ba1c96720608778be815c854a9f153df224b96b22cf260eb651e6e1d04778d3c06f6de0d3c75049a5f3bb4b6575599d6f50e21a7074d16e,"I would have to use a linked list that has a tail and that can keep track of the previous node, thus the ideal type of linked list I would use is a doubly linked list",2.0,69
20422,20422,24667,1b575ce85f9fe9d462e1de73f4e66ff04c921a768d297956a2d166b33e02a5691d14de4e07fdb716975b3003397dd6ecfd657024c0a233117dfee4b6480ebdcd,"I will need a Doubly Linked List

I will implement the following:

push -> I will create another link assigned by temp and link it by using tail->next pointer as well as updating the tail to point to the last link.

Complexity -> O(1)

pop -> I will make use of tmp variable to point to the second link, remove the first item and update the head to point to the new first link

Complexity -> O(1)

front -> I will just return the value at the head pointer

Complexity -> O(1)

size -> I will make use of the n_items to return the size of the queue when needed.

Complexity -> O(1)",9.0,69
20423,20423,24668,ab943cfa0d926aa21911a9961743ce4779859ba20a4ac4e15e75033134ef20f2d090435e99a19a4b2beb23e354a8983d0355213a926be357504dc13138c83605,"For this a Doubly linked list is required, the head and tail pointers keep track or rather the address of both ends of the data and it makes it simple and efficient to push and pop, to implement the que I will make a class with functions on public, the functions being dequeue, size, enqueue and front. The head will be considered the front of the que hence front returns the value at the head, for dequeue i will make a temporary pointer that points to the head and update the head to point to the next object thereafter deletes the temporary pointer, for enqueue I will create a link a new link with the value I want to push then create a temporary pointer that points to the tail and update tail to point to the new link thereafter delete the temporary pointer, for the size I return the integer of the number of items in the list from head to tail which can be achieved by transversing through the list.",9.0,69
20424,20424,24669,a483d97f2f6f4b566a91dffee7b0dc51b69866d7a50c6e53308e166eaac8f5373cd9dfbf9a10c25bd5d41a415c716306b0d1e020a1acf8282aad769edfdcc9c4,"We would need a doubly linked list for this, the head and tail help in the complexity as they keep track of both sides of the structure. To implement the queue I would make a struct as everything inside is public unless stated otherwise, the functions in the struct would then be push(), pop(), peek() and size which would return an integer value indicating the number of elements in the list, the head being the front of the queue, for popping I would make a temporary pointer pointing to the head then update the head to point to the next link then after that delete the temporary pointer, similarly for pushing I would make a link with the value needed to be pushed then make a temporary pointer pointing to the tail, after that update the tail to the new added link then make tail->prev point to the tail then of course delete the temporary pointer. For peek, the function would just return a reference to the front element, the head.",9.0,69
20425,20425,24670,bef6837a7fdfe1da5fe1293f44c76b96d3b8dcc796faa186ced378d3238a30c359695c10ba31e008e6450186def6f4c6da86e1819e6310ac4629db0e4ae2f7c4,"What should be put in the memory of a linked list is two pointers, a front and rear pointer. Each pointer will hold an address for the starting and end point and this is how the queue can be implemented. A singly linked list can be used for this.",0.0,69
20426,20426,24671,a2e71f759079413d4f87ec8f397142f2bf7f364e3ac1403027655c606e40a1106c0bace5c922e3aa206700cf3aa5120aeba8f93363e62c778029029dcc2335f1,"This would be a doubly linked list. 

For the front operation it is constant ,o(1), as the list is always keeping track through the head of the list. 

To enqueue (push_back()) items  one would need to only make a temp variable as the tail of the list keeps track of the back of the list and update the tail variable therefore not needing to traverse the list resulting in o(1) time.

To dequeue a temp variable would be created storing the current head function, the head reassigned to the next pointer and temp would delete the value of the old head hence there is no looping or traversing therefore o(1) time. ",9.0,69
20427,20427,24672,df0d62df6145f98b9d8d85662b958119c20c6015becf9534b762b6d6c7c046d872ff37d4ccc77da23e1570c5a7712fc862bda45087171a56e4c5cfc3750e2ad2,"1) a double link list

2) keep track of the size

Functions

	* Push_back O(1)
	* Pop_front O(1)
	* Size O(1)
	* Peek or front O(1)",9.0,69
20428,20428,24673,ec66e4473040e8ee3556fe295a682aef55293bdc440d5beebc8fb799f1964c0abc0afc761e0c9e5b3dec6cb5d26467ba51d5e312925807725d0b86097bb74bce,"You could use a singly linked list with a tail and have a variable which tracks size and updates whenever enqueueing or dequeueing. Enqueueing is constant time with a tail pointer as you do not need to traverse, and dequeueing is constant time as you have the head pointer and do not need to traverse to delete it.",9.0,69
20429,20429,24674,e1db971413a3e8370e48a08bd90e6c532854614ec97bf2846a8b6f64d7d2d64fceb404c5b40a925c2c496078dab9556b9aedc866e91bea3a7a6a8dc8cc19eb5b,"The pop(), front(), size() and push functions can all occur in constant O(1) time using a doubly linked list. A doubly linked list contains pointers to the next and previous item or node, as well as a head and tail pointer (which points to the front and back of the list, respectively). Since a queue only allows for adding items to the back of the list and removing items from the front of the list, there is no need to keep track of the items or nodes after the front item and before the back item. Therefore, removing from the front only requires a pointer that points to the first item so that the first item can be deleted, and the head pointer be updated to the next item in the list, this can be done in constant O(1) time. 

In order to add to the back of the list, the tail pointer can be used. A new node is created, the last item's ""next"" pointer points to the new node, the new node's ""previous"" pointer points to the node that tail points to and then the tail pointer is updated to point to the new node. This can be done in constant O(1) time. 

The front() operation can return the value at the front of the list using the head pointer, this can be done in constant time as it only requires the dereferencing of the head pointer.

The size() operation is implemented by keeping track of the number of items in the list, by incrementing when items are added, and decrementing when items are removed. This can be achieved in constant time.",9.0,69
20430,20430,24675,f7abd04c97a647b1e757bccd7284173478fbf8f28e28e3102567ab244a63fd5c67a5e953a932ab1f774cb73ace52fda53cdbbded4668ee4660e933d867e532bd,"_I could implement the queue by making the front of the list correspond to the front of the queue and the back of the list as the back of the queue. I would need a Singly Linked List with a tail pointer to implement this strategy as all the important functions of the queue (dequeue,,enqueue,,front and size) will all be O(1)._",7.0,69
20431,20431,24676,910daf6bb90bfaca5b8329327dbb6876d9a383514e01fe819f79abb1a27019ac7b7555a07d09a61e93831fa5c489e19d607608ea54797f25aad8bd641ed60e55,"We would need to use a doubly-linked list with a head and a tail pointer. To Enqueue and item we would need to use temp to create the new link, then make the tail pointers next point to tmp, then make tmps previous pointer point to the tail and then finally delete tmp. To Dequeue and item we would need to make tmp equal to head, then make head point to next and finally delete temp.",9.0,69
20432,20432,24677,4541bddfe14df82661aaba793d25bb038432ba934014876821269e81b4029af8b6064a54828f0509d14ee3f303c32ee014b7221977ad133bace3b01a694e694c,"To implement a queue using a linked list with constant time to enque we would add to the back of our list -to do this we would be using our tail pointer. Then when we deque we would remove from the front. Thus the type of linked list we would be using for this strategy is the tail pointer.

 would use a tail pointer. This is because ",2.0,69
20433,20433,24678,675e836215b62d793972ecb9d5ace2eaf438e0e5d0d26f496ddc3442ba479da55ac029b8a4555f73c538c50ecac4b04edc042861ca9b743e991c19c46392aa72,"Best option is to use doubly linked list has it provides constant time for every function. It has to include prev, value and next. For size is constant time for recording the number of items stored in a list. For pop-front is is constant time for assigning different pointer (tmp)to the head pointer and then assigning the head pointer to be the next link in the list, the delete the tmp pointer. For push_back as constant time, we apply a different pointer (tmp) as a new link , tail->next which is equal to tmp, tmp->prev which is equal to tail, lastly the tail should be equal to tmp pointer. And for front to be O(1) we return the value in the first link in the list.",9.0,69
20434,20434,24679,16751d82a0250cf90230a736276250ecd4342c2e9097f12ebacee397740771d03e925ee189c3aaacf702dbec6f3610c7e13e7ed44667c2823433286e585becf2,a doubly linked list would be the type of data structure to use in implementing the queue. with the aid of a tail pointer it will allow us to acces the last item and use the push back function at constant time. the first item will have a head pointer which will allow us to use the front function at constant time. empty will be constant time cause we can see if the head pointer is pointing towards anything. pop front from linked list are already  constant time.,9.0,69
20435,20435,24680,a7fd82a5660b8b1764aaf3905cfa33ae20bea31c698c90051afd8871bc86a6b25112ca62d2256ae4d96fc9b6c6488d5d0378685fcf8bb4b9bc5b8b918494fd4f,"We can use a doubly- linked list to implement a queue. Since we the operations to run at constant time, we can use a tail pointer. For pop_front and push_back it will be constant because we have a pointer to the first and last links. Empty will be constant because we can see if the head pointer is pointing at anything. Back and front will also be constant because we have pointers to those too. ",9.0,69
20436,20436,24681,8ccaa62cbbe76ea20aad42f0abeb4aea6b057f35352db9aef1c4c8bb791949070df63d7ca3789507be754a64de8d3383c759c83cb767d9e10e045b387bce8a09,i would implement it using vectors and pointers. nut i will specifically use a singly linked list with a tail to make the operations run in constant time. ,2.0,69
20437,20437,24683,78249ef9b62941992169ea6ab9335b72fe3732b0d62324e87cfd98782c3176ff3a0f6d77d1563959cb064ffef03d777dd5132e65d5820daed930a9e3247d9f38,Implementing a queue using a forward linked list taking the front of the forward linked list as the front of the queue and the back of the forward linked list as the back of the queue.To Push_back we transverse to the back of the linked link and add to the back this takes linear time complexity.To pop_front we make a temporary link that points to the link where the head is pointing and set head equal to head.next and delete the temporary link to avoid memory leak.Pop_front is constant time.If we want the front we say head.value and its constant time complexity.For the size we have to traverse through the forward list and its linear time complexity ,3.0,69
20438,20438,24684,d34efe98a2513ac08acc6faef18dfc38310a4938c3e2400c3ec9b606c14e0455c45534357347e63004ac9d2c3c1e1d7805afa99ff5f4d271c3dc0f7c2153d7d4,"* The type of the linked list list suitable for this queue would be the Doubly Linked List
	* My doubly linked list will have to have the tail and the head pointers
	* Our links also will need to have two pointers, prev and next.
	* We set next to point to the next link and prev to point to the previous link
	* Then our important functions will all be of O(1) time",9.0,69
20439,20439,24686,6d04032d059678dcb346209e5f60e18a44d0c551ad3d7c0e551f1957033a386ffc9828dc7e1374b35e8828c43ed8d61ae22f6c2de063b8779cad31efc30f066d,You'd need a doubly linked list for this strategy. We would then create the functions push and pop. Ins the push function would be data.push_back and inside the pop function would be data.push_front. This would make the time complexity of both functions run at constant time and in a doubly linked list both front and size run at constant time.,9.0,69
20440,20440,24687,ea2a1bfcbe729f7621c917f77c54d68d14594e336635f36baf52750af4fc628657adce12683b4083425f0f9b883a0f335d02fe57cab5815e5cb77320840dd672,We would need to use a doubly linked list - we make the head point to the node then make the tail point back to the same node. To add a new element we make a temporary pointer equal to a new link and then we update tail to equal to the temporary pointer. We pop by making temporary equal to head then head equal to the next node after head and then we can simply delete the temporary link. And everything else will be in constant time including size() .,9.0,69
20441,20441,24688,5d0d60194fd1b05c809499adb963afbac0ab800c552d7666ea7779f6183d17839f234e9ecee3ed11e567d9e2e5d5f869bc08bd2cc74894f9ca624282e8055b10,"To implement a queue using a linked list where all the operations are constant time, we would use a DOUBLY LINKED LIST WITH A TAIL POINTER

	* void push(T value) or enqueue(T value) -  would be O(1) as we would have a tail pointer pointing to the back of the Linked List, removing the need of traversing, which is O(n) or linear, and allows us to add to the back of the list or queue in a constant, O(1), amount of time as we already know where to add the value to
	* void pop() or void dequeue() - would be O(1) due to the Head pointer which points to the first Link or Node in the Linked List, which makes removing the first item in the Linked List or Queue take constant or O(1) time
	* T& peek() or T& front() - again, due to the head pointer of the Linked List, it is very easy to access the First Link or Node in the Linked List and too so the first value of the Linked List. To return a reference to to first item in a Doubly Linked List takes constant or O(1) time
	* size_t size() - A Doubly Linked List stores the number of items that are in the Linked List. Therefore no traversal is need to determine the size of the Linked List, and returning the number of items in the Linked List takes constant or O(1) time",9.0,69
20442,20442,24689,b9d82cd7c247fea1955a43aaaf5bb439ce7f4f53d3df9728ceb44f0e1b947c368ff1574400183b4d31d82813774edfdb38a1fdb56e3256ef8ab3e682f8c08da1,"The linked list would need to be able to push from the back and pop from the front. A doubly linked list is used. Since it keeps track of a head pointer and tail pointer and the number of items.
It can also traverse from back to front and front to back. One link has a pointer in the front and the back so traversing to get to the back is not needed. Since the number of items are kept track of, the size is also constant since no traversing is needed. All the operations have a constant time. ",9.0,69
20443,20443,24690,a4513e9eefe06c5d06cd544fbaa5db795547b8f01893c660dc4a8e31a77cbc61bded840bbf0b3fd52a94491adbe0a21a3d4396c46fe19d46198e8b7b21695be6,"You would need a doubly linked list to implement a queue where all operations are O(1)

This works because it has a head, tail, stores n number of items, and links point forwards and backwards, which allows for push back and pop front to be O(1) time, and also for Front and Size to be O(1)",5.0,69
20444,20444,24691,d5a3f7d660aa30769e68a7c616a4942c8f05f0c2e034be1b4e61932df724917fd2a406f53a34e25ab412791ed6463a16ef1b087d401683c22430b89ba7a21be9,"You would need a doubly linked list.

By using the tail pointer for the back of the list, this makes your push_back function O(1) as you don't need to traverse.

By using the head pointer for the front of the list, this makes your pop_front function O(1) as you don't need to traverse.

the doubly linked list also helps keep track of the size of the list so you don't need to traverse through the linked  list and count how many there are",6.0,69
20445,20445,24692,5c96945f14d6fc788ed8c6c36dabf314debb1526e588422f61ac844f148e394c747509da6ebf3fac148319b89d19dab295d5360db7c4991b8db71ccf538d7808,"It can be implemented by writing:

queue<Thing, list<Thing>> Q1;

This will create a doubly linked list where all the operations will be at constant time.",2.0,69
20446,20446,24693,9a6d2e6e6e0c1b575d6fd6f9cd31a3d7ef05b9fbb8f9b527d2f24c66326f4e25fb885d747e3511e370820c0e5c65531a52fb8637b76c7b43895037c2420cfc80,"Declare a head pointer that initial points to null. Allocate a new link and let the head pointer point to the new link we can then push back a value and allocate a new link. Let the previous pointer point to the current link.

A singly linked list with a tail will be good for this strategy.",2.0,69
20447,20447,24694,b8ff274cc91e39334247b9673eeb1e1ed2acdbcefc990de9bf2b4226b88349ab6bc97343b39be8aded8a6ab21d1bf5dc3045e9f7596480cb1279270e81abbd58,"Using a double linked list.

size() is constant time as the double linked list keeps track of size.

front(), dequeue and enqueue are also constant time.",9.0,69
20448,20448,24695,6398cd3a19a3d471bc5a210dfd041039aa199f2840055e48507502bec88a8f8eb3f128de790430daa8207ba0fde7dea8a8fb8416bcb584e1bb9e76ef88b1e1f2,"we would use a doubly linked list for this implementation. we would use the data.push_back() function to add to the back of the queue. we would use the data.pop_front() function to remove an item from the queue. the doubly linked list also keeps track of the size of the list which helps us in keeping the size of the queue, and the head pointer will easily be used to get the data at the front of the queue. this is all done in constant time.",9.0,69
20449,20449,24696,b96308b5b954fc4c2086f6faec027fc8299af60a164d99cbdc75a0802d3bb5ac5823699b9e2e5c78a86bbf73886ed3408a16b29a0f7ee6dc90b05a8f2f91fcd5,"In order to implement a queue we would need to use a doubly linked list which has links that contain prev, value and next. 

In order for the push_back operation to be implemented in constant time we would add a new link using the tail pointer. The tail->next should be equal to the new link (curr) that as the value that we want to add to the back of the queue. The curr->prev pointer should be equal to the tail and the tail pointer should be equal to the curr pointer.

In order for the front operation to be O(1) we would need to return the value in the head pointer (head->value).

In order for size to be O(1) we would just need to record the number of items stored in the linked list.

In order for pop-front to be O(1) we would need to use the head pointer. We would assign another pointer (curr) to point to the location where the head pointer is and the assign the head pointer to be head->next. Then finally we would delete the curr pointer which would delete the first link in the linked list. ",7.0,69
20450,20450,24697,252668df997d55b86d753e14db9bb82d9a9ab0f27d714f3256c72a03986a906ffccf1958bf221d3ab998a7770edda41ec2de25393f1d9a62f105684cf09211ed,You would use a singly linked list with a tail pointer to preform operations at a constant time . this can be done by making the tail point to next which will be pointing to the new value and then just make it so that the tail would equal the next pointer which will allow us to have access to the next item so it is easy to push back or pop front a value in constant time.,7.0,69
20451,20451,24698,4f0d170bb113012c8d343271d925a96ef0e199ecdca36f51a1fc99d7e0e8c67fb97155bfa738d3317830adb88f58c316437e0cf62b20c43f4e89ab893b6e7471,"You would need a doubly linked list to implement this queue. I would implement the queue by using/calling the push_back() function to push a given value into a linked list by parameter 

eg. data.push_back(t)           //t is the parameter

- the pop_front() function to pop the element at the front of the list

- the front() function to return the front of doubly the linked list

- the size() function to return the size of the doubly linked list. 

Because it is a doubly linked list this will all take place in constant time.",9.0,69
20452,20452,24699,9b5371bf3d8a67220ea9112f458e092347973d5a590a2ada7f6d386201210567493e4842dd7263535c03e1b4ce797297171327f4cefdbdd79731ace1f4e756bb,"We have a head and tail which link the points forward and backwards.

*push will be just data.push_back where it is constant time O(1)

*popping will be just data.pop_front which also takes O(1).

*size will be constant also as we have the tail pointer.

We Would need a doubly linked list.",9.0,69
20453,20453,24700,89502ac0aa9bcc7e1f53c6f2ab1184a643f5c96abf038408f562f5cb7340154d0c96d136d3c4ce774773aa13f3d95a0a98c70e80020a05dce05a8835fe30adf5,"We need to maintain a pointer to the last node to keep O(1) efficiency for insertion.

forward linked list single/double linked list",2.0,69
20454,20454,24701,0bce68d12d4bb423184167950cec8450c2529233502545e57429beb9cfc6f093c786ba9febad285f8197b7bbc233a3b506a933f196c9852e05b5416cd8c68c8e,"I would use a doubly linked list. We add to the back by 

nom=new->link ;

tail->prev=nom;

tail->nom ;

and we just need to push back and this will happen in constant time and if we are removing 

nom->head;

 head=head->next;

delete nom;

 and this would remove the item at the font and then we can get the size and the front in constant time in a list",9.0,69
20455,20455,24702,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,You would use a doubly linked list. you would implement this by  by creating the head and tail pointers for the linked list then the head pointer would point to the front of the queue and the tail pointer would point to the back of the end of the queue.,9.0,69
20456,20456,24703,c9533083b36a5867d42e175e5d9226d460bac0f67119822f32ea58c60b5c8ae66655217031dc5ae111931d8c34d1a88f17b852726bf446acb3dd87422ab66355,"Doubly linked list

void enqueue(T value){

         data.push_front(value);

 }

void pop(){

    data.pop_front();

}

T & peek(){
    return data.front();

}

bool empty(){

 if(size()==0){

    return true;

}

return false;

}

size_t size(){
 return data.size();

}",7.0,69
20457,20457,24704,ef56d487f412ffdca7b3412858b2ccd1fa21fc365016661f00994f5e06683c6e545b948b70c4775a9a839e6049995e36f03b1f06a7374933a80a9013b6052c37,"doubly linked list 

for size youd have to use the function size()

to add an item , you would get to the last item of the list , being the tail point , create a temp pointer which then creates a new link and thereafter update the the tail pointer to the new tail. this is push back

to remove an item , youd simply be removing the first link , the head pointer, so it will simply be pop back ",7.0,69
20458,20458,24705,a50f1f05303eb676c08e683fb412c46779741d1e408ab7173f3f3a12df3f04196b4fd7b7add1fd647d8efd191c43d6971e5cae7611afd814fbea2a7330f3ce46,"One will have to use a double linked list, with a tail.

Items will be pushed at the front and popped at the back

There would be an initialised counter to zero which is incremented when an object is pushed and decremented when an object is popped that way the operation will be constant time.

The reference to the front of the queue will be achieved using the back() function of double linked list with a tail.",7.0,69
20459,20459,24706,27704af10f29b9fd01985b3a533f1213c119ce01a32f451e037e0491eede8c71f38ccb8abe4edd8c056927c76b6bf0c23fb2a88f8cca52e5000b6c906d6692ef,"Use a tail pointer.

Add the back of the list using a tail pointer when enqueuing.

Remove from the front of the list when dequeuing.

We could use a singly linked list with a tail pointer or a doubley linked list.",7.0,69
20460,20460,24707,ba67943d9c3f68c2a82bf70197366cb2cce1d21f6696fe648aaf7068ed18399b5899a40e2f0d4a0c53a04c7e84020c544f2b79e8fc23a17b4dca16bd22dbd15b,"We will need a doubly linked list for this problem. We will have a tail, head and a new temp link. We will be able to go forward and backward using one linked list.",9.0,69
20461,20461,24708,dba55105f290263eab690cc35467de21c1485b240568356b922de9e4385ff6cd7f9c33bdddf55cba48dae5962652c3708da244fefbb69455c6e660d7de9c7d15,"if u were to use a singly linked list. it will still be o(n) time. since every time u push it need to run through all the values just to add the value. Similarly with the popback function. a singly linked list with a tail will be o(n) for some and o(1) for others. By using a Doublely linked list u can push_back, and pop_front since u know both the front and back.

You can access the head for pop function from the queue. and the tail for push function . this allows u to add to the last value in the queue. By knowing the front and back we know the size and front functions will also be constant.",9.0,69
20462,20462,24709,5888307e6e5630e26d91393f9d95b55394aa59f773d80fc5cba42e8220ea74538fd7609c1185eaef557523bfd3715cc3b2307d7a31ddf68499df84fa7da160d9,"firstly a doubly linked list would be best for this implementation

in order to implement a queue where all operations are constant time;

create a head pointer to always point to the first element

create a tail pointer to always point to the last element

create a temporary pointer;

for enqueue: set the temporary = new Link; tail-> next = temporary; temporary  -> previous = tail; tail = temporary; O(1)

for deque: set head = head->next; delete head->previous;

for isEmpty : traverse the whole array the if there is any element then it should return false; else return true;

for isFull: for all elements added keep the number of elements, for each element added n = n+1;

 if the number of elements (n) = the space allocated then it should return true; else return false;

for front: set return head->value if then queue is not empty; O(1)",9.0,69
20463,20463,24710,a58cc7a946eda613e1ba5b3286e27532a7ed6202aac74240dace327e45260834a089fa12052292c507fb1aec6f37cb1855be0992f9b6be6541ab2eebe4c77364,"the type of linked list you need is a doubly linked list, this is because it has a tail pointer therefore pushing back to the queue would be at constant time because we keep track of a tail pointer",5.0,69
20464,20464,24711,c6130d795cb6021c7594812b73d6b159744ce452f7f194d2a8acfd0f6313f2562bada8d95c7d6c5736c9d1d528be9655da041882fe8c7474badb6562243ddc74,I'd use a doubly-linked list that keeps the head and the tail pointers. It should also have a variable to keep track of how many items are in the list which updates every time we pop or push. The head pointer helps us to dequeue and return the item at the front in O(1) time. The tail pointer will make it possible to enqueue and return item at the back in O(1) time. The variable keeping track of the number of items in the queue will make it possible to return the size of the queue in O(1).  ,9.0,69
20465,20465,24712,8f4f0cec01fab6a6a49376ed0eca817677b16456497e4474dea2db6c84f10bbab5215841562427aec9d1d1cb57d57272e23d92898bef51a2205b3db761cea98d,"Firstly, it would be most ideal to use a doubly linked list out of all the linked list structures as we have a head and tail for finding the front and back as well as being able to traverse forwards and backwards for pushing to the back and popping from the front in constant time. It also has a variable storing the number of links which we can use for the Size function.

For pushing to the back: All I would need to do is create a temporary pointer variable pointing to the new link containing the new value. Link that the tail points to point to the new link. Make the new link's previous pointer point to the link that the tail points to. Finally set the tail = to the temporary variable as it points the the new link containing the pushed value.

For popping from the front: I create a temporary pointer variable = the head (pointing to the first value). We then make head point to the next link in the list and delete the temporary pointer variable. We also then decrement the variable storing the number of links.

Both of these functions take O(1) time we do not need to traverse the list. We simply update the list at each end in the same amount of time each time. The Size, Empty, Front and Back functions will also take constant time as we simply return the values or addresses of variables we already have.",9.0,69
20466,20466,24713,a41ff85d7c3f46c972cdda9b8d99297a4177ec80aa4a317631762cd6ae04cc877e3ccd31e4fd09e41eccdaa2cd1266d20e5947fd82dfa31e5b04a9f5e1bd8e0c,"I would use a doubly linked list (which has both tail and head pointers) to implement a queue. The front of the list would also be the front of the queue. 
For queue's ENQUEUE function, I would use the list's push_back function to add to the back of the queue. This takes constant time, regardless of size of n. 

For the queue's DEQUEUE function, I would use list's pop_front function to remove first item from queue. This takes constant time, regardless of size of n.

For FRONT function, use list's front function to returns value of first item in the queue. This takes constant time, regardless of size of n.

For SIZE function, use list's size function to return size of queue. This takes constant time, regardless of size of n.",9.0,69
20467,20467,24714,fcd3cd6f6ab23272e8ef67866982250cf0b69308ab1f155fea93b78f0f8230cc3a80d03659b858f52503462ba79795983adf53baae8dc1b2c6482664286cb263,"I'll need a doubly linked list in to implement this queue.

Ill implement a push_back , pop_front ,front and size",5.0,69
20468,20468,24715,23b5a4e63c9fefece084783cc1411977943e7d8d3612a093af2540d5bb113a4845b418786034d0d238575bbb9fe95d816e937dc9fe084e3f124b6dcce8457f10,You could implement a queue using a linked list where all operations are constant time by using a DOUBLY LINKED LIST. There is both a head and tail pointer and the lists point forwards and backwards as there are both 'next' and 'prev' (previous) pointers. ,9.0,69
20469,20469,24716,dc1d80fcfca2cd7f4c0d66c0e3645622562d53654a85ac238b9c0b928dfd07eeca15aea65682a467ac6bd4135a13a6043d96321ee55136fa0664700d6e749201,I'll use O(n),0.0,69
20470,20470,24717,03af6c40b97133a1240dcc22b0dd356e3929ea04c9cf63c336ed0f2605d19efb0d0a0e5a6c60e766990694456ae922f3a477316845f8028bca7fb236d74cb185,"A doubly linked list needs to be used because it requires O(1) ti,e to remove and insert at the end and beginning which is equivalent to when enqueuing(at the beginning) and dequeuing(at end). ",5.0,69
20471,20471,24718,bc7ce8dcf81474ef89d407bc167ddbdc0ae686813582e07ef0e124f6d6fe081339ab3b2bb05c54a356b901c5c208933d91dbaf731894bf50cc25eab5e102a8e6,"A doubly linked list can be used in order for all operations to be constant time.If the doubly linked list was implemented ourselves then we could implement our own tail and also if  keep track of the head and a tail then inserting at the back becomes simple.It stored the number of items that were in it and every time there was a link then that link would point both foward and backward.If we want to add to the back then this can be implemented as:the pointer after tail is equal to a new pointer with a value and then the tail is updated to tail next.This allows us to add a new whenever and then update tail to point to the last item.With the pop function,we can remove from the front of the queue:create a new link pointing to the first item,head,then head equals to the next link and then decrease n,the number of items,then delete the new link created.If the doubly linked list was implemented using a tail point then push_back,pop_front,size and front will be constant time.",9.0,69
20472,20472,24719,d02795a14cf200c3a4e42da8fa77ef31727a409d797dd41af60f44aca9829ba9ae25ee3cf59e3f4d5058d031c70d2bc7493c09427e32e68aa4eb4dcf5128f375,"I would use a doubly linked list 

to find the enqueue I will use a push back. and for the dequeue I will use a pop front. to return the reference to the front item I would use the Front function. to return the number of items I would use the size function.",9.0,69
20473,20473,24720,f2a1d44943cafd29447c9cc6d850c73ca115efbe45cc60a50c497d9c39593f6c44e4c2d4facba5ee2393c40106c70b0307d8a427a20ee6b2ecb0031a02f6d25c,"In a singly-linked list with just a head pointer, the cost to prepend a value is O(1) - we simply create the new element, wire its pointer to point to the old head of the list, then update the head pointer. The cost to delete the first element is also O(1), which is done by updating the head pointer to point to the element after the current head, then freeing the memory for the old head (if explicit memory management is performed). However, the constant factors in these O(1) terms may be high due to the expense of dynamic allocations.",5.0,69
20474,20474,24721,1db17093b11c1476f03e1842d3fd75c18d4034c323e18d85de2325fa751f6201dc73b8705d987e46f915cfc55474341bdc436a256b6ba4b925f54ea754c444c7,"Doubly linked list is always gonna be constant. Since there is no linear aspect where you have to reallocate

Push : uses push_back and pop uses pop_front where both are in constant time.",9.0,69
20475,20475,24722,a0053c94d18ea0e087a62013f5ac80c5b6b5b2b0c4aa9dd88e21096fafa1947351de1bc64c5f102a231a8bd4d8d7cf40acc72747f50d8fe1ae800f7aa85e0eed,In forward list using the pop and front functions with header pointers,9.0,69
20476,20476,24724,144fe98b924f74a4cb0e0020ec3ddfeccf820bfabdc366ff5bf990f2f806b30158897deffdf43eaec7d0e8b090cab1bb52a2dedd43e24a988f1cada5b7d709f1,"store the tail as well the size of the variable then we could increment or decrement

or use a single linked list with a tailed pointer (by adding at the front of the list and removing at the back of the list )",5.0,69
20477,20477,24725,b9398cac04fafed43567a061ce43d1f6d47a11dc43ed26ca3b7c803119e60ccce5216c5b0d8f2fe86de25d577c66b8be90d26d4412d9f88f080c8ddc823e6bcb,"To solve this you will have to use the enqueue and dequeue functions which will use a doubly linked list as they will take constant time

Firstly u must creat a new linked list and check if its empty then if its empty the new node is front and back 

U must then add the new node at the end of the queue and change the rear this is done using the dequeue function ",2.0,69
20478,20478,24726,1524a034e009646803d7074c495cb1bd3919f40bf0c99261b282adc7801990411f97759342d2d5b53fea8bfcd2292ae00d0444e55290b251e7ed8a081caf06dd,I would implement a linked list where the list can be traversed forwards and backwards.  I would implement a linked list with a head and tail pointer. Having a linked list with these capabilities ensures that all operations will take Constant time O(1). This type of linked list is a doubly linked list.,7.0,69
20479,20479,24727,c927373e71fe30f4255c61610bb88cd9a4bb26b4d4a5c6bc2711f05bbe84ffcf49fd97d920d1a706ea1e91d40784c2fadbc56f95b4fae450f318d7610a7daca1,"The queue can be implemented using a DOUBLY LINKED LIST. 

Using this method, one would constantly keep track of the number of elements stored inside the list('n'). Every time a link is added, this link would point both forwards and backwards.

THE PUSH() FUNCTION WOULD BE IMPLEMENTED AS FOLLOWS:

data.push_back();

THE POP() FUNCTION WOULD BE IMPLEMENTED AS FOLLOWS:

data.pop_front();",9.0,69
20480,20480,24728,a1c2b05bc77a92969182ba646d8a653eca3913d57c538fdf187c677d2b0c51d076b45d82612615ca734696b4dfc388e9684934287cf1a84a26d20f8be5134c6a,"Create a node , we maintain two pointer ,front and rear .the front point the first item of queue and rear point to the last item .the is a enqueue which add a new node after and moves rear to the next node .there is also a dequeue which removes the front node and moves front to the next node",0.0,69
20481,20481,24729,4428555ef8072ef23d17db65e798fc29286c3f011a1099d994917d7424cc31d5f0d195105018e3c14dd5ec04f91fc4ea0c088a5e61680d4692faa4d313c225c0,"For a queue I would use the doubly linked list so that I can be able to push front at the tail and pop front at the head, size and the other operations will be constant  ",5.0,69
20482,20482,24730,c0e222e387522491c144bc66b8d4aac6d8899881b15676a75bd42f6939be2d68b02062c035d5f028531cde71d4b0b2bb7581d5e165c7c3be11bd4e67e796913f,"A doubly linked list can be used to implement a queue where all operations are constant time. An item can be dequeued by changing the head pointer to point to the next item and deleting the first one. An item can be enqueued by accessing the tail pointer to get to the last item and adding a new item, changing the pointers to point to the new correct positions. These operations occur in constant time.",9.0,69
20483,20483,24731,c7fddd77b6fed9bc15d19de2718acf9bd47e63c47fabc90953d259ee95b77d6203c59c32fab4eab8591fe4a7373a9aafae0952036c94bc9ebef7955717c99e00,"We would need to use two pointers one to know which element was inserted first and the other one to know which one was inserted last, because queue we are only interested in only this two elements. use a function to add at the back, another to remove at the front and the one to return the size of the queue. WE can  use circular linked list.",2.0,69
20484,20484,24732,20a63554bf7ab6e06ce970a9c763f370f49fc1a727f591ec7304c432565faf9d2b891194e01cc67ff029c1fe6de8363ececadce22ee4af544785f47985cda509,Double linked list - two pointers one for the front of the qeue and one for the back.,2.0,69
20485,20485,24733,79e7d7f9dd31af42dafc3f30ed17b2ec3bfb7c371aeb90fda49a78ac5ff634413c5502ef51e48fca99485ebc6751e35a6357de07c8799c082943fd8aca0f76df,"I would need to keep track of the number of items, for size to be O(1), I would need to head and a tail(also a previous pointer to work with) to achieve O(1) in removing and adding, respectively in O(1).

Therefore I would need a doubly linked list,",9.0,69
20486,20486,24734,52f183a2edd50f67bf9165da2ed344e6b1dbef117bcc8a87e8fdd544cade3eccfad6434b2157d981bfdc96048e52a8b1696fb090b734b452d891d2f61d866105,I would keep a head pointer and a tail pointer.I would add to  the back of the list with the help of the tail pointer to enqueue.I would remove from the  front  of the list to dequeue with the help of a head pointer.I would also have a variable that keeps track of the number of items in the list and updates each time we push or pop.This requires a linked list.,5.0,69
20487,20487,24735,87b26af5215183ea5d646e967e1e3374a7a4afb5a13a2967680ff8a29d219e9ac775560a42891913325361c21b3cb2f9b5121d0317fb7c951cff2c01aed37b66," Use a singly linked list. Define the structure Node with int variable data, to store the value and the pointer link of type node to store the address of the next node. Declare the front and rear pointers and initialize them to null. if queue is empty when both front == null and rear == null, isempty() operator will be in constant time. Use two pointers, front and rear instead of head to keep track of the starting and end of the linked list. Using the front pointer we can dequeue in constant time and using the rear pointer we can enqueue a new node in constant time.",7.0,69
20488,20488,24736,2f8068722efcb5acef0b043ef7eeece2ba76bc57f445239c4ee08b7c2bb5238f231cca575128f6a330204e13d52f6c557830c59595c0c60a57b982bbb0aba187,We would use a doubly linked list and update n_items every time we add or remove in the queue thus the size function would also be constant time as it will only have to return n_items. In a doubly linked list pop_front and push_back are constant time.,9.0,69
20489,20489,24737,dc654a3d0a49a8045440d0a47a162366cb8c5b30f1fbfe16fd058e7bee5d840a459b70ea1468db1f0ce164b7af14bedf02e15cd2f876678ba6f0d0d5502b4093,"you will have a tail point to the next link  which will push back ,then point the head to the next item that will result in poping.

to find if its empty you just check if the head is pointing to a null pointer

you will need a singly linked list with a tail pointer  but backwards ",0.0,69
20490,20490,24738,ed5a8c0425e8a7a0d2d402e42e3298539ec0ceb1b43ca8fa3f4b83dce862ed24fe276be92f07cf85365c96c7391564d1c0da45fd6e6ba4bd80ecb01a39467209,"I would use a doubly-linked list.

for the four operations:

	* void push(T value) , I would use data.push_back(T value)
	* void pop() , I would use data.pop_front()
	* T& peek() , I would use ""return data.front()""
	* size_t size,  return data.size()",9.0,69
20491,20491,24739,0210a9d3772d4f5814d5d585f47b6503d720f89ae8ca72b5fb7136f3da85dccbdba73ac11df998e73774b6321c99446733c7c479dc009a4e0dc92678413ef102,I would implement the main functions the enqeue which will add a new node at the tail pointer. And implement the deqeue which removes the head and moves head to the next node. I would use a singly linked list with a tail pointer.,7.0,69
20492,20492,24740,0a640b06ce1d454be947795a6308fcfcc73f66b49b60199788f434bf91f3e08719c4b7dee42514e49b76fea543dcbe6b2a18d9de0cfa87cc5f82c989cd2f76ff,"A doubly-linked list with a head and a tail pointer would be suitable,

this was enqueue would be constant since the tail point would be used to add another link at constant time, the head pointer would be used to dequeue at constant time, a pointer could be pointed to whatever the head is pointing to, the head would point t whatever it's next pointer would be pointing to, the pointer can then be used to delete the link that it was pointing to, all at constant time.
front and back would be simple, just returning what the head and tail would be pointing to respectively, making it constant time.

Empty function would just check if head if nullptr or not, if it is then it would return true, otherwise false, all in constant time.",9.0,69
20493,20493,24741,a8dcc87a24b584021a1bb3ffd592a4ea66a1679acf3b2b41f26aef4e481760f4e64990e460e4e26ec12a8fef5d2354f5070843ac6e40f4a1e24bc122bfa91df9,"To implement a queue to produce constant time operations we could use a doubly linked list, so that push and pop are O(1) because of the presence of a previous and next pointer.

A doubly linked list is the best linked list  to use to produce constant time operations.",5.0,69
20494,20494,24742,936c1ec869d8f0942d3b84b8b6c320188374f7b930016464dda43168d457286fd222e445f17b63344d55d3ca25f550407692016dc54317e807a5e1c9658269bd,"doubly linked list.

add elements to the back of the queue.

dequeue.",2.0,69
20495,20495,24743,f83dd55ad9e075a60c5134f9bf47ed3397e5224c478fcc48237d4341af57f9ae0b4893b2d9bfdacde4458f44d6dacdaedccfab297dd76d28c1d773deaaf399e4,"To implement a queue using a linked list where all operations are constant time we make use of a Doubly Linked list. This type of link consists of 2 pointers pointing to the head and the tail which are linking the points forward and backwards. When popping we pop the front of the list and it takes 0(1) time , (data.pop_front). The size is obtained in 0(1) time in the presence of the tail pointer pointing at the item at the back. Push will be (data.push_back) at 0(1) time.

The strategy used is Doubly Linked List.",9.0,69
20496,20496,24744,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"-Define a 'Node' structure with two members data and next

-Define two Node pointers and set them to NULL.

-This would be a doubly linked list",0.0,69
20497,20497,24745,e8ac13437ca4eb4696e3ef433ae3842afba862c0118c6894733767a015023753193111e7d4c262c3227484acd644f4e441faf59e7cd3f61df893fbe34d31e198,"I will implement by creating a list that will have a tail pointer and a head pointer, In order to have constant time operations, I'd use a doubly linked list.",9.0,69
20498,20498,24746,6411a31397edca98a86156eda9fe940cd25214f5793edb40ff98bea1168dd2f02767f84a7d8f08cc5cbcf1da236fabf58172c048483fca623b7f16592128e03a,By using enqueue operation which adds a new node after rear and moves rear to the next note and dequeue operation which removes the front node and moves front to the next node. We  would need queue linked list implementation strategy.,0.0,69
20499,20499,24747,df7c40110480895f223a4ad7a154ce6d14071ffef29c798823d9a68e307bd1447fc569c4b8f3e4353216405210fd26445fb7aeea3ad07da82c16c8e5aa5ac0cd,"To do this we implement a singly linked list with a head pointer as well as a tail pointer that points to the last item in the list. We also keep track of the size function by incrementing or decrementing as we add or remove items from  our queue. Thus by making the front of the linked list the front of our queue and adding to the back of the list each time we add an item to our queue, the size is O(1), push_back is O(1) , pop_front is O(1) and front is also O(1).",9.0,69
20500,20500,24748,bd13f3a1f05cded43b306e7cf672db1fa9cf812229ead4318a993e62aa7ff42541e39b6868fb05069f972d798f5a5b109e0e615acf69b7c88b8e2bf435bfc374,"We would need to use a doubly-linked list for this strategy. The doubly linked list will contain a head, tail, and n which is the number of items stored in the list. Every time we add a link, that link will point both forward and backward. When pushing into our list we add to the back and the previous pointer points to null because it's at the front and the next pointer will point to null because it's at the back of our new link.",3.0,69
20501,20501,24749,a6a1956dca8537b87c581329dd539be0e1754c767a458496056c957b37b7d5cf8e38e7b6a815b9c917caee9a53108cd46c4caa581c67b0f0565e27d0605c7826,"Using a linked list, the last node is pointed by the rear and the first node is pointed at the front 

You should define a node with data and next 

Define pointers front and rear and set them to null 

A doubly linked list is used ",9.0,69
20502,20502,24750,cd3aa55745b79deafb0802ba9ebe30e68fbd1c089c006450727570d34769934d2b1c5a098a7d318146af21d8981711dce0bb006308d97edfcf9a088eb56e4532,"I would implement the queue by using a Doubly Linked List that has a head pointer and a tail pointer. Because the tail points to the end of the list, we can add items to the end of the list (push_back) and be able to determine the size of the list (size())  in constant time O(1). Since the head points to the first item in the list, items can easily be removed from this list in constant time as we simply pop the items from the front of the list (pop_front). We can also gain access to the first item (Front) in constant time.",9.0,69
20503,20503,24751,12066f8f6a7f4cd1c9586b77b6e85c69168c3e639d8a7cc579d0737f33e85026e0fc0bba1f43d9a6c097e420e073f5dd573d48b38e1cf440a6f948554edb9454,"In order to achieve constant time using linked list one has to use a doubly linked list.

These have a head and a tail to make it easy access previous elements/nodes.

In order to push back in constant time one can create a temporary node and equate it to a new link of the element we want to push back , this means the tails->next now equals to the temporary node . After that we equate our temp->prev to the tail. This means what we initially had as a tail is now our temporary but with a link that points to the new element. The new element will have a nullptr. Update the number of elements as n++.

In order to pop front we create a temporary node and equate it to the head and the have the head as the second element(head=head->next; ) then we can delete the temporary node hence we've deleted the first element in O(1) time. Update the number of elements as n--.

When performing the push_back and pop_front we may keep count of the number of elements we have(n) then that way when we need the size it can be access in constant time.

To get the front element we do not need to traverse , the first element will be access in constant time.",9.0,69
20504,20504,24752,50ac02db01dc47f0f24bb2a0e8bc1bebe3aac1ecfe652f1c87b260f45da4def0a267392e043e67a0b0f3a39374188322db34615d5257a196fc0978d4d004e1ed,"Doubly linked list will be the one that will have all operations to be in constant.

Push-back function:We will fist create a new  Link and a temporary pointer that will point to the new link.Then make tail dot next to point to what the temporary pointer is pointing to,which is the new link.From there make temporary dot prev to point to what the tail pointer is pointing to.Lastly make the tail pointer to point to what is temporary is pointing to.

pop front:Create a tmp pointer that will point to what head is pointing to,from there make head to point to the next node.lastly delete the node tmp is pointing to.",7.0,69
20505,20505,24753,0fd0096c1497543ca0003b9e3ba007221cbda2328585a2f2260277e1c7038bb2ae7ad23e03908936421523651b3b5785ece380b977ac663ea4a02a050d012617,"l will make use of the DOUBLE LINKED LIST and how l will do that is ,

how l will do that is like ,since there is a head and a tail in a double linked list , l will perform the the following,

thus when we want to pop from list: DATA.POP_FRONT

t_OP = HEAD;_

_HEAD=HEAD -> NEXT;_

_delete temp
_

thus when we the push back : DATA.PUSH _BACK

_tMP = NEW LINK();_
_TAIL -> NEXT = TEMP;_
_TMP -> PREV = TAIL_
_tail =tmp;
_
_
_

_we have advantage of the cache
_",9.0,69
20506,20506,24754,4c6239f4837a7e4857168ce1d90eccb0590dbff5755d1452f6eced3fa662d6b3d452d78b9021e9f1b0bb440c88d3e31a3396f8ac92fb89f14b2269d4512bdaa8,"we'll use a doubly linked list with both a tail pointer and a head pointer.

we'll create a tmp point that points to a new link containing a new item, let's call it v.

tail->next will now point to where tmp is pointing to;

tmp->prev will then point to what the tail is pointing to.

lastly the tail will point to what tmp is pointing to. This will allow us to enqueue in O(1).

To dequeue in O(1), we'll create a tmp pointer and make it point to what the head is pointing to.

we'll then make the head point to what head->next is pointing to, then delete tmp.

for front , we'll just find out what the head is pointing to and for back we'll just find what the tail is pointing to. both these processes take O(1).",9.0,69
20507,20507,24755,3b71cded09878fac739a748b2fcbc2d9e2bef1d7260004d93fa1cfe93d9b6830fe9dca43a0e8ef309e85cefb7f4580ca47263177668c6f4b88b993ec3fb19c7e,"-We use a double linked list and keep track of time

The types of linked list I would need are:

Push_back O(1)

Pop_front O(1)

Size O(1)

Peek or Front O(1)",9.0,69
20508,20508,24756,1d906c438dbb2a0adc2a7e04ed6b3c53c2ee28b5c43a5e83e583d5199a13a7bb6abb74579e2679fb4b6602b8efe2849ab290c6db2b1f573c02a4880312c09f25,"I would implement it using doubly linked list with a tail. In this case we'd have to keep track of the number of items in the list (n). We use the front of the linked list as the front of the queue. To add at the back of the list, we'd create some tmp list which would equal to the new link we want to add.",9.0,69
20509,20509,24757,eaeebfd434a43156f3712848577d3a5da6499b6e1784e16a24ab5777985e6e2eed30ffc0a110ed246a9badfba660cd9a812c4ed7d173d1a29f7e115ce4ad58b1,"I would use a double linked list or a forward list with a tail .
This would allow me to access the tail and point it to the next list for push back and enqueue the queue this would be constant time.

I would also have access to the head pointer and point it to the next item using head . next this would pop the front item and dequeue the queue and this would be constant time.

Since i have the Head and it points to the first thing i can just return the head for the front function and  this would be constant time.

For such every time i push back or pop front the queue i will update the size variable and for the size function i will just return the size variable in constant time.",8.0,69
20510,20510,24758,e083cbbf008c42438bc396229643f759537dd38e9f70943e360360b6f27f45207e60ac5070353bd70bc7b26433e973228b25ccf89b152c434341d5c266f31945," To implement a queue using a linked list where all the operations are constant time, we have to use a doubly linked list. 

Taking the first item of the linked list as the front item of the queue and the back item as the the last item in the queue. push front, pop back , peek and size will be constant time.",9.0,69
20511,20511,24759,a959a4bd23a818684dfb2a6c94ac89925575f3b11f0de3ed6d4df640b02681f2171e62de10059d8c04c758f13335e59b8e75b311b1045da8f168f89c32919f7f,"By using a queue as a structure, there are two pointers, the front and rear. By using enqueue() and dequeue(), you can add to the rear and remove from the front, with time complexities O(1). e.g.

struct Queue{

    void enqueue(int x){

    ....

      }

    void dequeue(){

.....

}",3.0,69
20512,20512,24760,0cd06500f6bc04ca04d6df402c164435dd4b1e3f62d49a5f81d45b91f4a6f4ac2ae8232fc2f485e2ef108625ecea2f61c466c82dcbccacd3d327b9b3b7efa90a,"I would implement this by using a doubly linked list which everytime we add a link, it would point both forwards and backwards. With this linked list i would implement by front back, empty, pop and push since all these are available in a linked list .",5.0,69
20513,20513,24761,fd8a875c5398ac6c36a731d0d10a006399599403b9ee2f4994b116a012c4bd603697ca87421ae17a8eaaa96913f3870bb71641db61fda611c4a27d1aa224e5e0,"To implement this you would first make a temporary node, and point it to the front of the queue .You then store the value of data of this temporary node in a variable. You then point the front pointer to the node next to the current front node, afterwhich you'll delete the temporary node by emptying it(using the free function)
To implement this we will use a singly linked list",1.0,69
20514,20514,24762,e627fede4d8a070ca528e22154030076326cf75a860ce09e9231ab5eb164fd945cbc3f05b7190cc8d307288292134d5c83514ef1ec1b1c4974bcf393c3c20f68,"A simple singly linked list with a tail pointer and a size counter would work as a queue with time complexity O(1). 

To queue an item use the tail to access the last item, point that item and the tail to the new link.

To dequeue simply store a reference (called temp) to the first item, point head to the item temp points at, then delete temp

To peek just use the head to get a reference to the first item.

To get size simply use the size counter(which increments with enqueue and decrements with dequeue)",9.0,69
20515,20515,24763,2e87414379efcd8b6abefa082fd766ea6bbd6a7c49327da9b14527216de652d464a74ad3edb281cf63c53ec51b9a87c17ffe7ae230ea816e625650e59f9bd068,"by using a tail pointer that works in reverse.

a singly linked list.",2.0,69
20516,20516,24764,5f92eb6a07aed01e019162660614241903fd30335dc49cd736d18a97a0b8e4d8d8eaa7a31ce7cb8ad65e895e5a8906b98d2e7635d42d019af72333c76c35da1a,We can implement a queue using a linked list where all the operations are constant time by adding a tail pointer. We would need a doubly linked list for this strategy. ,7.0,69
20517,20517,24765,a09890d1b445c23fabb578b3483b14013fc02062f1b3aa1b4c6df4bdeb9b3b91a9c90e4c472aa2da65ecaa5b831c0625b91b1940398021966ddfe90195c5216f,"Use a single linked list to implement the queue, that is set the head pointer to the first item in the in the queue, each time you push to the back of the list you update the pointer to the next item added to the list.",0.0,69
20518,20518,24766,407769fbf475dbb4360f6394c41bf1fe1b09a93e6d82ce4845a84070494a0f47c40c801c2682df7cfd3bd3657df86e3329652953a2e09d84c89aab85cdc47d86,I could make use of a doubly linked list. A doubly linked list contains a tail and a head which will allow me to point at the beginning or the end of my list. This will allow me to implement my functions at a constant time.,2.0,69
20519,20519,24767,cc4a3429058a6fb36c1c14635322568c508206ceead8cb4bef1f46c77dd76f655277f72ba9b8a42e6d49805547432d6dea2f783f4c165e7598b53d607e545ad2,"tmp = new link(V);

tail.next = tmp;

tmp.prev = tail;

tail = tmp;

Doubly linked list",4.0,69
20520,20520,24768,9b13f2d70694a174cc296db2532a81cde5f414c86e87388e32c45d14a1b85a47b70cc54fdcb2f6455012d569323883da99f34aab409453d8e838e0ae2bf41aff,"you will need a singly linked list + a tail.

tail -> next = new link (v);

tail = tail ->next;",0.0,69
20521,20521,24769,639a68158c22ced38b469e5ff5439c6df90887f4ac511792920966a4b66fbbb0736453130f1e07f675685ab76215a4ca74f33ab5a9bf6fded51b150fcaa550e3,You could implement a queue like this using a doubly linked list so that it has links to the front and back of the queue by means of a head and a tail pointer. All of these functions will occur in constant time as the tail can be pushed back (changed to an element that was added) in constant time and the head can be popped off (removed from the front of the queue) in constant time and thus you would implement it using these functions.,9.0,69
20522,20522,24770,525cefc66631b9eb601410acc1c632cc3a6d9976bb8f3ac653d46807a4053f29a6c3c85a0e8a38a43486b45bae46acd949e27f910bf00828afed11257c7034f3,You would need to use a double linked list. Since we already using 2 pointers as in a queue all our operations would take constant time.,5.0,69
20523,20523,24771,2c32439612d29606cd7276c7d7327878252b82b353a0e5c5a38f508a89318428edb5d433b571f4ed85a8cddd2dbf4c9c5eb5b82d38c65addb4bffc9179a95b21,"A doubly linked-list is able to implement all functions of a queue in constant time. This is implemented by creating head and tail pointers, along with next and previous pointers. Thus, when accessing an item in this list, it is easy to locate the values stores next to it. This would mean that the push and pop functions are constant time as they both require the respective head or tail pointers to point to something else, along with the addition or deletion of a value. This needs to occur every single time and is not directly dependent on the size of the list. Therefore, it takes a constant amount of time. ",7.0,69
20524,20524,24772,01414e21ecb9a1334890023f94a0d282ee23097fe9f9524ae17a5a130cb936a59877f182817dee70cef409eabab63c6b47a25ed1ae4ef0dfef7f2566f253e2b1,"It is best to use a doubly linked list with a head and tail pointer to implement a queue with constant time for all of its operations. The head pointer allows us to be able to use the front and pop functions in constant time because in the case of the front function, we will already have a reference to the first item and for the pop function, we will have to just have to change the head pointer to point to the ""second"" link and delete the previously first link. We will also be able to push in constant time because we already have a reference to the last item so we can just change its pointer to point to a new list. In this way, it will be added at the back of the queue. ",9.0,69
20525,20525,24773,3824a0678a0ee80961c81764186a1496645536aadc7127ac81665ef8825202d12ca91cc1dddb49cb3545dd95e3ab23ddf164ccd399cf03acc33959144061677d,"To make all operations of a queue using a linked list to be constant time, you would need just a singly linked list with a head and tail pointer. The strategy would be(for one that uses the front of the list as the front of the queue) :

	* When adding more things to the queue you use the tail pointer to link the next link to the chain this will remove the need to traverse for pushing values.
	* When you want the first value or front, you can simply call it by referencing the head pointer.
	* When you want to remove the front you would use the POP_FRONT function which is O(1).
	* When you want to see the size of the queue you could increment and decrement the size as you remove and add values so that when you call it, it removes the need to traverse making it O(1).
	* If your queue also happens to look at what's at the end you can use the tail pointer to see the value by referencing it.",9.0,69
20526,20526,24774,ac47e3ceebccb755b1987f028345ba571e2bbf0bc4ebc355e11ab520e9f3ffd71073789246ed0c633ccffb81e8b77e299c90427fa5f8a55f41455cee47d290e1,"Since we're implementing a queue using a linked list, the type of linked list that we would need is a forward linked list. We will be using a forward linked list we will be taking the back of the forward linked list as the back of our queue and the front of our forward linked list as the front of our queue. If we want to remove an from the front of the queue we will use the pop_front  function which will be 0(1) time. We gonna use the pop() function by setting head to the T value assuming that T is the type of object stored in the queue  . To  get the size we use the size() function and this will take us 0(1) time, but we gonna achieve this by traversing  through the forward linked list in order to get the number of items and this will take us 0(n) time which is no longer satisfies the given condition. If we want to add an item we will use a push_back funtion of which will just take 0(1) time if there's an empty space. If we want to return a reference to the front item we gonna use front() function and it will take 0(1) time.",9.0,69
20527,20527,24775,22140328599cc90e71d5de22898862c3b0e2dd7b2d6733a618551afede59cd91597d571fd42b02414ce2cee43da486638d6f616c5d08e161d9d14ea8e7479b0a,"we would implement a queue where our linked list will have two pointers, one pointing to the next and one pointing to the previous pointer and thus here we can use the doubly linked list where all our operations will be in constant time.",9.0,69
20528,20528,24776,d39f1221c1c1fa8d17ca77420f1bba8cbd56fd8e4b2efb35a70c05cd360218b8d98dd79e4c1abc4c057030cb040ef7358efbb5cda6b9051c1e5bddbf68b768c0,I would use a Doubly Linked List which has a head that points to the first item in the list and a tail which points to the last item on the list. I would also have a counter/ variable which keeps track of the number of items in the list.,2.0,69
20529,20529,24777,3dc26b747d97da3ab4afec05ff58fc24d9456624d1de4e773000cee11c5770c4305e55aba8a358eac1e51ad690a762f5e637a6ce6a5554139fe18ecd7662a5af,"we can use push_back to enqueue an item, by accessing the linked list on the tail to add an item,and that will take constant time.O(1)

we can use pop_front to dequeue ,by accessing the linked list on the header then pop the first item in constant time. 

we can use front by accessing the linked list through the header and return the first item in constant time.

we can use size by keeping track of the tail and then increment as we enqueue and decrement as we dequeue ,to take constant time.

By using a Doubly linked List. ",9.0,69
20530,20530,24778,61263672c5c532106e7f21122dcaab559eafcffe3f9da40ef6a4194409e8f1be9b62145c70c7a6a62ca846b85c63f3fbde4504110d16d1088e8621a2430bcdec,"We use the push_front and push_back operations to implement our queue, where we have two pointers for the head and tail. We use singly linked list with a tail pointer and we store the tail and size variables, so that all our operations are in constant time.",7.0,69
20531,20531,24779,97b7f5ff46c1c824381cef505f20511747560e70b8b1e616642dc4fcce22c546867f43d01ab15335e8a2a57b9d3fba9ae8276c6347ded2ad2c8d88ebec13760a,"The queue is implemented by maintaining two pointers that point to the first and last items of the queue, respectively, using a singly linked list.",2.0,69
20532,20532,24780,7034e661a6b51c59ff4e839b7430fa79082c9a14de4d5507d8b8f51bcf2e8507159f0b9ac4f2f0968d640ca40b95ebbbfcb9a489ff8f5bfe6ee49d4e9a458d5c,To implement a linked list where all operations are constant time I would need to use a Doubly Linked List. Since the list has a tail pointer the queue would not have to traverse to the back of the list every time it needs to add a new object to the queue. A Doubly Linked List also keeps track of the number of objects in the list so find the size of the queue would take constant time.,9.0,69
20533,20533,24781,d262858bac7cd6476e0cd48b8622c751312997fe7fae4adba9c98bf17ceadac187d9de2b401de3d1895e85edc24940f00a102bf214f436104f37cd1b8669240b,"I would use a doubly linked list, which has a head, tail , value, next and prev. So each link has two pointer: next and prev. To enqueue the first link, you would create a new link, where the head points to it and update the tail and point it to the new link also update the number of items by adding one. When enqueue after that, we would create a new link where the tail->next points to the new link and new link's prev points to the tail, then we update the tail to point to the new link and also increment the number of items. To dequeue, we create a new pointer that equals the head then make head equal head->next and decrement the number of items. To return the front would be just returning the head->value. And because we keep track of the number of items, returning the size would be constant time. ",9.0,69
20534,20534,24782,efa2c5b70f1ad8f0aebabd9a8317831d8e117c559aa0a29951f0659587ce28ce45a8ffe00e2d128d5b1b92e6f8033ccb1e7464d9f2f119aa95332037f62a3b76,"We would have to use a tail pointer

Use the tail pointer to add to the back of the list when enqueuing.

Remove from the front of the list when dequeuing",3.0,69
20535,20535,24783,eca946aebda9a9b4177d6f115af990d8e97aceaf5b9e945366e5e65b189b91181b165b8de20a658f63f6ad071cac081dfb0b61ed3ea41bd5546e198d3476c47b,a singly linked list,0.0,69
20536,20536,24784,bf9f7563cc9f901b96502125e7d25475a0aeee128b8258ce038a51e3af3c4093e4ee3d48f8e688baf55d2e74c7a660d473b521169612f2e6991be2accf5a47f1,"to implement a queue using a linked list the type will have to be a forward linked list, this means that we will be taking the back of the forward linked list as the back of the queue, and the front of our forward linked list as the front of our queue. To remove an item from the front of the queue, we can use the pop_front function which will have a constant time complexity ( (0)1) ). we can use the pop function by setting the head to the T value if T is the type of object being stored in the queue. If we want the size of the queue, we can use the size() function and this will have a constant time complexity and this will be achieved by transversing through the forward linked list to get the number of items and this will have a linear time complexity ( (0)n ), but this does not satisfy the condition. then if we want an item added we will use the push_back function which will have constant time complexity provided there is an empty space, lastly, if we want to return a reference to the front item, we should use the front() function and it has a constant time complexity ",0.0,69
20537,20537,24785,97a01199b925330f29640cdb86e45eea363ff96eb767b66ea518348ab8ed24fd59b309226c6a592a7f7ea6b67fef81cbfd1daad02d4a32f29300da894c457dc7,"create a link where the head is the front and tail is the back of the queue. when adding items to the queue we will have to add at the back of the list and change the tail to the new link we added. which the time complexity of it is constant 
When we remove we remove items from the front , so the head pointer and front change. The head pointer points to the second item then we remove the first then front become the next item.

determining  how many items in  the queue   will take constant time since its a link .which the time of this is constant.

The type of linked list for this strategy is Single Linked List with  tail.",7.0,69
20538,20538,24786,6c0c4055e14104657e8b2f93690d540761c32c74b87c67cb6acc284b0968521966239252478c024e2c1fdc28ec4e72c01b4f28c3de78e04b7bbf604f3bad167d,"For constant time you would need to use a double-lineked list. As you would need instant access to the front and back of the list. Enqueue and Dequeue would now be feasible as its double linked, size is associated with the tail link. Empty could be checked with the header link",9.0,69
20539,20539,24787,ef46ab4c4baea61ce39205f3f8b9ba2f08ab48270b777e4f042aafc6410a82e9cddc1dd033e57ccba5e191584e8763e9b5c270df38cd4daee3f921d844f6b7a8,"I would use a singly linked list, where I will implement my own tail; and be able to keep track of the tail and head. That will allow my operations to be constant time.

Singly Linked List ",7.0,69
20540,20540,24788,7ed1c803cb6942b25a462119e14146d3dfdc8b2d8405742d6e37974d2693c34f2838afb58a1bcf41b9fcd8829c1dff4d4b192c929c721bc46e1615dcea231b30,"A Doubly linked list that has prev, value and next is used. For front to be O(1) we return the value in the link in the list.

As for pop_front we achieve O(1) by assigning  a different head pointer(temp) and thereafter assigning the head pointer to the next link in the list. Lastly, we delete the temp pointer.

For push_back  to be O(1), we use a different pointer (temp) as a new link, the tail->next is therefore assigned to temp; temp-> prev should be equal to the temp pointer.

For its size to be at constant time, we record the number of items stored in a list.",8.0,69
20541,20541,24789,2f3e315687119ead6a818da568e78a6a6a1fca8ffa33209c3dff24c186275e23df6af032db0ab8c3cc902f57fda3972c9cc02a021860b531f2f8a447436717fc,"u will need the reverse linked list.
the is to reverse every latest move you made or to remove the latest objects you inserted. ",0.0,69
20542,20542,24790,02cb07161473723283d91a3c998f4ade4cb197abe855244e901ae8f3133fa745a87cf9dec28bee7621c8d3b8308477fc042faa7e0319e0ad9256c728f396d7bf,"Doubly Linked list.

Whereby the Front() function uses the head pointer to get the reference of the first item [O(1)], 

the push operation can be implemented by setting a temporary ptr to a new link; tail->next=temporary ptr; then set the temporary->prev=tail; then lastly set tail=temp. All this takes O(1) time.

Pop from the front would require a temporary pointer pointing to the head ptr, the head ptr, then the head ptr should be updated tp point to head->next, and then lastly delete the temporary ptr. This takes O(1) time.

 ",9.0,69
20543,20543,24791,640080dea627eeb31a3d305d032f6df57a0ee21da5dcbd20ff6bbe259d5ca01d650ffa6e7bab08f963664be0fe5ab3d7fb527ab7ad27b3354df44960876962d7,Doubly linked list,2.0,69
20544,20544,24792,1ec073b8c8fd76df82abd5195dc059b3bb969a0dcda29a3183557cfcb9cf9edfa565003c0b81e18a702d15e745574294a8e18968fa713fdba196a2197d0ea2e5,"I would need a doubly-linked list for this strategy. It is a type of list that has a head and a tail and it can store the number of items that in it. Each link in a doubly-linked list points both forward and backward, making it easy to add an item to the back and removing an item from the front. ",7.0,69
20545,20545,24793,3b012b96c98d84ed8e9f88d92fde8d672f449955feec04f1b94283d72586d2586b31cd4b32cb1464ddc219af63c953c4b0015e421667a55126d1bf7700e02016,forward linked list with a tail pointer ,1.0,69
20546,20546,24794,888a700ecff48b8e58609f74298e3e913836c7525e3508cee74dcd45d73e3b5cb35996869dd34b3342eba886899eba46a61c603fc724f15dfcf45804ca8c7ece,"You would need a doubly-linked list to ensure that access elements from the back or the front take the same amount of time. In a linked queue, each node of the queue consists of two parts i.e. data part and the link part. Each element of the queue points to its immediate next element in the memory. In the linked queue, there are two pointers maintained in the memory i.e. front pointer and rear pointer. The front pointer contains the address of the starting element of the queue while the rear pointer contains the address of the last element of the queue. Insertion and deletions are performed at rear and front end respectively. If front and rear both are NULL, it indicates that the queue is empty.",7.0,69
20547,20547,24795,e0c83344227ee0e9cbe053565e48a2fdd45505359ef079abf58dae6d4b8251e874c464186ed9d597d1e6bd62c45d87ea5c0897cd6938b6926936cb2def62d356,We implement the enqueue and dequeue operations and make sure there is no loop when implementing them to create a constant time complexity.,2.0,69
20548,20548,24796,9140ffa3b52741e2ae246773dfeed94b1141ba7c3dc70e8cb17fb6410cd6b017d81c18ceaa0264d9c4b8354cae095d12f4a720da352b65b62d37bdd0fc9fdc69,"To implement a queue using a linked list I would use a doubly linked list as this would have a head and tail pointer. In this list, each node would have a pointer to the address of the next node and the pointer to the address of the previous node. Since we add to the back of the list we would just update the tail  to point to the new link and then the link should point to what the tail was pointing to and this would take constant time. To remove an item we would update the head to point to what the current node's next pointer points to and simply set the next node's previous pointer to null, this would be done in constant time.",8.0,69
20549,20549,24797,e8cc8f379686cf17ff7a79c51f234b372a7158c41925760d6a62468ac2bc253c196a10ef5af7f8e787abc174ba6435f331d902d6901bc07bc87271a8d067f35c,"A doubly linked list is needed for this strategy.  A doubly linked list has a head, a tail and it stores the number of items stored in it. Every link will point both forwards and backward.   To push an item to the back of the queue, tail->next will equal to the new link,  the tail should point to the new link, and the prev pointer should point to the previous link while the previous links next pointer should point to the new links prev pointer.  The number of items stored will then be updated. This happens in constant time.  To pop a link from the front of the queue, tmp will equal the first link, the head will equal head->next (to update the head) and tmp would then be deleted. The number of items stored will then be updated.  Popping a link also happens in constant time.  The size and front functions also happen in constant time. Therefore all operations are constant time when implementing a queue using a doubly linked list.",9.0,69
20550,20550,24798,f2976011447672b5ea82a6f5b8159ecc9f0a4e8ffd33b6bddff412fce7c94244abe57dd0112220156e401a16e24a98cea2bd0caaf73b10b6bd34dde0d715c467,You can have two pointers one pointing at the front and one pointing at the back.  ,0.0,69
20551,20551,24799,20d849b0f14d796b315efcd61e863b25c7b0891949c9f1f08039226267e2ec02fc126e19dc6bac1596ae1c91066636280bb491c789bcd5f5ca3de77e3170945e,I would use a doubly linked list with a tail. I would use the front of the list as the front of the queue. Pushing to the queue would take constant time and popping from the back would also take constant time since we have a tail pointer allowing us to access the last item without having to traverse through the whole list. Accessing the element at the front would take constant time since we have the head pointing to the first item. Accessing the item at the back would also take constant time since we have a tail pointer. The size will also take constant time.,9.0,69
20552,20552,24800,f11178d26d71b36980a2e031712b410b8887af4a2b6c48901c6a568377c95cf608d8bdb211ef99a8ec80760d046f982bcd08b27ff9c8f8cd3f71083f65b80c48,"In a singly linked list there are 2 pointers, head pointer and tail pointer. The head pointer contains the address of the starting element while the tail pointer contains the address of the the last element of the queue. Insertions and deletions are performed at the head and tail respectively. If the front and tail are both null, it shows that the queue is empty.",7.0,69
20553,20553,24801,fd3ac26e8f1d74669c591d17cfba292d301a38f59035e0e015254638e09238378ffbb05277661aa625df195230a27bb79b8964e830815de826a62bf695fefa00,"I would use a DOUBLY-LINKED LIST.

WITH THE FUNCTIONS:

	* PUSH_BACK O(1)

tmp-= new Link(value);

tail->next=tmp

tmp->prev=tail;

tail=tmp;

      2. POP_FRONT O(1)

tmp = head;

head = head->next;

delete tmp;

      3. FRONT/PEEK O(1)

      4.SIZE O(1)",9.0,69
20554,20554,24802,f6f17fb0d6ed2ee394666ab57ff8bd41ae8d4cb739854dc87e46a47f80236a49aeffac32c2aff43a7f1a1c2bab91b37fa0dd5d365978db82be6ca12abbe4f2d0,"I would need a deQueue linked list for this strategy.

void deQueue( ){

    if (front == NULL)

          return;

  QNode* temp = front;
        front = front -> next;

   if (front == NULL)
        rear = NULL;
 
        delete (temp);
}",0.0,69
20555,20555,24803,fa9e03d0ca767f086bcd9ef36b2098757508e1e31055329ce57a6c2012e0fc52ea26b7511314fd601a7a535cdf128ba0717226b541ddae15232dd77b79a7f243,I would use doubly linked lists. ,2.0,69
20556,20556,24804,bb69eebb6b9661fb2659b9201956c2d150fd7601de8f2339f22c3c3c7289abd28101e1b6206a923a6b9fd81f7d0d617c8b5485dd0958ad06769fcf98922a4e97,"You will absolutely need a forward list so that so that it is easy to create a new pointer that will point to the item the head is pointing at and point head to the next item to pop the the first one.And to add at the back,we set the pointer to point to the last item in the list then we create a new list such that our pointer.next points at it...",0.0,69
20557,20557,24805,95fcb6f4498706b42ae9b99b85ac88399a6d3275d00b87217fb05c5101d1dbf721727b60bf9e8e6b2dc1c2bdad3d13b66bf7f2d975e8a5f8863dd7d1ee3dcbef,"we would use a doubly linked list as it has 2 links and all operations are of constant time. We can do this by our tail of the first item equal to the new link and the head of our next item equal to the link of the previous item so that once the first item is removed, we can then assign it to the head/ front of the queue. ",2.0,69
20558,20558,24806,e3fe34fe397fdba954ee04d79db645b0148c5938ca6f2f7a2907aa58749a445701d138ec6de61364a9d6a738e1bd62c299a45c7a655f0f5a3aa7fe48b798bb3b,doubly linked list,9.0,69
20559,20559,24807,ba17ced0b845a961a4ba2b9f572020680e40bd19c35ccad68ac84e48d9cb5d04fd0000feb318fb1b5fed6a59256f91eb5d0cc5f4be4d4f154e8d52a24ea8af8a,"In a queue data structure, we maintain two pointers , front and back. The front points the first item of queue and back points to the last item.

I have to efficiently implement enqueue-an operation which adds a new node after the last item and moves the last item to the next node. I have to efficiently implement dequeue-an operation which removes the front node and moves front  to the next node.

I would need a singly linked list.    ",5.0,69
20560,20560,24808,eec934572d7644ba0121c8b2feb2c582e9f3f4f5b58187b8858bc2ee24ad1c13bedfb2cdb5029267bc11b865502439fbacde60c9046792350b575350ddc17ef6,We require a linked list that has two pointers (next and prev). It should traverse forwards starting from the head and backwards starting from the tail so that the operations can run in constant time. We add an item to the back of the list using the tail pointer the prev pointer and remove an item from the front of the list using the head pointer and next pointer. We would use a doubly linked list. The front would be the first item in the linked list. We get the size by getting the index of the tail.,9.0,69
20561,20561,24809,9ab5ee6dcd1eeee42b584dd13d10dfb771aeae24b070596bf8e33f41840796cff5a58f61a4f76bd5d61ec8edd7ee76fc7e403b38a2b713cfce865554906c5149,"I would [prefer to implement this using a Double linked list

Push_back O(1)

tmp-=new Link(value)

tail->next=tmp

tail=tmp

Pop_front

tmp=head",7.0,69
20562,20562,24810,ba47d803e26988b75d891eb0e76061b355587a9834711cd75248db6b2b1c6cccc9c5cadcd161a1c0dfe6bd2d1a8b1014e37dd57461b73e39268808ede1fe4392,"By using a doubly linked list, where the front can be access with the head pointer taking constant time and the back by using the tail point which also takes constant time. We keep track to the items inside our list and when fetching the size we can just fetch the value we were keeping track of. Since we have 2 pointer in the front and at the back we can always pop_front by shifting our head pointer to point to the next node and allocate temp pointer to the previous node first then we can delete in right manner. All this takes constant time everytime. same process for pushing back.",9.0,69
20563,20563,24811,9ef08903fc9bcdb48895ecc5b1fae5cd197bde173b9729429afd0455acdabd651995bcf58c93f0a9f803a86fd3d68cb2f4b604260158eb5fae2f92dc6b1309cc,"For this strategy I would need a foward linked list.The back and front of my foward list will be the back and front of my queue,if I want to remove from the front of the queue I'll simply use pop_front which will  be 0(1) time.",3.0,69
20564,20564,24812,0c11d203426fce7b3dc05c5b901a557cc9648e7fd3384bd9d8800631c383636176c5236339b82c8cac354a014c4e904c016c4f55b6e4ea8b971819143c0b5cb5,"A singly linked list with a tail pointer. To make the size function constant time, a size variable would be stored so every time a new link is declared, the size variable is incremented.",9.0,69
20565,20565,24813,64e451748c8e64219c1dcf31828cb7ded38a1447346285c9e9b6559aebe71fd6c492c0cffcdb5c0c6a652b339b2aa51ca0d8310a628f12a661261dc55ced044f,"The following two main operations must be implemented efficiently. In a Queue data structure, we maintain two pointers, front, and rear. The front points to the first item of the queue and the rear points to the last item. enQueue() This operation adds a new node after the rear and moves the rear to the next node. A queue data structure can be implemented using a LINKED LIST DATA structure. The queue which is implemented using a linked list can work for an unlimited number of values. That means, queue using a linked list can work for the variable sizes of data (No need to fix the size at beginning of the implementation).",7.0,69
20566,20566,24814,73f479b1c32665dbc26a876d65d907d7b668722d4500809cc0e92a0c3b8fb6ef14ebbb966ba42d9df836ec685dff74ba0f52590c3d881cbfcb8d972c3fe69336,"* Step 1: Allocate the space for the new node PTR.
	* Step 2: SET PTR -> DATA = VAL.
	* Step 3: IF FRONT = NULL. SET FRONT = REAR = PTR. SET FRONT -> NEXT = REAR -> NEXT = NULL. ELSE. SET REAR -> NEXT = PTR. SET REAR = PTR. SET REAR -> NEXT = NULL. [END OF IF]
	* Step 4: END",0.0,69
20567,20567,24815,0acf933aafd8ccfefdb0a07c9cd769ff21b003c332b8b90f6edffc1573664ade1e2d7b54669b2cee7b03b35091d029450c66d87d0c0afdf5016d3799c57a4fc9,"enqueue -adds value to the back of the queue

dequeue - removes item from the front of the queue

double linked list",2.0,69
20568,20568,24816,e7c7348f23786b9e18a28e68e5d9ba68b1b693a74a0d58100a7db9e2aeee706b92e8dc4a38b20cb50289290e86666a9bfd49334f05b1673c8db1a8b26f9c9689,To implement a queue using a linked list where all the operations are constant we will have to use a doubly linked list,9.0,69
20569,20569,24817,4a108b6388ab518862a0eddc19b8d86fd9549abfafdc544be7cbe5e9a91a20102b9726ddaa529a19a86fc38fa4700a0fdd752705615738f3f81b854fa84c557b,"By adding an item at the end of the list and popping an item from the head of the list.

Double linked list",9.0,69
20570,20570,24818,09a1699e91053a97e967035388a9bb6bf2333dc132838738d78edc417a8028213044038d23bdf9e5be7458e9014620b5d4a10df02214eb4aa340c740ce44d5c1,A doubly linked list could be used or singly linked with a tail pointer.,2.0,69
20571,20571,24819,400853532d18057c486e48e90c2e3817295b0b8da4abab44abf1f9dd692996bce343aa72b93713cdef71a68aff30879c7ec75ca8ea25a59fd4c48084879663a5,Two pointers will have to be maintained. The front point will be for the first item in the queue and the back point will be for the last item in a queue. A doubly linked list will be needed for this strategy.,9.0,69
20572,20572,24820,763a776e81302d0ca35787de395275bfa7dace1cb9ac6ce690e840ef2f280482559135e73ff9334c7ef80b3304e1f6061c108364e0e55bf5e56d4aafbce8e073,we would first start with the enqueue which we will insert a new element at the back of the queue and then dequeue which removes the front element in the queue and them we would check if the queue is empty thereafter check the number of elements in the queue to see if there is still elements in the queue.,3.0,69
20573,20573,24821,bf4b5731c3c3bd0f2b59e631e277805959da8b9efedbe010df49f525b49b713ed8678bb3e54ddfd542bb302e79e236dfb9ec30ec253f0f80d3cd72c6a5094fbc,"To implement queue we need size(), front(), back(), push() and pop().

We cannot use forward_list hence the only option is linked list in vector underlying container them we will use erase(at front) as pop, push_back as enqueue, front() as top, end as a back()",0.0,69
23178,23178,27426,3227954877ff6b3d6e5d415eabaacb6ee56a5809874f349fcc72cbd6b74b9924802065f3198d52fa435eef46404fa2ce0465698400217a4b7b18ef03d8cc91ec,"When performing either of the traversals, each node will be visited exactly thrice.

For a post order traversal:

-First when the node is visited for the first time and we go left.

-Second when we return from left and go right.

-Third when we return from right and print out the value.

Similarly for the in-order and pre-order traversal where we will print after going left and before going left respectively. We visit each node exactly 3 times.

Since we visit each node in the tree during the traversal, the total times the nodes are visited throughout the traversal is 3*n.

Thus the complexity is linear O(n).",5.0,79
23179,23179,27427,55ff8d4f9ee8af9848a55dc4a2a3322adb850c959c61827806d583f4f72e4caf8076da8ae41627b21a0edd1eccee2cd496b303fbcb256d41e8ba6c3b55c02e66,"We visit each node 2 times.

The BST traversal complexity is O(n2) since every node is visited twice.",2.0,79
23180,23180,27428,06f90aca60b4b2db0e6d8bb78d0ed0da22ceb02b561b842eee51951b0e04be81e8817f795eb9597349f2e3c12b7befca0ed36322cff788052acb9b91388f1fdc,"IN ORDER - this happens by going to the left subtree, back to the node, then to the right subtree. this happens to every node in the tree. so here leaf nodes will be visited once but parents nodes will be visited twice.

PRE ORDER & POST ORDER - here all nodes are visited once only

O(n) will always be the complexity in all traversals as every node has to be visited and this will never change",4.0,79
23181,23181,27429,263fd6b7e81bd2b0bd84f67415866c3d75bf78011a0e0748b552d65d3fb35fc4bf5dca96f9ccb82225afdb2c9f73d9593526bb28fe17ab6d85ae420a8a33d70d,Depending on the position of the node we may visit each node once or twice. Leaves will be visited once and internal nodes will be visited twice.,3.0,79
23182,23182,27430,a0a0e3863f2cfe81dc13120d1d5fb28060efbca078cff0afc0ca4a53755acf909a3b28053a432d02251e8d53776e3aedf7eeff75f48fc36029b0d4fb7d46aa25,"When performing a pre-order traversal, we recursively process the value of the current node, then all of the values in the left subtree and finally all of the values in the right subtree.

When performing an in-order traversal, we recursively process all of the values in the left subtree, then the value of the current node and finally all of the values in the right subtree.

When performing a post-order traversal, we recursively process all of the values in the left subtree, then all of the values in the right subtree and finally the value of the current node.

When performing these traversals, we visit each node 3 times:

	* When we visit the node for the first time
	* After processing the left subtree
	* After processing the right subtree

Based on this information, we can see that each node is visited a constant number of times and the only factor affecting the complexity of a BST traversal would be the number of nodes in the tree. This would give a BST traversal a complexity of O(n).",4.0,79
23183,23183,27431,88e4f79f72acbc7dd458837989d41695a9b36b9c96cdb3ba66c7b90921d69150d478abfb1ed6fc7e89594f6b4ccd5c2a5625a644a888136358b59b68dc7b8205,"in a DFS algorithm we start with the root and visit all the nodes of one branch

. During a traversal, if a  tree n nodes, then each node is visited once  leading to a time complexity of O(n). Each traversal requires constant work at each node therefore iterating over all n nodes will results in O(n) time. 

The complexity of  a DFS traversal is O(n+m), where m is the number of edges and n is number of nodes. Since the maximum number of edges per node (in a binary tree) is limited o 2, the number of total edges in tree will be n-1.

this results in time complexity becoming O(n+n-1) which simplifies to O(n)",2.0,79
23184,23184,27432,20820f051ab9e7b5dde112869be67e2e49734267d017f30c8e3086343a31575407d74708ebc5d385e1b1a34dd7dd81fa4425af4e6cb2bbdba32928c419b4a8da,"- W

- The time complexity is O(n) since you traverse each node once. The amount of work done for each node is constant and doesn't depend on the rest of the nodes ",3.0,79
23185,23185,27433,6ce5c22e2014cf62c3f9857f1a5d029cd8403915d5de52ffef745d92a330418a129b81b3d1fc019ceb103f7414cb06b86a44ab05670ba63e692007c026c9822e,"For all 3 traversals, you will have to visit every node in the BST exactly once therefore it is O(n)",2.0,79
23186,23186,27434,763a776e81302d0ca35787de395275bfa7dace1cb9ac6ce690e840ef2f280482559135e73ff9334c7ef80b3304e1f6061c108364e0e55bf5e56d4aafbce8e073,"when using a depth first search we would use a stack and we would start from the root and then we traverse to the left and work our way down until we reach the end thus meaning we would have to backtrack and then pop the item when the end is reach and then when we are down from the left we go to the right of the tree making sure that when we traverse to the left that we only visit the node once and because we would have to visit each node once we would traverse through the entire tree

when performing a pre-order traversal we would start by printing the value and the traverse to the left and then to the right, it takes a structure and converts it into a string whereby we can reconstruct and it would give us the BST just like the tree we started with. i.e. a copy

in-order traversal we traverse to the left and the the value(parent) and then to the right, the purpose of the in-order traversal is to get a sorted list

post-order we traverse to the left and then to the right and thus we end up printing the value in between them after traversing to the left and right

the complexity of a BST traversal is linear time O(n) because we traverse each node once",3.0,79
23187,23187,27435,efe8bbe0531a8edbaeccdc4f50ad7d19da4ae088aef554a1013cb2ff8b78ba31a24fa0e8f957d84b8c738910275c42c68da1550413f3ef77aa9c38fb88257b54,"When performing a BST traversal, each internal node is visited n + 1 times, where n is the number of children that the particular note has, while the leaves are visited only once.

So, we have n nodes to visit, and each either 1 or n + 1 times. This gives a rough expression similar to: n + (n + 1). Taking into account the fact that we start at the root, we can subtract 1 from this expression to get one that represents the number of traversal steps that we will perform:

(n - 1) + n

from this expression, it seems as though the work done is linear since

(n - 1) + n = 2n + 1 [linear]

This would then give a linear complexity O(n)",9.0,79
23188,23188,27436,20a63554bf7ab6e06ce970a9c763f370f49fc1a727f591ec7304c432565faf9d2b891194e01cc67ff029c1fe6de8363ececadce22ee4af544785f47985cda509,n,0.0,79
23189,23189,27437,df0d62df6145f98b9d8d85662b958119c20c6015becf9534b762b6d6c7c046d872ff37d4ccc77da23e1570c5a7712fc862bda45087171a56e4c5cfc3750e2ad2,"1) If we do a pr order or post order we will need to visit every node.

2) If we include include passing by a node but not evaluating that could happen about half the amount of nodes in the tree.

3) So we have to 1.5 x n operations.

4) 1.5 x n operations is a linear amount of operation and we write it as O(n)",2.0,79
23190,23190,27438,f1847bb5d29f39224664df29173ee4eea8241f8aa777b795f86bafdb3b6165e8679750df7902af2beb1387f258e9970c22324224cff020b701254fc8b35d988f,"A node that has two children would be visited 3 times, a node with two children would be visited twice and a leaf would be visited once. Based on this, the complexity of a BST traversal would be O(n) because there would be 2n-1 visits made throughout the traversal.",9.0,79
23191,23191,27439,af813686acb18a064eece7968dc86f7e1ba2e2c4ebcbfb61de992275f213a5fe2248d15ae968c61ff6c270f401a739d21132339ee0a42afa471e88a17c352ab9,"In all Pre, In, Post-order traversals we visit each node only once, the edges are also only visited once. This is because of the Depth First Search.

Taking into account that through traversals each node is visited once and each edge is visited once, the time complexity would be O(N+E). Where N is the number of nodes and E is the number of edges.",0.0,79
23192,23192,27440,c927373e71fe30f4255c61610bb88cd9a4bb26b4d4a5c6bc2711f05bbe84ffcf49fd97d920d1a706ea1e91d40784c2fadbc56f95b4fae450f318d7610a7daca1,"One would visit each node 'n' times.

The time complexity of a BST traversal is therefore O(n), because the 'n' here would represent the number of nodes in the BST. ",2.0,79
23193,23193,27441,f7bbac457e26e926aa83f65c706f322284bcae4a69df367438ec5060865432bf63d2eef51ed308d86119a8e1745e619fe74662cd103d43378e65328b7630ff57,"Each node will be visited exactly two times.

The time complexity will be O(n) as you will only traverse through one node at a time. n will dependent on the size of the value you are searching for however it will always be linear time.  ",3.0,79
23194,23194,27442,b9d82cd7c247fea1955a43aaaf5bb439ce7f4f53d3df9728ceb44f0e1b947c368ff1574400183b4d31d82813774edfdb38a1fdb56e3256ef8ab3e682f8c08da1,"We visit each node depending on how many children they have. If a node has no children then the node will only be visited once before backtracking takes place to the previous node. If a node has one child then it will be visited twice before backtracking to the previous node occurs. If a node has two children then the node will be visited three times.

Children + 1 = times visited

The traversal would take O(n) complexity because each node would need to be visited at least once to traverse through the whole BST.",8.0,79
23195,23195,27443,e7c9b4fd869eb791a63c71759d17fa7e8a93618d661588fa6ae371946756531c0923d86aafe2bfd7289d74b69cb5fe841e3839957a75e6446f2d8394b4178536,"Each node will be visited at least once.

Thus I think the complexity will be O(n), reason being each node is visited once therefore if we 10 nodes it'll take O(10) so n is the number of nodes in the tree.",2.0,79
23196,23196,27444,d79246b4e37ca7cbd7cba0e73e77371bc01ee0686edc183593c8b72f08af7f56885ea93e866878670f104cfe50f22453d301d67ae7614531bda51a9f07fc7424,"In each tree traversal you will visit each node once to traverse the whole tree. When backtracking you will come back from the leaf of each path that was incorrect meaning you will visit all the interior nodes once again in the case that the value isnt in the tree. But the leafs will only be visited once as you will backtrack from there and not check that value again as it was already checked.

In the worst case, the value isnt found in the tree and the complexity would be O(n) as it will have to go through the entire tree.

In the best case the value is the root taking O(1) time.",4.0,79
23197,23197,27445,c7d75d976a010a38db71e259afee15ce7c42ba18fa8ef2214021124356299e2bc696f235d69042a2e7d6021b611ee4096167f90988dc7b1e755fca98c40f31fd,"When the root has two children, we will visit the root 2 times when performing pre, in or post-order traversal.

When the root has no children and the root is the only node in the tree, we would only visit it once when doing all 3 traversals.

The internal nodes with two children will be visited 3 times. If it has only one child, it will be visited 2 times.

The leaves will only be visited once when doing all three traversals.

The complexity of a BST traversal in Big-O notation will be O(n) time because when traversing for the pre, in or post order traversal, we will have to visit all the nodes in the tree.",8.0,79
23198,23198,27446,6c39b5e6a07e95287c054b22b9b14ae724def23d44c2473ffa57fa66d0dc3ed81fdc207205fd37cd3342b92b02f8364dc720791f8b6724f778e183c98d663fa5,"The pre-order traversal has us visiting the node and using the value during the first visit, it then goes to the children and has to visit the node once for each child due to backtracking. In the worst case being the node has 2 children, it is visited 3 times. In the best case the node has no children and is visited 1. In the case that the node has one child it is visited 2. This shows a formula of the number of visits being x+1, where x is the number of children of the node.

The in-order traversal has us visiting the node and not using the value during the first visit, it then goes to the left child, backtracks, uses the node value, goes to the right and then backtracks. In the worst case being the node has 2 children, it is visited 3 times. In the best case the node has no children and is visited 1. In the case that the node has one child it is visited 2. This shows a formula of the number of visits being x+1, where x is the number of children of the node

The post-order traversal has us visiting the node and not using the value during the first visit, it then goes to the left child, backtracks, goes to the right, backtracks and then uses the node value. In the worst case being the node has 2 children, it is visited 3 times. In the best case the node has no children and is visited 1. In the case that the node has one child it is visited 2. This shows a formula of the number of visits being x+1, where x is the number of children of the node

All traversals have the same formula for number of visits, dependent on the number of children for each node. This gives a formula for total visits to be n(x+1), where x is the number of children for a respective node and can either be 0,1 or 2. If we treat x as any of these we get a linear time complexity.

Thus all traversals will use O(n) time",8.0,79
23199,23199,27447,d31899b98e7fb3e761998737c0078a84e48727b178f33ae85b1caf85762f7c95a36780c3f84b13e4c3f8980c15788bdfcc7bddbb75a6b63b7a164f238d74d926,"If we were consider backtracking as visiting then only the leaves would be visited once. To calculate the amount of times each node is visited take the height of the node and add one (h + 1). However, if we do not consider backtracking as visiting the nodes, then each node is visited exactly once despite the recursive algorithm. 

Pre, in and post order traversals split and recursively call the left and right subtrees. In other words they divide the tree in half O(n/2), since it happens twice (left and right) this would be 2*O(n/2) and taking into consideration the printing of the values we would need to add a constant resulting in 2*O(n/2) + 1 time.

However since we are working with Big-Oh it suffices to say that the time complexity is simply O(n) time.",4.0,79
23200,23200,27448,e3ed8ae95e5b6d1651bf9302238959432ea0a53fe9eaf1c6d43781285ba398dd6c3e684c62871ee07f37076d5f77cd450bb218b0ee1d76a4f2732d8978e631aa,"When implementing a depth First Search, it takes n-1 times when the tree is in linked list format and takes logn times when the tree is complete to visit each node on the tree.

The Depth First Search takes linear time[ O(n) ] when the tree is in linked list format, this is due to the fact that we will visit the nodes of the tree for every single level of the tree. So it will take much longer when the tree has many levels, to which we have to reach the leaf. And takes logarithmic time[ O(logn)] when the tree is complete. Meaning it will take less times as we will visit the leaves quicker.",2.0,79
23201,23201,27449,c318ecd5c05d3ffa65238b75e8aa9e67390cc6fb32c2fdbfaf84c4d21eee7f78cf713a8bc77a69838390c129742df9afc0ddd3cf48a8b7ef5ea2fb0f43dc4114,"When performing traversals, we will visit a leaf node once, a parent node with one child twice and a parent node with two children three times. This includes backtracking.

Thus, since we visit each node a constant number of times depending on what category node it is, and we do this for each node in the bts (of which there are n nodes),  we will end up with a linear equation for the number of times we visit the all nodes and hence the complexity is linear at O(n).",9.0,79
23202,23202,27450,c2a635a9bcf4ad40fa50102eeb50a8298caf1f43a284d43931e8d6ff78372592382df0d5a087e759cf9a231e99eb6b2b3a8890e03edb12bf9295b2611174eebb,"When performing a pre order traversal the algorithm is Value, Left, Right which indicates that we visit each node in the tree therefore if there are n nodes we visit each node once which is n. Therefore the time complexity for the traversal algorithm would be O(n) for n nodes. 

A BST is made up of nodes and edges. In the worst case we would need to visit each node and each edge at least once which would make the time complexity of the BST traversal: O(nodes + edges) and if it is for n items the time complexity would be: 

O(n+(n-1)) => O(n+n-1) => O(2n-1) => O(2n)",5.0,79
23203,23203,27451,7034e661a6b51c59ff4e839b7430fa79082c9a14de4d5507d8b8f51bcf2e8507159f0b9ac4f2f0968d640ca40b95ebbbfcb9a489ff8f5bfe6ee49d4e9a458d5c,"We visit each parent node at least twice. We visit a leaf node only once.

The complexity of a BTS traversal is O(n) because we only need on loop.",4.0,79
23204,23204,27452,ec66e4473040e8ee3556fe295a682aef55293bdc440d5beebc8fb799f1964c0abc0afc761e0c9e5b3dec6cb5d26467ba51d5e312925807725d0b86097bb74bce,"How many times we visit a node is dependent on the number of children it has. Leaf nodes will only have to be visited once. Nodes with one child will be visited twice, and nodes with two children will be visited 3 times. The complexity of a BST traversal is O(logn) as the cost of traversing is lower the further down the tree you get.",6.0,79
23205,23205,27453,96ff995bc15298c864dd95ff4cd06e43f5504516f71d4f78f5c1f0733e5ceb2f157113507e8caf3713f3b3d57604ab1b94ede00706cbfa87faf4d4af71c1a3db,"For each DFS traversal, whether pre, post, or in - order, each edge in the tree will be 'crossed'/ traversed twice. Therefore i think the complexity of a BST DFS is O(2(n-1)); a linear complexity.",2.0,79
23206,23206,27454,b62aa4d567faf4c8c2d7b435cab87c30c9d1e6af89f8a0e3d7867630ef600446840f333742c814bc8a0c9d2f0ab23474abdecc13d41d7312f08a47b7fc5bb67c,"When performing these traversals, we may visit a node a proportional amount of times.

in the case of pre order traversal we visit each node only once, with a complexity of O(n)

in the case of post order traversal we visit each node only once, with a complexity of O(n)

in the case of in order traversal we visit each node only once, with a complexity of O(n)

Therefore the complexity of the BST is O(n) in the worst case and in general it would correspond to the height of the tree resulting in an O(h) complexity where h is the height of the tree.",3.0,79
23207,23207,27455,662455ba865b7fa66132ae6520e999c9ea1b9fa1f85d0b16ee30bd84db7aa0bec3c7fd7269d6521a07e1ad16d091e298c84cb6c69ff3537fa78efdac09fa4677,"In all three cases, pre-order , in-order and post order, we will visit the nodes more than once.

Consider performing a pre-order traversal on a binary search tree, we will need to visit the parent node. We then perform the search on its left child and return to the parent node before performing the search on the right node. Therefore we will visit the node three times:

1: Arrived on node. We now check the left child node

2: We checked the left child node and are now back at the parent node. Now do the right node.

3: We checked the right child node and are now back at the parent node.

After this, we return to the current parent nodes' parent node.

Similarly, for in-order and post-order traversals where the only difference being the order of nodes.

We visit each node exactly three times in a similar manner to pre-order traversals. 

From this I can conclude that:

Considering that visiting every node (n nodes) on a Binary search tree is linear time O(n) and that we visit every node 3 times the time complexity of BST Traversals are 3 visits for n nodes -> 3n.

Giving us a complexity of O(3n) -> O(n)",5.0,79
23208,23208,27456,8a35389fd7c8ad2535687771b1bb68c8efb0b7de8dcab378f3a060f04342ee373ba7cc2c9fd072651f8268858486a9bd9dd5269dda1258346fc90ac33d038576,Each element is visited once. When recursively calling the function we let the program traverse through the subtrees of each element. So it depends on how many elements we have and that means the time complexity should be O(n).,3.0,79
23209,23209,27457,c33667ae11b7bded2337c08d116fa497bbbd12dbb6b1affa7fb94c650c68ba165865aab5e81895db475a23ff725c4bc69da22573104a9522dcaf9138fd9b447c,"Each node gets visited twice.

The complexity of a BST traversal is  0(logn). Because we visit each node twice and therefore with each traversal the time required to find the next is decreased in a logathrimic function.   ",0.0,79
23210,23210,27458,74594d76e743115e9e80c4119a5039c4fec5aed2b1eb9af70c89d53a42b69ad2163ffd8ce8a40f97632e4be0cb18aad097e1d70fac3137214bb4656688c9555b,"Using a Depth First Search for traversal of a Binary Search Tree will visit each node of the tree exactly 1 + children_count of each node. Therefore leaf nodes will be visited once, a full node will be visited three times, and a internal node with one child will be visited twice.

Given the worst case tree of size n, the complexity of the traversal will be O(2(n-1)+1) and therefore O(n) as n-1 nodes will be visited twice and the leaf node will be visited once.

Given a balanced tree of size n, the complexity of the traversal will be O(3(n-2^h) + 2^h) simplified as O(n-2^h) as there are 2^h leaf nodes in a balanced tree to be visited once, and all the internal nodes have two children, therefore visited three times. h is given by log_2(n+1)-1 therefore O(n-2^logn)

As these cases are the best and worst case constructions of a binary search tree, the traversal complexity can be given as a inequality between these two cases therefore the complexity of any size n tree (O_n) is n-2^logn <= O_n <= n",9.0,79
23211,23211,27459,936024d8e9328998a220b77c48098f57a0d619263f7c2ad0ac4157dfe9370e11abee7f579d65a28c46224757256e636c01fe798d4c5eb4d7e1574b7de8511fbf,"In the In-order, we visit the left subtree, then root node and lastly then the right subtree. In pre-order we visit the root first, the left subtree second and then the right subtree. In the post-order we first visit the left subtree, then the right subtree and last the root node.

We visit each node only once for all traversals.

The traversals visits each node in the tree once, therefore the complexity for the BST traversals is O(n) when the tree contains N nodes.",2.0,79
23212,23212,27460,67bc8fffe61d28188b3d7107d51be90441e6dd51c98f3db877749a2a97847646dc952b6812856f170fac011bfccdf49477179e4f3e8c4e51b5aea238df99b414,We visit each node once so the time complexity will be (n),2.0,79
23213,23213,27461,fd0ace311926a44973b18eb55c0a2df285cc4ef58cf67836be1c2719041ca75111c81115da37e4e4879d8c00ffb63db68cb0de1c85a3fc373724acf7945dc463,"Each node that has 0 children is visited exactly once. Each node that has 1 child is visited exactly twice. Each node that has 2 children is visited exactly 3 times. 

A BST traversal has complexity of O(logn) because this is the worst case the traversal can have and does not have a best case. No matter how much the number of nodes grow the run time of the traversal grows logarithmically.",6.0,79
23214,23214,27462,3833aa3ef06cafdc78971652ad20444fe164affcf92c03de12570129a147987ae3263043850e741f6f77f4965176d32cb0f7b6200e6f1f08cf0158b373dc6fbe,We visit the root and the internal nodes 2 times and the leaves once for all of the traversals. The time complexity of a BST traversal  constant time or O(n) which comes from the fact that it passes the leaves once and it passes the rest of the nodes twice O(n+m) where n is the number of notes and m the number of edges. The number of edges are one less than the number of nodes therefore it becomes O(n+n-1)= O(2n-1) which is then simplified to remove hardware coefficients to O(n).,6.0,79
23215,23215,27463,ab914ab560d18c5aef3e43bda3ed23f3106afabfcaabd71fb45ebbdc423746252b1d705ea396aa70f877858829d5c8d335f73b945106c9ea584789a7d7f0ea77,"We visit each node exactly 3 times, regardless of whether we are doing a pre,in or post-order traversal. Thus if we have n nodes, and we visit each node 3 times, the time complexity would be O(3 x n) which would simplify to O(n). If we have a single node in the tree, we will have a time complexity of O(1)",4.0,79
23216,23216,27464,2639eb56a1989682f1b8fb8c5a3437ea6a5d663be094f02f4aaae47dc57a1af7165cfaae33d61d670e26c96083744d494e42187a468df938459fc0c70030a175,In a Binary Search Tree when we doing a depth first search we will start at the root and first visit a all the children of an internal branch and go as deep as possible before we start backtracking and we will do that for all other internal nodes. So we will visit each node exactly 3 times which will take O(n) time unless we have a single tree with only one root we will do O(1) times,3.0,79
23217,23217,27465,52b1f6fd8e6c0289a8004d7d61b231157f72159bdb1098720813eb6a4750543a581c16358208b2fe293a6bc58612fe418d8dd4bccc56d715f7137f43db02b99f,"You would visit a node at least 2 times. 

The time complexity for a BST traversal would be dependent on the n nodes. 
Worse case would be if the n nodes corresponds to the height of the tree, making it an O(n) time complexity. 

If it is a perfect Binary tree, then the time complexity would O(logn).

If there is only a root node, then the time complexity would be O(1) constant time. ",0.0,79
23218,23218,27466,fe62a1f5e7fe2a4e7ab8c966f31166711ff57cc766445f2fc4370a7348f81dab059b866c1f91a4b1ff166d595fb9234d29f7f66b2297a565d84b506f3bd0f6e7,"We visit each node exactly once for each traversal. Even if we backtrack or do the traversals recursively we only visit each node once. 
for these traversals , there are different paths through the tree but all of them visit a node once. this means the pre, in , and post order traversals are of complexity O(n) with n being  the number of tree nodes. 

These 3 traversals are a specific case of a BST traversal. for more general traversals of a BST we have :

 the best cases and  most average cases do not visit each node as they find an optimal, non-linear path through the tree . this gives an O(log(n)) complexity for best and average cases for binary search trees.

However, if we have the worst case , a degenerate tree , or linear tree,  or we traverse for a value that is not  present in the tree we have a time complexity of O(n).",4.0,79
23219,23219,27467,7f4b419d2ced93d50fb8649f87b2fa3a1ab4c6a1ecc8b63f150aeb372237c21eae97c5eba18c0880eb018ac5d3fb68e9a7180e8af2cbb1d90dc8d7f06f63f097,"Generally Since the BST has n nodes as a depth first search, each node has to be visited once. For each of the traversals each node is visited once and printed accordingly. 

but since backtracking through a node is considered to be revisiting that node again, the number of times a node is visited is doubled. So a node n gets visited 2n. 

In terms of Big-O Notation, the time complexity will be O(n) even though backtracking doubles the time, which still remains constant (2*n generally is n). This is because to traverse through a tree every node is visited in order to give us either the Pre, In or Post-order traversal as we are looking to see if that node is null or not before printing the traversals.",6.0,79
23220,23220,27468,18f6254c7b196766dbebfb4556ef6c2f9ff5e44918d8ea60921fbe90c8a42515b04ace17b80ecdd7f09efd69961a6da2d4a21f100e3ebd5acf67acba7ebaae55,"for all the traversals, if a node does not have any children, it is visited only once. For post-order traversal, if a node has two children , it is visited three times. If it has one child it is visited two times.

for in-order traversal and pre-order traversal, if a node has two children , it is visited three times except the root which is visited twice.  If it has one child it is visited two times except the root which is visited once.

The complexity is O(n), because we have to visit every node in the tree.",7.0,79
23221,23221,27469,833bd82b84984eac1561a2aa471c7fa8ce8fc83eb43410d162adbb99836f9c60ca90f110500d0a4cfae027c10757354954059b39ea510643c3c10d5e8f6e1bb9,"We visit each node once in each traversal, but we visit all the nodes, so we do a linear amount of work.

if there is only the root node then we just the root's value. otherwise we do the traversals.

O(n)",3.0,79
23222,23222,27470,db2da6294f4863255b8e851f3219cc1d358a9a52af31fcce04dfd21a77bd1b6105ebfb54ad3aa0cbea5dc9fb93c67b5af9e1ff40b17fbd626a20ad3636813679,"2^n worst case

1 best case

O(2^n) because in the worst case the node we are looking for is not on the tree soo we will visit each and every node.

O(1) in the best case where the node we are looking for is the root of the tree.",1.0,79
23223,23223,27471,7a27fb1fa642a9bd3d76e8ce98be5e4779f4184eab8b901b0ee0d165d466de6122db493ca631d33ef289f724ffb838136d578f3b72df159667217c69ae154ed3,"For a PRE ORDER TRAVERSAL, we print the value of the current node first then explore the subtree to its left, then the subtree on its right. Given a BST with n nodes, each leaf will only be visited only once. All internal nodes will be visited a maximum of 3 times. The internal nodes with 2 children will be visited 3 times and the internal nodes with only 1 child will only be visited 2 times. The total number of visits to each node correspond to the sum of the number of nodes and the total edges in the BST. (say N = total number of nodes; e = total number of edges) Given this information, the complexity of a PRE ORDER TRAVERSAL is O(N+e).

For an IN ORDER TRAVERSAL, the left subtree of the current node is visited first, then the current node is vistied, and then the right subtree of the current node is visited. Each leaf in this traversal also only gets visited once. And all other internal nodes gets visited at maimum 3 times. The nodes with 2 children gets visited 3 times and the nodes with 2 children gets visited 2 times. It is similar to the PRE ORDER TRAVERSAL. The complexity of this traversal is also O(N + e).

The same can be said about POST ORDER TRAVERSAL, post order traversal visits the left subtree of the current node, then the right then back to the current node. Given any BSt with n nodes, it can be seen that the same behaviour (to the pre and in order traversal) results from a postorder traversal. So the POST ORDERS complexity is also O(N + e).

In conclusion, it can be seen that BST traversal has a complexity of O(N + e), we know that the number of edges in a BST corresponds to (e = N - 1). Hence, it can be said that the complexity of BST traversals are O(N + N - 1) which is just O(n).",9.0,79
23224,23224,27472,16f09d60ea55f541a3437e3e2ab8e9c69f838f50f98dec712996c73779cd9f654e7fa72007ae7a3b8d9cb813c8fad8d686dc40ba57c222e292c85b1a88fc8b53,"since we each node only has a possibility of having one or two nodes, not more or less, and the number of edges in a tree is n-1, we only visit each node ONE time. 

therefore, the complexity of a pre, post or in-order traversal has constant time complexity: O(n).",2.0,79
23225,23225,27473,2238995f0ead9a3412ecc8b42340b20d5862bf47d5493b0c9fbe94b4e46ffb57c2cf52b4dd296cee7b6850d8a44e160d6bd1d96e80ab144e928044e44043acc6,"for each of these traversals, we visit each node once.

the complexity of a BST traversal is O(n), because n visits are performed.",4.0,79
23226,23226,27474,c9533083b36a5867d42e175e5d9226d460bac0f67119822f32ea58c60b5c8ae66655217031dc5ae111931d8c34d1a88f17b852726bf446acb3dd87422ab66355, ,0.0,79
23227,23227,27475,bacea88b3884d2acdf5b94b564c3ec6827ffca9c96b92221f37418e3f06607a9773dd54e02efe11a3f31dcc55f103233551301f8c7dbd6ce23f465133edd2ef3,"Since in the Depth First Search, we are visiting each node until we reach a dead-end, and backtrack to a different path in the BST until there are no more paths and backtrack to the root, it means we are visiting each node twice except the nodes in the dead-end( or except leaves which have no children).

If there is only one node that can be the root, we reaching the dead-end already and backtracking will not be allowed, hence we will be visiting that node once.

The complexity of a BST traversal will depend on the structure of the Binary Search Tree. In the best case, if the BST is structured in the way that the height is the shortest it can be, in Big-O Notation, the complexity is O(log(n)). This is because, depending on the depth of the node, we may traverse through each node more than once in an exponential fashion. 

If the BST is structured in the way of having the maximum height it can get, the complexity becomes O(n) because, we traversing along the longest path possible and this is the worst case, if we need to traverse till the dead-end and backtrack again.",5.0,79
23228,23228,27476,f568f900863758606ecd596c211921a4e2f0720e3778a3f2c91b74ff667248e8a2d4bcea0036dc07a6e043d08d7d7b64e5934aa3ba779587a955877ff84bfb17,"The tome complexity would be O(h), with h being the height, as you would need to go right to the bottom leaf node ( basically the last level of the tree) in order to try and find which value you are looking for or to traverse through the tree.  ",0.0,79
23229,23229,27477,482f7dae015b4c467d12506c33e2fe66aeff1ddddb85f2c9bce0e0756918b84a46072cd434d5bf20b674533a59b9c793d9d747268246eec497aed1c0f31a1c3c,"Pre-order Traversal (current-left-right): Visit the current node before visiting any nodes inside left or right subtrees, Each node visited once

In-Order Traversal (left-current-right): Visit all the nodes in the left subtree then the current node and then the right subtree. Each node visited once

Post-Order Traversal (left-right-current): Visit all the nodes in the left and right subtree before the current. Each node visited once

Time Complexity is O(n) as we traverse the entire tree as we access all the nodes in the tree.",3.0,79
23230,23230,27478,1d906c438dbb2a0adc2a7e04ed6b3c53c2ee28b5c43a5e83e583d5199a13a7bb6abb74579e2679fb4b6602b8efe2849ab290c6db2b1f573c02a4880312c09f25,"Starting from the root (as the first node we visit), then visit the node on the left. we would have to see if each node has been visited or not before we add it to the stack. So to see how many times we visit each node would be equivalent to n (number of nodes) nd edges.

time complexity would depend on the number of edges, E and vertices V. Therefore,

O(V+E). ",0.0,79
23231,23231,27479,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"We visit each node once in sorted order.  In the worst case is O(n) and in the best case is O(log n)

The time complexity of a BST traversal is O(log n) because the height becomes log n.",4.0,79
23232,23232,27480,aba8ccda4763601c960552191c4b4ea7d3e94521d25f84c03f905aac0bf9578acabd1a7e87e98918c1a32dbc6bc0f00b14222dbc9e37a19a4efb13f1c52924d7,"We visit each node until we hit a dead end, that is the height of the node.

If the node is a leaf, we will visit there once only, but if it is an internal node, then we will visit left , come back and visit right of the node recursively until we reach an end.

for pre, in or post-order traversal we will only visit each node once, once we get the values we are traversing left or right till we hit an end.

Complexity depends on the level order of the tree. ",4.0,79
23233,23233,27481,8f6fce38f378bd03b7e3015540844be6bf9823c5ceeeee423c75e7180e2218c7f9853b96b276e10dcc9cefdaf4b85b6d869df1573ced7bc1eae58f615449e857,"if a node is a leaf it will be visited once. 

if a node is a parent with one child and is the root of the last subtree being visited, it will be visited once as no backtracking will be done. 

if a node is a parent with one child and is not the root of the last subtree being visited, it will be visited twice as it will need to be visited once for traversal and once for backtracking. 

if a node is a parent with two children and is the root of the last subtree being visited, then it will be visited twice (once for itself and once for backtracking to get to the child)

if a node is a parent with two children and is not the last subtree being visited, it will be visited three times. once for its own traversal, once to backtrack to the other child and lastly to backtrack to its parent to continue the traversal. 

the complexity of a traversal will be O(n) because each node will be visited a constant number of times based on its position in the tree, so if we have n nodes we may have a time of O(an) where a is the sum of all the numbers of traversals each node undergoes. But O(an) is nothing but O(n).",9.0,79
23234,23234,27482,5b79e321acf32f26a1c6cc9091fa349a8baa70385c6fb736e55b942fea1901b561d1f53857749ead207a2933e580c9dfc66c9af868e9b035d1dff322ef7cd5be,"If the tree has a best case height of O(logn)  we would some nodes twice and some once and the time complexity of the traversal would be logarithmic 
if the tree has worst case height of O(n) we would visit the nodes once and the and the time complexity of the of the traversal would be linear 

The time complexity of a BST traversal would be O(logn) since the BST is more likely to have a best case height of O(logn) instead of the worst case height O(n).",0.0,79
23235,23235,27483,1d469feec8dabc8efe190b91bf2431897a77efbd16b2d85bdc6124d89beaeb95e4c3d1758db03e27ba5dac6295ff2b30f3eaaa927d0748ab45ecd18c4991abfb,"Using backtracking we visit each node at least two times but the time complexity of the whole tree is logarithmic and in big-O notation it is O(logn) for pre, in, post-order transversal ",1.0,79
23236,23236,27484,8988e05f865164f4560af96560c21e55905eac0bb5f61f3d6e278f9698c3b2aef4e2c138e098da5e867aaa523133fd657970eaa9429e994d798d7fd717f54fcc,"If we perform these three traversals as a Depth First Search, that means that every node that has a child/children/subtree will also be revisited when we backtrack. If an internal node has one child, then it will only be revisited once. If it has two children, it will be revisited twice. If the node is a leaf, it will only be visited once.

Therefore, if we have a tree with n nodes, m leaves, p internal nodes with one child and q nodes with two children, the number of times we visit each node in the tree is given by:

m + 2p + 3q = m + 2(n-q-m) + 3(n-p-m)

= 2n + 3n - 4m - 2q - 3p

= (5n) - 4m - 2q - 3p

Thus, a BST traversal using a Depth First Search takes O(n) work.",10.0,79
23237,23237,27485,55ea1e4f47f56380767c8e74fc048f88ea3f77cbdba15f1928ce2c49d72fc6281a93cc53faad127cf63dd846a712edf93d7e45216338f7bc4ae6a26df95dd66e,"The complexity of a Depth First traversal would be O(the no. of nodes + the no. of edges) therefore it will be O(n)

The complexity is O(n) because you traverse each node at least once and the amount of work you do for each node is constant therefore it'll be O(n) regardless.",2.0,79
23238,23238,27486,4ee5c3f6edd0831bd10d63a696f6638df5b754a34f97686d41e648c7e383b2fbf2f7080c3b7f108b718723955a3e61137ab00a8d8d64c8fb5453ee8eef444085,"* in a pre-oder traversal we visit each node once before visiting its children. time complexity of preorder is O(n) since the amount of work you do for each node is constant
	* in postorder traversal, the node we are looking at is once visited after its children. time complexity of postorder is O(n) since the amount of work you do for each node is constant",4.0,79
23239,23239,27487,9a6d2e6e6e0c1b575d6fd6f9cd31a3d7ef05b9fbb8f9b527d2f24c66326f4e25fb885d747e3511e370820c0e5c65531a52fb8637b76c7b43895037c2420cfc80,"In-order, Pre-order, and Post-order traversals are Depth-First traversals.

For a Graph, the complexity of a Depth First Traversal is O(n + m), where n is the number of nodes, and m is the number of edges.

Since a Binary Tree is also a Graph, the same applies here. The complexity of each of these Depth-first traversals is O(n+m).

Since the number of edges that can originate from a node is limited to 2 in the case of a Binary Tree, the maximum number of total edges in a Binary Tree is n-1, where n is the total number of nodes.

The complexity then becomes O(n + n-1), which is O(n).",2.0,79
23240,23240,27488,e81419dfc1d9569cd33a892060afd65b53683380b098be177940b37177a69388dbc26f4b88ae9117e614069eb6d29407e325e18a19fd38be90fa494f6adff772,"Doing a depth first search with n nodes in a BST whether it be a pre, in, or post-order traversal we visit each node 3 times. (once when we actually reach the node for the first time then once when we check if it has a left child (may or may not have one) and then if it has a right child (may or may not have one). Thus we visit each node 3 times after we have completed our left and right subtree checks and then backtracked to the parent of the node. Therefore we check each node three times. So what happens is: We visit a new node (visited 1st time) then we check if it has a left child (if it does we follow the path and if it doesn't we hit a nullptr) once we are done with the possible left subtree we come back to the same node (visited 2nd time) and check if it has a right child (if it does we follow the path and if it doesn't then we hit a nullptr) once we are done with that possible right subtree we return to the original node (visited 3rd time) and then go to the parent of the node. If we were to check each node once then we would have O(n) but now we have visited them 3 times each so the complexity goes to O(3n) but since we do not really care about the constant 3 so we have a linear complexity O(n). That was the general case. There do exist special cases such as if our BST only contained a root (no children) then our complexity would be O(1) since we just check 3 times and if our tree is empty it too is done in constant time O(1) as there is nothing to check since the root pointer is a nullptr. Thus I think the complexity of a BST traversal is linear time O(n) since we visit each node three times and there are n nodes so in total we get to O(3n) which is in essence O(n) - linear complexity.",4.0,79
23241,23241,27489,525cefc66631b9eb601410acc1c632cc3a6d9976bb8f3ac653d46807a4053f29a6c3c85a0e8a38a43486b45bae46acd949e27f910bf00828afed11257c7034f3,"In all three tree traversal methods we visit a single node three times or less, depending on the shape/type of tree we are traversing. Because of this I think the time complexity would be O(n) [linear] and quadratic in the worst cases O(n**2).",3.0,79
23242,23242,27490,66ba5975b098f5fa2bae0b86dceb6b280b99b8f4c6fff5dafe0a067b8a9153b49a39abe1525261732c63d25886c01c121ff46cf2ab2721a603f04674ea202257,"All 3 types of traversals require you to visit each node once. The time complexity of a depth first search traversal, with both recursive and iterative algorithms, is O(n+m) where m is the number of edges and since the number of child nodes is limited to 2, this can be written as O(n). ",2.0,79
23243,23243,27491,e1c10c192c9b6713ee5530dae2906c490884e9be67695456a693eb32bfedb4efb69953c8625279092ed97ffe2902abb90cc745c3952924b4e2ed73997890c89f,"We visit each node one to three times (depending on the number of children it has), giving an O notation of O(n).",5.0,79
23244,23244,27492,ea2a1bfcbe729f7621c917f77c54d68d14594e336635f36baf52750af4fc628657adce12683b4083425f0f9b883a0f335d02fe57cab5815e5cb77320840dd672,We visit each node exactly once and it will only put a node into a stack once and also explore very edge once too. it's time complexity would be dependent on the number of nodes and edges (0(no. of edges and nodes)). This is because the more nodes and edges there are then the longer it would take to traverse the the tree. If we were backtracking then we would visit each node twice at least since we would need come back some nodes to traverse back to the root - the time complexity for this would be 0(n).,5.0,79
23245,23245,27493,0210a9d3772d4f5814d5d585f47b6503d720f89ae8ca72b5fb7136f3da85dccbdba73ac11df998e73774b6321c99446733c7c479dc009a4e0dc92678413ef102,"In pre-order traversal we visit the root , traverse the left subtree and the traverse the right subtree.

In in-order traversal we traverse the left subtree, visit the root  and the traverse the right subtree.

In post-order traversal we traverse the left subtree  ,traverse the right subtree and visit the root  .

It the complexity of O(n) ,because each node is visited once. ",4.0,79
23246,23246,27494,17af69de9b004cebc772407eb454a4695fd215d61e6315c9d12ef0dd3a08b8a8642b4cc8dfc787e7755ff0571045a1730ffe50dbf1069009256ea87e870d4fed,Each node is visited once in all three traversals. The complexity would be O(n).,2.0,79
23247,23247,27495,feedd29892cd7ac7cbb3dcf2ebf122ea0910da8e729a40522cfec73f98427f11e38a2954619cb37c8da0cffc3dcb3d21b0fc9b9cb5630f1a8e01a0691d1d3af8,n-1,0.0,79
23248,23248,27496,4427e3a6ae2786ed5636c638581416e62adf38c90aed72214004ce5b4fc79bb1e5696556f9677084defd90b33f5cf052534401db22ff6a075c7131169ee1bcf8,"Each node will be visited a maximum of 3 times.. 

The complexity will be  O(n) because as the number of nodes increases we would have to got through more nodes. ",3.0,79
23249,23249,27497,cb120576f9fc254cce2a2bdcc2fab8a2f95f1ad24a5398cde6a97bb68344852b25ff6ddb6448c5c344141e6c8f5ee1dd504e841ca984819c02a7811908c51bc8,"While performing traversals (pre, in or post) the minimum amount of times a node will be visited will be once, even the worst case a node will be visited less than _n _times.

We can deduce from this that the amount of work being done will be (_n + x_) where _x _is the total number of times other nodes have been visited when they have been visited more than once, in big-O notation this becomes O(n) work being done to traverse through the tree.",6.0,79
23250,23250,27498,562a79f866657142ac8bf9d260020a41dd948177d2bce6c88383e228d52056cf2d2544e838847e98137352689514e6b5fccb58b9b8779b353c6c283dfc7313ad,"The first case to consider is when we have a perfect  binary tree where every internal node has two children . If we consider doing work on a node as also visiting that node and also backtracking through it as visiting it we see that for a node that has two children we are going to backtrack through it two times , once every time when going to the left or right subtree from this we see that if there are n internal nodes in this perfect tree then we are going to do 3n amount of work on the internal nodes. Since the number of leaves on this tree will be 2h we note that the total amount of work done will be 3n + 2h which is some linear function and thus we see that the complexity of these traversals on this tree will be O(n).

The second case to consider will be when we have one child for  all the nodes in the tree . This means we are going to only do 2 times the visitation work on a subtree then it becomes clear that we are still going to do O(n) work.

The third case could be when we have either 2 children or one child on a node, this means on some nodes we are going to do 2 times work and on some nodes do 3 times work. let number of nodes with only one child be x and let number of nodes with two children be k . If on a perfect binary tree we have that we do 3n + 2h work, we can define number of nodes in tree in terms of x and k -> number = x+k,  this means the amount of work done will be the work done on x and the work done on k, the work done on x will be 2x and the one one on k will be 3k but we also have to take account for the constant work done on leaves so lets let that be z, in simple terms we see that the work done will be z + 2x + 3k which is O(n), one could have also considered the work done on the tree it if was perfect then subtracted the work done on a single node that has one child times the number of such nodes and  this would have also been some linear function in terms of n therefore O(n).",10.0,79
23251,23251,27499,a18d348d984f5bd8aca6ebc4fccb86f8d160a802b4c7ee70a595f3b8caf6c18513e302bc5cfcbf90d284bd7a320b1536220dd429aa4a21d61efb3ef1771458a4,"In order to do a traversal through a tree we recursively move through all the nodes and their children. So if a node has two children we visit the left child subtree, return to the node, and then visit the right child subtree before again returning to the node. So for nodes of two children each we are visiting the nodes three times each.

For one child, we'd visit the node twice and for a leaf we'd visit the node only once (when we add it to the traversal)

So the cost would be O(3n + 2n+n)= O(n)",10.0,79
23252,23252,27500,9723aae78697f512e67589fc396726b9c942a3d3f5596d681f9e90a55d7c7cee67b2655817396577b22474e4f116aa7866389d9d9a43a0c0e1dd45d6998cde32,The complexity of a BST traversal would be O(n) beacause you traverse through each node once. The amount of work you do for each node does not depend on the rest of the nodes.,3.0,79
23253,23253,27501,a0052d1186f3fa53f67763ddf5dc1148fc540657d42f0891ff3ac99ce8c9f5c8c2cc81fa44f5583e909b3bdda1a0f1e6a21067a67ce2ede8b9d60f7eef57955f,"Post order traversal:
If the number we are searching for is a leaf, we will visit each leaf at most once but each parent with h = 1 at most twice. This is because Post order gives access to leaves but we traverse to get to second child and after to check.

If number is not a leaf, and has a height of 1, again we visit at most twice and then would come to the number and looking for second child. Same goes for larger heights.

Pre order 

If the number we are searching for is a leaf, at most 2. The same goes for backtracking to travel between children and to check the actual parents. Even if not a leaf, this pretty much holds

In order

Max visit is 2. As when we move between children, we check anyway. Once we move from left child t right child, we never should go back left. But then we have to go back to parents parents, after right child, which would backtrack through parent.

I think complexity of a traversal is constant. That is assuming you have access to the parent and don't need to traverse to find it. You simple navigate the value stored in the parent, which is not related to position on tree. 

 ",4.0,79
23254,23254,27502,5cd0a202ef51535fb2cf79db8f13b432c752afb35952cb0416813c6c757163698e13f6f62bd6292909baa9745f2197e7ed5a1f16eebc10eb62867568861dbf00,"For each of these traversals, the number of times we visit each node is dependent on the number of children each node has. If we include starting at the node as a visit, we would have:
If a node has 2 children: We visit the node 3 times. 1 - we are already at the node(and it is not null) ; 2 - we traverse left of the node and return to it; 3- we traverse right of the node and return to it. This would make 3 visits to the node, counting us currently at the node as a visit to it.

If a node has 1 child: We visit the node 2 times. 1- We are already at the node ; 2- we traverse left/right of the node if the left/right child is not null, afterwhich we backtrack back to the node. Since the node has 1 child, it would mean the other child is null and we dont do any traversing (which would mean no backtracking to the node for that side either)

if a node has no children: We visit the node once (on condition the node is not null): Since we are already at the node we count it as a visit and since its children are null, we dont do any traversing (hence no backtracking).

The complexity of a BST tree would be O(n). The reason being is even though we visit each node 1 or more times, we only traverse the left and right of each node once(irrespective of the order of traversing). Thus for a tree of n nodes, the time complexity of our traversal would be O(n)",10.0,79
23255,23255,27503,7c939bb7eae30ac9fde6bed7ba91e751cb79bad249785d6c36230c4d9e80b55aaaf08d983990b398d630a07852718c75269fe0b377bbd248cf1db616b416f57e,"In a binary search tree with n nodes, for all traversals, namely, pre-order, in-order and post-order traversals, I noticed that we visit all nodes 2N-1 times and based on that it gives me an indication that we do O(N) work when we travers a binary search tree.",2.0,79
23256,23256,27504,49da1899a556de47c2ec5c0aee3103579dd1b8665560fbd2cb26362bd85bf2a291f8280bc21e1f838e024dcd8764915c6b880be08a2f6c8f404d85517511406c,"We visit each node once at best (if it has no children), and thrice at worst (if it has 2 children). While theoretically we could do 3n total visits, the Big-O representation would be O(n), as the complexity remains linear.",7.0,79
23257,23257,27505,6faeacee0c2269025dd90b7721d39fd6ea59274d1116063ca6e894050048f55cfc48de8438d931d22afb7e2c6e6e2971358b83dd0ec2d867cc557d7b6b500315,"We visit each node 1 + it's depth times.
The time complexity is O(n) because all of these traversals are DFS traversals and we would therefore only visit each node once. There would be no backtracking since we don't come back to the same node after traversing it.__",2.0,79
23258,23258,27506,0c11d203426fce7b3dc05c5b901a557cc9648e7fd3384bd9d8800631c383636176c5236339b82c8cac354a014c4e904c016c4f55b6e4ea8b971819143c0b5cb5,"We visit each node once.

O(n). Since we visit each node only once and we have n nodes in the BST, traversing through the tree would make do a linear amount of work.",4.0,79
23259,23259,27507,854bde56afcd2bd2c31fbe39384369ef7c0ac613a004a4b239a7a7d08872fa336ab049f8f45358abb5e93ca8dfc33e8954bf246487197e2265435ed3c204826b,"We visit each node at most three times except for the leaf nodes since from the node we'll have to go left, backtrack to the node, go right an then backtrack to the node again marking it 3 times.

The time complexity of a BST traversal is O(n^3) since we have to visit each node in the tree at most three times",4.0,79
23260,23260,27508,2c32439612d29606cd7276c7d7327878252b82b353a0e5c5a38f508a89318428edb5d433b571f4ed85a8cddd2dbf4c9c5eb5b82d38c65addb4bffc9179a95b21,"when performing any BST traversals, a node is visited once if it has no children, at least 2x its height if it has only one child and at least 2x its height + 1 if it has 2 children. Therefore, the time complexity of a BST traversal is O(n) as the amount of time taken directly depends on the amount of nodes present within the BST.",6.0,79
23261,23261,27509,f7763ea222dac1e375943618ea39c7850a59642b77b7731de5c2d200f944ea90e1861bca5e13b98b4e1c518e004e6a6d55592f5ac74fe6b5f4bf1fc2d7073996,"When performing a pre, in, or post-order  transversal the leaves of a tree are visited exactly ones and the intermediate nodes are visited at least  twice if they have at least one child child and the root will be visited exactly two times.

Therefore I think the complexity of the BST transversal is O(n) because each node is visited at least ones.",6.0,79
23262,23262,27510,615a61127c6c0ce82fff3b905af9891145f1a8b7de3c813ff28357e83206738e51030e5e11f925cb1ff08e1e1848b449cb4a5ebd866eaf249477de58f163ccf4,"the most we visit a internal nodes with 2 children 3 times, with us visiting leaves once and the root node at most twice, 

therefore given a binary search tree of n nodes we can conclude that we would do 3n work in the average case as visits, with the worst case tree in height taking n work.

Therefore the average complexity of a bst Traversal would take O(n), as we would take 3n times on average if the internal nodes make up the bulk of the traversals.",8.0,79
23263,23263,27511,5888307e6e5630e26d91393f9d95b55394aa59f773d80fc5cba42e8220ea74538fd7609c1185eaef557523bfd3715cc3b2307d7a31ddf68499df84fa7da160d9,"O(n).  We visit a node two times if it has two children and only once if it has one child or if it is a leaf.

when doing a preOrder traversal we visit a node once if it has one child and twice if it has two children

when doing in we visit a node twice as well if it has two children and once if it has no children or just one.

when doing post we visit a node twice is it has two children and once if has only one child or no child.",4.0,79
23264,23264,27512,be31d5d430bb70d92105e501945893c26e6893599696162bc95d97dc68e8551bcabb0ec57e7e70881502e05fa1f8de1b8b173b3252cd099443fc870750db1827,"Any node that has either one child or is a leaf will only be visited once because a leaf signifies the end of that pathway and does not need to be visited once more. Furthermore any node ""p"" with one child will have every node underneath it visited within the one time that we visited that node ""p"" even if there are sub-nodes with more than one child.
On the contrary, only internodes will be visited more than once on the condition that the internode has more than one child. Since this is a binary tree, the condition will be that the internode has 2 children.

Since the most we ever visit a node is twice, the time complexity will be <=O(2n)",3.0,79
23265,23265,27513,18821a50a643c1101d4d4b4a20eab092e9ef83d83d66cc8b476254122713205813222ecc2114e01a4fff80d19f68cc23c5bc386f899d5730224a2f35e7ae4a2c,"The leaves are always visited once. The root is visited twice in pre and in but three times in post, this is assuming that the root has 2 children otherwise it is visited 1 time less for all if it only has one child. The left internal nodes are always visited three times in pre and in with the right internal nodes being visited only twice, the internal nodes are always visited 3 times in post. This applies for only when the internal nodes have 2 children, for 1 child the frequency decreases by 1 on both sides.

The complexity should be O(n) since there's a chance that we'll visit all the nodes",6.0,79
23266,23266,27514,f7abd04c97a647b1e757bccd7284173478fbf8f28e28e3102567ab244a63fd5c67a5e953a932ab1f774cb73ace52fda53cdbbded4668ee4660e933d867e532bd,"For all three traversals we visit a node at most two times when it's an internal node and only once if it's a leaf. 

The complexity of a BST traversal is therefore O(n) because traversals happen (n+constant) times since each and every node in the tree is visited so that all values can be printed out.",5.0,79
23267,23267,27515,6ba5306b04bb1c19ff5f5148036844fc07d1e828c1c4bdd9a403971c63a75670cfd9507d856d67663bf299025ddc744dc1aab73fcc8ad24aa24659b96dc9ae8e,"When performing an in-order traversal, each and every node is visited only once.

When performing both pre and post-order traversals:

Each node is only visited once if and only if  it is a leaf or if has one child.

Otherwise the node is visited two times, as it has two children.

The time complexity of a BST traversal will O(n) for both best and worst-case, since each node cannot be visited more than 2 times.",3.0,79
23268,23268,27516,17a5fd9d02d6fba8d8046ace71c42e033c0f094c5a424e213efe17ca2b15dcda4339210b67d2e20cb931a5cb55e9b6fb5621dde12a8a5e6da612e051b176b44e,"Amount of times nodes visited?
= n+4

Time complexity?
O(n) - traversing through all the nodes, therefore linear.",2.0,79
23269,23269,27517,e1db971413a3e8370e48a08bd90e6c532854614ec97bf2846a8b6f64d7d2d64fceb404c5b40a925c2c496078dab9556b9aedc866e91bea3a7a6a8dc8cc19eb5b,"Pre-order traversals require the printing of the value at the current node, then traversing to the left child where that value is printed. If the left child has a left child, another traversal is done to the left, and so on. Then backtracking occurs to the original node, where the right subtree is traversed in the same fashion with the value being printed, traversal to the left, value printed, then traversal to the right. A similar pattern occurs with both in-order and post-order, with the only difference being the order in which the nodes are traversed/printed. Each node will thus be visited a maximum of two times including backtracking. Therefore, the complexity will be O(log2n) in the best case, where the height of the tree is O(logn). In the worst case, with height O(n), the complexity will be O(2n).",0.0,79
23270,23270,27518,1e61ac69c9ccec529a9d57595e183d7f2b1fa6a9903d4933718e237d1b12f704ba69dec35931222592238b7ab802821e4d5dd2c83c64cb9301a8bb0ced8b2cba,"The amount of times a node is visited is dependent on the amount of children it has and the height of the tree.
Time complexity of a BST traversal is O(n)",4.0,79
23271,23271,27519,c66e418bde3624775409174d439f8c7a104e4c741d28aa9a32d3dff6f27ee3fc70a6b61ca496d004e7124e5afeca9e6a74cf0455c76878d506978153185a8efb,"Each internal node is visited 2 times in post-order except the root which is visited 3 times and leaves which are visited once. In pre- and in-order traversals, each internal node is visited 2 times and each leaf is visited once. The complexity would then be O(n) as all n nodes are visited twice and so it is still linear.",5.0,79
23272,23272,27520,5d0d60194fd1b05c809499adb963afbac0ab800c552d7666ea7779f6183d17839f234e9ecee3ed11e567d9e2e5d5f869bc08bd2cc74894f9ca624282e8055b10,"For Pre-, In-, and Post-Order Traversal:

	* Nodes with 2 children, we would visit them 3_ _times
	* Nodes with 1 child, we would visit them 2_ _times
	* Nodes with no children, or a leaf, we would visit them only once

Time complexity: A BST Traversal would do a linear or O(N) since you have to visit every single node at least once

The worst-case space complexity of a BST Traversal is O(N)
The best-case space complexity of a BST Traversal is O(LOGN)",10.0,79
23273,23273,27521,9140ffa3b52741e2ae246773dfeed94b1141ba7c3dc70e8cb17fb6410cd6b017d81c18ceaa0264d9c4b8354cae095d12f4a720da352b65b62d37bdd0fc9fdc69,"Assuming that we are dealing with the best case of the height of tree. We would visit each node once when doing a pre-order traversal, twice when doing a in-order traversal and three times when doing a post-order traversal..

The complexity of a BST traversal would involve going through the tree from root to the last leaf, which would correspond to the height of the tree and in the best case it would be O(logn) and O(n) in the worst case",1.0,79
23274,23274,27522,83c5e0cccc2c84d6aa6c84996703c9788a4c77ad197dc9cbe544f356daab1002c8cb4669771a7a17cb1f5a0ca37aa675d40cb959b05635bc4844ce29a466fa7e,"For a pre-order traversal, the left subtree of the root and the root itself are visited twice. When performing an in-order traversal, usually a left parent is visited twice. Right children and the root are visited once. When performing a post-order traversal, the nodes are visited twice.

The complexity of a BST traversal is O(n) because usually for n numbers, the work is 2n which is linear.",4.0,79
23275,23275,27523,e8cc8f379686cf17ff7a79c51f234b372a7158c41925760d6a62468ac2bc253c196a10ef5af7f8e787abc174ba6435f331d902d6901bc07bc87271a8d067f35c,"Each node is visited 3 times if it has two children, 2 times if it has 1 child and 1 time if it is a leaf node.

The complexity of a BST traversal is O(n) because a linear amount of work is done to traverse to each node.",8.0,79
23276,23276,27524,a4513e9eefe06c5d06cd544fbaa5db795547b8f01893c660dc4a8e31a77cbc61bded840bbf0b3fd52a94491adbe0a21a3d4396c46fe19d46198e8b7b21695be6,"The complexity of a BST traversal would be O(n) because the number of children a node can have is limited to two, hence total edges is a tree would be totalNoOfNodes-1, leaving us with a search complexity of n + n-1, which would be O(n) in Big-O",4.0,79
23277,23277,27525,12066f8f6a7f4cd1c9586b77b6e85c69168c3e639d8a7cc579d0737f33e85026e0fc0bba1f43d9a6c097e420e073f5dd573d48b38e1cf440a6f948554edb9454,"When performing the pre, in or post-order traversal we visit each node once. 

*Considering that our total number of edges is eventually 'n-1' ,it implies that our pre-order takes linear time overall O(n) while visiting just one node is O(1).

*for in-order each term is visited in O(1) time but overall we get O(n) work.

*Similar to the above, post-order has O(1) work for visiting a number but overall we O(n) time.

We end up having O(n) time overall because we visit n numbers hence we have n traversals which are linear work.

BST traversal is O(h) because we visit all nodes through out the entire trees height. (It differs then from best to worst).

But backtracking takes a times complexity of O(n!) so when we need to backtrack in any case then the time complexity for the 3 traversals would be O(n!).",0.0,79
23278,23278,27526,d2c94c0dca7decb41292af9de73a32afa110cab818c0e296b000bfe9dd7b6bf221a0332e01f53ce869a1f4affd4abbea90b7e61d9504a5178a430b94bbde20af,"In a binary tree, the internal nodes with 2 children are visited 3 times. It is initially visited, and then once the whole of the left subtree is visited, it will be visited once more, and then a third time once the right subtree is visited. This will occur because of backtracking. Internal nodes with 1 children follow a similar process and are visited twice, once initially and a second time after their child subtree has been visited completely. Nodes with no children are only visited once. 

The time complexity would be O(n) because the amount of visits increases linearly as more nodes are added.",8.0,79
23279,23279,27527,b44584ccd8b5f428825956ad2bd876dd80c6494335aff0205a382354e687bb945dfab58c9f5cd5ee6d0fb386b28c2c5331192bb900a0c9c779312ec0ec3d111c,"when preforming pre,in or post- order traversals we can visit some nodes more than others a node with two children will be visited 3 times, once to past to the left of the node, once to back track to go to the right of that node and once to back track back to the original node and visit its parent node to continue the search, however a node with only 1 child will be visited twice  and a node with no children will only be visited once. 

thus the complexity of a BST traversal is O(n), despite visiting multiple nodes twice or even tree times the time complexity is constant",9.0,79
23280,23280,27528,6398cd3a19a3d471bc5a210dfd041039aa199f2840055e48507502bec88a8f8eb3f128de790430daa8207ba0fde7dea8a8fb8416bcb584e1bb9e76ef88b1e1f2,"the depth first search will start at the root and will search to the lowest leaf before backtracking. this will make it visit each node exactly twice. due to this , the complexity of a BST traversal is O(n) .",4.0,79
23281,23281,27529,8f4f0cec01fab6a6a49376ed0eca817677b16456497e4474dea2db6c84f10bbab5215841562427aec9d1d1cb57d57272e23d92898bef51a2205b3db761cea98d,"Best Case: All nodes have only one child (we have a long rope of nodes). This would mean we visit each node once and so the total number of times we visit each node is 1.
Worst Case: The tree is perfect meaning each time we venture down to a node's child, we have to revisit the node which we were on as each internal node has two children. This means each node is visited at maximum 3 times and at minimum once.

Time complexity: O(n) - Linear

I believe the time complexity of all of the traversals will not only all be the same, but will also be linear. I say this as in terms of traversing each node, we visit them at least once, even in the worst case. This means we perform a constant amount of work n times. Thus the complexity must be linear or O(n).",6.0,79
23282,23282,27530,dba55105f290263eab690cc35467de21c1485b240568356b922de9e4385ff6cd7f9c33bdddf55cba48dae5962652c3708da244fefbb69455c6e660d7de9c7d15,"when u are performing pre-order, post-order, in-order traversal u will visit the nodes 2^n times. You will fist check if the BST has any nodes. it has no nodes, you will visit no nodes. if n=1 then we will only visit the 1st node. and the traversal will the same and will only go the 1st value.the big o notaion is 0(1).  if the node is null it is finished.  for post order  u first recur the left  position to the left of the subtree. then recur to the right of the subtree print the node.. for inorder traversal recur to the left. than prints the value. then recur to the right. and the pre order traversal u return the value than get the left value then the right value into the post funtion.so the time complexity can be defined as t(n)=t(k)+(t(n-k-1)+c. where k is the number of roots on the other side. if u dont use recursion. the time complexity is o(n). and best case time complexity is o(logn)",0.0,79
23283,23283,27531,3b71cded09878fac739a748b2fcbc2d9e2bef1d7260004d93fa1cfe93d9b6830fe9dca43a0e8ef309e85cefb7f4580ca47263177668c6f4b88b993ec3fb19c7e,"We must visit each node in specified order once in the worst case, so its time complexity must be O(n) and this is because in the vector in the worst case need to reallocate memory, copy all items and free the old memory and each item gets copied once",3.0,79
23284,23284,27532,2f2bbc70f8136ca3b18457b652aa1d5317919459278da63d7273a5c4e29eded00275f14d0a5826a3efa0a4d6a86ce51a6129f3ba53f25a66bc7e4755b291485f,"The number of the n-Degree of the node.

The complexity would be O(n), because if it traversed through the entire tree, each node is visited.",2.0,79
23285,23285,27533,936c1ec869d8f0942d3b84b8b6c320188374f7b930016464dda43168d457286fd222e445f17b63344d55d3ca25f550407692016dc54317e807a5e1c9658269bd,"EACH NODE IS VISITED ONCE.

COMPLEXITY IS 0(n) BECAUSE EACH NODE IS TRAVERSED ONCE",3.0,79
23286,23286,27534,a3989cc4476b1bbce9e79b34c3f0337ca13c9717a610fbe24ad51e9bdb052f2d445313904842463b1a859cd4d281ce72b5f85b0423f33b62cab82318e4116232,"When performing pre-order traversal we visit each node only once as we take the value, go to the left of it and the after that to the right of it. When performing in-order traversal we visit each node only once as we we take the most left node first and the value and then after that we take the right node of the value. When performing post-order traversal we visit each node only once as take most left node first and then the right and lastly the value.

The complexity of BST traversal is O(10 because we do constant amount of work as our tree does the work for us by arranging the nodes/values.",4.0,79
23287,23287,27535,8f8e96eb5a28d15c7802d177c96b97e53c9c9c2a37389d558dc50a5be6ad84289d3986f782da265340d7d86d9d174957d8d67890ddc79dd4587dd919a3bfb09b,"Each node is visited exactly once.

These traversals can be implemented recursively and no backtracking is required.

The complexity is O(n) and depends on how many nodes the tree has and since each node is only visited once.",4.0,79
23288,23288,27536,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,The time complexity for backtracking a tree is O(n + m) where n is the number of nodes and m is the number of edges . the different cases are when the tree is skewed to one direction meaning one subtree is empty and another subtree has children and the complexity of that particular case is O(n + m).Another case is when both subtrees left and right have equal number of nodes or children which then gives the time complexity of O(n)  because it  goes with the height of the tree which is n - 1 .,2.0,79
23289,23289,27537,336c0de60905df4ae163484013b5cc72929683b64ebae6f69a61ca7bbc767084419ba7cf9291246a9b63bc7e686a397f48c33976b41fb34999f9b50eee045aba,"in preorder we visit the parent  node at least once and twice if its children also have children, and only once on the leaf nodes.

in inorder we visit e parent node twice and more if its children also have children, and only once on the leaf nodes.

in postorder we visit the parent node twice and more if its children also have children and only once if it is a leaf node.

The complexity for best case is O(logn) because we reach the node faster and would be O(n) at the worst case when the value does not exist or is at the last node.",6.0,79
23290,23290,27538,1b575ce85f9fe9d462e1de73f4e66ff04c921a768d297956a2d166b33e02a5691d14de4e07fdb716975b3003397dd6ecfd657024c0a233117dfee4b6480ebdcd,"Depending on the structure of the tree, we could visit a node multiple times as we have to backtrack for traversals such as pre, in and post.  In DFS we shall visit each internal node 2 to 3 times depending on different cases and each leaf once.

The time complexity of a BST traversal according to Big-O Notation would be as follows:

O(n)

We will have to do linear amount of work as we will have to traverse the entire tree especially in cases of pre, in and post order traversals.

However if we are looking for a specific node in the tree our complexity can have different cases:

Best case:

O(1) - The value of the node we are looking for could be the root itself.

Worst case:

O(n) - The value is not in the tree and so we traverse the entire tree.

Also, if we are inserting a node we could have different complexities such as O(logn) or O(n).",6.0,79
23291,23291,27539,33903c4df6729a45e2485f57a528848aea77fb0ac81607f602f6f53f80eb513d5b18fef57c086d43fef4cdb3f78bbc1f8da0bcaa1e67afb26268e9484bbb4ded,"The answer depends on the type of the node in the BST. Usually the leaves of a BST are visited exactly once for all three types of traversals.

For a post order and pre order traversal the number of times an internode is visited is two while for an in order traversal the internodes are visited exactly once

The time complexity in big O notation is linear (O(n)) for all three types of traversals since the leaves of each node are visited once.",4.0,79
23292,23292,27540,f1ba85bcb3cb35dd3a5763fa5946a3ff7df7d0bf7beb3182d0ecb801d8abdf353d4eeb7909c0cc4e94c0d221fea7a7c70e57bb1e1c70aaf71f4a7a0e8fe5269d,"In a pre order traversal, once one reaches the left most leaf from the root, we would have to backtrack back up from the left most leaf to the nearest node with a child on the right. If this child on the right has a child to the left, we then follow down this path until we've visited the left most leaf from the initial node. The process is repeated a number of times until every node is visited. Backtracking occurs at least once for every node.",0.0,79
23293,23293,27541,23b5a4e63c9fefece084783cc1411977943e7d8d3612a093af2540d5bb113a4845b418786034d0d238575bbb9fe95d816e937dc9fe084e3f124b6dcce8457f10,"We visit each node depending on if it has any children. Leaves will only be visited once but internal nodes will be visited three times as we have to backtrack to them. 

Complexity is O(n) (linear time) as it has to go through all values of BST.",6.0,79
23294,23294,27542,87b26af5215183ea5d646e967e1e3374a7a4afb5a13a2967680ff8a29d219e9ac775560a42891913325361c21b3cb2f9b5121d0317fb7c951cff2c01aed37b66,"If there a n nodes, we visit each node n times. 

Time complexity of a BST traversal is O(n).",2.0,79
23295,23295,27543,03af6c40b97133a1240dcc22b0dd356e3929ea04c9cf63c336ed0f2605d19efb0d0a0e5a6c60e766990694456ae922f3a477316845f8028bca7fb236d74cb185,"A node is visited at least once. During backtracking when a child is visited, it is marked as visited and we wont transverse it once more and if all nodes have been visited we backtrack to the algorithm and do the process again.

O(h). Because every node has to be visited.",5.0,79
23296,23296,27544,675e836215b62d793972ecb9d5ace2eaf438e0e5d0d26f496ddc3442ba479da55ac029b8a4555f73c538c50ecac4b04edc042861ca9b743e991c19c46392aa72,"With a leaf it is visited once but all internal nodes are visited twice but is still linear time complexity. The complexity of BST because we visit each node twice , which is still linear time complexity.",6.0,79
23297,23297,27545,6d04032d059678dcb346209e5f60e18a44d0c551ad3d7c0e551f1957033a386ffc9828dc7e1374b35e8828c43ed8d61ae22f6c2de063b8779cad31efc30f066d,"it'll visit the nodes exactly 2^n times. First see if the BST has any nodes, if not it'll visit no zero nodes. It'll visit the first node if n=1 therefore when traversing the results will remain the same when traversing from zero items to one item. Its complexity is O(logn) in the best case and O(n) in the worst case. In the best it is because the binary tree is perfect so the height of the tree is the shortest it can be which makes traversing to certain items quicker and in the worst it is when the it is a degenerate tree which makes the height of the tree n which means that it would need to traverse through all the items if it needs to find the last item in the tree.",1.0,79
23298,23298,27546,d666547eff9169197da62fa32337eea89dac55402d95fbc8d78afc02e8aa4387e1901ff8dcf83d29734811357e0cd8804ded14f05805dedc3a85daadf9c4c43b,"In a BST with n nodes, you would traverse each node once. Since the number of edges that can come from a node is two when can say the time complexity is

O(n+n-1) which is just O(n)",3.0,79
23299,23299,27547,a37e8cb6bec1612d5c3aa242e7b3e8cea873cb6f52435ece79359c13b8144256dc3d86709b38c13890622651a1bea3e2d4c9e9d39d9c4884e7ba93253dd09e29,"O (n)

O (logn) 

Bst is easy than dfs and it saves time.",2.0,79
23300,23300,27548,c879e65c8f9657768bbf6800906a28bff217c7ef9063d46acfccc25071a9fc3aef2ccd29821fdc92e96d2f98ca66aa74a3fa2a8f0df86509064e53b0fb9b54bc,"Case of 1 node: Visit each node 1 time, Visits=n

Case of 2 nodes: Visit root once and second node once. Visits=n

Case of 3 nodes:

Case of a perfect tree:  Visits root once and it's children once. Visits = n

Case of a degenerate tree: Visits the root once, level 1 node once, level 2 node once. Visits = n 

Extrapolating this trend we can assume the best case time complexity is O(1) and the worst cases is O(n) ",2.0,79
23301,23301,27549,9b486d212bcbfc98bcb7006334a7bd057c017b3b5d6ddec828a1e7c71b279d57abf5933826cc5cd40f31ce09e30273c03c034afd55ad69a350c76adfabdffc7c,"Depending on the structure of the BST, in the best-case each node will only be visited once, meaning O(n) complexity (this being if each node only has one child).

In the worst-case, there would be a substantial amount of backtracking as the tree will be perfect or even complete in structure, meaning each node will be visited more than once.

However, the complexity overall will remain O(n) as the DFS will not consider backtracking through a node as simply just visiting it again, rather it keeps track of each node and will choose an alternate path when one terminates.",2.0,79
23302,23302,27550,a41ff85d7c3f46c972cdda9b8d99297a4177ec80aa4a317631762cd6ae04cc877e3ccd31e4fd09e41eccdaa2cd1266d20e5947fd82dfa31e5b04a9f5e1bd8e0c,"Leaves are visited exactly once always. The root is visited at most twice for in- and pre-order traversals, including at the beginning (it is visited once if tree is degenerate with all other nodes containing values greater or equal to the root value and twice in every other situation). Root is visited at most three times for post-order, and other internal nodes are visited at most three times (three for two children, twice for one).

The complexity is O",4.0,79
23303,23303,27551,4f0d170bb113012c8d343271d925a96ef0e199ecdca36f51a1fc99d7e0e8c67fb97155bfa738d3317830adb88f58c316437e0cf62b20c43f4e89ab893b6e7471,"pre-order  We visit each node at least once

in-order  We visit each node at least once and at most h times. (h=height of BST) Visit the left subtree first then the right subtree 

post-order We visit each node at lease once,

The time complexity of a BST traversal will be O(n) because you would at least be visiting each node at least once through each traversal. ",5.0,79
23304,23304,27552,d098e277cb3df3b25c9e42904322dbd46a16b60a20b139d8066f16584a8bb599eddc05cac924f310971f38fb613ad7daea71749bb268694cb7e0d2fdf74a35a0,"For the post order, inorder and preorder traversals, we visit each node once. The time complexity of each of the travesals is O(n) because the time complexity of visiting a single node is O(1) and we visit each node once,, when we have n nodes, we do n visits therefore, the total time complexity of accessing every node in the whole tree is O(n); that is O(1)*n.",2.0,79
23305,23305,27553,5ad20b3b420c21e1fc2861df4f4257210672d867b8a024855b258388d20148643f1a94c77f0aa2d4b47f8fba4b85741287207442ff519080915f15fdfd0e21b1,"The pre, in and post order traversals visit internal nodes twice and visit leaves once as they are the point where the depth first search starts backtracking. The complexity of a BST traversal is O(n) as the work done increases linearly relative to the value of n.",5.0,79
23306,23306,27554,c0e222e387522491c144bc66b8d4aac6d8899881b15676a75bd42f6939be2d68b02062c035d5f028531cde71d4b0b2bb7581d5e165c7c3be11bd4e67e796913f,"if the tree is degenerate, each node is visited once and if the tree is balanced , leaves are visited once and internal nodes are visited a maximum of 3 times.

The complexity is O(n) because the amount of work done for each node is constant. Adding up the number of visits results in O(n) as the summation depends on the number of nodes (n).",6.0,79
23307,23307,27555,ed5a8c0425e8a7a0d2d402e42e3298539ec0ceb1b43ca8fa3f4b83dce862ed24fe276be92f07cf85365c96c7391564d1c0da45fd6e6ba4bd80ecb01a39467209,"Complexity of a BST traversal is O(n) because we visit each node exactly once.

Number of times we visit each node:

Pre-order: 1

In-order: 2

Post-order: 3",2.0,79
23308,23308,27556,dec98074973763aa35f767e29ff1a337a2f96e27f7bb719852891850a70e146d6ceeda2c5cff7d622832dba02534fa96620c763e3c53dc17c1734a3ec63ba166,"If the node is a leaf then it'll only get visited once.
If it has 1 child it would get visited twice and,

If it has 2 children it would get visited 3 times.

O(n). A binary search tree gets traversed 2n-1 times when using back tracked, which is linear so it would be O(n) in Big-O notation.",9.0,79
23309,23309,27557,1db17093b11c1476f03e1842d3fd75c18d4034c323e18d85de2325fa751f6201dc73b8705d987e46f915cfc55474341bdc436a256b6ba4b925f54ea754c444c7,"O(n-1)

since BST only has maximum 2 nodes so total edges can only be n-1.",1.0,79
23310,23310,27558,2f8068722efcb5acef0b043ef7eeece2ba76bc57f445239c4ee08b7c2bb5238f231cca575128f6a330204e13d52f6c557830c59595c0c60a57b982bbb0aba187,"We would visit each node about three times at maximum because we would visit the node to get the value that its stored to print it out then to visit to get the left and right subtrees if they are there to recursively call the function, the manner at which this is done would depend on the order of traversal. Therefore the complexity will be linear O(n). ",3.0,79
23311,23311,27559,ab50392a96c4c3025a5963370825a15241a679c25a4771a2853db32d86a5e0a874ed37e6f390b06f6b3a0755f5bc0190ec94f83a3fd5bf730ba4d34a04efb6d1,"visit each node 3 times.

time complexity: O(n)",4.0,79
23312,23312,27560,5dcf09a63d08f8fcf484a27b8188aca8e05117584de8c4c8e580d2681056a972e8271fbb1e9e69a616d3a8d13ef9009ce7fbd4e4c680807f0aa62ce637934a9e,We visit each node only once in the BST traversals.  This would lead me into thinking that the complexity of the BST traversal is O(n),2.0,79
23313,23313,27561,0cd06500f6bc04ca04d6df402c164435dd4b1e3f62d49a5f81d45b91f4a6f4ac2ae8232fc2f485e2ef108625ecea2f61c466c82dcbccacd3d327b9b3b7efa90a,"All of the traversals as a Depth First Search are long and of course one needs to go to every node. An internal node would be visited 3 times if it has 2 children,but it would be visited twice if it has one child. This applies to internal nodes except the root. By that logic then the time complexity of a BST traversal would be O(V+E). V being number vertices and E being number edges. this is the conclusion since it does take more time but not exponential when not including backtracking. ",5.0,79
23314,23314,27562,5f87218a9157c9f2740bbc5a076009259b8932c2104f99371f2e9e9e870c16111399d5c3a60f311aebd8ac847ff222666d98c8552349e85bf1bc07e6e8aaa00e,"worst case n=O(n)
best case n=O(logn)
the complexity of a bst trasversal is O(N)",2.0,79
23315,23315,27563,9e606e329f6a5dc1874e2e7d1ce01689bc1c5df584fe109cc6c775ea15ec412db6a361b31855924672756d4e66bb398724a491f49547db72d1faa12ddcce7489,"In a BST, each node and all of its neighbours are visited exactly once when considering preorder, inorder and preorder cases, the time complexity is linear.  O(n).",4.0,79
23316,23316,27564,20d849b0f14d796b315efcd61e863b25c7b0891949c9f1f08039226267e2ec02fc126e19dc6bac1596ae1c91066636280bb491c789bcd5f5ca3de77e3170945e,"PRE-ORDER TRAVERSAL

In this case a node would first be visited as a child(except the root), secondly from its left child when backtracking, then from its its right child when backtracking occurs. This means that every node will be visited 3 times, including the root. This will always be 3n, hence the complexity in Big-O is O(n).

POST-ORDER TRAVERSAL

This is also similar to pre-order traversal and every node will be visited 3 times, hence the complexity will be linear, O(n).

INORDER TRAVERSAL

The complexity will also be linear, which makes it O(n).",3.0,79
23317,23317,27565,1ae15e0f8c76ae99b51e83372a1074e20d0c372f497d2600b23a4ed137e5d58ad3914d0e0fce9e4d1885de19b788d1beec93c22c6cc3c2146c9349afe08e62f9,"Each node will be traversed through at least once until the desired file is found. The best case is if the desired node is at the top of the tree, the time taken will then be constant - O(1). In the worst case, we would have to traverse through the entire tree which would take a constant time - O(n).",4.0,79
23318,23318,27566,e083cbbf008c42438bc396229643f759537dd38e9f70943e360360b6f27f45207e60ac5070353bd70bc7b26433e973228b25ccf89b152c434341d5c266f31945,"The traversal of a BST can be done by DFS(one of the ways of traversing). The complexity of the bst traversal is linear through the height. In big-O notation, it will be O(h). h is the height of the tree in interest. The traversal is linear because we have n nodes in a tree and we have to visit each and every single node. We usually start at the root node which is in depth 0, then check the children of the root(left child and right). We will check if the children of the root node also themselves have children and so on up until we reach leaves of the tree. The traversal will stop when it has reached highest depth which is equal to the height of the tree and only leaves are found in that depth.",2.0,79
23319,23319,27567,252668df997d55b86d753e14db9bb82d9a9ab0f27d714f3256c72a03986a906ffccf1958bf221d3ab998a7770edda41ec2de25393f1d9a62f105684cf09211ed,"We would visit each node once, in the preorder traversal, we would search the tree by visiting the current node then visit the left child and the right child of that node. in the in order traversal, we would visit left side of the node in the subtree then move to the current and finally the right subtree of the node. the post order traversals we visit the left then right subtree before visiting the current subtree of the node 

the time complexity would be O(n) , because we traverse through the node once , which means the work that needs to be done is constant nd it doesn't depend on the rest of the nodes",3.0,79
23320,23320,27568,b722c8fd9eec42aa602e4cbd2ceee62645727f2b19607bd1bed826053b9d70a2c8e8d845bbe5119d6c5e8f3413efde7438ae5ec2d12a60cf1215dd59daf4a367,Traversals of a BST will have a complexity of O(n). This is as each node will be visited at least once. Some may be visited more however it will always be a linear amount.,2.0,79
23321,23321,27569,75a3383738a198a57b5bf911227bc1acefa5387a63447f6ac8def117cc9ca26c926b9a06fe676ff769e333554195eaa647257e22733d67710ae7508ceb7f3115,standard insertion algorithm,0.0,79
23322,23322,27570,b96308b5b954fc4c2086f6faec027fc8299af60a164d99cbdc75a0802d3bb5ac5823699b9e2e5c78a86bbf73886ed3408a16b29a0f7ee6dc90b05a8f2f91fcd5,"When performing pre, in and post-order traversal if a node is a leaf node it is visited only once, if it is a node that has only one child then it is visited twice, if it is a node that has two children it is visited three times and if it is the root it is visited three times. Hence the complexity of a BST traversal is O(n) and this is because each node is visited at most three times which would give O(3n) amount of work but in our analysis of complexity we disregard any constants therefore the amount of work would just be O(n).",10.0,79
23323,23323,27571,8278e2d003c29d98e8cfc7117cefa90b7503054f5b50b162eaded6981387fa2f1b8b8f0ae2fa0d58942ac81f9cf7fda1cd474d106727d602bcd9f2d647883b50,"In DFS when trasversing every node is visited once

 Best case performance is O(1), while worst case performance is O(n).

in BST trasversal best case performance  and worst case performance are both  O(n).

because it trasverses level by level so it is dependent on the height of the tree",4.0,79
23324,23324,27572,27704af10f29b9fd01985b3a533f1213c119ce01a32f451e037e0491eede8c71f38ccb8abe4edd8c056927c76b6bf0c23fb2a88f8cca52e5000b6c906d6692ef,"We visit each node three(3) times.

Traversing in a BST has a time complexity of O(n) in the worst case and this is because we have to traverse all elements in the BST along the longest path from the root to the leaf of the tree.

Traversing in a BST has a time complexity of O(logn) in the best case and this is because we don't traverse all elements in the BST along the longest path from the root to the leaf of the tree.",3.0,79
23325,23325,27573,e7c7348f23786b9e18a28e68e5d9ba68b1b693a74a0d58100a7db9e2aeee706b92e8dc4a38b20cb50289290e86666a9bfd49334f05b1673c8db1a8b26f9c9689,"When traversing through a BST we only visit a node once.

In a best case the complexity of the BST traversal will be O(log(n)),this will occur if and only if we have an almost perfect BST. But on a worst traversal the complexity will be O(n), this will occur only when the BST has a maximum possible height. ",1.0,79
23326,23326,27574,0425e17b97b62d847bfbb7a5f37fa98ed826dc582b46528b4a148c459379ead81390caacfd23b1628779d134c7092014f555b05833c612700ef174bd131b6587,"For _pre_, we must visit each node twice. Once to find its value, and once when backtracking to get from node->left to node->right.

For _in_, also twice. Initially to get to node->left, and then again when backtracking to find _value._

For _post_, it is thrice. We visit initially to get to node->left, then backtrack to traverse to node->right, and then finally to get back to the node itself for _value_.

the traversal is thus linear in complexity O(_n_), since we must visit each node a constant number of times. Then, the total number of visits is proportional to the number of nodes.",2.0,79
23327,23327,27575,bbda30f1bc14304c6e790f22a459366d7df21db83cacfaab7fa97f23e08f9ea6d540b989b2f855a6b10224ce128ef7de8ce703f345305fd513061e429569c02a,"In a pre, in and post-order traversal the leaf nodes are visited once but internal nodes with one child are visited twice and internal nodes with two children are visited three times.

The complexity is O(log2n) and O(n) for degenerate trees.",8.0,79
23328,23328,27576,0cbc810c065e1ea82d7b36219a5e375cbce8ff096ba3665c665a2eb1c6f0befa244bcbe226b2da5880d6b84bb7f0100310c96f80f96a3b3863c5c650f01ebc3d,"The complexity is O(n +(n-1)) where n is the number of nodes and (n-1) is the number of edges. This is because the number of nodes visited is the complexity without any backtracking. If for example, one has travelled through one half of a BST and wishes to backtrack, they will not revisit nodes, they will only repeat the number of edges they travel along. This means that going into the tree would be in O(n) and traversing back out of the tree would be in O(n-1) time because the number of edges is one less than the number of vertices.",2.0,79
23329,23329,27577,361f392a37237e8771b2917669c443ba6d28c45bed8ae51a0114890d3cb7412fbd4e346b3dea716ce0116bf5b6bbde572fb9792b9da8a90824dec67c0144ddfd,O(n),2.0,79
23330,23330,27578,b8ff274cc91e39334247b9673eeb1e1ed2acdbcefc990de9bf2b4226b88349ab6bc97343b39be8aded8a6ab21d1bf5dc3045e9f7596480cb1279270e81abbd58,"Each node is visited once.

Time complexity = O(n) since each node is visited once. where n is the number of nodes",2.0,79
23331,23331,27579,ba67943d9c3f68c2a82bf70197366cb2cce1d21f6696fe648aaf7068ed18399b5899a40e2f0d4a0c53a04c7e84020c544f2b79e8fc23a17b4dca16bd22dbd15b,"DFS will go through each node n times. You can perform this by marking a value as marked after visiting it, so you see all the duplicates and eliminate them, so you can't visit the same value twice.

The BST will have O(n) complexity.",2.0,79
23332,23332,27580,4a10096efbe473298c3ffaa590c64747a3f122d6138157d16b669b6d6757b1ee312e247b5d7de57197c1100b67d525e21d2bdf5719b1e5397849be3138642057,"In Pre-Order Traversal, we visit each parent with 2 children 3 times, a parent with one child 2 times, the root 2 times, and  a leaf once.

In In-Order Traversal, we visit each parent with 2 children 2 times, a parent with one child 2 times, the root 2 times, and  a leaf once.

In Post-Order Traversal, we visit each parent with 3 children 2 times, a parent with one child 2 times, the root 2 times, and  a leaf once.",5.0,79
23333,23333,27581,b9398cac04fafed43567a061ce43d1f6d47a11dc43ed26ca3b7c803119e60ccce5216c5b0d8f2fe86de25d577c66b8be90d26d4412d9f88f080c8ddc823e6bcb,"We visit each node log(n+1)-1 which is considered the best case but in the worst case we will visit each node n-1 

And the complexity of the BST traversal is going to be O(logn) in the best case and O(n) in the worst case.

The complexity is O(logn) in the best case because the BST is non-linear which makes O(logn) suited for its complexity and O(n) is its worst case because the traversal of O(n) is linear.",2.0,79
23334,23334,27582,3d924476d27d7afee3c446be78c3bfa807a26922031bb4eac61f97a7c6f17eb08bf7666e6b4cc961e48bd773db3725b57e5ee0d093b4129e2c89bae53ea3a074,"we will visit each node only once

O(log(n))-1 which helps decrease the number of times a node is visited.",0.0,79
23335,23335,27583,f83dd55ad9e075a60c5134f9bf47ed3397e5224c478fcc48237d4341af57f9ae0b4893b2d9bfdacde4458f44d6dacdaedccfab297dd76d28c1d773deaaf399e4,"Each node is visited O(log(n)) times.

I think the complexity of a BST traversal is O(h) since h is the height of BST and this implies that in order to traverse searching for each element in an order ,either ascending or descending order ,there a worst case complexity of O(n). ",2.0,79
23336,23336,27584,9b5371bf3d8a67220ea9112f458e092347973d5a590a2ada7f6d386201210567493e4842dd7263535c03e1b4ce797297171327f4cefdbdd79731ace1f4e756bb,"we have to visit each node n-1 times.

the time complexity will be O(n) because we have to visit each node n-1 times and that will take linear time.",2.0,79
23337,23337,27585,bb69eebb6b9661fb2659b9201956c2d150fd7601de8f2339f22c3c3c7289abd28101e1b6206a923a6b9fd81f7d0d617c8b5485dd0958ad06769fcf98922a4e97,"for pre-order 

we will visit a value 2 times considering the Value Left Right principle of  plotting the pre order since will have to visit the value again in back tracking after finding its left and right and their children.

for post-order

we will visit a value 2 times following the left right value principle of plotting a post order since we will visit the note before finding it's children and again after finding it's children for backtracking.

for In-Order

we will need to find the value first then find it's left then backtrack and find it's right then we will plot this order this means that we will visit a note 3 times while plotting this order

I think the complexity is linear time since we will have to traverse to every node before we can plot the order this means O(n) ",8.0,79
23338,23338,27586,202c8344f9f859aa64da3cc8ceffb88155f17aa53a21d20d5da4fef5e39546500eff34cbff57a9c00ff1871c748bb37a08181469555e6609e93120b6d7b83edc,"Since each node is visited at most once, the complexity will be O(n).",2.0,79
23339,23339,27587,680d91225cab44dd05e534f9e43db41735c5c1d374cc902f5585fb054238f603a599d4ef9dab5fa3942be1f948538952ecb942a66b8672d9ac04303366506ece,"According to my analysis of the question, I came to the conclusion that when actually performing a pre-order, in-order, or post-order traversal as a Depth First Search we visit each node in particular N - 1 times. 

The time complexity in this instance is 0(N) as we visit each node every time. ",2.0,79
23340,23340,27588,4bd03f3c8f89617686a3536f1302b8ad51345512ea9473aae1ca497c4f25a59a5466e4df9b3e8a550246d3f93ec44b2398abe8c256bf5d3e51474d7b6863abb1,"BST visits nodes by levels from top to bottom and from left to right.

the binary search tree with n nodes has a minimum of O(log n) levels and each node is visited 3 times. 

BST has worst case time complexity is O(h)",1.0,79
23341,23341,27589,4541bddfe14df82661aaba793d25bb038432ba934014876821269e81b4029af8b6064a54828f0509d14ee3f303c32ee014b7221977ad133bace3b01a694e694c,We visit each node n amount of times.,0.0,79
23342,23342,27590,d34efe98a2513ac08acc6faef18dfc38310a4938c3e2400c3ec9b606c14e0455c45534357347e63004ac9d2c3c1e1d7805afa99ff5f4d271c3dc0f7c2153d7d4,"In Order

	* We visits the leafs only once

Pre

	* We visits the leafs only once

Post

	* We visits the leafs only once",2.0,79
23343,23343,27591,ba47d803e26988b75d891eb0e76061b355587a9834711cd75248db6b2b1c6cccc9c5cadcd161a1c0dfe6bd2d1a8b1014e37dd57461b73e39268808ede1fe4392,"we visit each node only once(in order traversal), if the tree has n amount of nodes and will be doing O(n) amount of work, but in post order ,1 time if its  a leaf,2 times if the node has both  children cause we cehck if it has a left child then we check if it also has a right child,

so i.e DFS traversals can be O(n+m) since a node can have at most 2 nodes now;

, Thefore the complexity of traversal in a binary search tree would be O(n)",4.0,79
23344,23344,27592,611e62668a69a44120f4c094b741411c87184ef32e42939a38515edfc5b988a4050fb89730be7833c2365cfa3031ef1f4593e6c36d340bca6106a175c159094f,"in a pre-order we visit each node once .in in-order we visit each node twice . in the post-order we visit each node 3 times . but in each traversal we only visit the leaves once 

i think the complexity of the traversals is O(n) . this is because based on the amount of time we visit each node which is O(n) I see that for the traversals i will have to combine these number of times together to get the overall time and adding O(n) with O(n) gives me O(n) again ",4.0,79
23345,23345,27593,cd3aa55745b79deafb0802ba9ebe30e68fbd1c089c006450727570d34769934d2b1c5a098a7d318146af21d8981711dce0bb006308d97edfcf9a088eb56e4532,"When performing BST tree traversals each node is visited at least once. Each node will be visited twice as we'll recursively traverse through the left and right subtree as well as the root. The complexity of the the BST will be linear, O(n). This is because traversing through the left and right subtree will be approximately O(n/2) = O(n) each of which is linear and traversing through the root is constant O(1). Thus, O(n) + O(1) = O(n) which is linear. ",2.0,79
23346,23346,27594,8ccaa62cbbe76ea20aad42f0abeb4aea6b057f35352db9aef1c4c8bb791949070df63d7ca3789507be754a64de8d3383c759c83cb767d9e10e045b387bce8a09,"starting from the source node, we keep moving to the adjcent nodes where we reach the farthest level. then we backtrack to the  prevvious node and pick an adjacent node , once again we probe till the farthest level where we hit the desired node.. for the time complexity , to make a lookup more efficient the tree must be balanced so that its maximum height is proportional to the log of n(log(n) . in such the time complexity of a BST is O(log(n)). because searching for any leaf in that tree is bounded by log(n).",0.0,79
23347,23347,27595,a50f1f05303eb676c08e683fb412c46779741d1e408ab7173f3f3a12df3f04196b4fd7b7add1fd647d8efd191c43d6971e5cae7611afd814fbea2a7330f3ce46,"The time complexity of the Traversals is O(n), a leaf node is visited once, and again a subtree with only one node is visited once while a subtree with 2 nodes is visited twice, we first visit the right or left node then the other side following that the time complexity is O(2n), the constant is ignored making the time complexity O(n).",4.0,79
23348,23348,27596,1848cd7f48fa46779deb7b0a0eb59a877c6d421045e3cfd89b389428863439dfcd907f1dfee5210fe7c99e6e24483c87f1eba9c0df60ab0e72ef97072d4bd765,"Preorder traversal - we visit each node only once and then print out the node value

Inorder traversal -  we visit each node twice and then print out the node value

Postorder traversal - we visit each node three times and then print out the node value

The Best case time complexity - the height of the tree will be log2(n+1) -1 

The worst case time complexity - the height of the tree will be  n-1 

Because In Big-O notation we we are interested in the shape of these funtions and so we say that the height is O(logn) or  O(n) respectively.",1.0,79
23349,23349,27597,a58cc7a946eda613e1ba5b3286e27532a7ed6202aac74240dace327e45260834a089fa12052292c507fb1aec6f37cb1855be0992f9b6be6541ab2eebe4c77364,"A node can be visited up to 2times , taking in consideration the backtracking. the complexity of the traversal is O(n) , ",4.0,79
23350,23350,27598,79e7d7f9dd31af42dafc3f30ed17b2ec3bfb7c371aeb90fda49a78ac5ff634413c5502ef51e48fca99485ebc6751e35a6357de07c8799c082943fd8aca0f76df,"From what I understand doing pre order traversal and DFS will give the same outcome, visiting every node to the then recursively to right again but fisr after vising root",0.0,79
23351,23351,27599,c7fddd77b6fed9bc15d19de2718acf9bd47e63c47fabc90953d259ee95b77d6203c59c32fab4eab8591fe4a7373a9aafae0952036c94bc9ebef7955717c99e00,"when performing a pre order traversal we have to visit each node 2  times maximum 3 times.

in order we have to visit each node only once or twice.

post order traversal  can be 1 or two to times you can visit each node

The complexity of the BST Traversal is O(n+ number of edges) ",5.0,79
23352,23352,27600,91d41b2f32ab492a059463744b0e5f6cd6e21e57c981adbf25309713090c378a42bc574b38c9745bce66a49918299962c618772aa540a5c09c38c4d73e58815f,"we only visit the node once when traversing through a BST.

for the best case complexity of the BST traversal will be O(log(n)) and it occurs only if we have the best BST.

on a worst traversal the complexity will be O(n) which occurs if the BST has a maximum possible height",4.0,79
23353,23353,27601,910daf6bb90bfaca5b8329327dbb6876d9a383514e01fe819f79abb1a27019ac7b7555a07d09a61e93831fa5c489e19d607608ea54797f25aad8bd641ed60e55,"We visit each node 2**n times since we have to check for the left and right children of the tree to determine where to get the next value and each node has at most 2 children.

O(n) because the amount of work that is done per node does not depend on the rest of the nodes.",5.0,79
23354,23354,27602,a1c2b05bc77a92969182ba646d8a653eca3913d57c538fdf187c677d2b0c51d076b45d82612615ca734696b4dfc388e9684934287cf1a84a26d20f8be5134c6a,"When traversing through a BST we only visit a node once.

In a best case the complexity of the BST traversal will be O(log(n)).The worst traversal the complexity O(n).",0.0,79
23355,23355,27603,0fd0096c1497543ca0003b9e3ba007221cbda2328585a2f2260277e1c7038bb2ae7ad23e03908936421523651b3b5785ece380b977ac663ea4a02a050d012617,"_HOW MANY TIMES WE VISIT EACH NODE, TRAVERSALS AS DEPTH SEARCH._

_
_

the n nodes, there are explored or (visited) ONCE, since the depth search puts the node in a stack  only once and uses the system of backtracking

the time complexity of visiting 1 node is O(1), but visiting every single node is O(n) because we have to visit every single node. moreover, the O(n-1) which is just O(n) fo the worst case.",1.0,79
23356,23356,27604,ef46ab4c4baea61ce39205f3f8b9ba2f08ab48270b777e4f042aafc6410a82e9cddc1dd033e57ccba5e191584e8763e9b5c270df38cd4daee3f921d844f6b7a8,"2n times

linear time

-It will take the same time no matter how many vertices are present.",2.0,79
23357,23357,27605,eaeebfd434a43156f3712848577d3a5da6499b6e1784e16a24ab5777985e6e2eed30ffc0a110ed246a9badfba660cd9a812c4ed7d173d1a29f7e115ce4ad58b1,"for in-order we will visit a node 3 times because we will find the value then it's left till we reach a leave then back track to the value then find it's right then traverse till we find a leave then traverse back to the value .

for Post-order we will first find that value then traverse left then backtrack to the value then traverse then right  then back to the value this means we will visit that node 4 times before passing it.

for Pre-order we will visit a node 4 times since we find it then traverse left backtrack to that node again then go right then back to that node for the forth time in this traversal

we do linear  work in all this traversals since we have to visit this nodes all of them one after due to the type of traversal this means it is O(n).",2.0,79
23358,23358,27606,df7c40110480895f223a4ad7a154ce6d14071ffef29c798823d9a68e307bd1447fc569c4b8f3e4353216405210fd26445fb7aeea3ad07da82c16c8e5aa5ac0cd,"For each of the BST traversals mentioned, each node is visited just once, therefore the time complexity is O(n).",2.0,79
23359,23359,27607,b1b3e86f0d270a61f8fd878f224a3849ed613dcb005f40bfd930beec1496e89a0e58f28b9b719a548b167e0db0c44afd5aae82094d2f118c0287dc3bf2b65cac,"Each node is visited once when performing Depth first search and the time complexity for the traversal would be O(V+E) ,where V is the vertices and E is the edges visited.

if we were to back track ,each internal node would be visited twice and the time complexity would be O(2V + 2E) ,because the edges as well as the vertices would be visited twice .",4.0,79
23360,23360,27608,c6130d795cb6021c7594812b73d6b159744ce452f7f194d2a8acfd0f6313f2562bada8d95c7d6c5736c9d1d528be9655da041882fe8c7474badb6562243ddc74,"All the leaves and internal nodes will be visited once during the traversals if the tree is a full tree. Also in a degenerate tree, all the leaves and internal nodes will be visited once during the traversals.  Therefore in the best case and the worst case of these traversals, the complexity is O(n) because the complexity depends on the nodes visited, and then the complexity is linearly dependent on the number of nodes in the tree.",4.0,79
23361,23361,27609,db0698cd03866d48da0c9cab1c327e767c6fb2c70ab318867db7094af47e41c16fc1528b63425d8d7a1a4e5cc071eef840fd0e4c5113866d0139015edb52f238,"Each node is visited 2n times

and the time complexity is (On) or exponential",0.0,79
23362,23362,27610,ffb312171739bda8140d790d7e76d39d8cb251ebc0d6e983413e101fe068405632084409e60fc3615fbb0328c8c628ab617f395e064e10a0893ff352b3482def,"When traversing through a BST using a recursive function, for each node the function can call itself twice depending on the number of children and then perform some task on the node itself. Although it seems like 3 operations per node it is actually one because when the function calls itself for a child it counts as an operation for the child. Meaning every node will have at most one operation done on it which makes traversing O(n) with n being the number of nodes, for all 3 kinds of traversals.",6.0,79
23363,23363,27611,2e87414379efcd8b6abefa082fd766ea6bbd6a7c49327da9b14527216de652d464a74ad3edb281cf63c53ec51b9a87c17ffe7ae230ea816e625650e59f9bd068,"Post Order we visit a node 3 times since we will need to traverse left then backtrack then right of it then backtrack for the third time 

In Order traversal visits a node 3 times since we find the left then we get the value then we find right then backtrack again to the value for the third time

Pre order we will visit a node 3 times since we will find the node then traverse left then back track to the node then traverse right then backtrack back to the node for the third time in that traversal.

We would do linear work since we visit a node we backtracking and checking it's left and right node this means it is O(n) complexity.",3.0,79
23364,23364,27612,ac47e3ceebccb755b1987f028345ba571e2bbf0bc4ebc355e11ab520e9f3ffd71073789246ed0c633ccffb81e8b77e299c90427fa5f8a55f41455cee47d290e1,"Since we would be visiting each node three times: For pre-order we have to visit the current node before visiting other nodes whether left or right, for in-order we have to visit the current node after visiting all nodes inside left subtree but before visiting any node in the right subtree, for post-order we have to visit the current node after visiting all the nodes of right and left subtree thus the complexity will be O(n) since we have to traverse all the elements and in that case we don't traverse the elements once but thrice. ",3.0,79
23365,23365,27613,0dd6ddfbe50025d9a72df696362b0bdfb49434124c6d6642bcd0c15ba9544de38a86488e790b653cf1d9ab0bbd206e27a92d4ffa059eb91de07bea325c7f7613,"Each node might be visited twice and that will require O(n) complexity. The node can be stored into the memory or in a stack, where later it will be visited again and deleted from the stack once it had been printed or processed.",2.0,79
23366,23366,27614,bc7ce8dcf81474ef89d407bc167ddbdc0ae686813582e07ef0e124f6d6fe081339ab3b2bb05c54a356b901c5c208933d91dbaf731894bf50cc25eab5e102a8e6,"When performing a pre order as a Depth First Search,the current node is visited and then the nodes to the left are visited until a leaf is reached.Once there are no children on the left,the children on the right are visited.

The in order traversal will find the leftmost node in the binary search tree and will visit that node,afterwards it will visit the parents of that node.Thereafter the child on the right it visited and it will go to the leftmost node to visit.

A post order traversal is when the leftmost leaf in the tree is visited and then it goes to the parent and then to the second leftmost leaf.This is done until the parent is the last node to be visited.

Each node may be visited twice.

The complexity of the BST traversal is O(n)",2.0,79
23367,23367,27615,3535a43df3300af7e5c3e95a4369804ca852c0470f1fe060d2a246291726064d9eeb362ff2318c56c2b2c1abd2d650cb0578f3dab1f0c9bef113f35bec7220b3,"A BST traversal as a Depth First Search has three cases per node :
0 children : 1 visit

1 child : 2 visits if found on the left of the root, 1 visit if found on the right side of the root

2 children : 3 visits

In the best case the time complexity will be O(1), there is only one node

In the worst case the time complexity relies on the sum of the number of visits per node therefore O(n)",8.0,79
23368,23368,27616,7784c26ab2d9766ae819dd1da89317a98dc39ebd7976e740ed6ab84978a76aaebcecee3ccbfd4bc08a3df68e244abf9916ece7c5f547ed6b7e35d519a43c7259,we visit each node 2 times.  The complexity is 0(n) because we need to visit each node in the tree at least once. ,2.0,79
23369,23369,27617,a09890d1b445c23fabb578b3483b14013fc02062f1b3aa1b4c6df4bdeb9b3b91a9c90e4c472aa2da65ecaa5b831c0625b91b1940398021966ddfe90195c5216f,"Due to the recursive nature of a depth first search algorithm each node is visited at least once giving it a time complexity of O(n), where n is the number of nodes regardless of whether it is an in-order, pre-order or post-order traversal.",2.0,79
23370,23370,27618,666d09a4d8260961dbb488b896e8680fe46f9012a9bfa6adbe518edfaed179e00538132a0e660a988cc51e3f8b8695b7b78d6679f0a1e7d0f26361ce20a96384," In each traversal, each node is visited once.

the Complexity is O(n)

this is because of the recusive calls we would make to the left and right children in order to print the entire tree in the expected format.",2.0,79
23371,23371,27619,5f92eb6a07aed01e019162660614241903fd30335dc49cd736d18a97a0b8e4d8d8eaa7a31ce7cb8ad65e895e5a8906b98d2e7635d42d019af72333c76c35da1a,"Since the DFS starts from the leaf node, we would visit each node at least once. This also accounts for backtracking.

The complexity of the binary search tree is O(n) because we traverse each node once and the amount of work done on each node is linear.  ",4.0,79
23372,23372,27620,4428555ef8072ef23d17db65e798fc29286c3f011a1099d994917d7424cc31d5f0d195105018e3c14dd5ec04f91fc4ea0c088a5e61680d4692faa4d313c225c0,We would be visiting the node once for this type of traversal but will be linear O(n) of n nodes ,2.0,79
23373,23373,27621,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"Leaf nodes are visited once will internal nodes are visited in a manner that accords to the children they have.

The complexity of BST ranges from O(logn) to O(n) with the former applicable for complete BSTs and the latter for degenerate BSTs.",6.0,79
23374,23374,27622,52f183a2edd50f67bf9165da2ed344e6b1dbef117bcc8a87e8fdd544cade3eccfad6434b2157d981bfdc96048e52a8b1696fb090b734b452d891d2f61d866105,Every internal node and leaf will be visited once during traversal if the tree is full.The same occurs for a degenerate  tree.The best and worst cases for  these traversals will be a comolexity of O(n)-that is O(n) for best case and O(n) for worst case.Complexity is linearly dependent on the number of nodes in the tree. The amount of work done for each node is constant.,4.0,79
23375,23375,27623,9082e5ab0ae09b23b5e0275a763493886db0b7f721520ca423ce3577e6b6ec09537f5d0b22aac121f7604a542a413dd81640198a15212f5aa5403c721b42c11e,"The complexity for a BST traversal is O(n).

This is because the location of a node in the tree is what determines or decides how many times we are to traverse hence we would traverse each node on our way atleast once and so we would be doing O(n + n-1) n-1 being the number of edges, and so as a result we would be still doing linear amount of work hence we write O(n).",3.0,79
23376,23376,27624,9b13f2d70694a174cc296db2532a81cde5f414c86e87388e32c45d14a1b85a47b70cc54fdcb2f6455012d569323883da99f34aab409453d8e838e0ae2bf41aff,"The complexity of BST traversal is O(n+m) since the number of edges that can come from a node is only limited to two in the case of a binary tree and the maximum number of edges in binary tree is n-1,with n being equal to the total number of nodes.

In the best case, it will be O(1) and in the worst case it will be O(logn) or O(n) depending on the structure of the tree. In the worst case, the number is not in the tree and the path we follow corresponds to the longest path from the roof to a leaf, as a result, we traverse h times so the amount of work done is proportional to the height of the tree, in the best case the search key is the value stored in the root",1.0,79
23377,23377,27625,fd8a875c5398ac6c36a731d0d10a006399599403b9ee2f4994b116a012c4bd603697ca87421ae17a8eaaa96913f3870bb71641db61fda611c4a27d1aa224e5e0,When a tree has been fully traversed then each node gets visited n+1or 3 times for most of the different cases. When we are doing all operations on one node the time complexity is O(1) . When we have a total of n nodes then the  time complexity will be O(n).,2.0,79
23378,23378,27626,3824a0678a0ee80961c81764186a1496645536aadc7127ac81665ef8825202d12ca91cc1dddb49cb3545dd95e3ab23ddf164ccd399cf03acc33959144061677d,"* Using a Depth First search in a BST in n nodes we visit each node once because we keep the nodes and move from them using recursion to the next node that we have already visited and continue to the ones that we have not.
	* The time complexity is O(n) , because we traverse the nodes as many as they are we don't repeat any or go back to any that we have.",4.0,79
23379,23379,27627,0a640b06ce1d454be947795a6308fcfcc73f66b49b60199788f434bf91f3e08719c4b7dee42514e49b76fea543dcbe6b2a18d9de0cfa87cc5f82c989cd2f76ff,"I think it is O(n), it seems to me that the number of times we visit a node depends on the edges or/and the number of children each node has. In some cases I find that the worst complexity of a traversal is O(n+(n-1)),

where (n-1) is the maximum number of edges, and n is the number of nodes. this gives O(2n-1) which I could just write as O(n) as it is linear.",2.0,79
23380,23380,27628,414c0211baa0f7785fed3a2ae8d654438eeb57e32a72d726d41fb80a14e5bb82594bc148b341e170426f496146bb1f57723f178ed8b08e3a2a9402960a0201df,"The number of edges from a node can either be 0, 1 or 2 in a binary tree, thus in a BTS with n nodes, the maximum number of total edges is n-1. 

The complexity of a Depth First Transversal depends on the number of nodes and the number of edges. [Gives Total complexity as=> number of nodes + max number of edges= n+ n-1. Thus O(n)

If the BST is empty: O(1). If we only have a root, and no children, O(1). If BST is left/right skewed: O(n). 

For all 3 traversals, we have to print the current value(O(1)), and then traverse to the left (time=n/2) AND to the right(time=n/2) of that node. We have to go through each node once.  [Gives Total complexity as =>2(n/2) +1= O(n)]

Thus the complexity of a BST traversal is linear: O(n).",9.0,79
23381,23381,27629,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,"In a BST with n nodes, we visit each node once therefore the complexity of a BST traversal is O(n).",4.0,79
23382,23382,27630,97b7f5ff46c1c824381cef505f20511747560e70b8b1e616642dc4fcce22c546867f43d01ab15335e8a2a57b9d3fba9ae8276c6347ded2ad2c8d88ebec13760a,"When performing a pre-order traversal in a BST with n nodes, each node would be visited at least once, with the root being visited twice, and internal nodes being visited 3 times.",2.0,79
23383,23383,27631,e394539baa7fd0006de5096759d1db9943b0b453927105fc99e564a56547ecb01587d2f0348be0224bd521c0377577b713f00c14b60183a6d229e89193dcb643,"O(n)

In order to visit each node, we have to transverse through each node in the tree. Depending on the number of notes, for example n nodes. We have to transverse through the n nodes.",2.0,79
23384,23384,27632,16751d82a0250cf90230a736276250ecd4342c2e9097f12ebacee397740771d03e925ee189c3aaacf702dbec6f3610c7e13e7ed44667c2823433286e585becf2,depending on the number of children each node has.each node with 2 children will be visited twice.nodes with 1 child will be visited once. Since the number of edges that origanatte from a node is limited to 2 and the total nimber of edges is n-1 where n is total number of edges the time complexity is O(n+n-1) which is constant time i.e. O(n),2.0,79
23385,23385,27633,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"-We start with the root node and travel down a single branch.If the desired node is found along that branch, rather if not we continue upwards and search unvisited nodes.This search has O(n).

*Let V be the number of vertices and E the number of edges in the graph.

-The time complexity is O(V+E)

-O(E) may vary between O(1) and (V^2) depending on how dense the graph is.

-Worst case scenario happens when you keep adding nodes that are always larger than the node before (its parent),the same can happen when you always add nodes with lower than their parents.",0.0,79
23386,23386,27634,267e2a74684712f40153e983cf911454f693aaba7aeefb5a018f4e1b42bb05582faee8c5c865be8869988dea6e1c2f220a507c49209244aad2cd13359f2247d7,"In the worst case the tree is unbalanced and has a height of n with its Big-O notation being O(h). Whereas the best case scenario is the n the tree is balanced, the height becomes log(n) and a Big-O notation of O(logn).",0.0,79
23387,23387,27635,50ac02db01dc47f0f24bb2a0e8bc1bebe3aac1ecfe652f1c87b260f45da4def0a267392e043e67a0b0f3a39374188322db34615d5257a196fc0978d4d004e1ed,"_In BST with n nodes, we can only determine how many times we  visit a node using the 3 traversals called in,pre and post order.A pre order traversal will give us a list of numbers in the order of value,then left,then right,meaning we visit each node once.In  an in order traversal ,the algorithm used is left,value,then right,  which gives us the order of values wihin a tree.Post order uses an algorithm left ,right,then value,which gives the post order list of values. The conclusion would be that out of all the 3 traversals,each node withn a BST will only be visited once even if we consider backtracking.The time complexity for the best case for the traversal sort would be O(n log(n)) and O(n) in the worst case.This is because we have to access every node  within a tree to actually come up with all the lists of the 3 traversals._",2.0,79
23388,23388,27636,bd13f3a1f05cded43b306e7cf672db1fa9cf812229ead4318a993e62aa7ff42541e39b6868fb05069f972d798f5a5b109e0e615acf69b7c88b8e2bf435bfc374,each node is visited once for each of the Bst traversals and the time complexity will be O(n).,2.0,79
23389,23389,27637,888a700ecff48b8e58609f74298e3e913836c7525e3508cee74dcd45d73e3b5cb35996869dd34b3342eba886899eba46a61c603fc724f15dfcf45804ca8c7ece,"In-order, Pre-order, and Post-order traversals are Depth-First traversals. The complexity of a Depth First Traversal is O(n + m), where n is the number of nodes, and m is the number of edges. Since the number of edges that can originate from a node is limited to 2 in the case of a Binary Tree, the maximum number of total edges in a Binary Tree is n-1, where n is the total number of nodes. The complexity then becomes O(n + n-1), which is O(n).",2.0,79
23390,23390,27638,c1e9e5684a44aa14de0a7d7593ec9809b4c2858f861776d6d9a8b2df4bba9cc394db455eb7a58c49a19ed6c08dee2a5b9eba1e9f390b469640fea31d4ffda4c0,"In a BST, each parent can have a maximum of two children nodes, a left and right child. For all non-degenerate Depth First Traversals (Pre, In, and Post-order traversals) we visit each node twice, when we visit it for the first time and when we visit it for the last time in our backtracking. This takes O(2n) which is still O(n). Since degenerate Binary Search Trees are effectively ""fancy"" linked lists, any traversal through the tree is the same as a linked list traversal i.e. O(n). The fact that we are traversing through the entire list, implies there's no best case or worst case, every time we have to traverse through all the nodes. Thus I believe the complexity of a BST traversal is O(n) - linear.",5.0,79
23391,23391,27639,e3fe34fe397fdba954ee04d79db645b0148c5938ca6f2f7a2907aa58749a445701d138ec6de61364a9d6a738e1bd62c299a45c7a655f0f5a3aa7fe48b798bb3b,"3n times

O(n) - ",2.0,79
23392,23392,27640,3d3c1be79bbed7b365d3aace59dfe14a7a1385e7072a675c0aa539c52e6b6368cbd7b12fc937010386846b4d8cccf764dc628c232956154c4f1395918f004d16,"The complexity of Depth First Search, according to wikipedia, would be O(|V|+|E|), ""where V is the number of vertices and E is the number of edges"".

As a result, the complexity of a BST traversal through this structure would be the same O(|V|+|E|) because we learned that a BST traversal (the act of choosing the longest path from the root of a tree to its leaf/ves) will correspond with its height (from the root, along the edges to the leaves).",1.0,79
23393,23393,27641,7db17fd2acfdd980933bf2f92abec54feac68e8b60f672ae1ba7781b8dd15de47315f37d74c147384e68a3a01e88e6539391471e6490908578bb1e2cdf85e7c7,"When performing pre , post or in -traversals the leafs will be visited n times. The internal nodes are visited

2n time as we use them to climb back up the tree when trying to access the nodes on the other side of the tree  .The complexity of BST will be linear if the tree is not degenerate and it will be logarithmic if it is degenerate. BST complexity in the best case is O(logn)  and in the worst case it is O(n)",1.0,79
23394,23394,27642,3dc26b747d97da3ab4afec05ff58fc24d9456624d1de4e773000cee11c5770c4305e55aba8a358eac1e51ad690a762f5e637a6ce6a5554139fe18ecd7662a5af,"We will visit the root node 2 times,
the other internal nodes we will visit them 3 times,

we will visit the leaf nodes once,

 the complexity is O(n) ,because all the nodes needs to be visited .",5.0,79
23395,23395,27643,a8dcc87a24b584021a1bb3ffd592a4ea66a1679acf3b2b41f26aef4e481760f4e64990e460e4e26ec12a8fef5d2354f5070843ac6e40f4a1e24bc122bfa91df9,"Each node is traversed once

The time complexity is O(n)",2.0,79
23396,23396,27644,ab943cfa0d926aa21911a9961743ce4779859ba20a4ac4e15e75033134ef20f2d090435e99a19a4b2beb23e354a8983d0355213a926be357504dc13138c83605,"The complexity for the BST transversal is O(n).

This is caused by the location of a node in the tree is what determines how many times we are to transverse hence we would traverse each node  on our way at least once so  that we would  be doing O(n+n-1)n-1 being the number of edges, and so, as a result, we would still be doing the linear amount of work  hence we write  O(n)",2.0,79
23397,23397,27645,4a108b6388ab518862a0eddc19b8d86fd9549abfafdc544be7cbe5e9a91a20102b9726ddaa529a19a86fc38fa4700a0fdd752705615738f3f81b854fa84c557b,in best case we have to visit 2 to the power of n times.,0.0,79
23398,23398,27646,912a17c5532a85cc610facff6c98d42b64fb259b767c809567c65cce318eb3dc8f21bcbe5e653de87fe40d2502ab66869bc553e63fc3a1d7697be613c3b49a69,"The number of times that we visit a node depends on the structure of the tree. In the pre-order traversal, we take the value, and then move left and then right. In the post order traversal, we move left, then right and then take the value. In the in-order traversal, we move left, take the vale and then move right. So this means that the number of times that we visit each node is variable. 

The number of times we visit the node would depend on the number of children it has, if the node has 2 children, then it will be visited 3 times, the first time when traversing and the second and third time when backtracking to get back to the parent node, whereas if the node has 1 child, it will be visited twice, one for traversing and one for backtracking through and if the node has 0 children, that node will be visited one time.

Based on this the complexity of a BST traversal is O(n + m) where n is the number of edges and m is max no of total edges",10.0,79
23399,23399,27647,ddf05f993d32eb46f0b5d18783c3f0bae7ba45bfb71b7a11c47b2697ab035bd02b089a647111ba9b72f32e9d1912bdd9dfcb6298cbd5226f8387827448c2cdef,n-1,0.0,79
23400,23400,27648,0acf933aafd8ccfefdb0a07c9cd769ff21b003c332b8b90f6edffc1573664ade1e2d7b54669b2cee7b03b35091d029450c66d87d0c0afdf5016d3799c57a4fc9,"The same as the number of indegree of the node

searching whether it is visited by its ancestor or not- if it is, it wont be entered into the queue.

 it takes O(N) time",2.0,79
23401,23401,27649,97a01199b925330f29640cdb86e45eea363ff96eb767b66ea518348ab8ed24fd59b309226c6a592a7f7ea6b67fef81cbfd1daad02d4a32f29300da894c457dc7,"pre-order traversal the minimum and maximum number  that we can visit each node is one.

in-order traversal the minimum number that we can visit each node is two times.

post order traversal is the same as in-order traversal the minimum number that you can visit each node is two time.",0.0,79
23402,23402,27650,78249ef9b62941992169ea6ab9335b72fe3732b0d62324e87cfd98782c3176ff3a0f6d77d1563959cb064ffef03d777dd5132e65d5820daed930a9e3247d9f38,When performing a depth first search we visit every node in a tree.The leaves are visited once and the parents are visited twice sometimes 3 times depending on the order we are doing.the complexity of a BST traversal is logarithmic because the height of the BST is O(logn).,0.0,79
23403,23403,27651,9ab5ee6dcd1eeee42b584dd13d10dfb771aeae24b070596bf8e33f41840796cff5a58f61a4f76bd5d61ec8edd7ee76fc7e403b38a2b713cfce865554906c5149,I think it depends on the tree but in most cases it visit them atleast more than one.,0.0,79
23404,23404,27652,a483d97f2f6f4b566a91dffee7b0dc51b69866d7a50c6e53308e166eaac8f5373cd9dfbf9a10c25bd5d41a415c716306b0d1e020a1acf8282aad769edfdcc9c4,"The complexity for a BST traversal is O(n).

Since the location of a node in the tree is what decides how many times we are to traverse therefore we would visit each node on our path atleast once and so we would be doing O(n+ n-1) n-1 being the number of edges, and so we would be still doing linear amount of work which is O(n).",2.0,79
23405,23405,27653,fd3ac26e8f1d74669c591d17cfba292d301a38f59035e0e015254638e09238378ffbb05277661aa625df195230a27bb79b8964e830815de826a62bf695fefa00,"PRE-ORDER

n-times

IN-ORDER

n-times

POST-ORDER

n-times

O(n) becacuse we visit n times.",2.0,79
23406,23406,27654,6e573d9284194cc7291f560a714a872dd47b4e061283e85a73d0f329ec03550a03a1a3f166b0239189f5a0ff40814ee55278425a8a226193ee0b842b340ab615,each time when a search is done and it has the worst case complexity of O(n) but in general the time complexity is o(h) where h is the height of the binary search tree.,1.0,79
23407,23407,27655,eec934572d7644ba0121c8b2feb2c582e9f3f4f5b58187b8858bc2ee24ad1c13bedfb2cdb5029267bc11b865502439fbacde60c9046792350b575350ddc17ef6,"1. Pre-order traversal: we visit each node once but with backtracking we visit the node twice.

Post-order traversal: we visit each node once but with backtracking we visit the node twice.

In-order traversal: we visit each node once but with backtracking we visit the node twice.

2. Complexity of BST traversal: 0(n). All traversals visit every node of a tree once. ",4.0,79
23408,23408,27656,6411a31397edca98a86156eda9fe940cd25214f5793edb40ff98bea1168dd2f02767f84a7d8f08cc5cbcf1da236fabf58172c048483fca623b7f16592128e03a,"When traversing through a BST we only visit a node once.

In a best case the complexity of the BST traversal will be O(log(n)),this will occur if and only if we have an almost perfect BST. But on a worst traversal the complexity will be O(n), this will occur only when the BST has a maximum possible height.",4.0,79
23409,23409,27657,798235659bb9174e71b3ff61763ec292691ece6655d9ff85d1fbb65ede38be3c46ca62a6d523bf01e0f519090370eeadd560efded9ef16231507d4492e919473,"Nodes are visited once.

The time complexity for a traversal is O(nlogn)",0.0,79
23410,23410,27658,7ed1c803cb6942b25a462119e14146d3dfdc8b2d8405742d6e37974d2693c34f2838afb58a1bcf41b9fcd8829c1dff4d4b192c929c721bc46e1615dcea231b30,"For a Pre-Order Traversal, you would have to visit a node once. In the case of backtracking , you do not consider it  that would make the pre-order traversal false.

In the case of In-Order Traversal, you would visit the node twice. When backtracking, if it is only the second  time the node is traversed then it is valid.

Lastly, in a Post-Order Traversal you need to traverse through the node three times, in a case of backtracking it is only allowed if it would be the second or third time the node is visited.

Complexity of a BST traversal is O(n) since we have to traverse all elements within the tree.",2.0,79
23411,23411,27659,d262858bac7cd6476e0cd48b8622c751312997fe7fae4adba9c98bf17ceadac187d9de2b401de3d1895e85edc24940f00a102bf214f436104f37cd1b8669240b,"The leaf nodes are visited once. The root is visited n-1 times. Internal nodes visited based on how many nodes are below it. The last subtree we visit, the root of that subtree is visited 1+ the number of nodes below it. The complexity is O(n) because we are doing linear traversals.",4.0,79
23412,23412,27660,bef6837a7fdfe1da5fe1293f44c76b96d3b8dcc796faa186ced378d3238a30c359695c10ba31e008e6450186def6f4c6da86e1819e6310ac4629db0e4ae2f7c4,"The leaf nodes will only be visited once because when a dead-end is reached, it will be popped off from the stack. The internal nodes will be visited twice because once a dead-end is reached and there's a pop off from the stack, it traverses back to the internal node. I think the complexity is O(n) because each n case must be looked at and then traversed back.",5.0,79
23413,23413,27661,61263672c5c532106e7f21122dcaab559eafcffe3f9da40ef6a4194409e8f1be9b62145c70c7a6a62ca846b85c63f3fbde4504110d16d1088e8621a2430bcdec,"The dfs visits every node once. The method starts from the root node and goes through branch by branch, it searches all unvisited nodes til it finds the one its is searching for. It only enters the node into the stack once.

The time complexity is O(n) where n is the height of the tree. This is because we traverse each node once, i.e. we do linear work for each node.",4.0,79
23414,23414,27662,a0053c94d18ea0e087a62013f5ac80c5b6b5b2b0c4aa9dd88e21096fafa1947351de1bc64c5f102a231a8bd4d8d7cf40acc72747f50d8fe1ae800f7aa85e0eed,"In post-order traversals, we visit each node at least one time.

The complexity would be O(logn).",0.0,79
23415,23415,27663,5c96945f14d6fc788ed8c6c36dabf314debb1526e588422f61ac844f148e394c747509da6ebf3fac148319b89d19dab295d5360db7c4991b8db71ccf538d7808,"In all the traversals, the leaves get visited once.

With the pre-order traversal, if the parent of a node has one child, that parent node gets visited twice. If it has two children, it gets visited three times.

With the in-order traversal, the parent of each node gets visited twice.

With the post-order, each node gets visited once.

The complexity of a BST traversal is O(n) or O(logn) because we have to traverse through each node and it is only O(1) when the root is concerned.",6.0,79
23416,23416,27664,2dd5e2f41652664c7010e9c75b107a0a619a9b54063e68bd2c6a9b76a1fcac07a9bceac7ca7bf3cdecc54ef1490301f90259c5d418e4b888c5d3f0477b59ef3c,We visit each node n-1 times. Complexity is O(h) where h is height,0.0,79
23417,23417,27665,e128973184d15ac7a750b822c9d3b3fe1c0b4d5c9ec9968806c119de2807128c5380243007b2944cf3a301c3270578e76aaa068c636326951a9eea7851758fdf,"In the pre-order traversal we visit the root then we go left after we visit right until all nodes are covered.In the in-order traversal we visit  the left node then the root then after we visit the right until all nodes are covered.In the post-order traversal we first visit the left node then the right node after that we visit the root until we cover all the nodes .We traverse each node once.

The complexity is O(n) ,because the amount of work we do for each node is constant and does not depend on the rest of the nodes.",3.0,79
23418,23418,27666,639a68158c22ced38b469e5ff5439c6df90887f4ac511792920966a4b66fbbb0736453130f1e07f675685ab76215a4ca74f33ab5a9bf6fded51b150fcaa550e3,Every internal node is visited three times due to backtracking and every leaf node is visited once. The complexity of each of these traversals is O(n+m) where m is the number of edges. The number of edges in a BST is limited to 2 thus the maximum number of total edges in  a BST is n-1. Therefore the complexity is O(n+n-1) which results in a complexity of O(n).,7.0,79
23419,23419,27667,01414e21ecb9a1334890023f94a0d282ee23097fe9f9524ae17a5a130cb936a59877f182817dee70cef409eabab63c6b47a25ed1ae4ef0dfef7f2566f253e2b1,"During a pre, in or post-order traversal, we can visit each node a maximum of 3 times (including backtracking) each although in a :
- Pre-order traversal, we record a node after 1 visit

- In-order traversal, we record a node after 2 visits 

- Post- order traversal, we record a node after 3 visits 

Because of this, the time taken to traverse a BST is 3 times the number of nodes (3n) so ideally it would be O(3n) but since this is still linear time, the time complexity is O(n) ",3.0,79
23420,23420,27668,1524a034e009646803d7074c495cb1bd3919f40bf0c99261b282adc7801990411f97759342d2d5b53fea8bfcd2292ae00d0444e55290b251e7ed8a081caf06dd,"Pre-order, in-order or post-order traversals are all depth first traversals. All of these traversals depend on the number of nodes (n) and edges (n-1) in the Binary Search Tree. This will cause the algorithm to visit each node n+n-1 times.

This makes the complexity of a Binary Search tree to be O(n).",2.0,79
23421,23421,27669,e0c83344227ee0e9cbe053565e48a2fdd45505359ef079abf58dae6d4b8251e874c464186ed9d597d1e6bd62c45d87ea5c0897cd6938b6926936cb2def62d356,"Using a DFS algorithm, in this traversale first the deepest node is visited and then its backtracks to its parent node if no sibling of that node exists.
Taking this into consideration the time complexity of the giving DFS would be 0(n).",4.0,79
23422,23422,27670,a959a4bd23a818684dfb2a6c94ac89925575f3b11f0de3ed6d4df640b02681f2171e62de10059d8c04c758f13335e59b8e75b311b1045da8f168f89c32919f7f,"The traversals travel to each node recursively, and visit each node once. The complexity of a BST traversal is O(n), because you are visiting each node once only.",2.0,79
23423,23423,27671,89502ac0aa9bcc7e1f53c6f2ab1184a643f5c96abf038408f562f5cb7340154d0c96d136d3c4ce774773aa13f3d95a0a98c70e80020a05dce05a8835fe30adf5,O(logn) each node is vististed once,0.0,79
23424,23424,27672,8127d4098ce90e5354b83277c230528a4f346dff2268e6e565e170f557f4828895b86ce9e4d45680788cfb7696e91c4b7e7c80cf0ef0611dfea212b6f772071c,"we only visit the node once;

the complexity of a BST traversal which is the worst case is when we go through the longest path from the root to the leaf which results in traversal equivalent to the tree's height and is O(logn) or O(n)

the best case is when we have a perfect tree and is O(1)",1.0,79
23425,23425,27673,f11178d26d71b36980a2e031712b410b8887af4a2b6c48901c6a568377c95cf608d8bdb211ef99a8ec80760d046f982bcd08b27ff9c8f8cd3f71083f65b80c48,"Pre order 3 times

In order 2 times

Post order 2times

The time complexity is O(n) since we have to go through all the nodes the binary search tree.",4.0,79
23426,23426,27674,acc027b1281fb7611892bbd9cd22b170d39dac509f3cbd3c4ae2298ef8fcce3e213c9bdb095b30f4b14371abefeb025cbed1bfbb0b3e1f2baccc7d74d415003e,"best case : O(1)

worst case : O(log n+1)-1",0.0,79
23427,23427,27675,c2e3a17d6cc0156e335ca9215e55053ddbc80682871f8957ca1d1b73d39dbe24e0950e6728cd273bbd1fbaac4e9fc1f8fc1eeb009c8b2565447f198e841deab0,We visit each node in logarithmic time,0.0,79
23428,23428,27676,6accb08d7786944c71cd9b921787862856d4a3c42592fbffde311b7d0b92a8f983d0c4f430c2af6d29dc0b77bc121c3af33f1ea64f2b5de47c11c3122369896f,"In a pre-order traversal, we would visit each node exactly once. In an in-order traversal, each node in a BST with n nodes would be visited exactly once. Similarly, in a post-order traversal, each node would be visited exactly once.

Therefore, all depth-first traversals must traverse each node exactly once.

Thus the time complexity of a BST traversal is _O(N)_. This is because the time complexity of depth-first traversals is _O(N + M)_ where _N_ is the number of nodes and _M_ is the number of edges. In the case of binary search trees, the maximum number of edges that can originate from a parent node is 2, thus the total edges _M_ in a BST are limited to _N_-1. The complexity of a BST traversal would thus be _O(N + (N-1))_ (where _M = N-1)_, which effectively becomes _O(N)_.",2.0,79
23429,23429,27677,a6a1956dca8537b87c581329dd539be0e1754c767a458496056c957b37b7d5cf8e38e7b6a815b9c917caee9a53108cd46c4caa581c67b0f0565e27d0605c7826,"With considering backtracking through a node as visiting it, we visit each internal node twice, while visiting each leaf node once 

The time complexity is O(n) 

The reason for this is every node is visited in all forms of transversal",4.0,79
23430,23430,27678,571f4b857c687d9d563078992ce0d593248d2c9f52df5afb071f8e300cfd009d7831df6cd94d1fdf3131324af503b103a8881171137c2ca59df7ead36faf3f74,"Leaves you travel to once. Parents of 1 you travel to twice. Parents of 2 children you visit once. The root gets the same number of visits as it has children

I think it would be O(n) you have to visit each node at least once making the minimun number nodes you visit n but because some nodes require you to visit more the formula changes to an + b which is still O(n)",6.0,79
23431,23431,27679,bf4b5731c3c3bd0f2b59e631e277805959da8b9efedbe010df49f525b49b713ed8678bb3e54ddfd542bb302e79e236dfb9ec30ec253f0f80d3cd72c6a5094fbc,"Depth-first search is technique used for traversing tree or graph where backtracking is used for traversal. In this traversal first the deepest node is visited and then backtracks to it’s parent node if no sibling of that node exist. In other words, we traverse through one branch of a tree until we get to a leaf, and then we work our way back to the trunk of the tree.

In Depth First Search, we have to see whether the node is visited or not by it’s ancestor. If it is visited, we won’t let it enter it in the stack",0.0,79
23432,23432,27680,3227954877ff6b3d6e5d415eabaacb6ee56a5809874f349fcc72cbd6b74b9924802065f3198d52fa435eef46404fa2ce0465698400217a4b7b18ef03d8cc91ec,"WORST CASE COMPLEXITY: The worst-case complexity is O(n) for a single linear search and this occurs when the value is not in the vector so we end up searching the entire vectore. If we search n times we do n^2 work, so the complexity becomes O(n^2).

BEST-CASE HEIGHT OF THE TREE: The best case height is O(logn) and this occurs when our tree is balanced, i.e it is a perfect, full or complete tree.

WORST-CASE HEIGHT OF THE TREE: The worst case height is O(n) and this occurs when the tree has degenerated into a linked list structure so inserts end up being linear and the height of the tree is linear.

WORST CASE INSERTION: O(n^2). A single insert would require a linear amount of work since our height is O(n) and we have traverse along the longest path in the tree to insert ~ n operations. So inserting n numbers would require n*n operations which is ~ n^2.

BEST CASE INSERTION: O(nlogn). After each insertion we have height of O(logn) so we will have to traverse a height of logn n times to insert so ~ n*logn operations. Hence the work we would do is linearthmic O(nlogn).

SEARCH AND CONSTRUCT BEST CASE: To construct the tree would require O(nlogn) and searching would require O(logn) time since our height is the best case. Since we search n times, we perform a total of O(nlogn) operations. Thus the total work is 2*nlogn. Hence O(nlogn).

SEARCH AND CONSTRUCT WORST CASE: To construct the tree would require O(n^2) and searching would be O(n). Since we search n times, we require O(n^2) time to search. Thus the total work is O(n^2).",41.0,80
23433,23433,27681,55ff8d4f9ee8af9848a55dc4a2a3322adb850c959c61827806d583f4f72e4caf8076da8ae41627b21a0edd1eccee2cd496b303fbcb256d41e8ba6c3b55c02e66,"- O(n), this occurs when v is at the end of the vector. We will do O(n2) work if we search n times.

- Best case height: log2(n+1)-1. This occurs when the binary search tree is perfect.

   Worst case height: n-1. This occurs when the binary search tree is degenerate

- O(n). This is because as we add more numbers the the amount of work increases linearly, which is similar to    a list. Since the worst case height is equal to n-1.

- O(logn). The amount of work it will take will increase logarithmically since the best case height is equal to      log2(n+1)-1.

- It will take us  O(logn) + O(n2) OR  O(n) + O(n2)",19.0,80
23434,23434,27682,06f90aca60b4b2db0e6d8bb78d0ed0da22ceb02b561b842eee51951b0e04be81e8817f795eb9597349f2e3c12b7befca0ed36322cff788052acb9b91388f1fdc,"in worst case we search O(n) or O(logn) times, this is how much work we do if we also search n times [depending on the structure of the tree], this occurs when we follow the longest path from the root to a left

best case - O(logn) -  this will occur when we have a balanced tree 

worst case - O(n) - the worst case would be traversing through the whole tree (longest path from root to leaf) to insert a new node. for example a tree that has only right child nodes and inserting a new node at the last node, so traversing through the whole tree

the work done is proportional to the height of the tree

the worst case height is n-1, so inserting all n numbers will have O(n) complexity as we will need to make comparisons will multiple nodes to insert the new nodes

the best case height is log2(n+1)-1, so inserting a node will only need one comparison and is therefore the best case

as said above the work done is proportional to the height of the tree for insertion. so the complete construction and searching for the tree:

best case - O(logn) - logarithmic time complexity

worst case - O(n) - linear time complexity",15.0,80
23435,23435,27683,263fd6b7e81bd2b0bd84f67415866c3d75bf78011a0e0748b552d65d3fb35fc4bf5dca96f9ccb82225afdb2c9f73d9593526bb28fe17ab6d85ae420a8a33d70d,"The worst-case complexity while using a vector would be O(n) and it occurs when the value being searched for is the last entry or not present in the vector. This will cause us to traverse through every entry in the vector and check whether the value is equal to that of what is being searched for, until we ultimately end up searching for it in the last entry.

If we use a BST to store values, the best-case height would be O(logn) - a height of log_n([n + 1] - 1) - which occurs when the BST is perfect and the worst case would be O(n) - height of (n - 1) -  when the tree only forms one path (degenerate tree).

We would have a worst-case of O(n) for insertion due to the tree essentially becoming a linked list when it is degenerate and the work for insertion being dependent on the worst-case height of the tree.

For best case, we have O(logn) due to work being dependent on the best-case height of the tree.

For the worst case, we would have do work O(n) to construct the tree and O(n^2) to search leaving us with work O(n^2 +n).

The best case would be constructed in O(logn) and searched for O(n) times. Leaving us with work O(logn + n)",41.0,80
23436,23436,27684,a0a0e3863f2cfe81dc13120d1d5fb28060efbca078cff0afc0ca4a53755acf909a3b28053a432d02251e8d53776e3aedf7eeff75f48fc36029b0d4fb7d46aa25,"When searching for a value in a vector, we access each index position of the vector in order. In the worst case, we will have to check every index position of the vector. This would have a complexity of O(n). If we search n times, we do a quadratic amount of work (O(n^2)).

If we create an empty BST and progressively add each number to the tree by calling the insert function, in the worst case, each node (excluding the leaf) will have one child. In this instance the height of the tree will be equal to n-1. In the best case, All of the nodes have two children (excluding the leaves). In this instance the height of the tree will be equal to log2(n+1) -1.

If we have the worst case height after each insertion, we would have to traverse the height of the tree (which is n-1 in this case) for each insertion. Each insertion would take O(n) time and if we performed n insertions, we would do nxn amount of work. This would take O(n^2) time.

If we have the best case height after each insertion, the height of the tree would be lower and we would only need to traverse log2(n+1)−1 times in order to insert a number. Each insertion would take O(log(n)) and if we performed n insertions, we would do nxlog(n) amount of work. This would take O(nlog(n)) time.

When searching for a number in a BST, the time complexity is O(1) if the value we are searching for is in the root. This is the best case. In the worst case, we have to follow the longest path from root to leaf, so we traverse h times.

If the tree has a height of n-1 (worst case) then the work we would do to construct the tree and search for different numbers n times would range from O(n^2) to O(n^3).

If the tree has a height of log2(n+1)−1 (best case) then the work we would do to construct the tree and search for different numbers n times would range from O(nlog(n)) to O(n^2log(n)).",41.0,80
23437,23437,27685,88e4f79f72acbc7dd458837989d41695a9b36b9c96cdb3ba66c7b90921d69150d478abfb1ed6fc7e89594f6b4ccd5c2a5625a644a888136358b59b68dc7b8205,"Time complexity to find an element in a vector is O(n) in the worst case, as you would need to iterate over all elements once.

best case is O(logn) and worst case is O(n). In the worst case, when the height of a tree is O(n), it is basically a linked list and degenerate. the binary search tree is a skewed binary search tree. In the best case, the tree is a balanced binary search tree.

O(n) because a linear amount of work needs to be done at each insertion

O(logn)",17.0,80
23438,23438,27686,20820f051ab9e7b5dde112869be67e2e49734267d017f30c8e3086343a31575407d74708ebc5d385e1b1a34dd7dd81fa4425af4e6cb2bbdba32928c419b4a8da,"-  The worst case complexity for finding a value in a vector is O(n) . The worst case arises when value 'v' is the last item therefore we traverse the whole vector giving n repetitions over loop and do linear amount of work.

- The worst case height is O(n) and this will happen if we have to insert on the furthest away leaf. The best case height is O(logn) and this is when insert right below the root .  

- we would do O(n) work. This is since every time we have to traverse the height from the root to  furthest node for each insertion.its basically adding O(n) every time and 

- we would do O(logn). this is sinc",20.0,80
23439,23439,27687,6ce5c22e2014cf62c3f9857f1a5d029cd8403915d5de52ffef745d92a330418a129b81b3d1fc019ceb103f7414cb06b86a44ab05670ba63e692007c026c9822e,"- Worst-case complexity for searching a vector is O(n) performing a linear search because needs to traverse through the entire vector. Search n times will be O(n^2)

- Worst-case for BST insertion is O(n) which is height dependent and will occur for a degenerate tree structure(numbers are in order). Best-case for BST insertion will be O(long) which will occur for a perfect/balanced BST structure(numbers not in order).

- O(n) -> denegerate BST structure because height of tree becomes n

- O(long) ->balanced BST structure because height of tree becomes log(n)

- Total O(n^2)",32.0,80
23440,23440,27688,763a776e81302d0ca35787de395275bfa7dace1cb9ac6ce690e840ef2f280482559135e73ff9334c7ef80b3304e1f6061c108364e0e55bf5e56d4aafbce8e073,"the worst case complexity of searching for a value in the vector would be O(1) because it would mean that if we have n numbers in random the time it would take to find the value would be slower since the size does not matter.

if we create an empty BST inserting items in the BST , the best case complexity would be O(logn) as that is exponentially faster because we would have to make sure that from the root we should traverse from the left and right  making sure that when inserting we insert both the children making the tree balance in order to make the height of the BST [log_2(n+1) - 1] otherwise it would take a linear amount of work if the tree is degenerating thus the height of the tree will be longer thus making it slower because the levels will be a lot.

the worst case height would be linear amount of work O(n) in which the height will be too long thus it will look like a linked list and it would be harder and take a lot of time to insert numbers if we have a long tree. h=n-1

the best case height would take O(logn) time as we wouldn't have a hard time inserting values because the tree won't be a long tree as it will be a balanced tree making it easier to insert numbers to the children. h=log_2(n+1)-1

in total the amount of work we do to construct the tree would be O(1)",20.0,80
23441,23441,27689,efe8bbe0531a8edbaeccdc4f50ad7d19da4ae088aef554a1013cb2ff8b78ba31a24fa0e8f957d84b8c738910275c42c68da1550413f3ef77aa9c38fb88257b54,"* The worst case complexity of searching for a value in vector is O(n). This occurs when the value that we are searching for is located at the end of the vector, thus requiring us to check all n elements of the vector to reach the value. If we do this n times, we will do n x n [O(n^2)] amount of work.
	* The best and worst-case height of the tree would be O(logn) or O(n) respectively. The best case come about when the algorithm consistently travels along the shortest path before inserting. (i.e the algorithm fills the left child and then the right child of the root, then goes on to insert the left and right children of all the internal nodes of one level before continuing to the next) The worst case occurs when the algorithm consistently along the longest path (i.e we insert either left of the right of the root, then we travel to that leaf we have just created by inserting and then insert a child to the left or right of that, then we again travel to the new leaf and insert, and so on...)
	* In the worst case height we would do O(n) work for each insertion. This is because we have a structure that closely resembles a link to list. Hence, because the structure does not allow for the use of pointer arithmetic, we would need to traverse to the furthest leaf, node-by-node, each time before going on to insert our next item.
	* For the best case height we would do O(logn) work for each insertion.
	* Worst case: O(n^2); Best case: O(nlogn)",41.0,80
23442,23442,27690,20a63554bf7ab6e06ce970a9c763f370f49fc1a727f591ec7304c432565faf9d2b891194e01cc67ff029c1fe6de8363ececadce22ee4af544785f47985cda509,n,0.0,80
23443,23443,27691,df0d62df6145f98b9d8d85662b958119c20c6015becf9534b762b6d6c7c046d872ff37d4ccc77da23e1570c5a7712fc862bda45087171a56e4c5cfc3750e2ad2,"* Worst case O(n) it occurs when the value does not exist in the vector and it needs to traverse through ever item not to find it in the end. When we search n times then we do O(n) of work.
	* Worse case inserting into a tree. We can achieve O(n) if we have a totally unbalanced tree that is all to one side, in which case the work will be the same as in a vector as each node need to be evaluated.
	* Best case is if we have a balanced tree in which case we will O(log n) of complexity. The very best case is when you search for the very first item in the tree O(1).

	* This will happen as each time it insert it will have to visit each node till it can insert, say we insert item n= 1 there is one iteration to find the tree. If we insert item  n = 2 we need 2 iteration on to find the tree and one to visit the first item and then insert it after. If we now insert item n = 3 we need 3 iterations for n = 4 we need 4 iterations...   O(1 + 2 + 3 + 4 +...+ n)  about O(n)

	* If the tree is balance then we will have O(log n) to insert one more value. There reason is that it only need to evaluate nodes equal to the height of the tree + 1, and the tree base expand algorithmically or we can say the height increase in the revers logarithmic function to the amount of items added.
	* 100 % unbalanced tree insert and search O(n + n) or O(2 n) -> O(n)

	* In a balanced tree insert and search O(2 log n) -> O(log n)",22.0,80
23444,23444,27692,f1847bb5d29f39224664df29173ee4eea8241f8aa777b795f86bafdb3b6165e8679750df7902af2beb1387f258e9970c22324224cff020b701254fc8b35d988f,"The worst case complexity of searching for a value in a vector is O(n). This would occur when the value that is being searched for is the very last value in the vector. We do O(n) amount of work when we search times.

The best case height of the tree is O(logn) and this happens when each node has up to the 2nd to last level has 2 children and the nodes in the last level have no children. The worst case height is O(n) and this happens when a degenerate tree is formed (the tree has a similar structure to a linked list)

O(n) amount of work would be done if we had the worst case height after each insertion because we would need to traverse through the tree n times before we can make an insertion. 

O(logn) amount of work would be done if we had the best case height after each insertion because the height of the tree would be logarithmic, meaning the number of nodes that would need to be visited before any insertion would be optimally reduced.",27.0,80
23445,23445,27693,af813686acb18a064eece7968dc86f7e1ba2e2c4ebcbfb61de992275f213a5fe2248d15ae968c61ff6c270f401a739d21132339ee0a42afa471e88a17c352ab9,"* The worst case is when the value v is not in the vector or is at the end of the vector (last item). The amount of work is O(n).
	* The best case is when the tree is a perfect(balanced) tree and the worst case is a degenerate tree. In terms of the height of the tree the best case would be O(logn) and worst case would be O(n-1) where n is the number of nodes.
	* The worst case would be O(n) because you would have to travers through the entire tree and then insert.
	* The best case would be O(logn) because of the tree being balanced and not having to traverse through every tree.
	* O(nlogn)",19.0,80
23446,23446,27694,c927373e71fe30f4255c61610bb88cd9a4bb26b4d4a5c6bc2711f05bbe84ffcf49fd97d920d1a706ea1e91d40784c2fadbc56f95b4fae450f318d7610a7daca1,"The worst-case time complexity of searching for a value 'v' in the vector would be O(n). The vector is unsorted, so one would have to search element by element until the the value 'v' is found or the vector is completely traversed. The worst case arises when the value 'v' is at the very last position in the vector, in which case one would have to traverse the entire vector, or when the value 'v' is not contained in the vector at all. If one searched the vector 'n' times, one would be doing O(n) amount of work.

In the best case, the height of the tree will be O(log(n)). This would occur when the shape of the BST in logarithmic in the number of nodes that are contained in the tree. In the worst case, the height of the tree will be O(n). This would occur when the algorithm needs to traverse the BST along the longest path from root to leaf.

The amount of work done in the worst case would be O(n). There are 'n' insertions, so this is a linear amount of work done.

The amount of work done in the best case would be O(log(n)). There is a logarithmic number of nodes contained in the BST in the best case.

In the best case, the total work done is O(1). In the worst case, the total work done is O(n).",23.0,80
23447,23447,27695,f7bbac457e26e926aa83f65c706f322284bcae4a69df367438ec5060865432bf63d2eef51ed308d86119a8e1745e619fe74662cd103d43378e65328b7630ff57,"Random vector:
The time complexity will be O(n) and this will occur if the number is the last data point of the vector. If you search through the vector n times, n^n amount of work will be done.

BST:

Best case time complexity will be O(log n). This will occur when there is a perfect BST. The worst time complexity will be O(n) and will occur in the case of a degenerate BST.

Worst case assumption:
The amount of work done will be O(n!) as each time you are inserting a number you have to traverse through all of the previous nodes.

Best case assumption:
The amount of work done will be O(n) as you don't need to traverse through every node in the tree and so the amount of work done is only dependent on how many nodes you wish to insert. 

Total:
O(n + n!)",22.0,80
23448,23448,27696,c75c72f439ed0a1083505ca2fb274424bfa93184c45c67c47245732cd59fc54e342192b7a0a8538fb3676603ded389cab9a3431e9d476a9d9b140adb5ff30721,"The worst case complexity for searching for a value v in a binary tree is O(h) where h is the height of the tree. This happens when the value we are looking for is in the deepest node of the tree. The work we would do to search n times is O(n^2)

The worst case height is h = n - 1 meaning the height is equal to the total number of edges in the true. This happens when the numbers are added in a way that the height of the tree is incremented each time a number is added, meaning that every node only has one child. The best case is when h <= log2(n+1) - 1. This is when the tree is a perfect tree.

With worst case insertion, the work we would do for each insertion is O(n), this is because in the worst case each insertion will also increase the height of the tree by 1. All the inner nodes only have one child. This makes it so that we have no benefit from the comparisons we make at each node and gives us the time complexity of a linked list.

In the best case each insertion will be O(log2(n+1)). This is because at each node we make a comparison and each comparison halves the amount of data we have to search. This is the scenario with a perfect tree.

In the worst case the construction and search n times will be O(n^4). In the best case the construction and search n times will be O(n^2*log2(n+1)^2).",25.0,80
23449,23449,27697,b9d82cd7c247fea1955a43aaaf5bb439ce7f4f53d3df9728ceb44f0e1b947c368ff1574400183b4d31d82813774edfdb38a1fdb56e3256ef8ab3e682f8c08da1,"For the worst case complexity you would need to search O(n) times, linear times, for the given number. The worst case would occur when the value v you are looking for is not in the vector and you would need to traverse through all the items. If you search n times, then work is n x n = n^2.

The best case for the height would be O(logn), logarithmic complexity. The best case for the height would be

h = log(n+1) -1

and this would occur if the tree is packed as tightly as possible to get a perfect tree. The worst case for the height would be O(n), linear complexity. The worst case for the height would be, 

h = n -1

and this would occur if the tree is in a degenerate form(similar to a linked list).

If we have the worst case height, it would mean the tree is a degenerate (equivalent to a linked list). So the time it would take to insert each item would take a linear time O(n), but that's for each item. So it would be n work x n items = n x n = n^2. The work taken to insert all n numbers would be O(n^2), quadratic time.

If we have the best case height, tree would be perfect. So time to insert each item would take O(logn) time, but that would be for one item. For n items it would take n x logn = nlogn. The work taken to insert all n numbers would be O(nlogn), linearithmic time.

Worst case total work to construct and search = O(n^2) complexity.

Best case total work to construct and search = O(nlogn) complexity.",41.0,80
23450,23450,27698,e7c9b4fd869eb791a63c71759d17fa7e8a93618d661588fa6ae371946756531c0923d86aafe2bfd7289d74b69cb5fe841e3839957a75e6446f2d8394b4178536,"1. Worst Case: O(n)

  It occurs when the value we are searching for is not contained in the list.

  We do the most work (linear work) with n being the size of the input.

2. Best case: O(1)

  It occurs when we do not have to do any traversals to place the new node.

  Worst case: O(n)

  It occurs when we have to traverse to the very end of the tree (h traversals with h being the height of the tree).

3. O(n) work. This is because the function would change slightly but would still be linear as we are still traversing the height to place the n items and log(base2)(n+1) - 1 <= h <= n-1

4.O(1) work. This is because the best height implies that no traversals would have to be made hence O(1) work would be done while placing n items.

5. Best Case: O(1)

   Worst Case: O(n)",4.0,80
23451,23451,27699,725a0125b367c6f17c35c11b2109d01e495cc98a9983ee64edff98f1e31691682af784e585cb9ffd4450baefac075cf1659b1b9f4409ec665f5bbef7fd4002df,"When searching through a vector the worst-case complexity is O(n), this occurs when the element we are searching for is at the end of the vector.

The best-case height is O(logn) and this occurs when the tree is more spread out and the worst-case height is O(n) as there is only one long path to follow in the tree.

It would be 0(n) because it is essentially a vector or a list because it is one long branch of nodes with only one child for every parent.

It would be O(logn) because the tree has multiple branches that aren't too long which means travelling through the tree would not take too long.

O(logn).",25.0,80
23452,23452,27700,d79246b4e37ca7cbd7cba0e73e77371bc01ee0686edc183593c8b72f08af7f56885ea93e866878670f104cfe50f22453d301d67ae7614531bda51a9f07fc7424,"Time complexity to search a vector in worst case is O(N). You will have to go through each element in the array to see if it matches what you are searching for. A linear amount of work.

In the best case inserting will take O(1) and in the worst case it will take O(n). This is because in the worst case we will have to traverse along the longest path from root to leaf before inserting and the worst case longest path will be of height n-1. The best case senario is when all the node have gone on one side of the tree and the value we adding goes on the other side of the root. So when the root only has one child and the value we are adding is the other child.

O(n) for each insertion and there are n number of insertions so therefore it will have a time complexity of 0(n^2).

in the best case the tree will have a height of log(n+1)-1 so to insert it will have a time complexity of O(logn). But this will be done n amount of times therefore a time complexity of O(nlogn).

best case O(n). worst case O(nlogn)",28.0,80
23453,23453,27701,c7d75d976a010a38db71e259afee15ce7c42ba18fa8ef2214021124356299e2bc696f235d69042a2e7d6021b611ee4096167f90988dc7b1e755fca98c40f31fd,"The worst case complexity in Big-O notation will be O(n) and this occurs when the number we are looking for is the last value in the vector or when the value is not contained in the vector.

The Best case height in Big-O notation will be O(logn) and this occurs when the binary search tree is perfect, meaning that every row has 2^k nodes where k is the level of the node in the tree and the tree is complete.

The worst case height in Big-O notation will be O(n) and this occurs when the tree is degenerate.

We would do O(n) work, and this is because in the worst case, our tree would be degenerate and we would therefore have to traverse through the longest path to insert the next node.

we would do O(logn) work as the tree would be perfectly stacked and complete.

in total, we would do O(n) work.",27.0,80
23454,23454,27702,be6529d2c60e9c3e44398e6d6378522b796199a001be8bd7e7bf876610ef85fd8204961bc4cabc5a2506d1dd5b074658c765a8f7b3311d9493c6efa1d870167b,"1) The worst case would be O(n). This would occur if v is the last item in the vector.To search n times we would do the work of O(n^2) work. 2) The best case would be h = log(n+1)-1 and this occurs in a complete binary search tree. The worst case would be h = n-1 and this occur in degenerated binary tree. 3) O(n), we have to traverse through every node in the tree. 4) O(log(n)), we would have to traverse through a minimum number of nodes. 5)To construct a tree the the complexity is O(h) so the worst case it would be O(n) and the best case would be O(log(n)).",10.0,80
23455,23455,27703,6c39b5e6a07e95287c054b22b9b14ae724def23d44c2473ffa57fa66d0dc3ed81fdc207205fd37cd3342b92b02f8364dc720791f8b6724f778e183c98d663fa5,"1.The worst case for searching for a value in a vector is when the value is not in the vector and every value in the vector is checked. This is of O(n) complexity and happens n times.

2.The best case height of the tree is O(logn) and happens when the subtree above the lowest leaf is perfect. the worst case is O(n) and happens when every node except the leaf node has exactly one child.

3. All nodes in the tree were traversed through when inserting so O(n) work is done. Because the tree is of the worst case height of n-1 and the insertion has to traverse through the entire height of the tree to maintain this worst case height, the work done is O(n)

4.The insertion has to traverse the height of the tree to make an insertion and assuming that the tree is of the best case height during all insertions, the complexity is O(logn) which is the height of the tree.

5.Constructing the worst case tree would take O(n) and the best case tree would be O(logn). Searching for different numbers in the worst case for the worst case tree would be O(n) and the worst case for the best case tree is O(logn). The best case for the worst case tree is O(1)  and the best case for the best case tree is O(1).",24.0,80
23456,23456,27704,d31899b98e7fb3e761998737c0078a84e48727b178f33ae85b1caf85762f7c95a36780c3f84b13e4c3f8980c15788bdfcc7bddbb75a6b63b7a164f238d74d926,"In an unsorted (random) list of numbers stored in a vector the worst case scenario for searching for a number v, would be if v is not in the vector. This would result in O(n) time. If we had to search this vector n times it would be we would have nxn traversals resulting in O(n^2) time.

If we added these numbers in the random order they are in to a binary search tree, we could have a variety of different looking binary trees. In the case where we have the maximum number of  nodes in the tree (prefect tree) we would have a height in O(logn) time. This would be the best case. Conversely, the worst case would be if our tree was degenerate (resembling a linked list), the height would be in O(n) time.

If we are once again working with a degenerate (worst case) tree it would take O(n) time to insert these numbers, this is due to the fact that we will need to traverse through the whole tree each time we need to add the next node. 

Alternatively if we are working with a perfect tree (the best possible structure) it would take O(logn) time to add all the numbers to the tree, since the tree is well structed we do not visit every node in the tree when inserting. This means we visit exponentially less (log) nodes the bigger the tree gets.

If we constructed a tree in the worst case scenario in O(n) time and then searched for a number in this tree that is in the worst case O(n) and did this n times this would result in O(n^2 + n) or just O(n^2). In the best case it would take us O(logn) to construct the tree, and in the best case searching for an element would also be O(logn), since we are searching n times it would result in and O(nlogn) time in total.",41.0,80
23457,23457,27705,e3ed8ae95e5b6d1651bf9302238959432ea0a53fe9eaf1c6d43781285ba398dd6c3e684c62871ee07f37076d5f77cd450bb218b0ee1d76a4f2732d8978e631aa,"The worst-case complexity is O(n), which occurs when the number we searching in the vector is not in the vector or is at the back of the vector. If we had to search n times, it would take n*n times which is O(n**2)  [Quadratic  time].

The worst case height when adding in a BST is when the height of the tree is n-1 and to which we keep adding to the leaves, this occurs in the BST when the number added is always less than every node or greater than every node. The best case height is 2**(n+1) -1, which occurs when every number inserted in tree causes a complete, full or perfect tree.

In the worst-case height insertion, we do O(n) times when inserting. This is because we will visit each node in the tree for n-1 times of which is linear time. Hence is O(n).

In the best-case height insertion, we do O(logn) times when inserting. This is because we visit each node for 2**(n+1) -1 of which is logarithmic time. Hence is O(logn).

In the worst case we use O(n*n) time and in the worst case we use O(n*logn).",21.0,80
23458,23458,27706,c318ecd5c05d3ffa65238b75e8aa9e67390cc6fb32c2fdbfaf84c4d21eee7f78cf713a8bc77a69838390c129742df9afc0ddd3cf48a8b7ef5ea2fb0f43dc4114,"The worst case complexity of searching for a value v in the vector is O(n) and this occurs when the value we are searching for is at the end of the vector.  If we search this n times, we do n^n work.

The best case height of the tree is O(log(n)) and this occurs when the BST is a complete tree. The worst case height of the tree is O(n) and this occurs when the BST is degenerate.

Since the length would be of O(n) after each insertion, we would do a work of O(n), n times. This will result in a final work of O(n^2).

Since the length would be of O(log(n)) after each insertion, we would do a work of O(log(n)), n times. This will result in a final work of O(nlog(n)).

In the first case, we would do a work of O(n^3) and in the second case, we would do a work of O(n^2 log(n)).",25.0,80
23459,23459,27707,c2a635a9bcf4ad40fa50102eeb50a8298caf1f43a284d43931e8d6ff78372592382df0d5a087e759cf9a231e99eb6b2b3a8890e03edb12bf9295b2611174eebb,"When searching for a value, the worst case would be if the value v is not in the tree which would mean that you did a traverse from the root and visited each value and compared which means you did O(n). If we searched n items n times it means we did a quadratic amount of work. 

When inserting values in the BST we have to compare each value with the previous node and this will affect the height of the tree, the height of the tree therefore we will need to traverse through the tree for insertion. The worst case with be if we need to traverse through the longest path from the root to a leaf and then insert which is O(n) and the nest case would be when we traverse through the shortest path or even insert in an empty tree which is O(logn).

The insertion is dependent on the height of the tree, therefore if we have the worst case height after each insertion that means that for each insertion we would need to do n comparsions which would lead to an overall time complexity of O(n).

If we have a the best case height after each insertion that would mean that the height of the tree would be the shortest path followed and not many comparisons had to take place which would therefore lead to an overall time complexity of O(logn)

Best case: O(logn)

Worst Case: O(n)",22.0,80
23460,23460,27708,7034e661a6b51c59ff4e839b7430fa79082c9a14de4d5507d8b8f51bcf2e8507159f0b9ac4f2f0968d640ca40b95ebbbfcb9a489ff8f5bfe6ee49d4e9a458d5c,"The worst time complexity of searching for a value in a vector is O(n) and this occurs when the value is not in the vector. The work we do if we search n times is quadratic O(n^2).

The best case height of the tree is O(logn) and this occurs when the tree is a perfect tree. The worst case height is O(n) and this occurs when the nodes are inserted on one side of the tree.

We would do O(n) work because we would need to traverse through the tree like we would traverse through a linked list to add a new value.

We would do O(n) work because we would still need to traverse through the tree in order to add a new value.

In total we would do O(n) amount of work to construct the tree and search for different numbers n times.",26.0,80
23461,23461,27709,ec66e4473040e8ee3556fe295a682aef55293bdc440d5beebc8fb799f1964c0abc0afc761e0c9e5b3dec6cb5d26467ba51d5e312925807725d0b86097bb74bce,"the worst-case complexity of searching for a value v in the vector is O(n), this occurs when the value is the last value in the vector. If we search n times then we do n^2 work.

The best case height is O(logn), this happens when the tree is complete, the worst case height is O(n), this happens when all your nodes form in one line, with none of the nodes having 2 children.

We would do O(n) work, as we would have to traverse down a tree of the greatest possible height, which would be linear work.

We would do O(logn) work, as we would have to traverse down a tree of the shortest possible height, which would be logarithmic work.

O(nlogn)",25.0,80
23462,23462,27710,96ff995bc15298c864dd95ff4cd06e43f5504516f71d4f78f5c1f0733e5ceb2f157113507e8caf3713f3b3d57604ab1b94ede00706cbfa87faf4d4af71c1a3db,"1.The worst case complexity would be when the value v is found at the end, last element, of the vector, and therefore traverses each one to check equality, thus it is O(n).

2. The best case height of the tree would occur when the tree is said to be perfect, that is every node is full , and at that point no lesser height is achievable, this is the minimum height which is, log(n+1)-1, this means that the insert function will be O(log(n)) in complexity. Conversely,  the worst case height of a tree would be a degenerate tree that has a height = n -1, the maximum height of a tree, which insert() will traverse n-1 times, thus is O(n) in complexity.

3.O(n) ,as said above the worst case would be in a case where the tree is degenerate and thus each node has a maximum of one child, thus requiring one to traverse each node before insertion.

4.O(log(n)), the best case when the tree is at its minimum height, i.e is a perfect , and thus since h = log(n+1)-1, which one would traverse before inserting.

5. 0(n^2)",28.0,80
23463,23463,27711,b62aa4d567faf4c8c2d7b435cab87c30c9d1e6af89f8a0e3d7867630ef600446840f333742c814bc8a0c9d2f0ab23474abdecc13d41d7312f08a47b7fc5bb67c,"The worst-case complexity for searching for a value in a BST is when the value does not exist in the tree. The complexity of this would therefore be O(n) as we would have to traverse the entire tree.

Best case height would be O(1) in this case we would not call the insert function as we have no values to insert.
worst case height would be O(logn) as we would have to recursively call on the insert function and traverse the entire tree.

if we have the worst case height - to traverse the tree and insert could take O(logn) or O(n)  work as it would be proportional to the trees height. 

which we choose corresponds to the structure of the tree.

With the best case height of O(1) the amount of work we could do would correspond to this as O(1) work.

In both cases to construct the tree and search for different n numbers, this will take O(n) work.

 ",0.0,80
23464,23464,27712,662455ba865b7fa66132ae6520e999c9ea1b9fa1f85d0b16ee30bd84db7aa0bec3c7fd7269d6521a07e1ad16d091e298c84cb6c69ff3537fa78efdac09fa4677,"Since we are working with vectors, the worst-case complexity of searching for a value v occurs when the value we are looking for is at the end of the vector i.e. last element of vector. This means we will have to do a linear amount of work as we search n numbers before finding v. Hence we have O(n). When we do this n times we are effectively doing O(n^2) work as we are doing n searches n times (n*n).

The best case height of the tree is h = log(n+1) - 1 and the worst case height is h = n - 1

The worst case height occurs when we have a skewed tree meaning the tree only has left children or only has right children. This could occur when the values we are inserting are already in ascending or descending order.

The best case height occurs when we have a balanced amount of left and right children for each node. 

We would be doing O(n) work every single time we insert a value therefore, by inserting n numbers we get a complexity of O(n^2)

This is because we have to iterate till the last node in the bst before we can insert ,which is linear work, each time for n numbers. This gives n iterations each time * n times ->O(n^2) complexity. 

We would still be doing a linear amount of work as we still have to iterate through n nodes n times however, in practice due to the height being ideal, the number of nodes to iterate through (n) is less than if we had worst case height. The complexity remains the same as we have to perform n iterations each time * n times -> O(n^2) complexity.

In both cases we will do Quadratic amount of work to construct and Quadratic amount of work to search for different numbers n times. ",22.0,80
23465,23465,27713,8a35389fd7c8ad2535687771b1bb68c8efb0b7de8dcab378f3a060f04342ee373ba7cc2c9fd072651f8268858486a9bd9dd5269dda1258346fc90ac33d038576,"The worst-case complexity is O(n). It happens when the item we are looking for is at the back of the vector. We do a linear amount of work.

The best case is when the BST is empty and we insert the root, then it is O(1). If the root is already there then the best case occurs when the tree is ordered and it will be O(logn). In the worst case, the tree is basically a vector and every node only has one child all the to the end. It then takes O(n).

If the worst height is at every insertion it means that the tree is set up like a vector, so it takes O(n) time.

This happens when the tree is ordered, it then takes O(logn) time.",11.0,80
23466,23466,27714,c33667ae11b7bded2337c08d116fa497bbbd12dbb6b1affa7fb94c650c68ba165865aab5e81895db475a23ff725c4bc69da22573104a9522dcaf9138fd9b447c,"* The worst-case complexity of searching in vector is O(n). Therefore the amount of work we do is n as there could be n number of items.
	* The best height of the tree is h where as the worst is h^2.
	* The amount of work we would do is O(n^2) because we will have to check the nodes left and right and up and down.
	* The amount of work for the best case would be 0(logn) because we wouldn't have to traverse left right and down. Rather we can just go in the same direction.
	* The amount of work in total to construct the tree and search would be O(logn + n^2).",5.0,80
23467,23467,27715,74594d76e743115e9e80c4119a5039c4fec5aed2b1eb9af70c89d53a42b69ad2163ffd8ce8a40f97632e4be0cb18aad097e1d70fac3137214bb4656688c9555b,"Searching the vector for v in an unordered vector is O(index(v)) therefore the worst case is O(n) when v is the last value of the vector. If we search n times then we do n^2 work.

The best case height would be log_2(n) and this occurs when the vector is not sorted. The worst case height of n-1 and occurs when the vector is already sorted.

We do O(n) work as we would need to travel to the bottom of the tree before adding the next value of the tree and the height of the tree is given as n.

We do O(logn) work as we would need to reach a leaf node given by the height of the tree as log_2(n+1)-1 or simplified as logn

In worst case building the tree and searching it n times would do O(n^2) work and in best case building the tree and searching it n times would do O(nlogn) work.",15.0,80
23468,23468,27716,936024d8e9328998a220b77c48098f57a0d619263f7c2ad0ac4157dfe9370e11abee7f579d65a28c46224757256e636c01fe798d4c5eb4d7e1574b7de8511fbf,"1) The worst-case time complexity is O(n) and we would have to do N amount of work or linear amount of work.
2) The best-case complexity is O(log2n).
The worst-case complexity is O(n-1) we have to travel from the root to the furthest leaf. We have to traverse through the entire height of the tree.

3) We would have to do linear work as we would have to travel from the root to the furthest leaf of the tree. O(n-1)

4) We would have to do logarithmic work. O(log2n)

5) In total we would have to traverse through the entire height of the tree.",17.0,80
23469,23469,27717,67bc8fffe61d28188b3d7107d51be90441e6dd51c98f3db877749a2a97847646dc952b6812856f170fac011bfccdf49477179e4f3e8c4e51b5aea238df99b414,"The worst case is when we search for the value v that is not in the vector.We will do O(n) amount of work.

The worst case for search function in BST tree is when the tree is degenerate so the height of the tree will be O(n). The best case is when the tree is not degenerate and the height is O(log(n)).

In the worst case we would have done O(n^2),for each insertion we do O(n) and we will do this n times.Therefore total work will do n*n work ,n^2 work.

For each insertion we will do O(log(n)) work and we do this n times.After n times insertions we would have done O(n*log(n)) work

In the best case we do O(n*log(n)) and in the worst case we do O(n^2)",38.0,80
23470,23470,27718,fd0ace311926a44973b18eb55c0a2df285cc4ef58cf67836be1c2719041ca75111c81115da37e4e4879d8c00ffb63db68cb0de1c85a3fc373724acf7945dc463,"The worst case in searching for an element is when the element is not in the vector because one then has go through all the elements and still not find the element and then you'd expect a linear amount of time. If we search n times in a vector then one is doing a linear amount of work.

The worst case for when adding n number of items in a tree is when the tree is degenerate and one has to traverse through the already added items before a new can be inserted, meaning a linear amount of time will taken (n-1). There is no best case.

To insert all the n items in that tree to get the best height case, one would do a linear amount of work where one just inserts the items to form a perfect tree, and there are 2k  nodes for a height k. There's no best case

Essentially at the end to construct and also search through a tree one would have to do a linear amount of work, if the time to construct is linear and the one to search is logarithmic ultimately we do linear amount of work.",12.0,80
23471,23471,27719,3833aa3ef06cafdc78971652ad20444fe164affcf92c03de12570129a147987ae3263043850e741f6f77f4965176d32cb0f7b6200e6f1f08cf0158b373dc6fbe,"The worst case for searching for v in the vector is if it is the last item in the vector or if it is not in the vector. Its time complexity is O(n). If we repeat this search n times its time complexity becomes O(n^2)

The best case is that we get a perfect tree, all nodes have 2 children. The height of the tree would be O(log n). The worst case would be where each progressively added value is greater than the previous or when each new value added is less than the previous, this forms a tree that is structured like a linked list. Therefore the height would be the n-1 and time complexity of O(n) for a traversal.

The time complexity would be O(n^2) for inserting at worst case scenario, this is because the tree behaves like a linked list and so before we add a value we traverse to the current last value which is takes n-1 traversals. Each traversal is based on an if condion which is constant time and it is run n-1 times bringing the time complexity to O(n) for each insertion and O(n^2) for the n insertions.

In the best case the height of the tree is log(n+1)-1, meaning our work done to traverse to a leaf is O(log n) and hence inserting a value n times, which involves travesing to a leaf is O(nlog n)

For the worst case it would be 2 x O(n^2), for best case it would be 2x O(nlog n).",39.0,80
23472,23472,27720,ab914ab560d18c5aef3e43bda3ed23f3106afabfcaabd71fb45ebbdc423746252b1d705ea396aa70f877858829d5c8d335f73b945106c9ea584789a7d7f0ea77,"1. The worst case for searching for a value v in a vector is O(n) and occurs when the value we are looking for is right at the end of our vector, thus we must traverse through n numbers to get to it, so if we repeat this n times, we get n x n = n^2, O(n^2)

2. The best case the height of the tree will be log2(n+1)−1 and in the worst case, the height will be n - 1 . The best case will occur when the order of our numbers in the vector causes us to construct our tree such that it is tightly packed together and closely resembles a perfect tree. The worst case occurs when the order of the numbers in the vector causes us to construct the tree such that it is stretched out.

3. If we have the worst case height after insertion then we will have a height of n-1, so in the worst case when inserting a number into the tree, we will have to traverse right to the bottom to insert our node, which will be O(n) time complexity.

4. If we have the best case height after insertion then the tree will have a height of  log2(n+1) - 1, so in the worst case we will have to go right to the bottom of our tree to insert a node, which will be  O(logn) time complexity
5. Best - O(nlogn)

    Worst -O( n^2 )",19.0,80
23473,23473,27721,2639eb56a1989682f1b8fb8c5a3437ea6a5d663be094f02f4aaae47dc57a1af7165cfaae33d61d670e26c96083744d494e42187a468df938459fc0c70030a175,"When searching for a value in a vector the worst case would be O(n) times since we will have to iterate through the vector to find the specific value v that we are looking for.

When inserting into a BST the best case in height would be O(logn) times depending on the structure, because if the numbers we are inserting is less than the root we would visit the root and constantly add to the left of the tree and if the number we are inserting is greater than the root we would add to the right. The worst case in height would be O(h) which would do linear amount of work and this will occur when the tree is a degenerate tree and it becomes a linked list.

Worst case it would take O(n) times, linear amount of work and this will occur when the tree is a degenerate tree and it becomes a linked list.

The best case  be O(logn) times depending on the structure, because if the numbers we are inserting is less than the root we would visit the root and constantly add to the left of the tree and if the number we are inserting is greater than the root we would add to the right.

We would do log(n+1)-1 amount of work.",19.0,80
23474,23474,27722,52b1f6fd8e6c0289a8004d7d61b231157f72159bdb1098720813eb6a4750543a581c16358208b2fe293a6bc58612fe418d8dd4bccc56d715f7137f43db02b99f,"1)The worse-case time complexity is O(n) and this occurs when when the value ""v"" is not equal to the first value in the vector. If we search n times, we have a time complexity of O(n^n).

2)The worst case height of the tree occurs when the inserted value traverses through the height tree in order to be inserted. For example, inserting values that would lead to the BST becoming a degenerate tree would be the worse case where each inserted value at a node has one child. Meaning the: height of the tree < nodes - 1 (h < n -1). In Big O notation, this is O(n).

The Best case height of the tree occurs when there are early ""holes"" making the insertion vary in time. For example, the insertions leading the BST becoming a perfect, complete tree or full tree, has a time complexity of   O(log2n).

3)We would do O(n) work as we would have to traverse through the whole height of the tree every time we insert while the height increases after each insertion.

4)Would we do O(logn) work as we would still have space/ holes for another insertion and each insertion does not gaurantee that the tree's height will increase.

5)In the worst case, you would do O(n^n) times work. In the best case you would do O(n) work. ",32.0,80
23475,23475,27723,fe62a1f5e7fe2a4e7ab8c966f31166711ff57cc766445f2fc4370a7348f81dab059b866c1f91a4b1ff166d595fb9234d29f7f66b2297a565d84b506f3bd0f6e7,"* The worst case for searching for value v in a vector would be when v is not even in the vector. This means we would have to traverse the whole vector to get to the back of the vector and still not find the value  , resulting in a time complexity of O(n).
	* For a BST , the best case would be if the value , v was the root value of the tree. This would give a an O(log n) which is h = log(n+1)-1 in terms of h. The worst case in when the value we search for is not in the tree, we would have to traverse the whole tree down to a leaf node and still not find the value. this gives an O(n) complexity which is h= n-1.
	* if we have the worst case height we have a sort of linear binary tree with one branch creating a linear 'list' (kind of degenerate tree). This defeats the advantage of the binary search tree method and with this linearity results in a much worse O(n) complexity.
	* the best case would be if we created a perfect binary tree from our insertions, this would result in O(log n) complexity.
	* for the worst case we would have two O(n) 'functions' as both the inserting and searching would be O(n) , this means the total work would be : {O(n) + O(n) = 2*O(n) but it it is still linear so it remains} O(n). 
	* We have two O(log(n)) functions in the best case but the total work would remain O(log(n).",15.0,80
23476,23476,27724,7f4b419d2ced93d50fb8649f87b2fa3a1ab4c6a1ecc8b63f150aeb372237c21eae97c5eba18c0880eb018ac5d3fb68e9a7180e8af2cbb1d90dc8d7f06f63f097,"The worst-case complexity of searching for a value is O(n). It occurs when we are looking through each value until we reach the value we are looking for. The work we do becomes increased because when searching through a vector which takes O(n) times n times, the total time it takes becomes O(n^2).

The worst-case is O(n) because a node is added every time we are adding a number, in a way we are going through each a every node in the tree.

The best-case is O(logn) because each level in the tree is has twice as many nodes as the previous one and it is in proportion with the input size.

the work would be O(nlogn) because we are visiting nodes in each level the same way which is O(logn) in the worst-case which is O(n). So multiplying the two gives us the new complexity.

the work would still be O(logn) because inserting in tree is proportional to its size.",11.0,80
23477,23477,27725,18f6254c7b196766dbebfb4556ef6c2f9ff5e44918d8ea60921fbe90c8a42515b04ace17b80ecdd7f09efd69961a6da2d4a21f100e3ebd5acf67acba7ebaae55,"The worst case in searching for a value in a vector is O(n).

worst case for adding in BST is O(n) and its when its degenerate.

Best case is O(1),and thats when we add only one thing",8.0,80
23478,23478,27726,833bd82b84984eac1561a2aa471c7fa8ce8fc83eb43410d162adbb99836f9c60ca90f110500d0a4cfae027c10757354954059b39ea510643c3c10d5e8f6e1bb9,"* Worst case for Searching for a value in a vector, is when the value we are searching for is not in the vector. and the complexity is O(n). If we search n times we do a quadratic amount of work O(n^2).
	* The best case is when we have only the root (one number in the vector) then we have a height of zero O(log n). Worst case is when we have a degenerate case and we have a height of number of nodes -1. O(h).
	* O(n^2), we will be doing O(n) amount of work n times, so that is n(amount of work) * n(times doing it).
	* O(log n), we will be doing O(log n) amount of work, which is the best case n times. O(log n) will dominate.
	* O(n)",26.0,80
23479,23479,27727,db2da6294f4863255b8e851f3219cc1d358a9a52af31fcce04dfd21a77bd1b6105ebfb54ad3aa0cbea5dc9fb93c67b5af9e1ff40b17fbd626a20ad3636813679,"O(n) this will be our worst case because we will check each and every index in the vector when the value is in the last index(n-1) or does not exist.

the best case will be when we are going to have a perfect or at least a complete tree then the height will be 2^n.

the worst case will be when  we will have the Degenerated tree and the height will be h=n-1.

in our worst case we will have O(log(h) base n).because the height is h=n-1.

in our best case we will have O(n) where n is the number of nodes.

O(n)",17.0,80
23480,23480,27728,7a27fb1fa642a9bd3d76e8ce98be5e4779f4184eab8b901b0ee0d165d466de6122db493ca631d33ef289f724ffb838136d578f3b72df159667217c69ae154ed3,"* The worse time complexity of searching _v _in the vector will be when v is not in the vector or when v is the last value in the vector, this means that we will traverse the whole length of the vector. This results to a complexity of O(n). Which means we will be doing the most work in this case. 
	* The best height case will be after all insertion, the height of the tree is 2^(n+1)-1 or O(logn)This can occur if the insertion was operating on some kind of sorting condition or if the vector was previously ordered in such a way that insertion will lead to a complete binary tree. The worst case will be is after inserting all values in the vector, it creates a BST with a maximum height of n. This occurs when the vector is sorted in either ascending or descending order. where each node has only 1 child on a specific side(either all left or alll right). This means that the tree is either right or left skewed. This results in a BST with n height. This is the worst case height. O(n)
	* If we had a worst case BST. when inserting each node, we would have to compare the node to ALL exisiting nodes in the tree. Each new node will then be found to be inserted at the last level of the BST. This occurs for each number we insert! In this case we travel the whole length of the BST and if there are n nodes, then we eill need n comparisons for each new node. This leads to a O(n) time complexity.
	* The best case occurs when we perform the least number of comparison for an insertion. In a complete balanced tree. We dont need to compare each insertion with ALL the nodes in the tree. The least number of comparisons needed is (L + 1) where L = level. hence for each node, L+1 will be the max number of comaprisons required in a best height case tree. With height as O(logn), the amount of work would be O(logn)
	* Best Case: constructing the tree will cost O(logn) and searching will be O(logn). Worst Case: constucting will be O(n) and searching will also be O(n).",27.0,80
23481,23481,27729,16f09d60ea55f541a3437e3e2ab8e9c69f838f50f98dec712996c73779cd9f654e7fa72007ae7a3b8d9cb813c8fad8d686dc40ba57c222e292c85b1a88fc8b53,"searcing for v in a vector has a worst-case time complexity of O(n). This linear time search happens when the vector is arranged in random order.

by creating an empty BST and adding each number to it we have that in the worst case searching for v will have a time complexity of O(n) or O(h) in the worst case and it will have a time complexity of O(lg(n))  in the best case. The worst case occurs when the height of the tree is left or right skewed (degenerate binary tree) . In the best case the tree is balanced so the search is half for each level. 

having a skewed height after each insertion will require O(n) time. this is the case because when inserting in a right-skewed tree (left-skewed) the new element must be put to the right (left)  of the previous element and this means that we need to traverse through every other previous element O(n). 

assuming we have the best case height when the node that needs to be inserted belongs to the side of the tree without a subtree. so inserting a value to the left of a root where the right of the tree has all other nodes. this will be O(1) time. 

in each case we need to do linear work.",19.0,80
23482,23482,27730,2238995f0ead9a3412ecc8b42340b20d5862bf47d5493b0c9fbe94b4e46ffb57c2cf52b4dd296cee7b6850d8a44e160d6bd1d96e80ab144e928044e44043acc6,"worst-case in the vector = O(n). If we search n times, n comparisons will be performed.

best-case height of O(1) occurs when the first value (root) is inserted. worst-case height of O(h) occurs when we traverse the tree along the longest path from root to leaf before we can insert the value.

worst-case height for n insertions is O(hn), because the worst-case for one insertion is O(h), so doing this n-times means we multiply h by n.

best-case height for n insertions is O(n) because the best-case for one insertion is O(1), so for n insertions we multiply 1 by n.

in the first case, we will do between O(hn)+O(log(nn)) and O(hn)+O(n) work.

and in the second case, we will do between O(n)+ O(log(nn)) and O(n) +O(n) work.",22.0,80
23483,23483,27731,bacea88b3884d2acdf5b94b564c3ec6827ffca9c96b92221f37418e3f06607a9773dd54e02efe11a3f31dcc55f103233551301f8c7dbd6ce23f465133edd2ef3,"The worst case is O(n), where we have to traverse through all the n items and not find the value we are looking for. We are doing a linear amount of work.

The best case is O(log(n)) and the worst case is O(n). The worst-case occurs when we have to traverse through the longest path( which is equal to the maximum height of the BST) in the BST before finally inserting the value. The best-case occurs when we have to add the value by traversing through the shortest path in the BST.

O(n), because in the worst case, the height of the BST is n-1.

O(log(n)), because in the best case, the height of the BST is log2(n+1)-1

We would do the work that is proportional  to the height of the tree ",15.0,80
23484,23484,27732,f568f900863758606ecd596c211921a4e2f0720e3778a3f2c91b74ff667248e8a2d4bcea0036dc07a6e043d08d7d7b64e5934aa3ba779587a955877ff84bfb17,"It is O(n), this will occur when the element you are looking for is att the end of your vector.

The best case would be O(logn) and the worst case would be O(n). The best case would be when you are inserting at the root and dont ed to traverse, the worst case woulf be at the bottom of the tree and would need to traverse through the tree n times. 

we would need to do O(n^2) amount of work, as we have to do O(n), n amount of times.

it would be O(2logn) as you are doing O(logn),  n amount of times.",30.0,80
23485,23485,27733,482f7dae015b4c467d12506c33e2fe66aeff1ddddb85f2c9bce0e0756918b84a46072cd434d5bf20b674533a59b9c793d9d747268246eec497aed1c0f31a1c3c,"1) The worse case would be O(n). This would occur if the value v is the last value/item in the vector. To search n time we would do O(n^2) amount of work as we have to traverse the whole vector to find the value v.

2) The best case would be h = log(n+1)-1, This would occur in a complete binary search tree as the height is relatively small compared to an uncomplete tree, a complete binary search tree has the lowest possible height

The worse case would be h = n-1, this would occur when we have a degenerate binary tree(""fancy linked list""), as a degenerate binary search tree has the maximum height possible

3) O(n), We would have to traverse through every single node in the tree, its basically a fancy linked list

4) O(log(n)), We would traverse through the minimum number of nodes to get to where we would like to insert as a binary search tree is put in such a way that each value has a certain place in the tree due to its size/numerical value.

5) To construct a binary search tree in the worse case it would be O(n) and in the best case it would be O(log(n)). To search for a number in the worse case would be O(n) as we need to traverse the entire tree to find that node, and in the best case O(log(n)) as you would only have to traverse the tree on certain nodes given the value you are looking for in the tree, therefore leaving out some nodes",22.0,80
23486,23486,27734,1d906c438dbb2a0adc2a7e04ed6b3c53c2ee28b5c43a5e83e583d5199a13a7bb6abb74579e2679fb4b6602b8efe2849ab290c6db2b1f573c02a4880312c09f25,"O(n) - It would take us a linear amount of time.

The best case would be O(logn) this is when we have a nicely structured tree like a complete or perfect tree. And the worst case would be O(n) this is when we have a tree that is badly structured like a degenerate tree.

O(n) because we would have to traverse every node before we can insert and therefore it would take a linear amount of work.

O(logn) because the shortest height.

O(n)",17.0,80
23487,23487,27735,9604cde612d14d7c1208567b5a899f58192d63e5eca49d1172cf02ada7bcc707c0c2961463156af2ceaf251b5e8002936b2f718d5d90b74662837e2ef34371cf,"The worst case complexity of searching a value is O(h), it occurs in the root to the leaf. The time complexity is O(logn).

When we are calling the insert function the best case height is O(logn) and the worst case height is O(h) and these cases occurs in the leaf.

Worst case height after each insertion will cause us to travel from the root to the leaf . The height of the tree may become n and we would do O(n) work.

Best case height after each insertion  will cause us to do O(logn) work

In total we would do O(1) work",0.0,80
23488,23488,27736,aba8ccda4763601c960552191c4b4ea7d3e94521d25f84c03f905aac0bf9578acabd1a7e87e98918c1a32dbc6bc0f00b14222dbc9e37a19a4efb13f1c52924d7,"Worst case is O(n), thia occurs when we are searching for a value that is not in the vector, and we will do n a mount of work.

Best case is O(log2n), now this depends on the structure of the tree and the worst case is O(n), this happens when you are adding the number goes to the right /left bottom of the tree e.g a degenerate treee.

O(n),  we are traversing through the height and the height just increases every time we insert.

O(log2n) , there will be times when we insert, the height of the tree will not be affected.

In th e worst case, it will take us O(n) , that is linear time and in the best case,O(1), which is constant time.",19.0,80
23489,23489,27737,8f6fce38f378bd03b7e3015540844be6bf9823c5ceeeee423c75e7180e2218c7f9853b96b276e10dcc9cefdaf4b85b6d869df1573ced7bc1eae58f615449e857,"(1) Worst case time complexity: O(n) when the value is at the end of the vector 

      if we do this n times we do n^2 work (quadratic). 

(2) The best case height for the tree is if we have a perfect tree. O(logn).

      The worst case height for the tree is h=n-1, thus O(n). This happens when the tree degenerates into a linked          list

(3) O(n^2) because we would just basically be calling the push_back function n times on a linked list. since the time complexity for push_back is O(n)[assuming no tail pointer] and we call it n times, we have O(n^2).

(4) O(nlogn) because it will take O(logn) time to find the position to insert a node at, and we are inserting n nodes.

(5) in the first tree it will take O(n^2) and in the second it will take O(nlogn)",41.0,80
23490,23490,27738,5b79e321acf32f26a1c6cc9091fa349a8baa70385c6fb736e55b942fea1901b561d1f53857749ead207a2933e580c9dfc66c9af868e9b035d1dff322ef7cd5be,"1. the worst - case time complexity would be O(n)

-this occurs when the value we are searching for is not in the vector 

 

2.

-Best-case height of the tree - O(logn) 

. Occurs when the tree is constructed perfectly

-Worst-Case height of the tree - O(n)

.Occurs when we try to make it as long as possible , basically the tree is degenerate and it has become a linked list 

3. 

In the worst case, we  needs to traverse the tree along the longest path from the root to a leaf before inserting. In this case, we traverse h nodes before we can perform the insert. So in the worst case, the amount of work done is proportional to the height of the tree.

4.  in the best case we will do O(logn) work since our tree is perfectly packed

5. In the best case we do O(logn)

n the worst case, the number is not in the tree and the path we follow corresponds to the longest path from the root to a leaf. In this case, we traverse hh times, so the amount of work done is proportional to the height of the tree. so we do O(n) work",23.0,80
23491,23491,27739,1d469feec8dabc8efe190b91bf2431897a77efbd16b2d85bdc6124d89beaeb95e4c3d1758db03e27ba5dac6295ff2b30f3eaaa927d0748ab45ecd18c4991abfb,"The worst case is when we search the whole vector without finding the value v which in big-O notation is O(n)

The best case for insertion function will be O(logn) when we insert in with conditions of if less then we insert at the left side of the node and worst case is O(n) which will occur when we have to search the whole tree before inserting the value at an appropriate node

At the worst case height we will do linear amount of work O(n) because we will have to go through each node 

At the best case height we will do logarithmic amount of workO(logn) because we will only visit the nodes that have maet the conditions for insertion

we do O(nlogn) ",18.0,80
23492,23492,27740,8988e05f865164f4560af96560c21e55905eac0bb5f61f3d6e278f9698c3b2aef4e2c138e098da5e867aaa523133fd657970eaa9429e994d798d7fd717f54fcc,"The worst case of searching for a value in a vector is when we would have to iterate through the entire vector to the last item, which would be O(n). If we search n times, then we would be doing O(n^2) work.

If we used a BST to search for a value, the best case would be that the value we're looking for is the root, so it would take O(1) time. The worst case would be that the value lies in a node that has a depth equivalent to the height of the tree i.e. it has the longest path in the tree relative to the root. In this case, searching for it would take O(log(n)) time.

If we have the worst case height in our BST, this means we'll have to do the maximum number of comparisons when inserting each value into the BST by traversing the height of the tree each time, which would be O(n) work.

If we have the best case height in our BST, this means we'll have to do the minimum number of comparisons when inserting, which would be O(log(n)) work.

In the first case, constructing the tree would take O(n) work and searching numbers n times would take O(n^2) work, so the total work done would be O(n^2).

In the second case, construction would be O(logn) and searching numbers n times would be O(nlogn), so the total work done would be O(nlogn).",34.0,80
23493,23493,27741,55ea1e4f47f56380767c8e74fc048f88ea3f77cbdba15f1928ce2c49d72fc6281a93cc53faad127cf63dd846a712edf93d7e45216338f7bc4ae6a26df95dd66e,"The complexity of searching for a value in the vector would be O(1) because it uses pointer arithmetic in the background, thus taking constant time.

If we create an empty BST and progressively add each number to the tree by calling the insert function, the best case would be O(logn) which occurs in a balanced tree and worst case O(n) which is a degenerate tree (basically a linked list).

We would do n-1 work in worst case because h must be less than or equal to n-1. Therefore O(n) amount of work.

In worst case we'd do O(n) and best case O(logn).",7.0,80
23494,23494,27742,4ee5c3f6edd0831bd10d63a696f6638df5b754a34f97686d41e648c7e383b2fbf2f7080c3b7f108b718723955a3e61137ab00a8d8d64c8fb5453ee8eef444085,"* worse case complexity is O(n)
	* best and worst-case height of a tree: best h>=log n/2",2.0,80
23495,23495,27743,9a6d2e6e6e0c1b575d6fd6f9cd31a3d7ef05b9fbb8f9b527d2f24c66326f4e25fb885d747e3511e370820c0e5c65531a52fb8637b76c7b43895037c2420cfc80,"The worst-case complexity of searching for a value v in the vector is O(n). This will occur when each node has only one child. If we search n times then O(n^2) work is done.

The best case height would have a complexity of O(logn). This would happen if we have a balanced tree.

The worst case height would have a complexity of O(n). This would happen if each node has only one child, so we would be basically be dealing with a vector.",19.0,80
23496,23496,27744,e81419dfc1d9569cd33a892060afd65b53683380b098be177940b37177a69388dbc26f4b88ae9117e614069eb6d29407e325e18a19fd38be90fa494f6adff772,"In the worst case for searching for a value v in the vector is O(n) linear time when we are searching for v which is not in the present in the vector.

When we pack the tree as tightly as possible and we have a perfect tree (or complete tree since filled from left) then we get our best possible height which is guaranteed to be O(log(n)) and in the worst case is when we have a degenerate Binary Tree where we have sort of a fancy linked list then we have a height of the worst case of O(n).

In the worst case where the degenerate binary tree has a height of O(h) then the inserting algorithm needs to traverse h other nodes before inserting each new node and so the inserting becomes proportional to the height. We would have to traverse the height (h) at that current moment. So to insert all n numbers we would have an efficiency of O(n).

In the best case scenario when the height is logarithmic O(logh) then the inserting algorithm needs to traverse through h other nodes before inserting the new node and so the inserting becomes proportional to the height. We would have to traverse the height (logh) to insert all n nodes. So in the best case to insert all n numbers we would have an efficiency of O(logn)

In the best case scenario with a logarithmic height O(logh) then to construct the whole tree would be n times logh which would be O(nlogh) which is linearthmic complexity and in the worst case when we have linear height O(h) and need to construct a tree with n nodes then we have O(n^2) which is quadratic complexity. Same is for searching n times. Best case is O(nlogn) and in the worst case is O(n^2)",38.0,80
23497,23497,27745,74ac16aad9cffebc9a82a3d84552ea746b2a726fb003881a5a45ccd11c8a938caed3d1a49b6f0f3b5bc663c85f99ca3ae1d10cb0f79247d51859bb82beada81b,"worst case complexity of searching for a value is O(n) time.this occurs when we have an incomplete binary tree.

if we create an empty bst the worst case time complexity is O(logn)",0.0,80
23498,23498,27746,525cefc66631b9eb601410acc1c632cc3a6d9976bb8f3ac653d46807a4053f29a6c3c85a0e8a38a43486b45bae46acd949e27f910bf00828afed11257c7034f3,"* O(n) and this occurs when the value v is not in the vector.
	* O(n) is the worst case and it would occur if our each node in our tree had either zero or one child. O(1) would then be the best case and it would occur when we have a perfect binary search tree i.e. every internal node has 2 children.",6.0,80
23499,23499,27747,66ba5975b098f5fa2bae0b86dceb6b280b99b8f4c6fff5dafe0a067b8a9153b49a39abe1525261732c63d25886c01c121ff46cf2ab2721a603f04674ea202257,"The worst case complexity for searching for a value in a vector occurs when the vector does not contain that value, as a result you would have to search through all N numbers in the vector. This results in a time complexity of O(N). If we searched N times, we would do N*N work, giving us O(N^2).

In the worst case, the algorithm needs to traverse along the longest path from the root to a leaf before being able to insert. Therefore, the work done is proportional to the height of the tree and as we traverse through H nodes. The best case occurs when all of the current nodes are in the right (or left) subtree and the value to be inserted belongs in the left (or right) subtree. The best case height of the tree in Big O is O(LOGN) and the worst case is O(N).

The worst case height of a subtree essentially becomes similar to a linked list. As a result we would have to traverse through all N nodes every time we insert a value. Therefore we are doing N*N work which is N^2. 

To construct the best case tree would be logn * n work and the worst case would be n*n",25.0,80
23500,23500,27748,e1c10c192c9b6713ee5530dae2906c490884e9be67695456a693eb32bfedb4efb69953c8625279092ed97ffe2902abb90cc745c3952924b4e2ed73997890c89f,"The worst-case searching through a vector of size n is having to do n-steps giving and ) notation of O(n).

The best case height of a tree is when the tree, once finished, is a perfect tree and thus has a height of O(logn). The worst case is when the tree is essentially identical to a linked list and so has height O(n).

We would be doing O(n) work, with n being the current number of nodes since we would need to traverse from the root every time.

We would do O(logn) work because we could take a more direct path to the value we are reaching for based on its relationships with its parent value. ",25.0,80
23501,23501,27749,ea2a1bfcbe729f7621c917f77c54d68d14594e336635f36baf52750af4fc628657adce12683b4083425f0f9b883a0f335d02fe57cab5815e5cb77320840dd672,The worst-case complexity of searching for a value v in the vector would be if the value we are searching for is at the end of the list meaning we would search the entire vector therefore 0(n). The best and worst case height of the tree during insertion would be log2(n+1) in the best case because the there would be a space to insert by the root (left or right) and n-1 or 0(h)  in the worst case because we would need to travel all the way from the root to the furthest leaf. For the worst case we would do n-1 work since it would depend on the height of the tree and for the best case we do 0(1) work since if there is always a space by the root we would do one action. In total we would do n-1 work.,12.0,80
23502,23502,27750,0210a9d3772d4f5814d5d585f47b6503d720f89ae8ca72b5fb7136f3da85dccbdba73ac11df998e73774b6321c99446733c7c479dc009a4e0dc92678413ef102,"- worst time is O(n) ,it happens when searching for number in a vector you need to traverse through to find it ,since they're in random order.

-In the worst case, we need to traverse the tree along the longest path (h nodes) before inserting.  So in the worst case, we will have O(n) that has n-1 height. In the best case, the height of the tree will be log2(n+1)−1 ,thus the height is O(logn)

-we do O(n) work in the worst case.

-we do O(logn)n work in the best case.

-we do(logn) ,because the of bst the list is unsorted.",14.0,80
23503,23503,27751,17af69de9b004cebc772407eb454a4695fd215d61e6315c9d12ef0dd3a08b8a8642b4cc8dfc787e7755ff0571045a1730ffe50dbf1069009256ea87e870d4fed,"In the worst case we need to traverse O(n), n being the size of the vector, times because the value v is the last element.

Best case the height is O(logn) when the tree is complete. Worst case the height is O(n) when every node has one child.

We would do O(n) work because we have to traverse along the height of the tree each time before insertion.

We would do O(logn) work because there are 2^n nodes.

Worst Case: O(n)+O(n), Best Case:O(logn)+O(1)",19.0,80
23504,23504,27752,feedd29892cd7ac7cbb3dcf2ebf122ea0910da8e729a40522cfec73f98427f11e38a2954619cb37c8da0cffc3dcb3d21b0fc9b9cb5630f1a8e01a0691d1d3af8,"n-1

n-1

n-1

n-1

n-1",0.0,80
23505,23505,27753,4427e3a6ae2786ed5636c638581416e62adf38c90aed72214004ce5b4fc79bb1e5696556f9677084defd90b33f5cf052534401db22ff6a075c7131169ee1bcf8,"* The worst case complexity is O(n) , because in the worst case the value _v_ would be at the end of our vector meaning we would have to go through all the values in the vector. If we search n times, complexity is O(n*n). [ 2 marks]
	* The worst case is O(n) and the best case is O(log n ) . The worst case occurs when the number of edges is n - 1, which results in a tree that is similar to doubly linked lists. The best case occurs when the inserting results in a perfect binary tree. [4 marks]
	* It would be O(n(n+1) / 2) because we would start at a complexity of 1 and keep on incrementing until n and the work would be 1+ 2+3+4+...+n, which is n(n+1)/2. [2 marks]
	* It would be O(log n)  because as we add more and more items to the tree the traversal remains fairly constant because the number of nodes we can insert on are high on the higher levels. [2 marks]
	* O(n*log n). [1 mark]",36.0,80
23506,23506,27754,cb120576f9fc254cce2a2bdcc2fab8a2f95f1ad24a5398cde6a97bb68344852b25ff6ddb6448c5c344141e6c8f5ee1dd504e841ca984819c02a7811908c51bc8,"* The worst case of searching for a value in a vector will be O(n), this occurs when the value is the last item in the array. If we have to search n times we will be doing O(n^2) amount of work.
	* In the worst case of the insert function we would have to traverse the entire height of the tree, this results in O(n) work being done. The best case would be when we have to insert into a tree that has no values in either the left or right subtree and the value we insert will be either to the left or right subtree depending on the case above, this will result in O(1) work being done to insert the value.
	* If we assume that inserting _n _numbers will give us a height of n-1 we can come to the conclusion that the work done to insert values would be O(n^n). This is because we when we're inserting a single value we will be doing O(n) in the worst case, and in this scenario we will have the worst case for each insertion thus we will have the worst case _n _times.
	*  We know that in the best case over time the work done will be O(_log n)._
	* O(log n + n^n)",17.0,80
23507,23507,27755,562a79f866657142ac8bf9d260020a41dd948177d2bce6c88383e228d52056cf2d2544e838847e98137352689514e6b5fccb58b9b8779b353c6c283dfc7313ad,"The worst case of searching for a value in an unordered vector is O(n) as we cant perform a binary search . When we search n times this means for every z in {range(n)} we are going to do n  work which will be n n times therefore O(n^2) work.

The best case height is when h  = log(n+1) -1 , this occurs when each and every internal node has two children . The wost case height is O(n)  and this occurs when we have repeated insertion in direction of the tree or the subtree

in the worst case scenario we would do O(n) work , suppose there are n nodes in this tree such that there are x nodes before the insertion position , because we have worst case height we see that insertion position = treeHeight - parentHeight+1 = parentDepth+1 , this means the more we insert in this worst case configuration the more work we will do in linear time.

in the best case, insertion would take O(log(n)) time because the way in the binary search tree was constructed meant that at each and every position when inserting, the space of insertion was halfed by two.

In the worst case,insertion is O(n) and therefore search will also be O(n) therefore total work would be O(n^2) work whereas in the best case since both insertion and search take O(log(n)) then searching n times will be linearithmic time O((n+1)log(n) ) since construction takes O(log(n)) and n searches are linearithmic",26.0,80
23508,23508,27756,a18d348d984f5bd8aca6ebc4fccb86f8d160a802b4c7ee70a595f3b8caf6c18513e302bc5cfcbf90d284bd7a320b1536220dd429aa4a21d61efb3ef1771458a4,"The worst case complexity would be O(n) which occurs when the value we are looking for is at the end of the vector. If we do the search n times then the complexity is O(n^2).

The best case for a tree of n-items would be a height of log(n+1)-1 which would occur when the root value is taken to be the middle-most value in an array (A) of all the sorted values. Then we divide the array (A) in to two subarrays left (containing all elements less than the middle-most value) and right ( containing all values greater than the middle most value) and then add the middle-most value of each subarray to the binary tree. We do this recursively until we've added all element to the array.

The worst case would be a tree of height O(n-1) which would occur if the values were in sorted order and were added to the tree from left to right or right to left.

The work required would be O(n) because we would have to move down the entire height of the tree before finding a valid position for the value. Since, for example, if we were given a set of values in ascending order each new value would be greater than any value in the tree and we would therefore have to traverse the entire tree to find a valid empty spot.

In the best case would be O(log(n)) because the tree would in the best case be a full binary tree. Which means every time we compare the value we are adding to a tree we either have to recurse through only the left-child subtree or right-child subtree which means we effectively eliminate half of the possible values in a tree after each comparison.",17.0,80
23509,23509,27757,9723aae78697f512e67589fc396726b9c942a3d3f5596d681f9e90a55d7c7cee67b2655817396577b22474e4f116aa7866389d9d9a43a0c0e1dd45d6998cde32,"1. The worst case complexity would be O(n) and this would occur if the value v is the last element of the vector. O(n^2) amount of work would be done if we search n times.

2. The best case height of a tree would be h = logn(n+1) - 1 which would be O(logn) in terms of Big-O notation. This would occur when all nodes are fully loaded with keys. Therefore, full/proper trees will have best case as all their nodes besides the leaves have 2 children.

The worst case height of the tree would be h= n - 1 which therefore relates to O(n), where we have to travel through all the nodes to get the longest distance to a leaf. This would occur when a degenerate tree has been created where each parent only has one node.

3. We would have to do O(n) amount of work when iserting n numbers. This would be because we have to traverse through from the root to the leaf node that resembles the height of tree each time before we place the next number. We have to traverse through all nodes each time.

4. We have to do O(logn) amount of work when inserting n numbers. 

5. Best Case: O(nlogn)

Worst Case: O(n^2)",34.0,80
23510,23510,27758,a0052d1186f3fa53f67763ddf5dc1148fc540657d42f0891ff3ac99ce8c9f5c8c2cc81fa44f5583e909b3bdda1a0f1e6a21067a67ce2ede8b9d60f7eef57955f,"1) The worst-case time complexity is O(N) and it would occur when the number is not contained in the vector. Thus every number needs to be checked. Thus if we search N times, we would be doing a quadratic amount of work, represented by O(n^2)

2) The worst case height would be n-1 and this would occur if the list is in fact sorted, thus each number is either larger or smaller than the last. The tree pretty much just becomes a linked list, with all nodes having one child, except the last, having no children. The best case is log2(n+1)-1 and this would occur if the three is actually an AVL tree, meaning the height of two children of a node differ by at most one. This completely protects us from the case of a long sub tree which is made up only of nodes with one child, which makes height a lot bigger.

3) I would say that in the worst case, we do a quadratic function of work or O(n^2). Firstly, the tree has become degenerate and is the worst case of height. Now whenever we want to add a number, in the worst case, wed have to traverse the longest path to a leaf (which would now be O(n) as its basically a linked list). But we do this linear work a linear amount of time thus, it becomes quadratic

4) In the best case, the height of the tree is 𝑙𝑜𝑔2 (𝑛 + 1) − 1 which is logorothmic, thus to traverse to a leaf would be O(logn). Thus to transverse to a leaf n times to do the insertion would be nlogn. Thus we would do a function of O(nlogn) work.

5) In the worst case, we are looking at quadratic to build the tree and then linear amount to search, totaling O(n^2)

In best case, its n times logarithmic to build the tree and n times logarithmic to search, meaning O(nlogn)",41.0,80
23511,23511,27759,5cd0a202ef51535fb2cf79db8f13b432c752afb35952cb0416813c6c757163698e13f6f62bd6292909baa9745f2197e7ed5a1f16eebc10eb62867568861dbf00,"1.The worst case of searching for a value in a vector is O(n). This occurs when the value we are searching for is at the end of a vector, since we would have to traverse through the whole vector. We will do an O(n) amount of work.

2. Worst case height - h = O(n) - this occurs when we would have to traverse through the longest path of the tree in order to insert the node.

Best case height - h = O(logn) - this occurs when we have a hole in the tree. 

3. We would do O(n) work. If it took us an n amount of work to insert each node. Then the total work would be the sum of all nodes doing n work for insertion (ie n+n+...+n) which simplifies to (letting k be the number of nodes inserting for O(n) amount of work for each node) kn. O(kn) would then simplify to O(n)

4. We would do O(logn) work. If it took us an logn amount of work to insert each node. Then the total work would be the sum of all nodes doing logn work for insertion (ie logn+logn+...+logn) which simplifies to (letting k be the number of nodes inserting for O(logn) amount of work for each node) klogn. O(klogn) would then simplify to O(logn)

5. Worst case - O(n) work

Best case - O(logn) work",21.0,80
23512,23512,27760,3d98aadbc95f1ceaf5723fac50fb4583048e99f3a608962c3b1c8cd33d79fc21685534ca4e509a1fb097360bbcf66d5d96593eff3b861f7814afdcae8fecdd1e,"The worst case complexity of searching for the value v in the vector is if the value is the last element in the vector. This would mean that we have to check every value in the vector and we would therefore do a linear amount of work.

The best case of the height is if we are adding n elements and the tree results in a perfect binary tree. In that case the height of the tree would be as short as it can possibly be. The worst case is if after the same number of nodes have been added the tree is neither full or complete. In this case the height of the tree will not be as short as it can be.",7.0,80
23513,23513,27761,7c939bb7eae30ac9fde6bed7ba91e751cb79bad249785d6c36230c4d9e80b55aaaf08d983990b398d630a07852718c75269fe0b377bbd248cf1db616b416f57e,"O(N) when searching for a value in a vector and that happens when the value which we are searching for is not in the vector.

we do O(N2 ) when we search n times.

The BEST CASE HEIGHT would be O(LOG(N)) and this happens when the tree is compactly packed tree which is almost a perfect binary tree.

The WORST CASE HEIGHT would be O(N)  and this happens when we have a degenerate binary tree which essentially means every node has only one child. The successive numbers will always be either greater or less than the root resulting in only one subtree, either left or right.

If we have the WORST CASE HEIGHT and we do n insertions, then we would do O(N) because we have a degenerate binary tree and so we would have to traverse to the last node each time we do an insertion.

If we have the BEST CASE HEIGHT and we do n insertions, then we would do O(LOG(N)) work. Since it is a best case height, it means the tree is compactly packed and so when we do an insertion we have only to do the first comparison of the value with the root value and thus we can avoid one subtree depending on whether the value was less than or greater/equal to the root value. Thus reducing the work of comparisons, resulting in less traversals.

In the WORST CASE scenario, we do O(N) for constructing the tree and O(N) for searching and since we search n times it results in O(N2) for searching and an overall O(N2) for everything.

In the BEST CASE scenario, we do O(LOG(N)) for insertion, and O(LOG(N)) for searching and we search n times resulting in O(NLOG(N)) for searching, and an overall of O(NLOG(N)) for everything.",35.0,80
23514,23514,27762,49da1899a556de47c2ec5c0aee3103579dd1b8665560fbd2cb26362bd85bf2a291f8280bc21e1f838e024dcd8764915c6b880be08a2f6c8f404d85517511406c,"The worst case time complexity in this case is O(n). This occurs when the value, v, is at the last position of the vector. It would have to do n checks.

Here, the best case height is O(logn). This occurs when the height of the tree is log2(n+1) -1. In the worst case, the height is O(n), or n-1, meaning the tree is degenerate.

The insertion, due to the worst case height of O(n), would have a big O representation of O(n). This is because, for every insertion, up to n, it would be necessary to traverse to the point n-1.

In the best case (here meaning the average case of a balanced tree), the insertion would be O(logn). This is because it would not need to compare the new node's value with every existent node in the tree. However, for a tree where the node being inserted would be inserted on the first level (only one comparison needed), it would be O(1).

Worst case, O(n) construction and O(n) searching. Best case, O(1) construction and O(1) searching.",25.0,80
23515,23515,27763,6faeacee0c2269025dd90b7721d39fd6ea59274d1116063ca6e894050048f55cfc48de8438d931d22afb7e2c6e6e2971358b83dd0ec2d867cc557d7b6b500315,"* Worst-case is O(n) when we have to search for _V _that is stored at the end of the vector. If we search _N_ times we will do a quadratic amount of work.
	* Best: the tree is a perfect binary tree and the height is O(logn). Worst: the tree is a degenerate tree and the height is O(n).
	* We would need to do O(n) work since every time we insert we would need to traverse to the end of the degenerate tree i.e. the whole tree.
	* We would need to do O(logn) work since after each insertion we only need to traverse O(logn) times to reach a node instead of traversing the whole tree (n)
	*  Best: we do nlogn work. Worst: we do n^2",36.0,80
23516,23516,27764,0c11d203426fce7b3dc05c5b901a557cc9648e7fd3384bd9d8800631c383636176c5236339b82c8cac354a014c4e904c016c4f55b6e4ea8b971819143c0b5cb5,"1. O(n), This occurs when the value v is the last element in the vector or when v is not in the vector. The complexity is constant because we have to traverse through the whole vector making the loop traverse over n times.

2. Best Case - O(logn)..If the tree is a perfect binary tree we do the least amount of traversing to insert a node.

    Worst Case - O(n), This commonly happens when the we have a degenerate tree and we have to traverse through all the nodes(n times) in order to insert a node.

3. O(n) / linear amount of work. If we a worst case height after each insertion that means we are traversing through every node in the tree, which will be n times. This will lead to degenerate tree

4. O(logn)- In this case will have a perfect binary tree and in this type of we do the least amount of work because a bode has either 0 or 2 children causing for a smaller height and having to         traverse less to insert a node.",27.0,80
23517,23517,27765,854bde56afcd2bd2c31fbe39384369ef7c0ac613a004a4b239a7a7d08872fa336ab049f8f45358abb5e93ca8dfc33e8954bf246487197e2265435ed3c204826b,"1.The worst-case complexity of searching for a value v in a vector is O(n), this mostly occurs when the number that we are searching for is not contained by the vector. We do n amount of work because we'll have to traverse the list comparing the value v with each number inside the list.

2.The worst-case height of the BST is O(n) and this occurs when the numbers that we are inserting to the BST are sorted irrespective of whether it is sorted from smallest-largest or largest-smallest and because this will result in the BST having a linear shape.

The best-case height of the BST is O(logn), this occurs when the numbers being inserted are not sorted as this will not result in a linear BST.

3.We would do O(n) amount of work because we would have to traverse through all numbers in the tree in order to insert the next number

4.We would do O(logn) amount of work because in this case we don't traverse through all the numbers in the tree since some numbers will be greater and others less than the root

5.we would do O(h) amount of work",19.0,80
23518,23518,27766,2c32439612d29606cd7276c7d7327878252b82b353a0e5c5a38f508a89318428edb5d433b571f4ed85a8cddd2dbf4c9c5eb5b82d38c65addb4bffc9179a95b21,"The worst case search for value v would be O(n). This would occur when we need to traverse through all values in order to find v.

The best case height of the tree would be O(logn) and the worst case would be O(n). The best case would represent a perfect tree, where the height is exponentially shorter than the worst case as there are more paths originating from the root. The depth is larger, thus, the same nodes do not need to be traversed through continuously. The worst case displays a tree that represents more of a linked list. The height is very long, thus, the same nodes need to be traversed through continuously. There is also a much smaller depth and fewer possible paths.

Assuming we have the worst case height, O(n) work needs to be done for insertion as all nodes need to be traversed through. Thus, the time taken depends on how many nodes already exist and needs to be revisited.

assuming we have the best case height, O(logn) work needs to be done for insertion. This is because the node depends on the height of the branch that is visited. Thus, the time complexity is exponentially shorter as it is dependent on the height of the branch as opposed to just the amount of nodes present. Thus the shortest amount of time taken can be concluded as 2^height.

Therefore, in the best case, we do an exponential amount of work, depending on the tree height 2^height or O(logn). In the worst case we do linear work depending on the amount of nodes present O(n).",27.0,80
23519,23519,27767,f7763ea222dac1e375943618ea39c7850a59642b77b7731de5c2d200f944ea90e1861bca5e13b98b4e1c518e004e6a6d55592f5ac74fe6b5f4bf1fc2d7073996,"(1) The worst-case complexity of searching for a value v in a vector is O(n)

(2)The worst-case complexity of Insertion IS O(N^2) and the best-case complexity is O(N) .

(3)....

(4)...

(5).....",7.0,80
23520,23520,27768,615a61127c6c0ce82fff3b905af9891145f1a8b7de3c813ff28357e83206738e51030e5e11f925cb1ff08e1e1848b449cb4a5ebd866eaf249477de58f163ccf4,"1. Worst case complexity for searching a value v in a vector is O(n), this occurs when the value being searched is the last element in the searched in the vector.

if we search for n values, and have to traverse n values that would make the complexity O(n^2)

2. The best case height for the BST is log2(n+1)-1,

and this occurs when the numbers are evenly spread out in values and are randomly assorted.

the worst case would occur if the vector is already sorted before inserting the values into the BST, resulting in a linked list making the height of the tree n-1.

3. to insert all numbers will be O(n^2) work. this is as we would need to travel n distance to insert a values from a list n times.

4. we would do O(nlog(n)) work, as to insert a single value takes log(n) amount of work, therefore to insert n values would O(nlog(n)) work.

5. in the worst case we would do, it would n^2 + n^2 = 2n^2 times therefore O(n^2) work
    in the best case it would take nlog(n) times to insert and nlog(n) times to search n values therefore nlog(n) + nlog(n) = 2nlog(n) therefore O(nlog(n))",41.0,80
23521,23521,27769,5888307e6e5630e26d91393f9d95b55394aa59f773d80fc5cba42e8220ea74538fd7609c1185eaef557523bfd3715cc3b2307d7a31ddf68499df84fa7da160d9,"O(h). This occurs when the value we are searching for is not in the vector. if we search n times the we do an n amount of work

the best case is when we have a full binary tree and the worst case is when we have an unbalanced tree which is complete. For the best case of the height O(1),  for the worst case O(n)

O(n). We would do linear amount of work since we would have to traverse all the nodes to reach the longest path to a node with no children.

O(1), when we have the best case then that means we have both left and right children from the root so inserting would be either to the left or to the right. The best caase is when we have a full binary tree

O(n)",19.0,80
23522,23522,27770,0a1930b4d16e62ac7ee353c6144c568d9ee6c791d0d3632d3ce78fd24bb2c65d328c4924d6cafd1daed9790efaefb16fe2a520125cf9396ef372146945ae0496,"In an unsorted vector, the worst case occurs when the element being searched for is at the end of the vector, as you have to traverse through every element in the vector to find it. The worst case complexity is O(n).

In an empty BST, when adding numbers, the worst case would occur when the tree formed is skew. Thus the worst case height of the tree would be O(n) to insert n amount of elements.  If the tree is not skew, i.e it is balanced, the best case height of the tree would be log n and time complexity is O(log n).

The time complexity would be O(n), thus n amount f work would be done each time.

Time complexity would be O(log n) as the height of the tree id log n.",19.0,80
23523,23523,27771,18821a50a643c1101d4d4b4a20eab092e9ef83d83d66cc8b476254122713205813222ecc2114e01a4fff80d19f68cc23c5bc386f899d5730224a2f35e7ae4a2c,"O(n) it occurs when v is the last element in the vector and we'd be doing O(n2) amounts of work.

Best case is O(log(n)) when we're dealing with a perfect tree

Worst case being O(n) when every internal node in the tree has only one child.

O(n2) it would take O(n) work to insert one in the worst case so inserting n times would result in O(n2)

O(n2)",30.0,80
23524,23524,27772,f7abd04c97a647b1e757bccd7284173478fbf8f28e28e3102567ab244a63fd5c67a5e953a932ab1f774cb73ace52fda53cdbbded4668ee4660e933d867e532bd,"The worst case complexity of searching for a value v in a vector is O(n) and this happens when v is not part of the numbers in the vector, we do linear work if we search n times which is O(n). 

The best case height of the tree is log2(n+1)-1 and this case occurs when the resulting tree after n insertions is a perfect tree whereby all internal nodes have 2 children and leaves have 0 children. The worst case height of the tree is n -1  and this occurs when the tree is in a linked list like structure whereby insertions would lead to each node in the tree starting with the root has only one child,,,the algorithm will traverse along the longest path before inserting.

For a worst case height we would do O(n) amount of work which is a linear amount of work. I came to this conclusion with the fact that each insertion would require comparing and traversing through each and every node present in the tree to the last one  thus for n insertions ,,n comparisons and traversals will have to take place. 

For a best case height we would do O(logn) amount of work when inserting all n numbers. I came to this conclusion with the fact that a best case height which is log2(n+1)-1 causes the algorithm to traverse along the shortest paths in the tree whenever an insertion happens.

The total work we will do in total from these two cases for constructing and searching the tree is O(logn) + O(n) ",29.0,80
23525,23525,27773,6ba5306b04bb1c19ff5f5148036844fc07d1e828c1c4bdd9a403971c63a75670cfd9507d856d67663bf299025ddc744dc1aab73fcc8ad24aa24659b96dc9ae8e,"The worst-case time complexity of searching for a value v in the vector is O(n), this happens when the value v is the very last value in the vector. If we search the vector n times then we do a linear amount of work, O(n).

The height of the tree in the best-case is O(logn), this happens when the structure of the tree, after inserting all the numbers, is a perfect BST. In the worst-case the height of the tree is O(n), the numbers are inserted in such a way that the BST is degenerate.

We would do a linear amount of work, O(n) in the worst-case. Since we need to traverse the BST along the longest path from the root to a leaf before we can insert a number, the amount of work we do will thus be proportional to the height of the tree(height = n -1 in the worst case).

The amount of work we do will be O(logn) in the best-case. We will not be necessarily traversing the longest path every time we insert a a number. The amount of work is proportional to the height of the tree in the best-case.",19.0,80
23526,23526,27774,17a5fd9d02d6fba8d8046ace71c42e033c0f094c5a424e213efe17ca2b15dcda4339210b67d2e20cb931a5cb55e9b6fb5621dde12a8a5e6da612e051b176b44e,"1. worst-complexity of searching for a value v
O(n).
Happens if you have to traverse through the entire list.
work = n^2

2. Best and worst-case height?
worst = O(n) - occurs when you have to traverse through the left and right children of each node of the tree.
best = O(log(n)) - occurs when there is a hole in the tree.

3. O(log(n^2))",15.0,80
23527,23527,27775,e1db971413a3e8370e48a08bd90e6c532854614ec97bf2846a8b6f64d7d2d64fceb404c5b40a925c2c496078dab9556b9aedc866e91bea3a7a6a8dc8cc19eb5b,"The worst case complexity of searching for a value in the vector would be O(n). This occurs when the value is not in the vector and n comparisons would need to be made. Searching n times would be a linear amount of work, O(n).

The best case height of the tree is O(logn) when the BST is structured in the best way, i.e. the Binary Search Tree is perfect, with the greatest number of nodes in the lowest height possible. However, when the tree has only one node (root), the height will be constant, O(1) as the height will be zero and no traversal is needed. The worst case height will be O(n), this occurs in a degenerate tree where the height is equal to n-1.

The worst case height after each insertion will result in the height being equal to the number of nodes - 1. Therefore, inserting each number will require a traversal through the entire tree, n-1 times. The work will be O(n).

The best case height will be O(logn), therefore, inserting each number will require a logarithmic number of traversals, making the work O(logn).

With the best case height, constructing the tree will be O(logn), and searching the tree will be O(logn) in the worst case (the value is not found at the root). Therefore, the total work would be O(2logn). With the worst case height, both construction and searching will be O(n), therefore, the work will be O(2n).",22.0,80
23528,23528,27776,1e61ac69c9ccec529a9d57595e183d7f2b1fa6a9903d4933718e237d1b12f704ba69dec35931222592238b7ab802821e4d5dd2c83c64cb9301a8bb0ced8b2cba,"Worst case complexity is O(n) and this occurs when the value isn’t in the value. 

Best case is if we create a perfect binary tree and this occurs with a bushy tree. Worst case is when we create a degenerate tree which has an extremely big height, this occurs when each node has one child.

We would have O(n) because the function is linear. So if we have a million nodes to insert it will take 1 million comparisons to insert.

We would have O(logn) because the function is exponentially. This means it will be faster to do comparisons when inserting the number.

It would take much more work with the worst case scenario then the best case scenario.",19.0,80
23529,23529,27777,c66e418bde3624775409174d439f8c7a104e4c741d28aa9a32d3dff6f27ee3fc70a6b61ca496d004e7124e5afeca9e6a74cf0455c76878d506978153185a8efb,"- The worst case would take O(n) time and would occur when the element is the last element of the vector. By searching n times, the amount of work done becomes quadratic.

- The best case would be O(logn) and would occur when a perfect tree is formed. The worst case would be O(n) and would occur if every item placed in the BST has a greater value than the previously added item, forming a linked list of sorts..

- It would be O(n^2)  in the worst case as every item that has been added would need to be traversed to add a new item and so it must traverse n items, n times, resulting in O(n^2)

- It would be O(nlogn) in the best case because logn items would need to be traversed to add a new item and this would happen n times. 

- In the best case, O(2nlogn). In the worst case, O(n^3).

               ­­­",37.0,80
23530,23530,27778,5d0d60194fd1b05c809499adb963afbac0ab800c552d7666ea7779f6183d17839f234e9ecee3ed11e567d9e2e5d5f869bc08bd2cc74894f9ca624282e8055b10,"* The worst-case time complexity for searching for a value is O(N) or LINEAR. This worst-case time complexity will occur if the desired value is either not in the vector, or at the very last location of the vector. Both scenarios, we must traverse the entire length of the vector. If we search _n _times then we will be doing O(N^2) or a QUADRATIC amount of work
	* The best-case height of a Binary Search Tree will be O(LOGN). The worst-case height of a Binary Search Tree is O(N). A worst-case height will occur if the tree is not balanced or skewed. A best-case height will occur if the tree is balanced or a complete or perfect BST forms
	* Inserting a value to a BST in the worst-case height, the amount of work done by the function will be proportional to the height of the tree, therefore the amount of work that will need to be done is O(N)
	* Since the amount of work done is proportional to the height of the BST, the amount of work done by the insert function after the best-case height is O(LOGN)
	* Best-case: We would do a linearithmic or O(LOGN) amount of work constructing the tree, and a constant or O(1) amount of work if the value we're searching for is at the root of the tree, but in general, a linearithmic or O(LOGN) amount of work when searching for a value

Worst-case: We would do a linear or O(N) amount of work constructing the tree, and a linear or O(N) amount of work searching for a value in the tree",25.0,80
23531,23531,27779,9140ffa3b52741e2ae246773dfeed94b1141ba7c3dc70e8cb17fb6410cd6b017d81c18ceaa0264d9c4b8354cae095d12f4a720da352b65b62d37bdd0fc9fdc69,"1. The worst case would be O(n),this occurs when the value we are looking for is not in the vector. We would do n^2 work

2.The best case would be O(1),this would occur when we insert the value in the BST and we find that the tree is empty. The worst case would be that we insert the value and we have to traverse the height of the tree, this would be O(logn) if we have packed in the perfect order and it will be O(n) if we packed the data in a bad way

3.We would do O(n) work and this is because each insert would happen after we have traversed the height of the tree and if we have the worst case the of the tree would be O(n) and for this reason we would do n comparisons which corresponds to O(n) work

4. Assuming that we have the best case, the height of the tree would be O(logn) so if we were to insert all the items we would need to traverse the height of the tree to add the last item which would need O(logn) of work

5. We would do O(nlogn) work in the best case and we would do O(n^2) work in the worst case",39.0,80
23532,23532,27780,83c5e0cccc2c84d6aa6c84996703c9788a4c77ad197dc9cbe544f356daab1002c8cb4669771a7a17cb1f5a0ca37aa675d40cb959b05635bc4844ce29a466fa7e,"The worst case complexity for searching a vector for a value v is O(n). This occurs when the value v is the last item in the vector. If the vector is searched n times then the complexity is O(n^2) since the work is n^2.

The best case height of a tree is when the tree is full. This occurs when the nodes either have 0 or 2 children. The complexity is then O(log n). The worst case for a tree is when each node, except for the last node, has 1 child. This type of tree is known as a degenerate binary tree. The complexity for the height is O(n).

In the worst case scenario, to insert a number, the entire list must be traversed in order to insert the number. Since the tree is degenerate, it would be like trying to push a value to the back of a list. Therefore the worst case is O(n).

In the best case scenario, since the height of the tree is equal to log (subscript 2)(n+1) - 1, the best case is O(log n).

In the worst case, constructing and searching for numbers is O(n^2) and in the best case it is O(log n).",32.0,80
23533,23533,27781,6a787853e1f57b2d3b0d74f5ae62b179adb7413dd588b37a8f7082bdd65e471590c4f39498c937e59e73bcf33962fea95df098117d05b73852f11db547a99d9b," worst Time complexity of searching is O(n)

The best case time complexity of insertion is O(log(n)) and the worst case is O(log(n).",8.0,80
23534,23534,27782,e8cc8f379686cf17ff7a79c51f234b372a7158c41925760d6a62468ac2bc253c196a10ef5af7f8e787abc174ba6435f331d902d6901bc07bc87271a8d067f35c,"The worst-case complexity of searching for a value v in a vector is O(n) and this occurs when the value does not appear in the vector.  A linear amount of work is done.

The worst-case height is height n-1, with O(n) complexity.  This occurs when a tree is degenerate and so resembles a linked list (all nodes have only one child).  The best-case height is height log2(n+1) -1, and this occurs when the tree is perfect (all nodes have 2 children - except for the nodes at height 1, they may have either 0, 1 or 2 children). This is height O(logn).

The worst-case height would result in linear work being done for each insertion O(n).

The best-case height would result in a logarithmic amount of work being done for each insertion O(logn).

The amount of work done is proportional to the height of the tree to search the tree, therefore a linear amount of work would be done O(n).",19.0,80
23535,23535,27783,a4513e9eefe06c5d06cd544fbaa5db795547b8f01893c660dc4a8e31a77cbc61bded840bbf0b3fd52a94491adbe0a21a3d4396c46fe19d46198e8b7b21695be6,"1) Worst case would be O(n) because we would have to check each number, and it's considered the worst case because the value might be at the end of the vector. If we search n times, we would do n+1 amount of work.

2) Best case would be O(log n), and that would be when it is a complete tree. The worst-case would be O(n) and that would be when it is a degenerate tree (each node has 1 child)

3) We would do O(n) work, and this is because we would have to pass every single node to find a place to insert the new value since the tree would look very much like a linked list.

4) We would do O(log n) work, because we will be following a path according to if the value is greater or less than another value, greatly cutting down on our time to find the place to insert.

5) O(n^2)",27.0,80
23536,23536,27784,12066f8f6a7f4cd1c9586b77b6e85c69168c3e639d8a7cc579d0737f33e85026e0fc0bba1f43d9a6c097e420e073f5dd573d48b38e1cf440a6f948554edb9454,"1. The worst case in searching for a value from a vector is when either the value is not present in the vector or the value is the last value in our vector hence we have to traverse through the entire vector values, here we do linear work i.e O(n).

2.(i)When we insert values into a BST the worst case occurs when we have to traverse the entire tree before inserting a value ( an example of this is when we insert the smallest/biggest number out of all the numbers we have hence we move all the way to the last node then insert) , this is when we traverse the trees height before inserting and this is linear work i.e O(n).

(ii) The best case when inserting a value into a BST is normally when we have a hole in the tree (this is when the 'root/any node that isn't the leaf ' had one child and then the value we are to add fills the space/hole . ) This happens through logarithmic notation O(logn).

3.The worst case height notation is O(n).  if we're inserting n numbers and we have the worst case height after each insertion then it means we always traverse the entire tree length to insert a number hence we have still remain with our worst case height notation of O(n).

4. The best case height notation is O(logn). If every insertion results in the best case height then every insertions from the n numbers will result in the notation O(logn).

5. Constructing a tree takes O(h) with 'h' being the tree height, when we now have to search for different numbers 'n' times then we get the worst and best case. Best case being O(1) when the number we're searching for is the root. The worst case could be O(n) or O(logn) depending on the tree structure, O(logn) being for a perfect tree worst case.",17.0,80
23537,23537,27785,d2c94c0dca7decb41292af9de73a32afa110cab818c0e296b000bfe9dd7b6bf221a0332e01f53ce869a1f4affd4abbea90b7e61d9504a5178a430b94bbde20af,"The worst case for searching for a value v in a vector is O(n) and this occurs when v is the last item at the back of the vector. The amount of work done will be n amount of work as each number in the vector will be compared before reaching the final item.

The best-case height of a BST is O(logn). these occurs when every node in the tree is filled with a value. The worst-case height is O(n). This case will occur when the algorithm needs to traverse along the longest path from the root to the leaf in order to insert.

 In the worst case, the amount of work to insert all numbers will be O(n). This is because the algorithm will have to traverse through every number already inserted before inserting the new number.

In the best case, the amount of work to insert all numbers will be O(logn). In the best case, the BST will be structured correctly and because of this, not every number will be compared before inserting as it will check if the current node is less than or greater than the new number, and will recursively go through the subtree from that current node and not the whole BST.

 In the best case, inserting and searching for different numbers will be O(logn) and in the worst case, inserting and searching will be O(n).",17.0,80
23538,23538,27786,b44584ccd8b5f428825956ad2bd876dd80c6494335aff0205a382354e687bb945dfab58c9f5cd5ee6d0fb386b28c2c5331192bb900a0c9c779312ec0ec3d111c,"the worse case complexity when searching for a value in a vector is O(n) this will occur when the value is at the end of the vector, if we were to search n time we do n^2 work.",3.0,80
23539,23539,27787,6398cd3a19a3d471bc5a210dfd041039aa199f2840055e48507502bec88a8f8eb3f128de790430daa8207ba0fde7dea8a8fb8416bcb584e1bb9e76ef88b1e1f2,"1. the worst case when searching for a value v is O(n). this occurs if the value is the last element in the vector.

2. the worst case when adding to the tree is O(n). this would occur if we have to traverse through all the existing elements before insertion . the best case when adding to a tree is O(logn). this would occur when the height of the tree is in the best case. 

3. O(n), as we would have to traverse through the entire tree before insertion.

4. O(logn) as the height of the tree would be log(n) in the best case.",12.0,80
23540,23540,27788,8f4f0cec01fab6a6a49376ed0eca817677b16456497e4474dea2db6c84f10bbab5215841562427aec9d1d1cb57d57272e23d92898bef51a2205b3db761cea98d,"* O(n) - Linear. This occurs if the value is in the last position of the vector. We will do n^2 work if we search n times.
	* Insertion into a BST

	* Best Case: Each internal node has two children. This would mean the larger the tree, the less height would change after each insertion. O(logn) - Logarithmic.
	* Worst Case: Each internal node only has one child. This would mean the larger the tree, the more nodes would need to be traversed after each insertion. O(n) - Linear.

Worst case height = n - 1. Therefore, if for each number we insert, we must travel passed each node, we would do O(n^2) work as we would have to traverse n nodes n times. O(n^2) - Quadratic.Best case height = log(n+1) - 1. Therefore, as we insert more numbers into the tree, the height will change less and less. This would also mean the amount more work than the previous insertion after each insertion also decreases over time. We would do O(nlogn) work as we would have to traverse log(n+1) - 1 nodes n times. O(nlogn) - Linearithmic.Constructing and Searching

	* Best case: Constructing will take nlogn work + searching n times = nlogn + n
	* Worst Case: Constructing will take n^2 work + searching n times = n^2 + n",41.0,80
23541,23541,27789,dba55105f290263eab690cc35467de21c1485b240568356b922de9e4385ff6cd7f9c33bdddf55cba48dae5962652c3708da244fefbb69455c6e660d7de9c7d15,"The worst case time complicity for searching for value v in a vector is when u search every item in the vector and and the value is not found. so it the time complexity is o(n). we will do n amount of work if we search it n times and it the  last item or not found. or we will do work till the item is found in the vector so >n amount of work.

so initially their will be 0 nodes so the height will be 0. Once we add 1 item will just simply add it into the tree. and it will become the root without any children. so the height will remain 0. once we start adding children to the root value. the height will search  The number of edges on the longest path from the root to a leaf. so it will worst case o(n-1) so linear time. This will search till the root of the tree. this is the worst case time complexity. the best case time complexity is o(logn) when the value is at the leaf of tree.

For inserting the value will have to find the the number of edges from the root to the longest path from the root to the leaf. so it will will take n-1 times to keep searching for the longest path added from the root to the leaf.so it will take o(n-1) times;

for inserting the value from the leaf to the next value it will. so it would search from the current value to the next one. so will be o(logn) since the tree is balanced.

we will do a total of o(n) work to construct the tree since we have to go through each value to insert it and search it n time.",21.0,80
23542,23542,27790,3b71cded09878fac739a748b2fcbc2d9e2bef1d7260004d93fa1cfe93d9b6830fe9dca43a0e8ef309e85cefb7f4580ca47263177668c6f4b88b993ec3fb19c7e,"The worst case is Big O(n) and sometimes it will happen that we do not have the number that we are searching for in a vector.

The best case height of the tree will be h = log2(n+1) -1.

The worst case height of the  tree will be n-1.",5.0,80
23543,23543,27791,2f2bbc70f8136ca3b18457b652aa1d5317919459278da63d7273a5c4e29eded00275f14d0a5826a3efa0a4d6a86ce51a6129f3ba53f25a66bc7e4755b291485f,"For the worst-case complexity, it would O(n), and this would occur if the value is not in the vector or is the last value in the vector.

For the best-case height it would be O(logn) and this would be when the value is at the leaf of a tree.

For the worst-case height it would be O(n-1) and this would be when the value is at the root of a tree.

For inserting the values, we would be doing O(n) work as we would have the height be n, and would insert them individually. Hence us doing O(n) work.

For inserting the values, we would be doing O(logn) work as we as the best-case height would be if the tree is complete.

To construct the tree, it would do O(n) work and to search for a value it would be O(logn).",21.0,80
23544,23544,27792,936c1ec869d8f0942d3b84b8b6c320188374f7b930016464dda43168d457286fd222e445f17b63344d55d3ca25f550407692016dc54317e807a5e1c9658269bd,"1.WORST CASE IS 0(n*2).occurs when all inputs are different. 0.5n*2+1

2.best case:h=log2(n+1

worst case:H=n-1

3.O(logn)

4.O(n)

5.we do O(1)  amount of work",6.0,80
23545,23545,27793,a3989cc4476b1bbce9e79b34c3f0337ca13c9717a610fbe24ad51e9bdb052f2d445313904842463b1a859cd4d281ce72b5f85b0423f33b62cab82318e4116232,"The worst case complexity of searching for a value v in the vector is O(n) and this occurs when the value v is not in the vector. We do linear amount of work.

The best case height of the tree is O(log(n)) and this occurs when our tree is not a degenerate. The worst case height of the tree is O(n) and this occurs when our tree is a degenerate and became a linked list.

We would do a O(n) amount of work as our tree would be like a linked list and we would just be inserting our values going down.

We would have done O(n) amount of work as we would have to go back to the previous node all the time to check.

We would do constant amount of work provided the node(value) we want is in the tree",27.0,80
23546,23546,27794,8f8e96eb5a28d15c7802d177c96b97e53c9c9c2a37389d558dc50a5be6ad84289d3986f782da265340d7d86d9d174957d8d67890ddc79dd4587dd919a3bfb09b,"The worst case of searching for a value in a vector occurs when the value is at the back/end of the vector since we would then have to search through the entire vector from the start/beginning. This takes O(n) time and depends on how many elements are in the vector. If we were to search _N_ times the work done is n*O(n).

The best case height is O(logn), and occurs when the tree is balanced.

The worst case height is O(n), and occurs when the tree is degenerate.

When inserting, the work done depends on the height of the tree.

The work done in the best case is O(logn) when inserting a value into the tree. The tree is balanced and so we do not need to traverse every node. When inserting _N_ numbers the work done is O(nlogn).

The work done in the worst case is O(n) when inserting a value into the tree. The tree is degenerate and so we would need to traverse through every node before being able to insert a new element. When inserting _N_ numbers the work done is O(n^2).

Worst case total work: O(n^2) + n*O(n).

Best case total work: O(nlogn) + n*O(n).",37.0,80
23547,23547,27795,f4debaed9518cebe07277fbc6a1a427b3b49ad2f5df06234a9ca97b5e7abc3c76bca6dd791def2ebc753df680f825e521d18fc584971614c1d810f0fc7ab9f41,"The worst case complexity of a vector search is O(n) and it happens when searching of an element that is not in the vector 

The BST insert function has a worst case when we have to insert at the end of a longest path and the time complexity of it is O(n) and the best case is when we can insert the element or value right next to the root which gives a complexity of o(1)

The work to do for n items is n-1 which in complexity is O(n) because we would be inserting in the longest path which makes our height to increase

to search for an item in BST is O(n) because we would need to compare the value we are searching n times 

 ",11.0,80
23548,23548,27796,c6919e466976b48c2f7b3823eb90c377fa8e67b3a290bcb3ab3a7c56083193c911bc05ef76e986e61a0a361e9ed5a7fec55840ba6afe1022bc97e18b5eabbeef,"Worst case for searching value v in a vector is when the value is at the end of the vector. Complexity is order O(n).

Best case will is O(1) and occurs when the tree is empty, or  O(nlogn) when the tree is not degenerate.   West case is when the tree is degenerate and resembles a linked list, in that case it will be O(n). it only grows from one side.",8.0,80
23549,23549,27797,336c0de60905df4ae163484013b5cc72929683b64ebae6f69a61ca7bbc767084419ba7cf9291246a9b63bc7e686a397f48c33976b41fb34999f9b50eee045aba,"the worst case of searching through a vector is O(n) and this happens when the value""v"" is at the end of the vector or does not exists at all.

The best case takes O(log(n)) , this happens when the element you have to insert is at the top of the tree or needs few traversal and the worst case is O(n) and happens when you have to traverse the whole tree before inserting the value.

we would be doing O( log(n)-1) since we have best case at every height ,we have to traverse one less height to insert n numbers.

Overall we will be doing O(n) work.",15.0,80
23550,23550,27798,1b575ce85f9fe9d462e1de73f4e66ff04c921a768d297956a2d166b33e02a5691d14de4e07fdb716975b3003397dd6ecfd657024c0a233117dfee4b6480ebdcd,"-> The worst case complexity would be when the v is not in the vector meaning we have to traverse the entire vector, resulting in O(n) time complexity.

-> If we create an empty BST, in best case, the height of the BST will increase gradually by log2(n + 1) - 1, resulting in O(logn) complexity. In the worst case, the height of the BST will be of the degenerate tree, making us do linear work because of h being n - 1 and therefore the complexity would be O(n).

-> We will follow the BST algorithm to insert any number to the BST. Worst Case - O(n) - We will have to traverse the entire tree along the longest path from the root to a leaf before insertion. The amount of work done is proportional to the height of the tree. The worst case height is n - 1. Therefore we will do linear amount of work depending on the structure of the tree.

-> Best Case - O(logn) - We know that in the best case the height of the tree is log2(n+1)−1 and therefore complexity will be O(logn) as we will insert numbers and the height will increase gradually.

-> In total we would do O(n) amount of work as when we will construct and search for different numbers, we will traverse the entire tree.",23.0,80
23551,23551,27799,33903c4df6729a45e2485f57a528848aea77fb0ac81607f602f6f53f80eb513d5b18fef57c086d43fef4cdb3f78bbc1f8da0bcaa1e67afb26268e9484bbb4ded,"The worst case complexity is O(n) and it occurs when the value v is at the back of the vector. We work n times more.

The worst case occurs when the value inserted is larger than the previous value for all values inserted since it gives a linked list and complexity is O(n). The best case occurs when each internode has two children. The complexity is O(n). This is because you can fit more children per depth which reduces height.

O(n). This is because a traversal has to be preformed which goes to every single node.",11.0,80
23552,23552,27800,f1ba85bcb3cb35dd3a5763fa5946a3ff7df7d0bf7beb3182d0ecb801d8abdf353d4eeb7909c0cc4e94c0d221fea7a7c70e57bb1e1c70aaf71f4a7a0e8fe5269d,"1.)The worst case complexity for searching for a value in a vector is O(n) and this occurs when the value we are searching for is at the back of the vector. If we were to search n times for a value in a vector, the time complexity of this operation would be O(n^2).

2.)In a BST, The best case height of the tree is given by: h=log2(n+1)-1 (n = number of nodes). Or O(logn) in big O notation. This occurs when new items are inserted in such a way so that there are 2^k nodes at level k of the tree. This can be seen in a complete(leafs fill up from the left to the right at level k) as well as in perfect tree. This sorting ensures that the minimum number of edges to get from the root to the furthest leaf is achieved, as most if not all the leaves are the same number of edges away. – The worst case height of a BST is given by: h = n-1 (n = number of nodes). In big O notation this is O(n). This typically occurs when adding a new node in the tree results in a new leaf that has no siblings or other nodes at the same depth. Also seen on degenerate binary search trees which resemble a singly linked list with an extra pointer to nothing.

3.)",22.0,80
23553,23553,27801,23b5a4e63c9fefece084783cc1411977943e7d8d3612a093af2540d5bb113a4845b418786034d0d238575bbb9fe95d816e937dc9fe084e3f124b6dcce8457f10,"Worst case complexity of searching for a value in a vector is constant time O(1). This is when we have to search through all the numbers in the vector (and it's not there). O(1) constant amount of work is done.

When inserting, if we're looking at the best case, the height = log2(n+1)-1 and if we're looking at the worst case, the height = n-1. The best case occurs when we're inserting a value into the root node and the worst case occurs when we're inserting a value at the end of the longest path from the root to the leaf.

Worst-case height when inserting does O(n) linear amount of work because amount of work is proportional to height and we have to go down the longest path from the root to a leaf.

Best-case height when inserting does O(logn) amount of work which is exponentially faster because we only have to insert the value into the root node.

Best-case would do O(logn)+O(n) amount of work while worst-case would do O(n)+O(n) amount of work.",21.0,80
23554,23554,27802,87b26af5215183ea5d646e967e1e3374a7a4afb5a13a2967680ff8a29d219e9ac775560a42891913325361c21b3cb2f9b5121d0317fb7c951cff2c01aed37b66,"The worst- case complexity of searching for value V in the vector is O(n) and it occurs when the value is in the last position in the vector, N work will be done because of N number of repetitions.

The worst-case height of a BST of complexity O(N), occurs at maximum height(n-1).The best-case height will be of complexity O(LOGN) and will occur at the minimum height log2(n+1) -1.

Worst-case height would be at maximum height. If we have N number of nodes, the maximum height would be = n -1. O(N) work would be done. 

Best-case height would be at minimum height. If we have N number of nodes, the maximum height would be = log2(n+1) -1. O(LOGN) work would be done.",27.0,80
23555,23555,27803,03af6c40b97133a1240dcc22b0dd356e3929ea04c9cf63c336ed0f2605d19efb0d0a0e5a6c60e766990694456ae922f3a477316845f8028bca7fb236d74cb185,"O(n). The worst case occurs when the value is in the last position of the vector or not in the vector, and as a result we will have to search throughout the whole vector.

Best-case O(1). If the ITH element we want to insert is smaller than all the elements in the tree and out tree is skewed to the right, we would have to insert on the left of the root. Else if the ITH element we want to insert is greater than all the elements in the tree and out tree is skewed to the left, we would have to insert on the right of the root.

Worst-case O(n). If the ITH element we want to insert is smaller than all the elements in the tree and our tree is skewed to the left, we would have to go through every element in the tree searching for a possible insertion. Else, if the ITH element we want to insert is greater than all the elements in the tree and our tree is skewed to the right, we would have to go through every element in the tree searching for a possible insertion.",13.0,80
23556,23556,27804,675e836215b62d793972ecb9d5ace2eaf438e0e5d0d26f496ddc3442ba479da55ac029b8a4555f73c538c50ecac4b04edc042861ca9b743e991c19c46392aa72,"1.The worst case of searching for the v in a vector is O(n) and occurs when the element we are searching for is not in the vector.

We do O(n) amount of work to search n times.

2.The best case height O(log)   occurs when the number we have to insert to the tree is eligible to be placed in the first free space during the traversal.

Worst case height O(n) or O(n-) occurs when the algorithm has to traverse along the longest path which is from the root to the leaf.

3. We would do O(n^2) because in the worst case complexity is O(n), inserting numbers would result  in O(n^2) amount of work.

4. We would be doing 0(n log n) amount of work because with best case the complexity is O(log n)and inserting n numbers would result in O(n log n) amount of work.

5. In the best case when constructing the tree and searching for n numbers we would be doing O(n^2log  n) amount of work and in the worst we would be doing O(n^3) amount of work.",26.0,80
23557,23557,27805,6d04032d059678dcb346209e5f60e18a44d0c551ad3d7c0e551f1957033a386ffc9828dc7e1374b35e8828c43ed8d61ae22f6c2de063b8779cad31efc30f066d,"O(n) this occurs when v is the last item in the vector or is not in the vector. We do n amount of or we do work until we find the item we are searching for.

Best case height is O(logn). This occurs when the value is at the leaf of the tree , this is because we know the height of the tree so we only need to know where to insert the value below the leaf which would make the process faster.

Worst case height is O(n-1). This occurs when the value is at the root of the tree therefore we have to traverse through n-1 one items until we find a place to insert the value.

We'd be doing O(n) work as having the worst case height for each insertion would make the tree's height n-1 which means that to insert a new item we would have to traverse all the items in the tree to insert the item therefore we do O(n) work.

We'd be doing O(logn) work as having the best case height after each insertion would make the tree's height the shortest it could be which would make it a complete tree. This means that when inserting the values it traverses a short amount of items to insert the value.

Constructing the tree would be O(n) work and searching would be O(logn) work.",23.0,80
23558,23558,27806,a37e8cb6bec1612d5c3aa242e7b3e8cea873cb6f52435ece79359c13b8144256dc3d86709b38c13890622651a1bea3e2d4c9e9d39d9c4884e7ba93253dd09e29,"O (n)- when the value is not in the vector. 

O (log2 (n+1)) - best case for height

n-1 = worse case for height

O (logn) is for inserting all n numbers.",6.0,80
23559,23559,27807,c879e65c8f9657768bbf6800906a28bff217c7ef9063d46acfccc25071a9fc3aef2ccd29821fdc92e96d2f98ca66aa74a3fa2a8f0df86509064e53b0fb9b54bc,"1) O(n). This occurs when the value that we are searching for appears at the end of the vector. If we call the worst case search scenario n times then we would be doing n^2 work based on the list of numbers in the vector.

2) Best case: O(logn). This occurs when we have a full/perfect tree . Worst case: O(n). This occurs when we have a degenerate tree.

3) O(n^2). In the worst case of a degenerate tree we would be doing quadratic work as we would need to full traverse the tree first every time which would take linear work before inserting the next number which you would perform n times to insert each number. The linear amount of work being performed a linear amount of time means that you would be performing a quadratic amount of work.

4) We would be performing O(logn) for inserting the worst case of the best case height and performing this  n times means that we would perform O(logn) work in total.

5) O(n^3)",30.0,80
23560,23560,27808,9b486d212bcbfc98bcb7006334a7bd057c017b3b5d6ddec828a1e7c71b279d57abf5933826cc5cd40f31ce09e30273c03c034afd55ad69a350c76adfabdffc7c,"O(n) is the worst-case complexity of searching for a value. This would occur if the value v is not in the vector and we search the entire vector. So we will do a linear amount of work.

In the best-case, the complexity would be O(logn), meaning logarithmic. This is dependent upon the structure of the tree, the best-case structure being a perfect BST.

In the worst-case, the complexity would be O(h) or O(n-1), with h being the height of the tree and n being the number of nodes, meaning we would do a linear amount of work. This would occur if we has to insert a value that required us to traverse the BST entire height, from the root to the furthest leaf.

A linear amount of work, O(n) as we would need to traverse the entire tree height to insert each value, and each node will only have one child.

A logarithmic amount of work O(log(n)) as each insertion would be the shortest depth possible, which would occur in a perfect binary tree.

In the best-case we will do O(logn) amount of work and in the worst-case O(n-1). ",17.0,80
23561,23561,27809,a41ff85d7c3f46c972cdda9b8d99297a4177ec80aa4a317631762cd6ae04cc877e3ccd31e4fd09e41eccdaa2cd1266d20e5947fd82dfa31e5b04a9f5e1bd8e0c,"SUPPOSE THAT WE ARE GIVEN A LIST OF N NUMBERS IN RANDOM ORDER IN A VECTOR. WHAT IS THE WORST-CASE COMPLEXITY OF SEARCHING FOR A VALUE V IN THE VECTOR (IN BIG-O NOTATION) AND WHEN DOES THIS OCCUR? HOW MUCH WORK DO WE DO IF WE SEARCH N TIMES? [2 MARKS]

The worst-case complexity for searching for _v_ in the vector is O(n). The worst case occurs when the value is not in the vector so _n_ comparisons are done as each element must be visited since it is unsorted. 

IF WE CREATE AN EMPTY BST AND PROGRESSIVELY ADD EACH NUMBER TO THE TREE BY CALLING THE INSERT FUNCTION, WHAT IS THE BEST AND WORST-CASE HEIGHT OF THE TREE (IN BIG-O) AND EXPLAIN WHEN THESE CASES OCCUR. [4 MARKS]

The best case for height of the tree is O(logn) and this occurs when the binary search tree is perfect (i.e. if the tree has the maximum amount of nodes as a tree its height can have). This way, the tree has the shortest possible height of a tree with its number of nodes and the height is the same from the root to any leaf. The worst case is O(n) and occurs when the tree is degenerate (i.e. if all the nodes have only one child except for the last one). Since the nodes are in this list-like structure, the height is always going to be the longest possible of a tree with that many nodes.

ASSUMING THAT WE HAVE THE WORST CASE HEIGHT AFTER EACH INSERTION, HOW MUCH WORK (IN BIG-O) WOULD WE DO WHEN INSERTING ALL NN NUMBERS? EXPLAIN HOW YOU CAME TO THIS CONCLUSION. [2 MARKS]

The work will be O(n2) since each insertion is linear as one more traversal is performed than the element before (e.g. if the previous element required _k_ traversals before it could be added to the list, the current one to be inserted will require _k+1_ traversals) but taking all _n _insertions into account, this total work is quadratic as the number of traversals increases with the number of insertions in a quadratic fashion.

ASSUMING THAT WE HAVE THE BEST CASE HEIGHT AFTER EACH INSERTION, HOW MUCH WORK (IN BIG-O) WOULD WE DO WHEN INSERTING ALL N NUMBERS? EXPLAIN HOW YOU CAME TO THIS CONCLUSION. [2 MARKS]

The work is O(logn). 

IN THESE TWO DIFFERENT CASES, HOW MUCH WORK WOULD WE DO IN TOTAL TO CONSTRUCT THE TREE AND SEARCH FOR DIFFERENT NUMBERS N TIMES? [1 MARK]

For the best case, this is O(nlogn). For worst, it is O(n3).",33.0,80
23562,23562,27810,4f0d170bb113012c8d343271d925a96ef0e199ecdca36f51a1fc99d7e0e8c67fb97155bfa738d3317830adb88f58c316437e0cf62b20c43f4e89ab893b6e7471,"1) The worst time complexity would be O(n)- this occurs when the value is not found in the vector if we search n times work= O(n^2) n times as much work
2) The best case height is O(log n)   

    The worst case height is O(n)

3)The amount of work will be proportional to the height of the tree O(h)

4)The amount of work will be O(logn)

5)O(n)",17.0,80
23563,23563,27811,d098e277cb3df3b25c9e42904322dbd46a16b60a20b139d8066f16584a8bb599eddc05cac924f310971f38fb613ad7daea71749bb268694cb7e0d2fdf74a35a0,"The worst case of searching for a value v in the vector is O(n);this occurs when the value v is not in the vector; we do O(n2) amount of work if we search n times.

The worst case height of the tree is n-1 and the best case height of the tree is  log2(n+1)-1; the best case height occurs when the tree is organised in a way that it has 2k nodes at each level k in the tree and the number to be placed in the tree is eligible to be placed at the first available space in the tree during the traversal. The worst case, however, occurs when we have to traverse along the longest path from  the root to the leaf.

Since the worst case height is O(n), then we would do O(n2) amount of work that is; O(n)*n amount of work. I came to this conclusion simply by multiplying the number of times(n) we insert a number, by the time complexity of each insert in the worst case case (O(n)).

When we have the best case height; since the best case height is O(logn); then we would do O(nlogn) amount of work; that is O(logn)*n. I came to this conclusion simply by multiplying the number of times(n) we insert a number, by the time complexity of each insert in the best case(O(logn)).

In the best case, when constructing the tree and searching for n numbers we would be doing O(n2logn) amount of work. while in the worst case to construct the tree and search we would be doing O(n3) amount of work.",36.0,80
23564,23564,27812,5ad20b3b420c21e1fc2861df4f4257210672d867b8a024855b258388d20148643f1a94c77f0aa2d4b47f8fba4b85741287207442ff519080915f15fdfd0e21b1,"The worst case complexity of searching for a value v in the vector is O(1) time (constant). This occurs regardless of where v is stored within the vector because vectors use contiguous memory and pointer arithmetic. We do O(n) work if we search n times cause the amount of work done increases linearly in relation to the increment of n.

The best case height for the binary search tree would be O(log(n)). This occurs when the binary tree is a full tree.

The worst case height for the binary search tree would be O(n). This occurs when the tree is constructed in such a way that every node has only one child, leading to the tree having a linear structure. 

The amount of work done when inserting n numbers into a tree with the worst case height is O(n). This is because there will be n nodes with each node having one child except the leaf and as n increases the work done increases linearly.

If we have a tree with the best case height, the work done after the insertion of n nodes will be O(log n). 

Constructing the tree and searching for different numbers n times would both be O(nlog n)amount of work.",17.0,80
23565,23565,27813,4d5583055b5cf0ef4bd7f80832ec9b8940eedb6261741378493c7c1e768d88d15f96d3b8d5850288f3731056d59b3dbe1878b8c16bbb307054b4401de38adc38,"1) When the value v is not in the tree. We would have to go through each node in the tree. Depending on the structure of the tree we would have to do O(logn) which is the best case or O(n) which is the worst case. 

2) The worst case would be when we have to traverse the longest path, h in order to compare and then insert this would happen if the number becomes progressively smaller or larger as we insert. This would take O(n) time as the amount of work done is proportional to the height of the tree. In the best case where a full binary tree is formed then we will do O(logn). This is due to the structure of a full binary tree.   

3) O(n) as the amount of work is proportional to the height and since the path from the root to the leaf increases with each insertion the amount of work increases as each comparison has to go through h nodes. Since the worst case for height would be n-1 then it would O(n) work.

4)O(logn) as the amount of work is proportional to the height. The tree will have internal nodes with at least one internal node having two children which would shorten the number of traversals needed and since the best case for height is log2(n+1)-1 the work would be O(logn)

5) The worst case would be O(n) traversals and best case would be O(logn) traversals.  ",19.0,80
23566,23566,27814,c0e222e387522491c144bc66b8d4aac6d8899881b15676a75bd42f6939be2d68b02062c035d5f028531cde71d4b0b2bb7581d5e165c7c3be11bd4e67e796913f,"The worst case in O(n) and this occurs when the value v is not in the vector and traverse to the end on the vector.  We would do O(n) * n  = O(n) work  if we searched n times.

the complexity of insertion is proportional to the height of the tree so the worst case in O(n) and this occurs when the tree is degenerate and has height n(number of nodes). The best case is O(log n ) and  this occurs when the tree is balanced with height log(n).

We would do O(n) * n  = O(n) work because each insertion would take O(n) time and and the summation would result in O(n) work.

We would do n * O(log n ) work which is O(log n ).

O(n) in the worst case and O(log n ) in the best case.",38.0,80
23567,23567,27815,ed5a8c0425e8a7a0d2d402e42e3298539ec0ceb1b43ca8fa3f4b83dce862ed24fe276be92f07cf85365c96c7391564d1c0da45fd6e6ba4bd80ecb01a39467209,"worst-case complexity of searching for a value is O(n) n a vector. It happens when the value we are looking for is not in the vector and we have to iterate through n number of values.

with insertion, the best case is O(1) when we have a hole at the root's subtrees (immediate open spaces). worst case would be O(n-1) when we have to traverse through the longest path of the tree.

Worst case height is a degenerate binary tree and we would have to do O(n) work. This is because everytime we insert, we traverse through the height of the tree which is n-1 long. the work would then be O(n-1).

Best case is when we have to traverse through the shortest path of the tree, which would require O(log2 n) work.

In worst case total is O(n) and best is O(1).",3.0,80
23568,23568,27816,dec98074973763aa35f767e29ff1a337a2f96e27f7bb719852891850a70e146d6ceeda2c5cff7d622832dba02534fa96620c763e3c53dc17c1734a3ec63ba166,"O(n). It occurs when the value v is the last element in the vector. We would have to go through every single element to get to the value v.

If we searched n times then we would've done n² amount of work ( O(n²) )

The best case height would be O(log n). This whole occur even if we get a tree where all the nodes have 2 children or 0. All the nodes above height h would have 2 children and the nodes in height h would all be leaves.

The worst case height would be O(n). This would occur if all the nodes in the tree have 1 child except the node at the end, it would have no children. This would result in a tree with the height = n-1.

O(n²). With each insertion, we would have to traverse to the last node from the root before adding the new node, that would result in n-1 traversals and the insertion at the end. Doing this n times adds up to (n-1)(n-1) which is (n-1)² and that would be O(n²) in Big-O notation.",26.0,80
23569,23569,27817,1db17093b11c1476f03e1842d3fd75c18d4034c323e18d85de2325fa751f6201dc73b8705d987e46f915cfc55474341bdc436a256b6ba4b925f54ea754c444c7,"O(logn)

since searching is O(h) and worst case is O(logn)",7.0,80
23570,23570,27818,2f8068722efcb5acef0b043ef7eeece2ba76bc57f445239c4ee08b7c2bb5238f231cca575128f6a330204e13d52f6c557830c59595c0c60a57b982bbb0aba187,"1) The worst case for searching the value v in a vector would occur when v is not in the vector and we would have to search all over the vector which is O(n) linear time.

2) In the worst case we need to traverse the tree along the longest path from the root to a leaf before inserting. This means we need to traverse h nodes before we insert. The amount of work we need to do would depend on the structure of the tree. In the best case, the height of the tree would be log(n+1)-1(e.g when the tree is perfect) and in the worst case, the height would be n-1. Therefore O(logn) if the tree is in the best case and O(n) if it is in the worst case.

3) We would do O(n) work because the height of the tree in the worst case is n-1 which looks like a linked list.

4) We would do O(logn) work because the height in the best case is log(n+1)-1 which is exponential( like in a perfect tree).

5) I think it would be 2n which would be linear time O(n).",22.0,80
23571,23571,27819,ab50392a96c4c3025a5963370825a15241a679c25a4771a2853db32d86a5e0a874ed37e6f390b06f6b3a0755f5bc0190ec94f83a3fd5bf730ba4d34a04efb6d1,"worst-case: O(n) this occurs when the value is at the last position or not in the vector.

worst case: O(n) occurs when the tree is either left skewed or right skewed therefore you would have to travel from the root to the deepest leaf node in order to insert.

best case: O(1) occurs when all nodes are in the roots right subtree and the one to be inserted belongs in the left subtree or vice versa.",6.0,80
23572,23572,27820,5dcf09a63d08f8fcf484a27b8188aca8e05117584de8c4c8e580d2681056a972e8271fbb1e9e69a616d3a8d13ef9009ce7fbd4e4c680807f0aa62ce637934a9e,"Worst case: O(n), This would happen if the value v is not in the vector or at the end of the vector. If we searched n times them we would have a total time complexity of O(n^2). 

Best case: O(logn). This would happen when each node as 2 or 0 children . The worst case would happen when each node has only one child resulting in a O(n) complexity.

O(n^2), as we are doing n amount of work n times. (Quadratic)

O(nlogn), as we are doing logn amount of work n times.(Linearithmic)

Best case: O(nlog(n^2))

Worst case :O(n^3)",34.0,80
23573,23573,27821,0cd06500f6bc04ca04d6df402c164435dd4b1e3f62d49a5f81d45b91f4a6f4ac2ae8232fc2f485e2ef108625ecea2f61c466c82dcbccacd3d327b9b3b7efa90a,"The worst-case complexity of searching for a value v in the vector is O(n), it happens when v  is not in the list or if it is when it is the last number.

For inserting into an empty BST, worst-case height would be  if we have a degenerate tree, so h=n-1, O(n), and best case would be a perfect tree with h=log2(n+1)-1, O(logn).

Assuming that we have the worst case height after each insertion,  we would do have linear work, O(n) since the worst would be going only left or only right n-1 times.

Assuming that we have the base case height after each insertion,  we would do have logarithmic work, O(logn). For every parent you would have 2 children.

In these two different cases, we do  O(n) linear work, in total to construct the tree and search for different numbers n times.",19.0,80
23574,23574,27822,5f87218a9157c9f2740bbc5a076009259b8932c2104f99371f2e9e9e870c16111399d5c3a60f311aebd8ac847ff222666d98c8552349e85bf1bc07e6e8aaa00e,"v=O(logn)
O(n) times

h=O(logn)

h=O(1)

work=O(logn) times",7.0,80
23575,23575,27823,9e606e329f6a5dc1874e2e7d1ce01689bc1c5df584fe109cc6c775ea15ec412db6a361b31855924672756d4e66bb398724a491f49547db72d1faa12ddcce7489,"The worst-case: O(h), where h is the height of the tree. This occurs when the value v is either at a leaf that has the longest path from the node or when the value v is not in the tree.

The best-case height occurs for a perfect tree where the height of the tree is defined by log(n+1)-1. O(logn). The worst-case height occurs for a degenerate tree where the height is defined by n-1. O(n).

When we have a worst-case height, the tree is of the degenerate type. Thus the time complexity is: O(n), but since we have to insert n items, the time complexity is n*O(n). Thus the time complexity is O(n^2).

When we have a best-case height, the tree is of the perfect type. Thus the time complexity is: O(logn), but since we have to insert n items, the time complexity is n*O(logn). Thus the time complexity is O(nlogn).",34.0,80
23576,23576,27824,20d849b0f14d796b315efcd61e863b25c7b0891949c9f1f08039226267e2ec02fc126e19dc6bac1596ae1c91066636280bb491c789bcd5f5ca3de77e3170945e,"The worst case is linear O(n), when the value is not in the vector and we traverse through the whole vector. We do a linear amount of time if we search n times.

The worst case is when we have a degenerate tree and we have to travel through the longest path to insert a value. This takes a linear amount of time, O(n). The best case is when we traverse the shortest path relative to the height of the tree, in this case we can do a logarithmic amount of work, which is O(long) in Big O.

We do a linear amount of work, O(n). This is because the tree is structured like a linked list and we have to traverse through every node to get insert another one.

We do a logarithmic amount of work O(long). This is because our tree is balanced.

In the first case we will do a linear amount of work and in second case we will do a logarithmic amount of work.",19.0,80
23577,23577,27825,828a54706b7956f06065af9a928b49958122a77b54a5e0593021ac1ee5bfac90e0bf9488291ceaad9b7538bfadd4796253d8359db184b0bd7f7e1ed456e8f30c,"The worst case complexity for searching for a value in an unordered vector is O(n) and occurs when the value is at the end of the vector. We do linear amount of work.

The best case height of the tree is log2(n+1)−1 which has a time complexity of O(logn) and this case occurs when the tree is balanced. The worst case height of the tree is n-1 which has a time complexity of O(n) and this case occurs when the tree is degenerate.

We would do O(n) work. because each time we need to insert we traverse the tree from the root.

We would do O(logn), because the best case to traverse through a tree is logarithmic.

O(n).",19.0,80
23578,23578,27826,1ae15e0f8c76ae99b51e83372a1074e20d0c372f497d2600b23a4ed137e5d58ad3914d0e0fce9e4d1885de19b788d1beec93c22c6cc3c2146c9349afe08e62f9,"The worst case of searching through a vector is if we would have to traverse through the entire vector. This would take a linear amount of work - O(n).

The height of the tree in the worst case would be n-1. The worst case is when the algorithm needs to traverse the tree along the longest path from root to leaf before insertion. The height of the tree would be O(n) or O(logn).

We would do work that is proportional to the height of the tree, so O(n) or O(logn).

In the best-case, the value that is being inserted would be at the root which would only require 1 traversal. Therefore it would take a constant amount of time - O(1).

It would take an exponential amount of work - O(n^2).",25.0,80
23579,23579,27827,e083cbbf008c42438bc396229643f759537dd38e9f70943e360360b6f27f45207e60ac5070353bd70bc7b26433e973228b25ccf89b152c434341d5c266f31945,"The worst case complexity of searching for a value in a vector can be linear (0(n)). The worst case happens when there are n items in the vector and the value we are searching for is not in the vector, we have to traverse through all the values.

When adding nodes in a tree, the height of the tree matters, it complexity can be linear or constant. 

when the tree has zero nodes, adding a number/node will be constant or sometimes logarithmic no matter how much the number is. This also applies to trees with height of one.

the worst case will be when the height is greater than or equal to two, adding a number/node to the tree will be linear through the height of the tree h. 0(h).",4.0,80
23580,23580,27828,252668df997d55b86d753e14db9bb82d9a9ab0f27d714f3256c72a03986a906ffccf1958bf221d3ab998a7770edda41ec2de25393f1d9a62f105684cf09211ed,worst case Complexity would be O(n) as to search through the vector we would iterate through it sequentially and this would occur for any amount of time depending on how many items will increase the time taken hence O(n),4.0,80
23581,23581,27829,b722c8fd9eec42aa602e4cbd2ceee62645727f2b19607bd1bed826053b9d70a2c8e8d845bbe5119d6c5e8f3413efde7438ae5ec2d12a60cf1215dd59daf4a367,"1) The worst-case complexity is O(logn) or O(n), and this happens when the value v is not in the tree. When traversing n times we do O(n) work.

2) The worst case is O(n). This happens when what we want to insert is inserted after the longest path of the tree.

     The best case is O(logn) technically, but is really O(1). This is as the best case happens when what we want to insert gets inserted just after the root.

3) It will be O(n). This is as the worst case height will always be n-1, which will always give O(n).

4) It would either be O(1) or O(logn) depending on the value of n. This is as the best case height will always give a O(logn) when inserting. But if the value is inserted just after the root then it will be O(1).

5)",5.0,80
23582,23582,27830,a2e71f759079413d4f87ec8f397142f2bf7f364e3ac1403027655c606e40a1106c0bace5c922e3aa206700cf3aa5120aeba8f93363e62c778029029dcc2335f1,"1.

Worst case is O(n). This occurs when there is not a value found in a node. This is the worst case as every node in the tree has to be visited to find the value but results in being not there. For searching n times in an O(n) case would lead to an O(n^2) work.

2.

Worst case is if having to travel the longest path down the tree O(n-1) 

Best case is the shortest path travelling down the tree O(log2n)

Another best case would be if there was a hole in the tree in the above levels

3.

O(n) as every node would have to be visited to check if the value can be inserted anywhere and once it is seen that it cannot then place it on a new level

4.

5.",16.0,80
23583,23583,27831,75a3383738a198a57b5bf911227bc1acefa5387a63447f6ac8def117cc9ca26c926b9a06fe676ff769e333554195eaa647257e22733d67710ae7508ceb7f3115,"In worst case scenario its going to take time if searching for value v in n times ,means that it is going to take n times to get the value v in vector as its is linear.

Best-case the height of the tree will be log(n+1)−1 and in the worst case, the height of the tree will be n−1. Worst case,follow  the longest path from the root to a leaf than in the best case whare the number is stored in the root and we do O(1) amount of work.

n number of times as it is linear leading to O(n) in Big notatio.

O(logn) as algorithms that help make sure that the tree is always balanced and therefore has a height that is O(logn).

O(1) amount of work.",21.0,80
23584,23584,27832,b96308b5b954fc4c2086f6faec027fc8299af60a164d99cbdc75a0802d3bb5ac5823699b9e2e5c78a86bbf73886ed3408a16b29a0f7ee6dc90b05a8f2f91fcd5,"When searching for a value v in a vector, the worst case complexity is O(n) and this occurs when the value we are searching for is not in the vector because we would have to traverse through all the values in the vector. If we search n times we will be doing O(n^2) amount of work.

If we create an empty BST and add each number to the tree, the best case height of tree would be O(logn) and it would occur when the number we have to insert to the tree can be placed in the first free space in the tree during the traversal. The worst case height of the tree would be O(n) and it occurs when the insert function has to traverse along the longest path from the root to the leaf in order to insert a number into the tree.

If we have the worst case height after each insertion we would do O(n^2) amount of work because when we have the worst case height the complexity is O(n) and if we had to insert n numbers into the tree this would result in O(n^2) amount of work. If we have the best case height after each insertion we would do O(nlog n) amount of work because when we have the best case height the complexity is O(log n) and if we had to insert n numbers into the tree this would result in O(nlog n) amount of work.

In the worst case we would do O(n^3) amount of work in order to construct a tree and search for different numbers n times. In the best case we would do O(n^2log n) amount of work in order to construct a tree and search for different numbers n times.",37.0,80
23585,23585,27833,8278e2d003c29d98e8cfc7117cefa90b7503054f5b50b162eaded6981387fa2f1b8b8f0ae2fa0d58942ac81f9cf7fda1cd474d106727d602bcd9f2d647883b50,"1. Worst-case  complexity  for searching for a value vv in the vector  work  is 0(n) this occurs when if the value is at the back of the vector or its not in the vector

2 best case  height is log(n+1)-1 when the tree is balanced or a complete BST and worst case height of a tree with n nodes is n-1. because binary search tree is not  balanced in any way or its degenerate or somewhat a linked list or chain,

3.Work woldbe O(n) because the worst case runtime is dependent on the height of the tree which is n-1 when it is skewed trees.

4.work O(logn) because the best case runtime is  not dependent on the height but on the balance  of the tree thus it being  complete binary tree

5. O(n)",22.0,80
23586,23586,27834,27704af10f29b9fd01985b3a533f1213c119ce01a32f451e037e0491eede8c71f38ccb8abe4edd8c056927c76b6bf0c23fb2a88f8cca52e5000b6c906d6692ef,"The worst-case complexity of searching for a value v in the vector is O(1). This occurs when we get an out of bound index which we  would just detect and throw an error.

The worst case height of the tree when calling the insert function to progressively add each number if we create an empty BST will be O(n) because we need to traverse the tree along the longest path from the root to a leaf before inserting. We traverse h nodes before we can perform the insert.

The best case height of the tree when calling the insert function to progressively add each number if we create an empty BST will be O(logn) because we simply add at the root of the tree.

If we have the worst case height it would take O(n). We need to traverse the tree along the longest path from the root to a leaf before inserting. We traverse h nodes before we can perform the insert. The BST is badly formed.

If we have the best case height it would take O(logn). We simply add at the root of the tree. The BST has a good structure.

It would take O(n) work. ",15.0,80
23587,23587,27835,e7c7348f23786b9e18a28e68e5d9ba68b1b693a74a0d58100a7db9e2aeee706b92e8dc4a38b20cb50289290e86666a9bfd49334f05b1673c8db1a8b26f9c9689,"The worst case for searching for an element in a vector is O(n), this occurs when the element we are searching for is not available in the vector.

The best case insertion in BST happens when we are inserting a root node and it has a time complexity of O(1). The worst case occurs when our algorithm needs to traverse the tree along the longest path, from the root to a leaf before inserting and the complexity for this will be O(n).

The amount of work done will have to be proportional to the height of the tree which is O(h)=O(n).

The amount of work will be O(n)

The amount of work will be O(log(n))",11.0,80
23588,23588,27836,0425e17b97b62d847bfbb7a5f37fa98ed826dc582b46528b4a148c459379ead81390caacfd23b1628779d134c7092014f555b05833c612700ef174bd131b6587,"1)
Worst case: v not present in vector
 time complexity O(_n_)

then, for n searches: O(_n_^2)
2)
Best case: O(_log_(_n_)) - This occurs when the numbers create a complete tree.
Worst case: O(n) - This occurs when each node can have only one child. Essentially, the tree is just a list.
3)
The tree has basically become a list, but we must traverse the entire height for each insertion. The complexity is linear O(n), because the sum from i=1 to n of i is a linear function of n.
4)
For the best case, we have O(_log(n_)) complexity for each insertion. I'm really not sure how to find the overall complexity for n insertions of this kind.
5)

Worst Case: O(n)
Best Case: O(_log_(_n_)) ??",19.0,80
23589,23589,27837,bbda30f1bc14304c6e790f22a459366d7df21db83cacfaab7fa97f23e08f9ea6d540b989b2f855a6b10224ce128ef7de8ce703f345305fd513061e429569c02a,"The worst-case complexity of searching for a value _v _in the vector is O(n) and it occurs when searching for either the last value in the vector or a value that is not in the vector. We do a quadratic amount of work if we search _n _times. 

The best-case complexity is O(log_n_) for the height which occurs when the nodes of a tree are arranged in a manner that gives the smallest height. The worst-case complexity is O(_n_) and it occurs when the tree is Degenerate.

If we have the worst case height we do O(_n_) amount of work. The reason for this is that when inserting a values, the values could all be greater or less than the value inserted before thus we keep inserting a the last node at the last level which produces a linear amount of work.

If we have the best case height we do O(log_n_) amount of work. The reason for this is that we would be inserting the values in a manner which fills all the nodes in each level. ",31.0,80
23590,23590,27838,0cbc810c065e1ea82d7b36219a5e375cbce8ff096ba3665c665a2eb1c6f0befa244bcbe226b2da5880d6b84bb7f0100310c96f80f96a3b3863c5c650f01ebc3d,"1. O(n-1): The worst case is when the number is not in the vector. 

2. Best case: O(log(n+1)-1) is when the tree is perfect and the vector is ordered. 

Worst case: O(n-1) is when the tree is degenerate.

3. The program will look for a left or right value and waste time doing so as the tree will only continue downwards and not branch off into any direction. 

4. This is because when the program wants to insert a value on the left, it will have a value and the same for the right. The program will never look in a direction unnecessarily to insert values.  

5. O(n +(n-1)) where n is the number of vertices and n-1 is the number of edges",19.0,80
23591,23591,27839,361f392a37237e8771b2917669c443ba6d28c45bed8ae51a0114890d3cb7412fbd4e346b3dea716ce0116bf5b6bbde572fb9792b9da8a90824dec67c0144ddfd,O(1),0.0,80
23592,23592,27840,b8ff274cc91e39334247b9673eeb1e1ed2acdbcefc990de9bf2b4226b88349ab6bc97343b39be8aded8a6ab21d1bf5dc3045e9f7596480cb1279270e81abbd58,"Part 1: O(n^2) when v is not in the vector all n times we search

Part 2: best-case height = O(logn)
worst-case height = O(n)

Part 3: O(n^2) work is done as the tree is basically like a linked list and pushing to the back of a linked list is of complexity O(n) and we are inserting n times

Part 4:O(nlogn)

Part 5: answered in part 3 & 4",34.0,80
23593,23593,27841,ba67943d9c3f68c2a82bf70197366cb2cce1d21f6696fe648aaf7068ed18399b5899a40e2f0d4a0c53a04c7e84020c544f2b79e8fc23a17b4dca16bd22dbd15b,"Worst case complexity for a value v in vector in O(n). You must search element by element until you find the element, it would be worse if the element is not in the vector or if it's the last element. 

Worst case for insertion for empty BST is  O(n), best case O(logn). You need to start at the root and compare the element to be inserted. When the BST is empty we need to create a node with the new value and insert that node into the space.

O(n) will be the Big-O worst case, which is why the tree will be dgenerate.

Best case we will do O(logn) 

Overall work would be O(nlogn)",22.0,80
23594,23594,27842,4a10096efbe473298c3ffaa590c64747a3f122d6138157d16b669b6d6757b1ee312e247b5d7de57197c1100b67d525e21d2bdf5719b1e5397849be3138642057,"The Worst-Case time complexity is O(n) and it occurs when it has to traverse throughout the entire vector (when v is not in the vector) and it does a _quadratic_ amount of work if we search n times.

The Best-Case height of the tree would be, O(logn), which occurs when there is no traversal needed and it has the smallest height possible. The Worst-case height would be O(n), which occurs when the tree is degenerate.

Inserting all n numbers would require a linear amount of work because in the worst case, the algorithm needs to traverse the tree along the longest path from the root to a leaf (the height) before inserting.

Inserting all numbers in the best-case height would require a logarithmic amount of work because the algorithm would have a minimal traversal.",34.0,80
23595,23595,27843,b9398cac04fafed43567a061ce43d1f6d47a11dc43ed26ca3b7c803119e60ccce5216c5b0d8f2fe86de25d577c66b8be90d26d4412d9f88f080c8ddc823e6bcb,"The worst complexity of the BST is the O(n) and it occurs when a tree is degenerate when it appears to be more and more like a linked list 

The best case height when inserting to create a BST is log2(n+1)-1 and the worst case is n-1 . The best case occurs when we have a proper tree with a maximum of 2 childrens each of which may lead to new children and we have the worst case when the tree becomes degenerate in which case the tree becomes more and more like a linked list

We would do linear amount of work which is much more slower than the exponential amount of work done in the best case. Because when your doing a linear amount of work the code is slow and focuses a lot on traversing than inserting 

We would do an exponential amount of work since it will be O(logn) time complexity which results in a much more complex and faster system 

Exponential amount of work will be done",15.0,80
23596,23596,27844,3d924476d27d7afee3c446be78c3bfa807a26922031bb4eac61f97a7c6f17eb08bf7666e6b4cc961e48bd773db3725b57e5ee0d093b4129e2c89bae53ea3a074,O(n),2.0,80
23597,23597,27845,f83dd55ad9e075a60c5134f9bf47ed3397e5224c478fcc48237d4341af57f9ae0b4893b2d9bfdacde4458f44d6dacdaedccfab297dd76d28c1d773deaaf399e4,"The worst case complexity is O(n) and it occurs for an unsorted array .We do O(n) work if we search n times.

Best-case ->O(Log(n))

Worst-case -> O(n)

Best-case -> O(Log(n))

In both cases we would do O(n) work to construct the tree and search for different numbers.",8.0,80
23598,23598,27846,9b5371bf3d8a67220ea9112f458e092347973d5a590a2ada7f6d386201210567493e4842dd7263535c03e1b4ce797297171327f4cefdbdd79731ace1f4e756bb,"The worst case will be O(n) and this occurs when the search tree is skewed to either side. The amount of work done is n-1.

The best Case is O(1) and the worst case is O(n). for the best case there is space already in the vector and we just insert the number while for the worst case its when there is no space in the vector and we have to reallocate space and also copy the values and delete the previous shell to avoid memory leaks.

we would do O(n) work. Because the tree will be skewed  so we would always have to go to the back of the vector and add the number always.

we would do O(1) work. because we would just add the number to the vector which will be constant time also.

n-1 work.",13.0,80
23599,23599,27847,bb69eebb6b9661fb2659b9201956c2d150fd7601de8f2339f22c3c3c7289abd28101e1b6206a923a6b9fd81f7d0d617c8b5485dd0958ad06769fcf98922a4e97,"We do linear work as we traverse through the whole vector visiting every element till we find the element  and this means O(n).

this happens when we do not know the position of the element or the element is not in the vector.

The worst case for insertion Function in a BST  happens when we have to traverse the longest path on the tree from the root to the leave before inserting O(n). Best Case is when we traverse the shortest path and the height is small and we do O(logn).

Since we do worst case height of O(n) per insertion this means that this will repeat as many times as i will be inserting n terms this will lead to n*n*n... till n^n .

for best case since we do O(logn) this means that even if we do it repeatedly we will still do O(logn).  O(logn)*O(logn)  is still O(logn)  

We will do the O(n)",34.0,80
23600,23600,27848,202c8344f9f859aa64da3cc8ceffb88155f17aa53a21d20d5da4fef5e39546500eff34cbff57a9c00ff1871c748bb37a08181469555e6609e93120b6d7b83edc,"1)O(n)...as we would have to go over multiple values one by one 

best-  O(logn)....when its a balanced tree

worst -O(n)......when it resembles a linked list, being degenerate.

3)we would need to do O(n) amount of work which is directly proportional to the height of the BST.

4)we would need to do O(logn) amount of work as it would be now inversely proprtional to the height.

5)we would need to do O(logn)amount of work",25.0,80
23601,23601,27849,680d91225cab44dd05e534f9e43db41735c5c1d374cc902f5585fb054238f603a599d4ef9dab5fa3942be1f948538952ecb942a66b8672d9ac04303366506ece,"* The worst-case complexity of searching for a value V in the vector is that it is linear and it happens every time the node is visited. 15n

	* If we create an empty BST and progressively add each number to the tree by calling the insert function, the best and worst-case height of the tree (in Big-O) is 0(n2)

	* Assuming that we have the worst case height after each insertion

	* Assuming that we have the best case height after each insertion

	*",0.0,80
23602,23602,27850,4541bddfe14df82661aaba793d25bb038432ba934014876821269e81b4029af8b6064a54828f0509d14ee3f303c32ee014b7221977ad133bace3b01a694e694c,"The worst case complexity of searching for a value v in the vector is O(n) this occur when our value is at the back of the vector or n-th position and we have to do n-comparisons .We do n size amount of work as the size would be n.

The worst case height is when we have a degenerate tree (when we insert at the height furthest from the root) hence when the amount of work is linear O(n). This is because we would have to traverse all the way down the tree until we are at a height thats the most far from our root.

If we had best case we would do O(log n) amount of work because we would have a balanced tree/

In total we would have O(n) amount of work done.",19.0,80
23603,23603,27851,d34efe98a2513ac08acc6faef18dfc38310a4938c3e2400c3ec9b606c14e0455c45534357347e63004ac9d2c3c1e1d7805afa99ff5f4d271c3dc0f7c2153d7d4,"* The worst-case of searching for a value v is O(n) because the vector is not sorted.This worst case may happen when when the value v is at the end or not in the vector. If we search n times we would have to do linear work
	* The best-case height of the tree would be log base 2(number of node + 1) - 1. This occurs when the BST is a perfect tree. The Worst-Case height would be number of nodes - 1, (n-1). This occurs when the BST is degenerate
	* We would do O(n-1) because the height of the worst-case height is h = n -1. Which turns out to be O(n)
	* We would do O(logn), by Mathematical Induction
	*  ",19.0,80
23604,23604,27852,ba47d803e26988b75d891eb0e76061b355587a9834711cd75248db6b2b1c6cccc9c5cadcd161a1c0dfe6bd2d1a8b1014e37dd57461b73e39268808ede1fe4392,"The worst case has to be O(n)  since the elements are unsorted you have to search element by element until the element you want is found ,the element can be in the first position, last or in between. the worst case the arises when the element is in the last position or not even in the vector.

since a BST doesn't just store in any order. the best case of height would be O(log n) where each node would be completely full since each node holds 2 values and it becomes a balanced binary search tree. The worst case would be adding to an unbalanced binary tree O(n) where it just unevenly continues to grow.

O(n),IN the worst case, we need to traverse the longest path from the root before inserting. So we traverse h nodes before we can insert .SO the amount of work done now will be proportional to the height of the tree. So now its degenerate and basically becomes a linked list

O(log n),In the best case its a balanced tree with shorter height and takes less time to traverse from the root to the balanced leaves, making it easier to detect the place of insertion.

O(n) for both.",26.0,80
23605,23605,27853,611e62668a69a44120f4c094b741411c87184ef32e42939a38515edfc5b988a4050fb89730be7833c2365cfa3031ef1f4593e6c36d340bca6106a175c159094f,"the worst would be O(n) in big O . this would happen if the number you are searching for is not in the vector and you have to do n comparisons if there are n items . if you search n times then you do a linear amount of work that depends on the value of n 

let n be the number of nodes in the tree , the best case would be if we have the minimum height that we can have for a tree of n nodes which is O(log n) in big O this case will occur if the values we are given construct a perfect tree  when we use the basic insert algorithm  .In the worst case the height will be n-1 which is O(n) in big O . this will happen if the tree is degenerate eg. when the nodes we are adding are the next maximum value or minimum value so we keep on adding on one side of the tree .  

we would do a linear amount of work  . this is because in the worst case the height of the tree is linear and adding will need you to traverse the entire height of the tree before doing the insertion so you will do a linear amount of work O(n) 

if you have the best case height then you will do O(log n ) amount of work . this is because the amount of work is dependent on the height of the tree and since the tree will be O(log n) in height then also insertions will be like that

in the first case you do O(n) amount of work . in the second case (best case) you do O(log n ) amount of work ",22.0,80
23606,23606,27854,cd3aa55745b79deafb0802ba9ebe30e68fbd1c089c006450727570d34769934d2b1c5a098a7d318146af21d8981711dce0bb006308d97edfcf9a088eb56e4532,"The worst-case complexity for searching for v in a vector would be linear, O(n), and this is when v is stored in the last position in the vector. And we would do a linear amount of work if we were to search n times.

The best would be logarithmic O(logh) and this occurs when we're inserting the value at the root of the tree (Depth zero). The worst case would be linear, O(h), and occurs when we're inserting values at the leaves of a tree that have a depth of one or greater.

In the worst case, a linear amount of work, O(n-1) = O(n) will be done in order to insert a value in the BST. I came to this conclusion as each node either in the left subtree or right subtree will need to be visited at least once.

In the best case, a logarithmic amount of work, O(log(n+1) - 1) = O(logn) will be done in order to insert the value into the BST. I came to this conclusion as there will be no need to traverse through the list as the value is added directly to the root and it will have a depth of 1 (whether this is on the left or right side of the root).

The total amount of work required to construct and search the tree would be linear.",17.0,80
23607,23607,27855,8ccaa62cbbe76ea20aad42f0abeb4aea6b057f35352db9aef1c4c8bb791949070df63d7ca3789507be754a64de8d3383c759c83cb767d9e10e045b387bce8a09,"the worst-case complexity of searching for a value v in a vector is O(n).

the best case height is O(log n). it happens when each lookup ,search , insertion or deletion takes time proportional to the log of the number of items sored in that tree. however the worst case is O(n). and occurs when the tree isn't balanced .but mainly it happens when you keep adding numbers that are always bigger the the previous number or numbers lower than the parent.",14.0,80
23608,23608,27856,a50f1f05303eb676c08e683fb412c46779741d1e408ab7173f3f3a12df3f04196b4fd7b7add1fd647d8efd191c43d6971e5cae7611afd814fbea2a7330f3ce46,"The worst case is O(n), this happens when value v is found on the last position thus we have to do n times work.

The worst case height of the tree is when the binary tree is chain of nodes in a straight line which results in a a O(n) height. The best case height is O(log(n)), this occurs when the tree is balanced.

O(n) of work will have to be done as the value has to be inserted on the last position thus an n times iteration will have to be done.

Work of log(n) will have to be done as the tree is balanced, so iterating to the certain value takes time complexity of O(log(n))

In total the time complexity for the first case and second case will be O(h) h for the height of the tree, O(n) work will have to be done.

 ",27.0,80
23609,23609,27857,1848cd7f48fa46779deb7b0a0eb59a877c6d421045e3cfd89b389428863439dfcd907f1dfee5210fe7c99e6e24483c87f1eba9c0df60ab0e72ef97072d4bd765,"The worst case complexity of searching is O(logn) or O(n) depending on the structure of the tree. and this occurs when the number is not in the tree and the path we follow corresponds to the longest path from the root to a leaf.

Best case height ->  log2(n+1)-1

worst case height -> n-1

In the worst case,our algorithm needs to traverse the tree along the longest path fromthe root to a leaf before inserting,and in this case we traverse h nodes before we perform insert.

for best case it will be O(1) amount of work, because in the best case the search key(x) is the value stored in the root 

O(n) total work",3.0,80
23610,23610,27858,a58cc7a946eda613e1ba5b3286e27532a7ed6202aac74240dace327e45260834a089fa12052292c507fb1aec6f37cb1855be0992f9b6be6541ab2eebe4c77364,"the worst time complexity would O(n), it can occurs when the value we are searching for is not there. the best case for height is O(logn), it occurs when the binary tree is perfect. the worst case for height is O(n), and occurs when the each node in the tree has a single child or the tree is degenerate. in the worst case for insertion O(n) work would be done which is a linear amount of work. in the best case for insertion O(logn) work would be done. O(logn) + O(n) work will be done, which is logarithmic  ",27.0,80
23611,23611,27859,79e7d7f9dd31af42dafc3f30ed17b2ec3bfb7c371aeb90fda49a78ac5ff634413c5502ef51e48fca99485ebc6751e35a6357de07c8799c082943fd8aca0f76df,"If value v is the last element in the vector and do linear amount of work traversing, and its complexity would be O(n).

The worst case height is O(n), that when we have to insert the number to the leaf of the height.

The best case height is O(logn) when we are inserting the root or closest to the root node.",8.0,80
23612,23612,27860,c7fddd77b6fed9bc15d19de2718acf9bd47e63c47fabc90953d259ee95b77d6203c59c32fab4eab8591fe4a7373a9aafae0952036c94bc9ebef7955717c99e00,"The worst case of searching for an element in a vector is O(n) This will occur when we have to go through all the elements to reach v. we have to search n times.

 The worst case height for inserting an element in a BST is O(n) it occurs when all the node have one child.

The best case height for inserting an element in a BST is O(n-1)  occur when most nodes have 2 children unless it's a leaf.",11.0,80
23613,23613,27861,91d41b2f32ab492a059463744b0e5f6cd6e21e57c981adbf25309713090c378a42bc574b38c9745bce66a49918299962c618772aa540a5c09c38c4d73e58815f,"the worst case for searching an element in a vector is linear denoted by O(n),it mostly occurs when the element we are searching for is not available in a vector.

the best case insertion in BST occurs when we are inserting a root node and it has a time complexity of O(1).

the worst case occurs when our algorithm needs to transverse the tree along its longest path, from the root to a leaf before inserting and the complexity of this will O(n)

the amount of work is propotional to height of the tree which is O(h)=O(n).

 where the amount of work will be O(n) 

the amount of work will be O(log(n))",12.0,80
23614,23614,27862,910daf6bb90bfaca5b8329327dbb6876d9a383514e01fe819f79abb1a27019ac7b7555a07d09a61e93831fa5c489e19d607608ea54797f25aad8bd641ed60e55,"The worst-case for a vector is O(n).  It occurs when there is no more extra space so the vector has to reallocate memory, copy all the items across, and then free old memory. We do a linear amount of work.

Insertion in a binary tree has a worst case of O(n) as we have to traverse through all elements and insert the number at the end. It has a best case of O(h) which is also the general time complexity, with h being the height of the tree.

O(n). Since the worst-case height for a BST is h = n-1 and we have to do n traversals because we do not include the root as one of the traversals.

O(h). We do the same amount of work as the height of the tree, and since h = log2(n+1)-1, we get the shortest height of the tree and therefore a lower amount of work to do.

O(n).",11.0,80
23615,23615,27863,a1c2b05bc77a92969182ba646d8a653eca3913d57c538fdf187c677d2b0c51d076b45d82612615ca734696b4dfc388e9684934287cf1a84a26d20f8be5134c6a,"The worst case in vector happens when you are searching for an element that is not available to the vector and the complexity is O(n).

The best case insertion in a BST occurs when we are inserting the root node and the complexity is going to be O(1). The worst case happens when our algorithm needs to traverse the tree along the longest path, from the root to a leaf before inserting and the complexity is O(n).

The amount of work done will have to be proportional to the height of the tree which is O(h).

The amount of work will be O(n)

The amount of work will be O(log(n))",6.0,80
23616,23616,27864,0fd0096c1497543ca0003b9e3ba007221cbda2328585a2f2260277e1c7038bb2ae7ad23e03908936421523651b3b5785ece380b977ac663ea4a02a050d012617,"1. the worst case for searching for a value v in a vector,

in the worst case, let's say the value v is at the back of the vector we need to traverse until the last item which takes us the linear amount of time O(n) which is the worst..In the best case, it only takes a constant amount of time O(1)

2.the best case for insertion occurs when all the nodes are in the roots left subtree, this results in a constant amount of time.

3. the worst performance of such action will be O(log2n) which is usually resulting in O(n)

4. In the best case it just takes a constant amount of time, when we look from the level order traversal, it can just go 1 depth before going to the next taking the constant amount of time

the total amount of work creating a binary tree, its O(n-1) in the worst case which is just O(n), then in the best case it is log base 2(n+)",7.0,80
23617,23617,27865,ef46ab4c4baea61ce39205f3f8b9ba2f08ab48270b777e4f042aafc6410a82e9cddc1dd033e57ccba5e191584e8763e9b5c270df38cd4daee3f921d844f6b7a8,"O(n)

-When you have to search the whole tree.

- linear work

Best-Case  = O(logn)

  -It occurs 

Worst-Case = O(n)

-The more the number of branches it increases the linear it gets.

O(n^2)

-

O(logn)

-

Linear Work",15.0,80
23618,23618,27866,eaeebfd434a43156f3712848577d3a5da6499b6e1784e16a24ab5777985e6e2eed30ffc0a110ed246a9badfba660cd9a812c4ed7d173d1a29f7e115ce4ad58b1,"1.

O(n) is the worst case since we will traverse through the tree to find the value you are looking for and you might end up searching the entire tree if the does not contain that Node.

2.

the best-case for the insert function in a BST is O(logn) this means that we did not traverse the list we just found and empty space at the start and inserted our value in there.

The worst-case is O(n) because we will have to traverse the whole entire tree to find an empty space where we will enter our node in that tree making it linear complexity.

3.Since worst case height it is n-1 but for Big-O it is O(n) then doing this repeatedly we will have a quadratic equation since it will be n*n complexity for that insertion

4.Since best case it is O(logn) this means that the insertion is fast this means that doing this repeatedly will still be O(logn) complexity 

5. When we cross O(n) with O(logn) this will arise with O(n) complexity since it will do more work in linear to construct the tree by visit each node.",20.0,80
23619,23619,27867,df7c40110480895f223a4ad7a154ce6d14071ffef29c798823d9a68e307bd1447fc569c4b8f3e4353216405210fd26445fb7aeea3ad07da82c16c8e5aa5ac0cd,"(I) WORST-CASE  FOR SEARCHING IN A VECTOR IS O(n). This occurs when the number v, we are searching for is at the end of the vector.

(II) A)BEST CASE OF HEIGHT OF A BST is log2(n+1) - 1  which is O(logn). This  occurs when

     B) WORST CASE HEIGHT OF A  BST is n-1  which is O(n) . This occurs when each node has exactly one child and the tree is basically a vector.

(iii) Inserting n numbers would be O(n) because the tree is now like a vector since each node will have at most 1 child and the data structure becomes linear

iv) Inserting n numbers would be O(logn) because the tree has subtrees now.

v)",26.0,80
23620,23620,27868,b1b3e86f0d270a61f8fd878f224a3849ed613dcb005f40bfd930beec1496e89a0e58f28b9b719a548b167e0db0c44afd5aae82094d2f118c0287dc3bf2b65cac,"The worst case complexity for searching a value v in a vector is O(n) ,when v is at the last postition or not even in the vector because we have to traverse the whole vector which will repeat n times.

The best case for the insertion function is O(log n) .which is O(log h).when the tree is perfect.

The worst case is O(n),when the value we are inserting is either lesser/greater than all other value or its the last value given  because we have to traverse through all the elements in order to insert it into a tree.Therefore in general ,the complexity is O(h) 

the total work is O(logn) ",15.0,80
23621,23621,27869,c6130d795cb6021c7594812b73d6b159744ce452f7f194d2a8acfd0f6313f2562bada8d95c7d6c5736c9d1d528be9655da041882fe8c7474badb6562243ddc74,"1. The worst case of searching for a value is O(n) when the value is last in the vector or not there at all, we'll have to do n comparisons and most work will be done.

2. The best case of the height of the tree will be h = log2(n + 1) -1 when the tree is a full tree where all internal nodes have the maximum number of children. The worst-case height of the tree will be h = O(n - 1) when the tree is a degenerate tree where all internal nodes have one child (including the root).

3. The work done in the worst case height is O(n) as we will create a new node every single time we insert. 

4. The work done in the best case height is O(log2n) when the tree is full and we can add two values before creating any new nodes.

5. In the best case O(logn) work will be done, in the worst-case O(n2) work will be done.",25.0,80
23622,23622,27870,db0698cd03866d48da0c9cab1c327e767c6fb2c70ab318867db7094af47e41c16fc1528b63425d8d7a1a4e5cc071eef840fd0e4c5113866d0139015edb52f238,"Worst case complexity: 2h

Best case height: log(n+1)-1

worst case height: 2h",2.0,80
23623,23623,27871,c2c29b17660ccaffde93650bbaabbeca722766be9c7f4c24079c9b3711df082352b0623847e9af19ff96cf4f2d45d0bd1cd360dd8fa3d9a37f5041dcc804b8b1,The worst case is O(n). The worst case occurs when the value we are searching for appears at the end of the vector. We would have to transverse through the vector from the first element up until we reach the last element.,3.0,80
23624,23624,27872,ffb312171739bda8140d790d7e76d39d8cb251ebc0d6e983413e101fe068405632084409e60fc3615fbb0328c8c628ab617f395e064e10a0893ff352b3482def,"1) O(n) and O(n2) if searched for n times

2)The best case height would be O(logn) which happens when the current height is always filled with nodes before the height increases. The worst case is when each insertion requires a full height traversal which would be O(n).

3)Each insertion would require a (n-1) amount of work which is a linear function making the complexity O(n).

4)As the height of the tree increases the amount of work needed to be done would decrease exponentially making it O(logn).

5)In the worst case we do O(n2) and in the best case O(nlogn)",28.0,80
23625,23625,27873,2e87414379efcd8b6abefa082fd766ea6bbd6a7c49327da9b14527216de652d464a74ad3edb281cf63c53ec51b9a87c17ffe7ae230ea816e625650e59f9bd068,"Worst case occurs when the item we are searching for is at the end of the vector in which we would have to traverse to the end of our vector resulting in linear work O(n) and also when the item we are searching for is not in the vector which results in O(n).

Best case would be O(log n) which occurs when we traverse the shortest path and the height is short. Worst for the insertion function occurs when we have to traverse using the longest path in the tree from the root to the leaf before finally inserting in O(n) linear work.

Since we have the worst case of O(n) per insertion this would mean that this will repeat as long as we are using the insertion function in the case of n items it will result in n*n numerously until the insertion of n items is done doing work of O(n^n)

Since we have the best case of O(log n) per insertion this would mean that this will repeat as long as we are using  insertion function  in the case of n items it will result in log n * log n numerously untill the insertion of n items is done doing work of O(log n).

linear work will be done O(n).",12.0,80
23626,23626,27874,ac47e3ceebccb755b1987f028345ba571e2bbf0bc4ebc355e11ab520e9f3ffd71073789246ed0c633ccffb81e8b77e299c90427fa5f8a55f41455cee47d290e1,"i) The worst-case complexity will be O(n) because we have to traverse in each and every node, meaning we have to traverse all elements to check for v. When the tree is either a perfect binary tree or not. We do O(n) work.

ii) The best-case would be O(log n) and the  worst-case would be O(n-1), this cases occurs when we have either a perfect binary search tree or not . 

iii) It would do O(n) it is because we have to traverse all the elements and check where we can insert our element.

iv) It would be O(n) time, because we have o traverse through the tree.

v)We would do O(n).",19.0,80
23627,23627,27875,0dd6ddfbe50025d9a72df696362b0bdfb49434124c6d6642bcd0c15ba9544de38a86488e790b653cf1d9ab0bbd206e27a92d4ffa059eb91de07bea325c7f7613,"1. The worst-case complexity done is O(n). This occurs when the value v is not in the vector The amount of work done will be proportional to the size of the vector.

2. In the best-case, the height of the tree is O(log n), and this occurs when we start at the root of the tree and start comparing the value to be inserted to the value of the current node (root). In the worst-case, the height of the is O(n), and this occurs when the algorithm needs to transverse the tree the longest path from the root to the leaf before inserting.

3. We would have O(n) work done. This is because we would have to traverse h (height) nodes before we can perform the insert function.

4. We would have done O(log n) work done. Each number is inserted into an empty space in the tree.

5. For best case, it's O(1) work done, and for worst case it's O(log n) or O(n) work done.",27.0,80
23628,23628,27876,bc7ce8dcf81474ef89d407bc167ddbdc0ae686813582e07ef0e124f6d6fe081339ab3b2bb05c54a356b901c5c208933d91dbaf731894bf50cc25eab5e102a8e6,"1)The worst case when when searching though a vector is when the number isn't there,so you had to compare the search value to every single number in the vector thus you would have to do n comparisons because there are n numbers.The amount of work is linear or O(n).

2)In the worst case,we need to traverse the tree along the longest path from the root to a leaf before inserting.Here we traverse n nodes before performing the insert.Thus the amount of work done will be proportional to the height of the tree.In the worst case the height of the tree will be n-1 and in Big O notation it is O(n).

In the best case,the height of the tree will be log2(n+1)-1 and in Big O notation it is O(logn)

3)In the worst case,we need to traverse the tree along the longest path from the root to a leaf before inserting.Here we traverse n nodes before performing the insert.The amount of work that needs to be done will depend on the structure of of tree.Thus the amount of work done will be proportional to the height of the tree.In the worst case the height of the tree will be n-1 and in Big O notation it is O(n).

In the best case,the height of the tree will be log2(n+1)-1 and in Big O notation it is O(logn)

4)In the best case,the height of the tree will be log2(n+1)-1 and in Big O notation it is O(logn)

5)insertion will either be log2(n+1)-1 or n-1,and for search it will either be O(1) or O(n),the addition of this will give the total work done",22.0,80
23629,23629,27877,3535a43df3300af7e5c3e95a4369804ca852c0470f1fe060d2a246291726064d9eeb362ff2318c56c2b2c1abd2d650cb0578f3dab1f0c9bef113f35bec7220b3,"1. O(_n_), we do _n_ amount of work

2. The best-case occurs when a node already has one child and the value fills the space of the other child, O(log(n))

Worst case occurs when you're increasing the height to its maximum to fit that many nodes, O(n)

3. O(n), the worst case takes n amount of work each time, so it is just determined by the sum, it is still a linear function.

4.  O(n), It is the sum of the logarithmic function, which is a linear function.

5. O(n)",17.0,80
23630,23630,27878,7784c26ab2d9766ae819dd1da89317a98dc39ebd7976e740ed6ab84978a76aaebcecee3ccbfd4bc08a3df68e244abf9916ece7c5f547ed6b7e35d519a43c7259,"the worst case in searching a vector is 0(n) and this occurs when the number we are looking for is at the end of the vector or is not there at all.

in a BST the worst case is O(n) and the best case is 0(logn), these are determined/occur according to the height of the tree, if we have to traverse the entire height of the tree before inserting a new node then it is the worst case 0(n) but if there is an opening in a node at a lower level then we can the best case",17.0,80
23631,23631,27879,a09890d1b445c23fabb578b3483b14013fc02062f1b3aa1b4c6df4bdeb9b3b91a9c90e4c472aa2da65ecaa5b831c0625b91b1940398021966ddfe90195c5216f,"It would be O(n), that is when the value that we are looking for does not exist in the vector, therefore you would have to iterate n times.

The best case would be the O(1) since we are inserting in an empty tree and the worst case would be O(n-1)  since we would have to traverse the longest path of the tree.

 We would have to do O(n-1) work since we will be traversing the longest path which is to the leaf of a de-generate tree each time we insert a number.

We would be doing O(log(n)) work since it means we will be having a perfect tree, meaning we will be filling every node in a level before going to the lower level.

The best case would be the O(log(n)) and the worst case would be O(n-1).",11.0,80
23632,23632,27880,666d09a4d8260961dbb488b896e8680fe46f9012a9bfa6adbe518edfaed179e00538132a0e660a988cc51e3f8b8695b7b78d6679f0a1e7d0f26361ce20a96384,"The worst-case complexity of searching for a value v is O(n) and this occurs when the binary tree's structure is degenerate (similar to a linked list). If we search for the value v, n times, we do O(n^2) a quadratic amount of work.

For inserting into a BST progressively:

The best case height is O(logn), this occurs when after all the insertions, the tree is a complete binary search tree.

The worst case height is O(n), this occurs when the resulting tree is a degenerate binary search tree (like a linked list).

 The worst case height will result in a O(n^2) amount of work to insert n numbers.

We know that to insert a number that we must do n comparisons, and is repeated 

1+2+3+....+n times which (using mathematical induction) we get A summation n(n+1)/2

which is quadratic and hence O(n^2).

The best case height will result in a O(logn) amount of work to insert n numbers.

We know this because inserting a single number results in O(logn) amount of work and this is repeated n times, hence we would get O(nlogn) but in Big-O notation we are more concerned with the function that controls the shape of the complexity thus O(logn)

O(n^2) for the worst case and O(logn) for the best case.",40.0,80
23633,23633,27881,5f92eb6a07aed01e019162660614241903fd30335dc49cd736d18a97a0b8e4d8d8eaa7a31ce7cb8ad65e895e5a8906b98d2e7635d42d019af72333c76c35da1a,"The worst-case complexity when searching for a value in a random ordered vector is O(n). This occurs when the value we are searching for is not in the vector or it is the last element of the vector. The work we do when searching n times is O(n^2).

The best-case height of the tree is log(n+1)-1 and the worst-case height of the tree is n-1. The best-case occurs when the tree is a perfect tree. The worst-case occurs when the tree is a degenerate.

The work done would be O(n). The tree would become a degenerate and this will mean that for every insertion, we would iterate through n nodes.

The work done would be O(n/2). Since it is the best-case height, the work would be cut in half because compared to the insertions done, the nodes we insert from will be nearer to the root.  

We would do O(n) work.",17.0,80
23634,23634,27882,4428555ef8072ef23d17db65e798fc29286c3f011a1099d994917d7424cc31d5f0d195105018e3c14dd5ec04f91fc4ea0c088a5e61680d4692faa4d313c225c0,"1. The worst-case complexity will be O(n), it occurs when the value is on the end of the list and linear work

2. The best-case will be O(1) and the occurs if there's only one value in the tree, the worst-case will be O(logn) or O(n) since we will have to traverse n when the tree has n nodes.

3. The worse case will be O(n), this will occur when the tree is the same a linked list.

4. O(1) would be the best case and occurs when theres only one value on the tree.

5. Best-case will be O(1) and the worst case would be O(logn) or O(n). ",12.0,80
23635,23635,27883,a1ff29383b61a8e73b1404e2bd227756b44c2ed8377f0648b22e37a9c8be547abfc96a6062f35278e29ec0330211f9dcf47ebc8346d639bb224d15bc6bf39d59,"The worst case complexity occurs when v is at the end of the vector as n-1 searches have to occur resulting in a linear complexity O(n).

The worst case height after insertion would be quadratic complexity as all insertion would have to start at the root node each time to proceed to the requisite leaf node. This means linear searching must be done with each insertion resulting in quadratic searches.

Best case height after insertion would be logarithmic complexity as all insertion would start from the root node but would only have to traverse to the requisite leaf node in a number that accords to the height. Thus resulting in logarithmic searches.

The former would be O(n^3) whilst the latter would be O(nlogn).  ",23.0,80
23636,23636,27884,52f183a2edd50f67bf9165da2ed344e6b1dbef117bcc8a87e8fdd544cade3eccfad6434b2157d981bfdc96048e52a8b1696fb090b734b452d891d2f61d866105,"1.The worst-case time complexity is O(n).This occurs when the value is the last one in the vector(the nth value) or if it does not appear in the vector at all.We do most work as we will have to do n-comparisons.

2.The best-case height of the tree will be h=log2(n+1)-1 when all internal nodes have reached their maximum capacity of children and our tree is full.

	* Worst-case height will be h=O(n-1) where the tree is a degenerate tree and all internal nodes including the  root has only one child.

3.Work done on the worst-case height will be O(n) since a new node is created  every time we make an insertion.

4.Work done on the best-case will be O(log2n) when the tree is full and  we can add 2 values before any new nodes are created.

5.Work done in the best-case will be O(log2n) and O(n2) in the worst-case.",28.0,80
23637,23637,27885,0bce68d12d4bb423184167950cec8450c2529233502545e57429beb9cfc6f093c786ba9febad285f8197b7bbc233a3b506a933f196c9852e05b5416cd8c68c8e,"1. Searching for a value v

Searching for a value in a vector / linear search has O(n) complexity the worst case occurs when item is not in the vector and we search through all n items in the vector.

2.

n the worst case, our algorithm needs to traverse the tree along the longest path from the root to a leaf before inserting and this is O(n). In this case, we traverse h nodes before we can perform the insert. So in the worst case, the amount of work done is proportional to the height of the tree. this means that the amount of work we need to do will depend on the structure of the tree,in the worst case, the amount of work done is proportional to the height of the tree. In the best case, the height of the tree will O(logn).

3.O(n)

4.O(logn)",21.0,80
23638,23638,27886,9082e5ab0ae09b23b5e0275a763493886db0b7f721520ca423ce3577e6b6ec09537f5d0b22aac121f7604a542a413dd81640198a15212f5aa5403c721b42c11e,"In the worst case it would be O(n) since in the worst case the data would be stretched out hence we would need to do traverse through each element atleast once, if we do a search n times then the time complexity is the sum up of all the searches which is still linear O(n).

The worst case would have O(n) and The best case height would have O(logn), for the worst case this is because the tree would be stretched thus inserting to the last node would require every node to be visited atleast once, for the best case since insertion since  takes big-o of height, if the height is logarithmic we would have O(logn) since the tree would be ordered and hence some nodes wont be even visited once.

We would do O(n) for insertion since inserting to the leaf would require us to traverse n-1 times thus resulting in a linear complexity.

We would do O(logn), since we have the best height everytime then we wont need to traverse to most if not all nodes whenever we insert to the tree and we wont be traversing to the same location everytime thus meaning it wont be O(1).",14.0,80
23639,23639,27887,9b13f2d70694a174cc296db2532a81cde5f414c86e87388e32c45d14a1b85a47b70cc54fdcb2f6455012d569323883da99f34aab409453d8e838e0ae2bf41aff,"O(n) and it occurs when we have large amounts of data and the access and search time associated become too expensive and that is when we are searching for vectors or linked lists. if there are 1 million items then a linear search would perform 1 million comparisons.

in the best case the height will be log2(n+1)-1 and in the worst case it will be n-1.in the worst case, the algorithm will need to traverse the tree along the longest path from the root  to a leaf before inserting.

with the best case, if the value to be inserted is less than the current node's value, then we recursively insert the value in the subtree. when we find an empty space in the tree, then we create a node with the new value and insert that node into the space.

worst case after each insertion the height will be n-1 and with the shape of the function it will be O(logn) or O(n). The tree is degenerate and has become a linked list.

in the best case the height will be log2(n+1)-1 and we do O(1) work. The search key is(x) is the value stored in the root.

so the total work we need to do in n times is log2(n+1)-1<=h<=n-1 .",3.0,80
23640,23640,27888,fd8a875c5398ac6c36a731d0d10a006399599403b9ee2f4994b116a012c4bd603697ca87421ae17a8eaaa96913f3870bb71641db61fda611c4a27d1aa224e5e0,If the elements are not sorted the the time complexity will be O(n) and this also applies for worst case because would have to traverse the entire vector one by one and if v is at the end then it'll take O(n) as the worst case time complexity,3.0,80
23641,23641,27889,3824a0678a0ee80961c81764186a1496645536aadc7127ac81665ef8825202d12ca91cc1dddb49cb3545dd95e3ab23ddf164ccd399cf03acc33959144061677d,"* When searching in a vector the worst-case complexity is when the value v is not in the vector and we still go through every position in the vector to find it, this has a time complexity of O(n) and we do 0(n) amount of work
	* The best case for a BST for its height is LOG2(N+1)-1 (SUB-SCRIPT 2) OR OLOG(N) and this occurs when the tree is branched out. The Worst case for a BST  height is N-1 OR O(N) THIS OCCURS WHEN THE LIST IS DEGENERATE OR HAS A LINKED LIST LIKE STRUCTURE
	* The amount of work done by the worst case of a  height of a tree will be O(n^2), because this form will be require to find the leaf every time in order to insert a new value.
	* The amount of work that will be done by the best case of a tree will be 0(log(n)) because the tree is balanced.",21.0,80
23642,23642,27890,7b72a3cfa202855ca92e0c8594b6a4108a2a7362ff4fcc28ef2228b8b36b337e628baa0458dcafc8f661dd4fe06b22f28bb9bd3468afca5d2aaffb32f04408e7,The worst case complexity when searching for a value in a vector is O(n) .That when the value v is at the end of a vector.The is (n_^2) work done  if we search n times._  The best-case of the tree would be  0(log,9.0,80
23643,23643,27891,0a640b06ce1d454be947795a6308fcfcc73f66b49b60199788f434bf91f3e08719c4b7dee42514e49b76fea543dcbe6b2a18d9de0cfa87cc5f82c989cd2f76ff,"* Worst-case complexity for searching for a value is O(n), this occurs when v is at the very back of the vector or when it's not in the vector at all. if we do the search n times then we are doing quadratic work, O(n^2).

*Best case height is h=n-1 this occurs when we have a complete BST, ",13.0,80
23644,23644,27892,414c0211baa0f7785fed3a2ae8d654438eeb57e32a72d726d41fb80a14e5bb82594bc148b341e170426f496146bb1f57723f178ed8b08e3a2a9402960a0201df,"•Worst case for searching in a vector: O(n). This occurs if the value is not in the vector, thus we search through all the elements, only to find that it's not there. This means we do a linear amount of work/ run the loop ""n"" times.

•The best case height for a BST: O(log(n)). This is when the height=log(n+1) and it occurs when we first insert a number into the empty BST, then we can just create the node and set it as the root. The worst case height for a BST: O(n). This is when the height= n-1, and thus when we insert a value into the BST, we have to traverse through the whole height of the tree(longest path from root to a leaf). 

•We would have O(n), if we have the worst case height (h=n-1) after every insertion. That is the maximum height from n nodes.

•We would have O(logn), with best case height after each insertion. The height in the best case=log(n+1)-1

•In the best case: O(log n). This is when you have a perfect BST. 

In the worst case: O(n), this is in the case when the BST is either skewed to the left/to the right, and acts as a linked list. Inserting each item will require be of linear complexity, since we have to traverse through all the items each time. Searching for an item, will also turn into a linear search over all the items.",15.0,80
23645,23645,27893,c9e41b3531b2998cc20c6fd6bfb72f12a3f05d93d2460de290dbb99541ee03315e8e22e2be5a7b30f37df60e1adfc4e78e74654e1dc07e433825a90adb57acf0,"1. The worst case complexity is O(n). This can happen when the value is in a leaf node or if the value does not exist in the binary tree.

The worst case height is O(n) and the best case height is O(logn)",11.0,80
23646,23646,27894,97b7f5ff46c1c824381cef505f20511747560e70b8b1e616642dc4fcce22c546867f43d01ab15335e8a2a57b9d3fba9ae8276c6347ded2ad2c8d88ebec13760a,"The worst-case complexity is O(n) and this occurs when the value v is not in the vector.

The best-case height of the BST when adding a number to the tree is O(logn), and the worst is O(n).

Work that is proportional to the height of the tree, which would be O(n) because the algorithm needs to traverse the tree along the height before inserting.

The amount of work done to insert all n numbers will be O(n)",17.0,80
23647,23647,27895,d02795a14cf200c3a4e42da8fa77ef31727a409d797dd41af60f44aca9829ba9ae25ee3cf59e3f4d5058d031c70d2bc7493c09427e32e68aa4eb4dcf5128f375,"the worst case complexity of the search would be O(n) and this may occur if the value being searched for is not in the vector.

if we insert numbers in a empty BST, the best case height of the tree will occur if each node in the tree has exactly two or zero children, and the time complexity will be O(logn). the worst case height will occur if the each node has exactly one child and the time complexity will be O(n).",19.0,80
23648,23648,27896,e394539baa7fd0006de5096759d1db9943b0b453927105fc99e564a56547ecb01587d2f0348be0224bd521c0377577b713f00c14b60183a6d229e89193dcb643,O(n)-when we have n elements in the vector we have to transverse through all the elements until we reach element v.,2.0,80
23649,23649,27897,16751d82a0250cf90230a736276250ecd4342c2e9097f12ebacee397740771d03e925ee189c3aaacf702dbec6f3610c7e13e7ed44667c2823433286e585becf2,"the worse time complexity occurs when the value we looking for is right at the end of the vector after a traversal this occurs in linenar time.

the best case height occurs when each node has 2 children or no children. the worst case height occurs when each node hass one child.

we would have to traverse through each node in order to insert the next value. this process will repeat itself with every new value added. this will occur in linear time. with every new insertion the height of the tree increases or the number of nodes increase making the next traversal longer

because the height is greatly reduces in the best case the number of traversals needed to insert the next value is also decreased the amount of work done will also be linear because with every new insertion the height of the the tree increases or the number of nodes increase making the next traversal longer

O(n+1)",23.0,80
23650,23650,27898,504915003c176d83e297a3b02982f36cd4f9eb065693233829d19ac7452cb2f35bee19b20786ce2df4001c615d9cc356818ba8a54f2475a1e5225bc243c46b0d,"1)O(1),accessing n is O(1), depending on neither the size of the vector, nor the element being accessed.

2)Worst case[O(n)] and best case are O(1).For both these cases, we have to loop over all the elements, so the runtime complexity of insert function is linear in the size of the tree;we have to copy a million things;just to add to add one.

-Taking the worst case; O(n),assuming that that happens every time is both incorrect(it can't happen every time) and too pessimistic.

3)O(n).In a tree,the worst case runtime is dependent on the height of the tree.Since a binary search tree is not guaranteed to be balanced in any way, the worst case height of a tree with n nodes is (n-1).Therefore, the worst case run time for insert is O(n).

4)The inequality of calculation of height indicates that, for a given height h, there is a range of node quantities that will have h as a minimum height in common.So all binary trees containing n nodes will have height of at least log(n).So thus the best case is O(logn)

5)Time complexity of all BST Operations = O(h); whereby h stands for height.",12.0,80
23651,23651,27899,50ac02db01dc47f0f24bb2a0e8bc1bebe3aac1ecfe652f1c87b260f45da4def0a267392e043e67a0b0f3a39374188322db34615d5257a196fc0978d4d004e1ed,"The worst case complexity of searching for a value v in a vector is O(n),which is a linear amount of time. This happens when the value v is in the middle of a vector or at the very last end.

If we create an empty BST and call the insert function progressively, in the worst  case the height will be n-1.However in big O notation,  the height will take  O(n) time complexity of time. In the  best case the height will take  O(logn) amount of time because the height of a tree will be  log2(n+1)−1 .

The worst case height after each insertion would be O(n) work,that is because at the time we would be dealing with a very large tree .In the best case the time complexity would be O( logn ),that is when we are dealing with a small tree. 

If we have a best case height insertion,the the time complexity would be O(logn) because the tree would be a small tree.

In total we would do a logarithmica amount of work",19.0,80
23652,23652,27900,bd13f3a1f05cded43b306e7cf672db1fa9cf812229ead4318a993e62aa7ff42541e39b6868fb05069f972d798f5a5b109e0e615acf69b7c88b8e2bf435bfc374,"The worst-case complexity for searching v in a vector is O(n). This happens when v is at the end of the vector.

The best case height of a BST is O(logn). It occurs when

And the worst-case height of a BST is O(n). It occurs when each node has one child and the tree is a vector.

The work would be O(n) since each node will have at most one child and is like a vector now.

The time complexity will be O(logn) since the tree has subtrees.

it would take a linear amount of work",17.0,80
23653,23653,27901,d5a3f7d660aa30769e68a7c616a4942c8f05f0c2e034be1b4e61932df724917fd2a406f53a34e25ab412791ed6463a16ef1b087d401683c22430b89ba7a21be9,"1. worst case complexity is O(n) and this occurs when the value you are searching for is the last element in the vector and so you will have to go through all the elements in the vector before you can get to the element you are searching for

2. Worst case is O(n) and this occurs when the algorithm needs to traverse the tree a long the longest path (from root to a leaf) before inserting

the best case is O(log n) when we have to insert from the root.

3. We would do O(n) as the amount of work done is proportional to the height of the tree.

4. we would do O(log n) as the amount of work done is proportional to the height of the tree.

5. in worst case it will be O(n)

in best case it will be O(log n)",13.0,80
23654,23654,27902,888a700ecff48b8e58609f74298e3e913836c7525e3508cee74dcd45d73e3b5cb35996869dd34b3342eba886899eba46a61c603fc724f15dfcf45804ca8c7ece,"The worst time complexity for searching such a vector is linear time, O(n). This is because the item might be at the end of the vector and the algorithm only terminates one it has found it. Thus, it would iterate through the entire array and the number of elements of such an array is n. 

For inserting element 0, it must be inserted as left child of 1. Therefore, we need to traverse all elements to insert 0 which has worst case complexity of O(n). In general, time complexity is O(n). So then, suppose: the existing binary search tree has one node in each level, and it is either a left-skewed or right-skewed tree – meaning that all the nodes have children on one side or no children at all. We want to insert a node whose value is greater than the highest level node’s value in the case of a right-skewed binary search tree or is less than the highest level node’s value in the case of a left-skewed binary search tree. When we insert a new node, we first check the value of the root node. If the value of the new node is greater than the root node, we search the right subtree for the possible insertion position. Otherwise, we explore the left subtree for the insertion. we have to travel from the root to the deepest leaf node in order to find an index to insert the new node. If there are N nodes in the binary search tree, we need N comparisons to insert our new node. Therefore, in such cases, the overall time complexity of the insertion process would be O(n). As for the best case. The best-case occurs when all nodes are in the root’s right subtree, the one to be inserted belongs in the left or all nodes are in the root’s left subtree, the one to be inserted belongs in the right. Hence we just need to perform one comparison in order to insert the new node. Therefore in the best case, the time complexity of insertion operation in a binary search tree would be O(1) - constant time. If there are n nodes in a binary search tree, maximum height of the binary search tree is n-1 and minimum height is ceil(log2n). If binary search tree has height h, minimum number of nodes is h+1 (in case of left skewed and right skewed binary search tree). If binary search tree has height h, maximum number of nodes will be when all levels are completely full. Total number of nodes will be 2^0 + 2^1 + …. 2^h = 2^(h+1)-1",13.0,80
23655,23655,27903,c1e9e5684a44aa14de0a7d7593ec9809b4c2858f861776d6d9a8b2df4bba9cc394db455eb7a58c49a19ed6c08dee2a5b9eba1e9f390b469640fea31d4ffda4c0,"In a vector, the worst case for searching is the case in which the search value v is not in the vector. It is in this case that we'd have to search through the entire vector of size n, implying a linear complexity - O(n).

A characteristic feature of a BST is the linear ordering: all values in the left subtree are less than the parent node and all values in the right subtree are greater than the parent node. When inserting into the BST we thus need to be mindful of these constraints. If the value being added is the less than the parent node, we add on the left and if its greater than we add on the right. The best case for height occurs when we have a perfect binary search tree, in which we have logarithmic height ,             h = log(n+1) - 1. This thus takes O(logn). The worst case occurs when we a degenerate BST, in which the height is the longest path, through n nodes, and thus O(n) complexity.

In the worst case we'd do O(n^2) as we go through each node n times when inserting; when adding a new node we'd have to start from the top.  ",26.0,80
23656,23656,27904,e3fe34fe397fdba954ee04d79db645b0148c5938ca6f2f7a2907aa58749a445701d138ec6de61364a9d6a738e1bd62c299a45c7a655f0f5a3aa7fe48b798bb3b,"O(n), the worst case is if the value we are searching for is the last value in the vector, therefore we would have to go through all the elements. 

Worst-case: O(n) - when you have to traverse through the entire height of the tree to insert a value

Best-case: O(logn) - when there is a node with wither 0 or 1 child, the real best case is when there is a hole at the root node and we can insert directly

  : in the worst case the amount of work done is proportional to the height of the tree

  ",12.0,80
23657,23657,27905,3d3c1be79bbed7b365d3aace59dfe14a7a1385e7072a675c0aa539c52e6b6368cbd7b12fc937010386846b4d8cccf764dc628c232956154c4f1395918f004d16,"* (1)O(1)
	* (2.1)Best case: is when we have a hole and we are able to insert a value in it [O(1)]. Depending on the structure of the BST (binary search tree), we could have O(log n) instead.
	* (2.2)Worst case: O(n). A traversal through the entire height of the tree was needed (the longest path from root to leaf), so the work done is proportional to the height of the tree. In terms of the number of nodes, we would get n-1, because the worst case would correspond with the number of edges in a BST (generally n-1). In big-O notation this is written as O(n).
	* The worst case of height would be n-1 [O(n)] due to the relationship held in log2(n+1)-1 ≤ h ≤ n-1. A traversal through this height n times would lead us to O(n^2). This would be similar to traversal in a for loop.
	* The best case of height would be log2(n+1)-1 [O(log n)] due to the relationship held in log2(n+1)-1 ≤ h ≤ n-1. A traversal through this height n times would be O(nlogn) as it would mimic a for loop.
	* Best: O(1); Worst: O(n)",29.0,80
23658,23658,27906,7db17fd2acfdd980933bf2f92abec54feac68e8b60f672ae1ba7781b8dd15de47315f37d74c147384e68a3a01e88e6539391471e6490908578bb1e2cdf85e7c7,"Th worst case complexity of searching a value is O(logn), this occurs when we have a degenerate tree. The best case of searching a value is O(n) but this is not the case if the value we searching for is the root node as it will take O(n) to find the root.

Best case of insertion is O(n) while the worst case is O(logn).The worst case occurs when we have a degenerate tree .The worst case is when we have to travel along the longest path from the root to the leaf before inserting .

when we have the worst case height after each insertion we will have O(n) amount of work to insert our values. This is because the tree is degenerate and we need to travel the longest path from root to leaf before inserting our values.

The best case insertion takes O(n) amount of work. This occurs when we have a perfect tree as the algorithm will exponentially insert each value accordingly

total work to construct a tree takes O(logn) in the best case and takes O(n) n the worst case.  ",7.0,80
23659,23659,27907,3dc26b747d97da3ab4afec05ff58fc24d9456624d1de4e773000cee11c5770c4305e55aba8a358eac1e51ad690a762f5e637a6ce6a5554139fe18ecd7662a5af,"* O(N) complexity, it occurs when v is not in the vector or v is the last element. if we search _N_ times we do linear work.
	* The best case height is O(LOG(N)),when the BST is full or complete.   The worst case height is O(N) when each node has one child.
	* O(N) ,because when you insert you traverse through all nodes to the  last node and then insert.
	* O(LOG(N)),because you don't have to traverse through all nodes to insert.
	* logarithmic work",27.0,80
23660,23660,27908,a8dcc87a24b584021a1bb3ffd592a4ea66a1679acf3b2b41f26aef4e481760f4e64990e460e4e26ec12a8fef5d2354f5070843ac6e40f4a1e24bc122bfa91df9,"The worst case for searching for a value in vector is O(n) and this occurs when v is at last index of the vector.

The best case for height when inserting on a BST is O(nlog)

The worst case for height when inserting on a BST is O(n), because each node will be treversed",11.0,80
23661,23661,27909,ab943cfa0d926aa21911a9961743ce4779859ba20a4ac4e15e75033134ef20f2d090435e99a19a4b2beb23e354a8983d0355213a926be357504dc13138c83605,"In the worst-case complexity, it would be O(n) since in the case the data would be stretched out hence we would have to transverse through each element at least once if we search n times then the time complexity is the sum of all the searches which is still linear O(n).

The worst-case would have O(n) and the best-case height would have O(logn), for the worst-case this is because the tree would be stretched thus inserting to the last node would require every node to be visited at least once. For the best case since insertion takes the big-o of height if the height is logarithmic we would have O(logn) since the tree would be ordered hence some nodes won't be even visited once.

We would do O(n) for insertion since inserting to the leaf would require us to transverse n-1 times resulting in linear complexity.

We would do O(logn) since we have the best height every time then we won't need to transverse to most if not all nodes whenever we insert into the tree and we won't be transversing to the same location every time meaning it won't be O(1).",14.0,80
23662,23662,27910,4a108b6388ab518862a0eddc19b8d86fd9549abfafdc544be7cbe5e9a91a20102b9726ddaa529a19a86fc38fa4700a0fdd752705615738f3f81b854fa84c557b,worst case for v is O(n),2.0,80
23663,23663,27911,912a17c5532a85cc610facff6c98d42b64fb259b767c809567c65cce318eb3dc8f21bcbe5e653de87fe40d2502ab66869bc553e63fc3a1d7697be613c3b49a69,"The worst case occurs when we would need to traverse along the longest pat from the root to the leaf node. This process is proportional to the height of the tree and would take O(n) time.

If we progressively add nodes to an empty binary search tree using the insert function, the amount of work done depends on the structure of the tree. In the best case, the height of the tree will be log2(n+1)−1 and in the worst case, the height of the tree will be n−1. In Big-O notation. The best case occurs when all the nodes have either zero or 2 children. The worst case occurs when all the nodes have exactly one child, this type of tree is called degenerate.

Assuming that we have the worst case height after each insertion, we would need to do O(n) work, since we would need to traverse through each node from the root and each traversal increments by one.

Assuming that we have the best case height after each insertion, the tree structure would be balanced and so the height be O(logn) and so we would have to do O(logn) work

In the 2 different cases, we traverse h times, so the amount of work done is proportional to the height of the tree. This means that we either do O(logn) (this is in the best case, if we have a perfect tree) or O(n) depending on the structure of the tree, in the worst case. In the best case, the search key (x) is the value stored in the root and we do O(1) amount of work",30.0,80
23664,23664,27912,ddf05f993d32eb46f0b5d18783c3f0bae7ba45bfb71b7a11c47b2697ab035bd02b089a647111ba9b72f32e9d1912bdd9dfcb6298cbd5226f8387827448c2cdef,"O(n)

h=log(n+1)-1 and h=n-1

no

Yes

O(n)",4.0,80
23665,23665,27913,0acf933aafd8ccfefdb0a07c9cd769ff21b003c332b8b90f6edffc1573664ade1e2d7b54669b2cee7b03b35091d029450c66d87d0c0afdf5016d3799c57a4fc9,"O(1) - constant time

worst case = O(n),  best case = O(1)

 - O(n)

O(1)",7.0,80
23666,23666,27914,78249ef9b62941992169ea6ab9335b72fe3732b0d62324e87cfd98782c3176ff3a0f6d77d1563959cb064ffef03d777dd5132e65d5820daed930a9e3247d9f38,"The worst case complexity for searching for a number in a vector is when the vector is not sorted and we will do linear amount of work to search the whole vector O(n). For a add function in a binary tree the amount of work we need to do will depend on the structure of the tree,In the best case the height of the tree will be log(n+1)-1 and in the worst case the height of the tree will be n-1.in the worst case we will do linear amount of work O(n).In the best case we take logarithmic time complexity O(logn).the amount of work we do to construct the binary tree will depend on the structure of the tree .",13.0,80
23667,23667,27915,9ab5ee6dcd1eeee42b584dd13d10dfb771aeae24b070596bf8e33f41840796cff5a58f61a4f76bd5d61ec8edd7ee76fc7e403b38a2b713cfce865554906c5149,"WHAT IS THE WORST-CASE COMPLEXITY OF SEARCHING FOR A VALUE V IN THE VECTOR (IN BIG-O NOTATION) AND WHEN DOES THIS OCCUR? HOW MUCH WORK DO WE DO IF WE SEARCH N TIMES?

SOLUTION:

For the worst-case time complexity of linear search will be linear O(n). And this occurs when the element to be searched is not present in the array or vector. It does take a lot of work to search n times since it is linear.

IF WE CREATE AN EMPTY BST AND PROGRESSIVELY ADD EACH NUMBER TO THE TREE BY CALLING THE INSERT FUNCTION, WHAT IS THE BEST AND WORST-CASE HEIGHT OF THE TREE (IN BIG-O) AND EXPLAIN WHEN THESE CASES OCCUR

SOLUTION:

The best case would be the logarithmic time complexity O(log n) and the worst case would be the linear O(n) time complexity. One of the cases happen when the case is either left skewed or right-skewed.

ASSUMING THAT WE HAVE THE WORST CASE HEIGHT AFTER EACH INSERTION, HOW MUCH WORK (IN BIG-O) WOULD WE DO WHEN INSERTING ALL N NUMBERS? EXPLAIN HOW YOU CAME TO THIS CONCLUSION.

SOLUTION:

We would do n-1 work and this would ensure that we have a balanced binary search tree.

ASSUMING THAT WE HAVE THE BEST CASE HEIGHT AFTER EACH INSERTION, HOW MUCH WORK (IN BIG-O) WOULD WE DO WHEN INSERTING ALL N NUMBERS? EXPLAIN HOW YOU CAME TO THIS CONCLUSION.

SOLUTION:

We would just use log(n) and this is because the logarithmic time complexity when it comes to insertion of height in trees brings the best cases.

IN THESE TWO DIFFERENT CASES, HOW MUCH WORK WOULD WE DO IN TOTAL TO CONSTRUCT THE TREE AND SEARCH FOR DIFFERENT NUMBERS N TIMES? 

SOLUTION

O(n)",19.0,80
23668,23668,27916,a483d97f2f6f4b566a91dffee7b0dc51b69866d7a50c6e53308e166eaac8f5373cd9dfbf9a10c25bd5d41a415c716306b0d1e020a1acf8282aad769edfdcc9c4,"The waste-case complexity for the searching is O(n) and  this occurs when the data is stretched and not compact hence we would need to visit each node atleast once.

The best case is O(logn) which is when we have a logarithmic height hence we wont need to visit all elements and worst case is O(n) when data is stretched out thus we have to visit each node atleast once before inserting.

Since inserting to the last or leaf node will require us to traverse n-1 times the complexity is O(n).

In this case we would do O(logn) in complexity since data would be ordered and we wouldnt have to visit all the nodes.",8.0,80
23669,23669,27917,fd3ac26e8f1d74669c591d17cfba292d301a38f59035e0e015254638e09238378ffbb05277661aa625df195230a27bb79b8964e830815de826a62bf695fefa00,"* The worst-time complexity is O(n). This occurs when the element we are searching for is the last element in a vector or it is not in the vector. The time would still be O(n) if we search n-times.

	* Best case height is log2(n+1)-1
	* worst case n-1. (this is when the number is not in tree and the path we follow corresponds to the longest path from the root to the leaf).

	* For worst case height after each insertion. It would be O(logn) or O(n) depending on the structure of the tree.

	* For best case height. It would be O(1)

	* O(logn) work",17.0,80
23670,23670,27918,eec934572d7644ba0121c8b2feb2c582e9f3f4f5b58187b8858bc2ee24ad1c13bedfb2cdb5029267bc11b865502439fbacde60c9046792350b575350ddc17ef6,"1. Worst-case complexity of searching for a value v in the vector: O(n)

This occurs when v is at the end of the list or is not in the list.

We do n^2 amount of work if we search n times.

2. Best-case height of tree: 0(logn). This occurs when the tree is a complete binary tree. We do not have to traverse the tree a very long way as in with a degenerate tree.

Worst-case height of tree: 0(n). This occurs when the tree is degenerate (has a height of n-1 and is similar to a linear data structure (linked list or vector). Because of a degenerate tree, we have to traverse the tree along a longer path.

3. O(n). Every time we traverse the tree, we have to traverse a long path from the root to the leaf before we insert a value. The height of the tree is directly proportional to the amount of work done. Thus as the height is worst-case, the work will also be worst-case.

4. 0(logn). The height of the tree is directly proportional to the amount of work done. Thus as the height is best-case, the work will also be best-case.

5. (n-1)^2 (O(n^2) for worst-case as it is n (for worst-case insertion) times n (for worst-case searching).  log(n+1)-1 (O(log(n))  in best case as it is log(n+1)+1 (for best-case insertion) times 1 (O(1)) (for best-case searching).",26.0,80
23671,23671,27919,09a1699e91053a97e967035388a9bb6bf2333dc132838738d78edc417a8028213044038d23bdf9e5be7458e9014620b5d4a10df02214eb4aa340c740ce44d5c1,"-When searching through a vector for a number, worst case is when a value is not found, and the entire vector is traversed through, leading to a worst-case complexity of O(n)

-The best case would be a height of O(log2(n+1)−1) for a perfect tree and the worst-case would be a height of O(n-1) for a tree with each node only having either one left or right child, creating a tree which is similar in structure to a singly linked list, and has the number of edges less than the number of consecutive nodes, which is n-1, corresponding to the height in this case.

-Worse-case complexity in insertion for a tree of height n-1, would be O(n). This is because there would be n nodes that would be traversed through before adding to the end of the tree. In the worst case every single node is visited, n nodes, leading to n traversals and a linear amount of work.

-Worst-case complexity in insertion for a tree of logarithmic height is O",17.0,80
23672,23672,27920,6411a31397edca98a86156eda9fe940cd25214f5793edb40ff98bea1168dd2f02767f84a7d8f08cc5cbcf1da236fabf58172c048483fca623b7f16592128e03a,"The worst case for searching for an element in  a vector is O(n), this occurs when the element we are searching for is not available in the vector.

The best case insertion in BST happens when we are inserting a root node and it has a time complexity of O(1). The worst case occurs when our algorithm needs to traverse the tree along the longest path, from the root to a leaf before inserting and the complexity for this will be O(n).

The amount of work done will have to be proportional to the height of the tree which is O(h)=O(n).

The amount of work will be O(n)

The amount of work will be O(log(n))",11.0,80
23673,23673,27921,798235659bb9174e71b3ff61763ec292691ece6655d9ff85d1fbb65ede38be3c46ca62a6d523bf01e0f519090370eeadd560efded9ef16231507d4492e919473,"Worst case for a search in a vector is O(n), it occurs when v is last position in vector.

Best case for insertion in BST is O(nlogn)

Worst case for insertion in BST is O(n)",13.0,80
23674,23674,27922,bf9f7563cc9f901b96502125e7d25475a0aeee128b8258ce038a51e3af3c4093e4ee3d48f8e688baf55d2e74c7a660d473b521169612f2e6991be2accf5a47f1,The worst case is when the vector won't be sorted. It will do linear amount of work the amount of work will depend in the structure of the tree if we are adding,0.0,80
23675,23675,27923,7ed1c803cb6942b25a462119e14146d3dfdc8b2d8405742d6e37974d2693c34f2838afb58a1bcf41b9fcd8829c1dff4d4b192c929c721bc46e1615dcea231b30,"1. O(n)

2. For the Best Case, it would be O(log n) this makes sure that the tree is balanced. Then, the Worst Case, O(n),one would have to do linear work in height therefore the amount of work is proportional to the height of tree.

3. Worst case - O(n), the tree needs to traverse through all the numbers, n before inserting.

4. The amount of work required to do depends on the structure of the tree. The shape of the functions determine the best case thus, O(log n).",13.0,80
23676,23676,27924,d262858bac7cd6476e0cd48b8622c751312997fe7fae4adba9c98bf17ceadac187d9de2b401de3d1895e85edc24940f00a102bf214f436104f37cd1b8669240b,"The worst case complexity is O(n) in a vector, this occurs when we find a value that is not in the vector. The best case height is O(logn). The worst case height is O(n). The best case height occurs when the binary tree is a Perfect Binary tree. The worst case height is when the binary tree is a Degenerate Binary Tree. The worst case work we would do is O(n). Because the worst case tree is a degenerate tree where each node only has one child, this makes us do a linear traversal to insert a value. The best case work is O(logn) because in a perfect binary tree, there are maximum number of nodes on each level with 2 to the power of k where k is the level. This leads to when finding the height we need to find the log which leads to logarithmic traversal when inserting. The amount of work we do in total is n times which is linear, therefore O(n).  ",26.0,80
23677,23677,27925,bef6837a7fdfe1da5fe1293f44c76b96d3b8dcc796faa186ced378d3238a30c359695c10ba31e008e6450186def6f4c6da86e1819e6310ac4629db0e4ae2f7c4,"The worst-case complexity of searching for a value v will be O(n) because we would have to traverse the entire vector if v was not in the vector or in the last position. We would be doing a linear amount of work. 

In the best case height, which would be log2 (n+1) - 1 the Big-O would be O(log n). In the worst case, the Big-O would be O(n) which is a linear amount of work and that would be because of the worst-case height being n - 1. 

We would do logarithmic amount of work in the best case and linear amount of work in the worst case. ",12.0,80
23678,23678,27926,61263672c5c532106e7f21122dcaab559eafcffe3f9da40ef6a4194409e8f1be9b62145c70c7a6a62ca846b85c63f3fbde4504110d16d1088e8621a2430bcdec,"1.  Worst case complexity of searching would be O(n) , this occurs in a normal tree. If we search n times then we do linear amount of work.

2. Best case height is O(logn), occurs when we get logarithmic time of insertion and height of tree is log(n+1)-1

 Worse case height is O(n) , occurs when we do linear amount of work to insert the numbers to the binary tree of height of n-1

3. We would have linear amount of work when inserting all the numbers because the amount of work done is proportional to the height of the tree.

4.  Because of the structure of the tree, we may have logarithmic amount of work  when inserting. 

 

5. The amount of work we do in total , in the best case would be O(logn), and in the worst case would be O(n).",19.0,80
23679,23679,27927,a0053c94d18ea0e087a62013f5ac80c5b6b5b2b0c4aa9dd88e21096fafa1947351de1bc64c5f102a231a8bd4d8d7cf40acc72747f50d8fe1ae800f7aa85e0eed,"O(n) would be the worst-case complexity as the program would have to linearly go through every item on the list and not find the item it is searching for, the work done would be n*n.

The worst case for insertion would happen if we need to traverse along the longest path of the tree before we can insert the item, the notation would be O(logn). The best case would happen when we have to perform the least number of traversels and the notation would be O(n).

We would have to traverse through the whole tree to the last item on the list and then insert the item, the notation would O(n)

The best case would happen when we can perform the least number of traversals inorder ro insert the item.

The total amount of work done would be n-1",4.0,80
23680,23680,27928,5c96945f14d6fc788ed8c6c36dabf314debb1526e588422f61ac844f148e394c747509da6ebf3fac148319b89d19dab295d5360db7c4991b8db71ccf538d7808,"1. The worst-case is either O(n) when searching for a value v in the vector and this occurs when the value is not in the vector which requires you to traverse through the whole vector to look for that value.

2.  When calling the insert function, the best case is h = log2(n+1)-1 and the worst case is h = n-1. The best case is when the insertion is the root and when the node it will be going to already has a space free to the left/right of it. The worst case occurs when we have to traverse through the longest path in the tree before we can perform insertion.

3. We will do O(n) work in this case because it would mean that the tree is degenerate because in every case of insertion the amount of work done will be proportional to the height of the tree.

4. We will do O(logn) amount of work because it would mean that the tree is perfect.

5. O(logn) ",6.0,80
23681,23681,27929,f2a1d44943cafd29447c9cc6d850c73ca115efbe45cc60a50c497d9c39593f6c44e4c2d4facba5ee2393c40106c70b0307d8a427a20ee6b2ecb0031a02f6d25c,"The worst case for searching for a value v in a vector is if the vector is unsorted. in this case we'd have to traverse through the whole vector until the value is found, and the worst case arises when the element is at the last position or not in the vector. The worst time complexity would linear O(n).

The worst case height would be adding a value greater than the current height of the tree; in that case we'd have to traverse the whole height of the tree and then add the value which would have the complexity of O(n) and depending on the structure, the best case would have logarithmic complexity O(logn) unless there's a hole in the root of the tree.

In this case the tree is degenerate and basically becomes a linked list and does a linear amount of work.

We would do a logarithmic amount of work depending on the structure of the tree.

O(logn) and O(n)",11.0,80
23682,23682,27930,2dd5e2f41652664c7010e9c75b107a0a619a9b54063e68bd2c6a9b76a1fcac07a9bceac7ca7bf3cdecc54ef1490301f90259c5d418e4b888c5d3f0477b59ef3c,"The worst case complexity is O(n) and occurs when v is not in the vector. We would do O(n^2) work.

The best case height is log_2(n+1) -1 and in the worst case height is n-1. Worst case occurs when we need to go all the way along the longest path to a root. Best case occurs when we can immediately insert.

We would do O(nlog_n) work. Height is proportional to O(log_n) and we insert n times. ",19.0,80
23683,23683,27931,e128973184d15ac7a750b822c9d3b3fe1c0b4d5c9ec9968806c119de2807128c5380243007b2944cf3a301c3270578e76aaa068c636326951a9eea7851758fdf,"the worst case will be n-1

we can search for n only once ",1.0,80
23684,23684,27932,639a68158c22ced38b469e5ff5439c6df90887f4ac511792920966a4b66fbbb0736453130f1e07f675685ab76215a4ca74f33ab5a9bf6fded51b150fcaa550e3,"* The worst- case is O(n) where n is the number of elements in the vector. This occurs the elements are unknown and there's no knowledge of sorting and thus the search will occur over the entire vector to find v. 
	* The best case height is is h=n/2 which would therefore be h=4/2=2 and this will happen when the root is given 2 nodes and 1 node is then added to either. The worst case will be h=n-1 which would be h=4-1=3 and this would happen when 1 node is added at each level instead of adding 2 nodes at the root.
	* O(n) work will be done as each node will have to be visited in constant time.
	* O(log(n)) work will be done as the numbers will be added via backtracking according to which number is larger than/equal to or smaller than the root node and thus backtracking will insure that less work is being done especially when popping back.
	* O(n) work will be done when searching in the worst case and O(log(n)) work will be done when searching the best case.",5.0,80
23685,23685,27933,01414e21ecb9a1334890023f94a0d282ee23097fe9f9524ae17a5a130cb936a59877f182817dee70cef409eabab63c6b47a25ed1ae4ef0dfef7f2566f253e2b1,"Given a random ordered set of numbers in a vector, the worst case scenario would be having to go to every element in a vector if the number being searched for is in the last index or if it is not in the vector at all. The worst case time complexity would be O(n).

Using a BST to sort and store the numbers in the vector, the best case height of the tree would be O(log (n)) if the tree ends up being more balanced ( almost equal number of nodes on each side)  whereas the worst case height would be O(n) if the tree ends up being ""messy"" or unbalanced 

Having the worst case height, we would have to traverse through almost every node in the tree. This would result in us doing a O(n) amount of work as we check and compare almost every node before we insert. 

Having the best case height, we may find that we only do half the work for each level of the tree as we do not have to visit as many nodes to insert our next number so we may only end up doing O(log(n)) amount of work too 

In total:

for the worst case - we need to do O(n) amounts of work

for the best case - We need to do O(log(n)) amounts of work ",26.0,80
23686,23686,27934,1524a034e009646803d7074c495cb1bd3919f40bf0c99261b282adc7801990411f97759342d2d5b53fea8bfcd2292ae00d0444e55290b251e7ed8a081caf06dd,"* The worst time complexity for searching for a value in a vector is O(n). This occurs when searching through an entire vector of n elements. When searching a vector of size n, n times we would do O(n^2) work.
	* The best-case height for the Binary search tree is log2(n+1)−1 and the worst-case height of the Binary search tree is n-1. The worst-case height occurs when the algorithm has to traverse the longest path from the root to the leaf before the algorithm can insert. The best-case height occurs when the algorithm has to only traverse a short portion of the tree from the root to the closest leaf.
	* We would do O((n^2)) in the worst-case scenario as it takes O(n) time to traverse from the root to the leaf in the worst-case scenario and we have to insert all n numbers.
	* We would do O(n(logn)) in the best-case scenario as it takes O(logn) time to traverse from the root to the leaf in the best-case scenario and we have to insert all n numbers.
	* It would take the best-case scenario O(n(log2(n+1)-1+logn)) work. It would take the worst-case scenario O(n(n-1+n)) work.",35.0,80
23687,23687,27935,6c0c4055e14104657e8b2f93690d540761c32c74b87c67cb6acc284b0968521966239252478c024e2c1fdc28ec4e72c01b4f28c3de78e04b7bbf604f3bad167d,"1.)

O(n), the value is at the end of the vector

2.)

Best, is when every parent has 2 kids. So the height will be O(logn)

Worst, every node stacks one on another. n-1

3.)

4.)

5.)",11.0,80
23688,23688,27936,a959a4bd23a818684dfb2a6c94ac89925575f3b11f0de3ed6d4df640b02681f2171e62de10059d8c04c758f13335e59b8e75b311b1045da8f168f89c32919f7f,"1. O(n)

2. Best: log(n+1)-1, in a perfect/complete BST || Worst: n-1, when the BST is shifted/skewed to either side.

3. O(n), because you would need to find each node first, and then insert the number. This is one more than the number of edges.

4. log(n+1), you would need to traverse to each node and insert the number, this is one greater than the amount of edges.

5. nlog(n)",15.0,80
23689,23689,27937,89502ac0aa9bcc7e1f53c6f2ab1184a643f5c96abf038408f562f5cb7340154d0c96d136d3c4ce774773aa13f3d95a0a98c70e80020a05dce05a8835fe30adf5,"Vector complexity O(n)

we have to traverse all elements. Therefore, insertion in binary tree has worst case complexity of O(n) &

O(logn)

do",5.0,80
23690,23690,27938,8127d4098ce90e5354b83277c230528a4f346dff2268e6e565e170f557f4828895b86ce9e4d45680788cfb7696e91c4b7e7c80cf0ef0611dfea212b6f772071c,"worst case occurs when we search through the longest path which is equivalence to the height of the tree and it is O(n) or O(logn)

when we insert using insert function the best case is O(logn) which occurs when there are no swaps and taking short path and the worst case is O(n-1) it occurs when we traverse on the longest path of the tree

the worst case will be O(n-1) because we would've taken the longest path to insert all the values

the best case will be O(logn) because we would've traversed on the shortest path to add all values

O(logn)",17.0,80
23691,23691,27939,f11178d26d71b36980a2e031712b410b8887af4a2b6c48901c6a568377c95cf608d8bdb211ef99a8ec80760d046f982bcd08b27ff9c8f8cd3f71083f65b80c48,"The worst case will be O(n) since we have to traverse through the whole vector. I occurs when the value is the last position or when it not in the vector.

The worst case is O(n) and the best case is O(1). The worst case occurs when the binary search tree is growing in one direction and working just like a linked list since every node will have only when child(with the exception of the leaf),we then have to traverse though the all the elements for insertion. The best case occurs when all nodes are in the root's right subtree and the one to be inserted belong to the left.

O(n),because since we have to traverse through all the values for insertion.

O(logn) since the tree will be height balanced.

O(n)",17.0,80
23692,23692,27940,acc027b1281fb7611892bbd9cd22b170d39dac509f3cbd3c4ae2298ef8fcce3e213c9bdb095b30f4b14371abefeb025cbed1bfbb0b3e1f2baccc7d74d415003e,"SEARCHING FOR v:

worst-case complexity: O(n)

Height of tree:

best case:n/2

worst case:n-1

WORK DONE AT WORST CASE HEIGHT AFTER EACH INSERTION:

O(n)

WORK DONE AT BEST CASE HEIGHT AFTER EACH INSERTION:

O(n)

We would do O(n) amount of work in each of these cases",13.0,80
23693,23693,27941,c2e3a17d6cc0156e335ca9215e55053ddbc80682871f8957ca1d1b73d39dbe24e0950e6728cd273bbd1fbaac4e9fc1f8fc1eeb009c8b2565447f198e841deab0,"Worst case is if we have to travel to the last leaf with the longest height.

The worst case when we call insertion is we need to insert at the node with the longest path. 

The best case when we call insertion would be if we are inserting at the root. 

It would be logarithmic because we would be inserting at the nearest node to the root. 

We would do n-1. ",0.0,80
23694,23694,27942,6accb08d7786944c71cd9b921787862856d4a3c42592fbffde311b7d0b92a8f983d0c4f430c2af6d29dc0b77bc121c3af33f1ea64f2b5de47c11c3122369896f,"The worse case complexity of searching for a value in a vector would be _O(N) _and this occurs when the value v is the last item in the vector. The amount of work we would have to do when searching n times is _O(N^2)_ as we would have to traverse the entire vector.

The best case height of the tree would be _O(LOGN)_ and this occurs when we start at the root and insert our value at each node in the tree. The worst-case height of the tree would thus be O(N) and this occurs when we traverse the tree along the longest path from the root to the leaf before inserting our values.

In the worst-case height scenario, we would have to do _O(N)_ work to insert all n numbers into a binary search tree. This is due to the fact that we have to traverse all the elements in the worst case as we would have to compare all n nodes to insert each value.

The amount of work done in the best case to insert all n numbers would thus be _O(1)_. This occurs because only one node comparison is made when inserting the new value/node. 

For the worst-case height, the amount of work done in total would be _O(n^2)_, and in the best case, the total amount of work would be _O(logn) _when constructing and searching the tree for different numbers _N_ times.",22.0,80
23695,23695,27943,a6a1956dca8537b87c581329dd539be0e1754c767a458496056c957b37b7d5cf8e38e7b6a815b9c917caee9a53108cd46c4caa581c67b0f0565e27d0605c7826,"The worst-case complexity would be O(n). This worst case arrises when the element which we are searching for is either not in the vector at all or in the last position, which leads to us having to search the entire vector to locate the element. 

The best case height is n-1, which occurs when all levels are completely full and the binary tree is left skewed

The worse case is log2n, and occurs when the binary tree is right skewed

The amount of work we would do when inserting all n numbers is O(n) in the worst case height. The tree is linear 

The amount of work we would do when inserting all n numbers is O(logn) in the best case height. The tree is a complete binary tree ",25.0,80
23696,23696,27944,571f4b857c687d9d563078992ce0d593248d2c9f52df5afb071f8e300cfd009d7831df6cd94d1fdf3131324af503b103a8881171137c2ca59df7ead36faf3f74,"The worst case is O(n) and it occurs when the value you are looking for is not in the the search tree. if you search for n items in the worst case it would be O(n^2)

If we were to insert into an empty BST. The best case is h = logn and this happens when you have a random order of values you need to add to the BST. The worst case is h = n and this happens when the values are added in accending or descending order

it would be O(n!). If you have an empty list and you add a node this happens in O(1) then if you add another node it would take 1 traversal and then you add the new node. Then if you add another node it needs to make 2 traversals. If you take the amount of times you would need to do this for n insertions you get: 1x2x3x...xn = n!

It would O(logn). The best case involes a binary search tree where the h = logn. That means in order to do a new insertion it would have to traverse logn amount of nodes to insert a new node therefore making it O(logn)",17.0,80
23697,23697,27945,bf4b5731c3c3bd0f2b59e631e277805959da8b9efedbe010df49f525b49b713ed8678bb3e54ddfd542bb302e79e236dfb9ec30ec253f0f80d3cd72c6a5094fbc,"* The worst-case complexity of searching for a value v in the vector is O(n) and this happens when the value is not in the vector and so we end up making n comparisons.
	* Best Case Height if the tree is O(log(n)) when the tree is complete and the first value input is neither the smallest or the biggest number among the numbers being input, and the Worst Case Height is O(n) which occurs when the tree becomes degenerate 
	*  O(n).  Because in the worst case, the amount of work done is proportional to the height of the tree since our algorithm needs to traverse the tree along the longest path from the root to a leaf before inserting.

	* O(log(n)). Because if since we have the best case height we can assume that the structure of the tree is close to proper, complete, etc. and is not degenerate.
	* If the search number is stored in the root the work would be O(1) and O(n) or O(log(n)) otherwise.",13.0,80
